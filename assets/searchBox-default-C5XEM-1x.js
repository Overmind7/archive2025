const t='{"documentCount":1009,"nextId":1009,"documentIds":{"0":"/article/spho5myq/","1":"/article/xohq6a7n/","2":"/note/","3":"/article/xohq6a7n/#生成模型的几种评价指标","4":"/article/y2c5r5w7/","5":"/article/xohq6a7n/#psnr","6":"/article/7m8pc013/","7":"/article/j1i3k2nb/","8":"/article/xohq6a7n/#ssim","9":"/article/7m8pc013/#标题h2","10":"/article/mwjqbj4j/","11":"/article/j1i3k2nb/#开启-docker","12":"/article/iza96syq/","13":"/article/xohq6a7n/#inception-score","14":"/article/7m8pc013/#标题h3","15":"/article/mwjqbj4j/#ros-中部署orbslam2","16":"/article/dn3kvzl7/","17":"/article/j1i3k2nb/#一些错误","18":"/article/4jk28jru/","19":"/article/iza96syq/#安装-ros","20":"/article/xohq6a7n/#frechet-inception-distance","21":"/article/7m8pc013/#标题h4","22":"/article/mwjqbj4j/#orbslam2-编译","23":"/article/dn3kvzl7/#dfm","24":"/article/prdbghba/","25":"/article/j1i3k2nb/#准备数据集","26":"/article/4jk28jru/#设置-swap","27":"/article/iza96syq/#安装-ros-clio","28":"/article/7m8pc013/#标题h5","29":"/article/mwjqbj4j/#安装依赖","30":"/article/dn3kvzl7/#重点关注","31":"/article/phyy3f9t/","32":"/article/j1i3k2nb/#准备-3rscan","33":"/article/4jk28jru/#删除-swap","34":"/article/iza96syq/#运行-clio-ros","35":"/article/7m8pc013/#标题h6","36":"/article/mwjqbj4j/#编译-opencv-3-4-5","37":"/article/842dffc6/","38":"/article/j1i3k2nb/#准备-3rscan-mv-和-3rscan-mv-fast","39":"/article/7m8pc013/#标题2-badge","40":"/article/mwjqbj4j/#编译-pangolin","41":"/article/842dffc6/#bad-interpreter","42":"/article/yfgydiz3/","43":"/article/j1i3k2nb/#evaluate-esam-on-3rscan-mv-class-agnostic","44":"/article/lhkmyeqo/","45":"/article/ae45vjba/","46":"/article/7m8pc013/#标题3-badge","47":"/article/mwjqbj4j/#编译-eigen","48":"/article/842dffc6/#usr-bin-env-bashr-没有那个文件或目录","49":"/article/yfgydiz3/#_1-检查是否已安装-screen","50":"/article/s5jbgxuk/","51":"/article/j1i3k2nb/#evaluate-esam-e-on-3rscan-mv-class-agnostic","52":"/article/lhkmyeqo/#string","53":"/article/55d8rr54/","54":"/article/ae45vjba/#deep-interactive-object-selection-cvpr-2016","55":"/article/6j4jzzjo/","56":"/SLAM/zc7d97ub/","57":"/article/7m8pc013/#标题4-badge","58":"/article/mwjqbj4j/#编译-liborbslam2-so","59":"/article/yfgydiz3/#_2-安装-screen","60":"/article/s5jbgxuk/#创建容器","61":"/VLN/","62":"/VLN/3ec8oyvr/","63":"/article/lhkmyeqo/#字符串类型转换函数","64":"/article/55d8rr54/#出现原因","65":"/article/ae45vjba/#interactive-image-segmentation-with-first-click-attention-in-cvpr-2020","66":"/article/6j4jzzjo/#安装自定义显卡驱动版本号","67":"/article/mwjqbj4j/#orlbslam2-中的定义错误","68":"/article/yfgydiz3/#_3-创建一个-screen-会话","69":"/article/s5jbgxuk/#安装常用软件","70":"/VLN/#综述","71":"/VLN/tfxszik8/","72":"/VLN/3ec8oyvr/#摘要","73":"/article/lhkmyeqo/#vector","74":"/article/55d8rr54/#解决方法","75":"/article/ae45vjba/#interactive-image-segmentation-via-backpropagating-refinement-scheme-cvpr-2019","76":"/article/mwjqbj4j/#ros-安装","77":"/article/yfgydiz3/#_4-断开与当前-screen-连接","78":"/article/s5jbgxuk/#配置-ssh-链接","79":"/VLN/#awesome-vision–language–action-models-for-autonomous-driving","80":"/VLN/tfxszik8/#摘要","81":"/demo/","82":"/VLN/3ec8oyvr/#_1-引言","83":"/article/lhkmyeqo/#概念","84":"/article/ae45vjba/#f-brs-rethinking-backpropagating-refinement-for-interactive-segmentation-cvpr-2020","85":"/demo/0krmw2bt/","86":"/demo/ndqlc44k/","87":"/article/mwjqbj4j/#rosdep-安装","88":"/article/yfgydiz3/#_5-恢复某-screen-会话","89":"/VLN/#semantic-map-综述","90":"/VLN/tfxszik8/#_1-引言","91":"/demo/naiz5386/","92":"/VLN/3ec8oyvr/#_2-自动驾驶发展历程","93":"/article/lhkmyeqo/#vector构造函数","94":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/","95":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/","96":"/article/ae45vjba/#edgeflow-iccv2021","97":"/article/mwjqbj4j/#验证安装","98":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/wa7eu24i/","99":"/article/yfgydiz3/#_6-删除不需要的-screen","100":"/VLN/tfxszik8/#_2-背景知识","101":"/demo/naiz5386/#denoising-diffusion-probabilistic-models","102":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/m8d6eifb/","103":"/VLN/3ec8oyvr/#_2-1-经典模块化流水线","104":"/article/lhkmyeqo/#vector增加函数","105":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#摘要","106":"/article/ae45vjba/#ritm","107":"/article/mwjqbj4j/#ros-中安装-orbslam2-节点","108":"/%E6%95%B0%E6%8D%AE%E9%9B%86/","109":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/wa7eu24i/#_1-引言","110":"/VLN/tfxszik8/#_2-1-具身任务-embodied-tasks","111":"/demo/naiz5386/#_1-difussion","112":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/m8d6eifb/#摘要","113":"/%E6%95%B0%E6%8D%AE%E9%9B%86/9p83pjh6/","114":"/VLN/3ec8oyvr/#_2-2-端到端自动驾驶","115":"/article/lhkmyeqo/#vector删除函数","116":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#_1-引言","117":"/article/ae45vjba/#focalclick-towards-practical-interactive-image-segmentation-cvpr2022","118":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/","119":"/%E6%84%9F%E7%9F%A5/","120":"/article/mwjqbj4j/#相机驱动安装","121":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/wa7eu24i/#_2-相关工作","122":"/%E6%84%9F%E7%9F%A5/nkx8aw6d/","123":"/VLN/tfxszik8/#_2-1-1-机器人学任务","124":"/demo/naiz5386/#_2-training","125":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/m8d6eifb/#i-引言","126":"/%E6%95%B0%E6%8D%AE%E9%9B%86/9p83pjh6/#概述","127":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/q4lwpm2b/","128":"/VLN/3ec8oyvr/#_2-3-自动驾驶中的vlm","129":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/g4otw67p/","130":"/article/lhkmyeqo/#vector遍历函数","131":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#贡献","132":"/article/ae45vjba/#interactive-object-segmentation-in-3d-point-clouds","133":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/rqcexhzb/","134":"/%E6%84%9F%E7%9F%A5/#backbone","135":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/96xa12ja/","136":"/article/mwjqbj4j/#相机标定","137":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/wa7eu24i/#_3-问题表述-任务感知-3d-场景理解","138":"/%E6%84%9F%E7%9F%A5/nkx8aw6d/#实例分割","139":"/VLN/tfxszik8/#_2-1-2-具身智能任务","140":"/demo/naiz5386/#_3-sampling","141":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/m8d6eifb/#前作的缺点","142":"/%E6%95%B0%E6%8D%AE%E9%9B%86/9p83pjh6/#数据收集","143":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/q4lwpm2b/#motion-supervision","144":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/jeaasjxx/","145":"/VLN/3ec8oyvr/#_2-4-从vlm到自动驾驶vla","146":"/article/lhkmyeqo/#vector关于元素数量函数","147":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#_2-3d动态场景图","148":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/1po6vfar/","149":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/rqcexhzb/#mapping-network","150":"/%E6%84%9F%E7%9F%A5/#_3d","151":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/96xa12ja/#出发点","152":"/article/mwjqbj4j/#运行","153":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/wa7eu24i/#_4-任务驱动聚类","154":"/%E6%84%9F%E7%9F%A5/nkx8aw6d/#r-cnn","155":"/VLN/tfxszik8/#_2-2-同时定位与建图-simultaneous-localization-and-mapping-slam","156":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/m8d6eifb/#ii-相关工作","157":"/%E6%95%B0%E6%8D%AE%E9%9B%86/9p83pjh6/#场景规划","158":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/q4lwpm2b/#point-tracking","159":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/cc7ucksh/","160":"/VLN/3ec8oyvr/#_3-vla4ad架构范式","161":"/article/lhkmyeqo/#vector其他函数","162":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#_2-1-第1层-度量-语义网格","163":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/umashxv4/","164":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/1po6vfar/#related-work","165":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/rqcexhzb/#latent-space-interpolations","166":"/%E6%84%9F%E7%9F%A5/#bev","167":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/96xa12ja/#成果","168":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/wa7eu24i/#_5-clio-实时任务驱动开放集3d场景图","169":"/%E6%84%9F%E7%9F%A5/nkx8aw6d/#流程","170":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/8deusd81/","171":"/VLN/tfxszik8/#_2-2-1-slam-基础","172":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/m8d6eifb/#度量语义和层次化映射","173":"/%E6%95%B0%E6%8D%AE%E9%9B%86/9p83pjh6/#车辆配置","174":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/cc7ucksh/#相关工作","175":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/9laka0pz/","176":"/VLN/3ec8oyvr/#_3-1-多模态输入与语言指令","177":"/article/lhkmyeqo/#map","178":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#_2-2-第2层-对象和代理","179":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/umashxv4/#bundle-adjustment","180":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/1po6vfar/#method","181":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/rqcexhzb/#style-mixing","182":"/%E6%84%9F%E7%9F%A5/#occ","183":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/8deusd82/","184":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/96xa12ja/#train","185":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/l60xc115/","186":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/wa7eu24i/#a-clio前端","187":"/%E6%84%9F%E7%9F%A5/nkx8aw6d/#贡献","188":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/8deusd81/#用-sde-描述扩散模型","189":"/VLN/tfxszik8/#_2-2-2-slam-技术","190":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/m8d6eifb/#环路闭合检测和优化","191":"/%E6%95%B0%E6%8D%AE%E9%9B%86/9p83pjh6/#传感器校准","192":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/cc7ucksh/#方法","193":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/9laka0pz/#生成模型","194":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/olqxk7qw/","195":"/VLN/3ec8oyvr/#_3-2-核心架构模块","196":"/article/lhkmyeqo/#unordered-map","197":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#_2-3-第3层-地点和结构","198":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/1po6vfar/#网络架构","199":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/rqcexhzb/#stochastic-variation","200":"/%E6%84%9F%E7%9F%A5/#融合occ","201":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/2gu6h6qk/","202":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/fmdki2js/","203":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/8deusd82/#生成模型分类","204":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/96xa12ja/#infer","205":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/l60xc115/#intro","206":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/wa7eu24i/#_3d对象原语。","207":"/%E6%84%9F%E7%9F%A5/nkx8aw6d/#问题","208":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/8deusd81/#sde-based-diffusion-process","209":"/VLN/tfxszik8/#_2-2-3-语义-slam","210":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/m8d6eifb/#iii-实时增量3d场景图层构建","211":"/%E6%95%B0%E6%8D%AE%E9%9B%86/9p83pjh6/#传感器同步","212":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/cc7ucksh/#理论依据","213":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/9laka0pz/#概率密度函数","214":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/olqxk7qw/#denoising-diffusion-probabilistic-models","215":"/%E6%84%9F%E7%9F%A5/2ucyndyj/","216":"/VLN/3ec8oyvr/#_3-3-驾驶输出","217":"/article/lhkmyeqo/#unordered-set","218":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#_2-4-第4层-房间","219":"/%E6%84%9F%E7%9F%A5/8daubjva/","220":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/1po6vfar/#result","221":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/rqcexhzb/#perceptual-path-length","222":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/2gu6h6qk/#扩散模型与受控图像生成","223":"/%E6%84%9F%E7%9F%A5/6lykl9kg/","224":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/fmdki2js/#unconditional-ddpm","225":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/8deusd82/#方法","226":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/96xa12ja/#结果","227":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/l60xc115/#潜在空间-lantent-space","228":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/wa7eu24i/#_3d地点原语","229":"/%E6%84%9F%E7%9F%A5/nkx8aw6d/#fast-r-cnn","230":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/8deusd81/#与之前工作的联系","231":"/VLN/tfxszik8/#_2-3-系统设计策略","232":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/m8d6eifb/#a-第1-3层-网格、对象和地点","233":"/%E6%95%B0%E6%8D%AE%E9%9B%86/9p83pjh6/#隐私保护","234":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/cc7ucksh/#intra-attention-similarity","235":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/9laka0pz/#score-based-models","236":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/olqxk7qw/#_1-difussion","237":"/%E6%84%9F%E7%9F%A5/hjwas0y4/","238":"/VLN/3ec8oyvr/#_4-vla4ad范式进展","239":"/article/lhkmyeqo/#头文件","240":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#_2-5-第5层-建筑物","241":"/%E6%84%9F%E7%9F%A5/8daubjva/#_1-数据集","242":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/2gu6h6qk/#基于迭代去噪过程的图像编辑","243":"/%E6%84%9F%E7%9F%A5/6lykl9kg/#pointcontrast","244":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/fmdki2js/#guided-diffusion-diffusion-models-beat-gans-on-image-synthesis","245":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/8deusd82/#问题","246":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/96xa12ja/#clip损失引导生成","247":"/%E6%84%9F%E7%9F%A5/ysjzc8s9/","248":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/l60xc115/#latent-diffusion","249":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/wa7eu24i/#b-clio后端","250":"/%E6%84%9F%E7%9F%A5/nkx8aw6d/#流程-1","251":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/8deusd81/#ve-sde","252":"/VLN/tfxszik8/#_2-3-1-端到端方法","253":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/m8d6eifb/#网格和对象","254":"/%E6%95%B0%E6%8D%AE%E9%9B%86/9p83pjh6/#数据格式","255":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/cc7ucksh/#inter-attention-similarity","256":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/9laka0pz/#langevin-dynamics","257":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/olqxk7qw/#_2-training","258":"/%E6%84%9F%E7%9F%A5/hjwas0y4/#创新点","259":"/%E6%84%9F%E7%9F%A5/5gkchwm1/","260":"/VLN/3ec8oyvr/#_4-1-pre-vla-语言模型作为解释器","261":"/article/lhkmyeqo/#初始化","262":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#_2-6-组合和查询","263":"/%E6%84%9F%E7%9F%A5/8daubjva/#_2-评价指标","264":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/2gu6h6qk/#ivlr-conditioning-method-for-denoising-diffusion-probabilistic-models","265":"/%E6%84%9F%E7%9F%A5/6lykl9kg/#motivation","266":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/fmdki2js/#ilvr-conditioning-method-for-denoising-diffusion-probabilistic-models","267":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/8deusd82/#在数据密度较低的位置-score的估计往往是不准确的","268":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/96xa12ja/#diffusioncllp","269":"/%E6%84%9F%E7%9F%A5/ysjzc8s9/#_3d-representation","270":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/l60xc115/#感知压缩","271":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/wa7eu24i/#任务驱动对象检测。","272":"/%E6%84%9F%E7%9F%A5/nkx8aw6d/#贡献-1","273":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/8deusd81/#vp-sde","274":"/VLN/tfxszik8/#_2-3-2-模块化流水线","275":"/%E6%84%9F%E7%9F%A5/89ng5ct4/","276":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/m8d6eifb/#地点","277":"/%E6%95%B0%E6%8D%AE%E9%9B%86/9p83pjh6/#数据标注","278":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/cc7ucksh/#attention-map","279":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/9laka0pz/#ddpm","280":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/olqxk7qw/#_3-sampling","281":"/%E6%84%9F%E7%9F%A5/5gkchwm1/#训练","282":"/%E6%84%9F%E7%9F%A5/4r1v104o/","283":"/VLN/3ec8oyvr/#_4-2-自动驾驶模块化vla模型","284":"/article/lhkmyeqo/#创建空的set","285":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#_3-kimera-空间感知引擎","286":"/%E6%84%9F%E7%9F%A5/8daubjva/#_3-分类","287":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/2gu6h6qk/#sdedit","288":"/%E6%84%9F%E7%9F%A5/6lykl9kg/#方法","289":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/fmdki2js/#创新点","290":"/%E6%84%9F%E7%9F%A5/9px4btak/","291":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/8deusd82/#要加少强度的噪声","292":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/96xa12ja/#vq-vae","293":"/%E6%84%9F%E7%9F%A5/ysjzc8s9/#model","294":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/l60xc115/#语义压缩","295":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/wa7eu24i/#任务驱动地点聚类。","296":"/%E6%84%9F%E7%9F%A5/nkx8aw6d/#faster-r-cnn","297":"/%E6%84%9F%E7%9F%A5/f025awky/","298":"/%E6%84%9F%E7%9F%A5/hy41uhht/","299":"/VLN/tfxszik8/#_2-3-3-权衡","300":"/%E6%84%9F%E7%9F%A5/89ng5ct4/#overview","301":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/m8d6eifb/#b-第4层-房间检测","302":"/%E6%95%B0%E6%8D%AE%E9%9B%86/9p83pjh6/#全景","303":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/cc7ucksh/#attention-aggregation","304":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/9laka0pz/#sr3","305":"/%E6%84%9F%E7%9F%A5/5gkchwm1/#特征提取","306":"/%E6%84%9F%E7%9F%A5/4r1v104o/#oneformer3d","307":"/%E6%84%9F%E7%9F%A5/e38qiahx/","308":"/VLN/3ec8oyvr/#_4-3-自动驾驶统一端到端vla模型","309":"/article/lhkmyeqo/#拷贝构造","310":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#第3-1节-kimera-vio-视觉-惯性里程计","311":"/%E6%84%9F%E7%9F%A5/8daubjva/#_3-1基于投影的网络","312":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/2gu6h6qk/#repaint-inpainting-using-denoising-diffusion-probabilistic-models","313":"/%E6%84%9F%E7%9F%A5/6lykl9kg/#shapenet-有监督预训练测试","314":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/fmdki2js/#diffusion-probabilistic-models-for-3d-point-cloud-generation","315":"/%E6%84%9F%E7%9F%A5/9px4btak/#pointgpt-的整体架构","316":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/8deusd82/#求-score","317":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/96xa12ja/#vqgan","318":"/%E6%84%9F%E7%9F%A5/ysjzc8s9/#input-encoder","319":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/l60xc115/#method","320":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/wa7eu24i/#_6-实验","321":"/%E6%84%9F%E7%9F%A5/nkx8aw6d/#region-proposal-network","322":"/%E6%84%9F%E7%9F%A5/f025awky/#abstract","323":"/%E6%84%9F%E7%9F%A5/hy41uhht/#spformer","324":"/VLN/tfxszik8/#_3-语义地图","325":"/%E6%84%9F%E7%9F%A5/89ng5ct4/#invariant-convolution","326":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/m8d6eifb/#iv-持久表示-环路闭合检测和3d场景图优化","327":"/%E6%95%B0%E6%8D%AE%E9%9B%86/9p83pjh6/#如何使用-nuscenes-数据集","328":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/cc7ucksh/#iterative-attention-merging","329":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/9laka0pz/#训练过程","330":"/%E6%84%9F%E7%9F%A5/5gkchwm1/#构建特征体-feature-volume","331":"/%E6%84%9F%E7%9F%A5/4r1v104o/#解决的问题","332":"/%E6%84%9F%E7%9F%A5/e38qiahx/#稀疏卷积","333":"/%E6%84%9F%E7%9F%A5/xdnte8ex/","334":"/VLN/3ec8oyvr/#_4-4-自动驾驶推理增强vla模型","335":"/article/lhkmyeqo/#使用迭代器构造","336":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#第3-2节-kimera-mesher-3d网格重建","337":"/%E6%84%9F%E7%9F%A5/8daubjva/#_3-1-1-多视图表示","338":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/2gu6h6qk/#基于显式分类器的图像引导生成","339":"/%E6%84%9F%E7%9F%A5/6lykl9kg/#算法","340":"/%E6%84%9F%E7%9F%A5/9px4btak/#point-cloud-sequencer","341":"/%E6%84%9F%E7%9F%A5/qidw72m1/","342":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/8deusd82/#目标函数","343":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/96xa12ja/#问题","344":"/%E6%84%9F%E7%9F%A5/ysjzc8s9/#initial-prediction-of-sdf","345":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/l60xc115/#autoencoder","346":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/wa7eu24i/#a-开放集对象聚类评估","347":"/%E6%84%9F%E7%9F%A5/nkx8aw6d/#cls-layer","348":"/%E6%84%9F%E7%9F%A5/f025awky/#方法","349":"/%E6%84%9F%E7%9F%A5/hy41uhht/#摘要","350":"/VLN/tfxszik8/#_3-1-什么是语义地图","351":"/%E6%84%9F%E7%9F%A5/89ng5ct4/#mesh-convolution","352":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/m8d6eifb/#a-环路闭合检测和几何验证","353":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/cc7ucksh/#结果","354":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/9laka0pz/#推理过程","355":"/%E6%84%9F%E7%9F%A5/5gkchwm1/#differentiable-homography","356":"/%E6%84%9F%E7%9F%A5/4r1v104o/#主要贡献","357":"/%E6%84%9F%E7%9F%A5/e38qiahx/#_1-minkengine","358":"/%E6%84%9F%E7%9F%A5/xdnte8ex/#损失函数","359":"/%E6%84%9F%E7%9F%A5/he59dm4t/","360":"/VLN/3ec8oyvr/#_5-数据集与基准","361":"/article/lhkmyeqo/#使用数组作为初值构造","362":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#第3-3节-kimera-semantics-3d度量-语义重建","363":"/%E6%84%9F%E7%9F%A5/8daubjva/#_3-1-2-体素化表示","364":"/%E6%84%9F%E7%9F%A5/occ/52xxd530/","365":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/2gu6h6qk/#diffusion-models-beat-gans-on-image-synthesis","366":"/%E6%84%9F%E7%9F%A5/6lykl9kg/#结果","367":"/%E6%84%9F%E7%9F%A5/occ/zkgf7k1b/","368":"/%E6%84%9F%E7%9F%A5/9px4btak/#点云序列","369":"/%E6%84%9F%E7%9F%A5/qidw72m1/#petr","370":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/8deusd82/#image-inpainting","371":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/96xa12ja/#方法","372":"/%E6%84%9F%E7%9F%A5/ysjzc8s9/#surface-refinement-with-volume-subdivision","373":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/l60xc115/#clip-text-encder","374":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/wa7eu24i/#实验设置","375":"/%E6%84%9F%E7%9F%A5/nkx8aw6d/#reg-layer","376":"/%E6%84%9F%E7%9F%A5/f025awky/#_1-初始深度图生成","377":"/%E6%84%9F%E7%9F%A5/hy41uhht/#method","378":"/VLN/tfxszik8/#_3-2-地图的结构是什么","379":"/%E6%84%9F%E7%9F%A5/89ng5ct4/#输入特征","380":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/m8d6eifb/#b-3d场景图优化","381":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/cc7ucksh/#类似工作","382":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/9laka0pz/#实验结果","383":"/%E6%84%9F%E7%9F%A5/5gkchwm1/#特征体构建","384":"/%E6%84%9F%E7%9F%A5/4r1v104o/#架构","385":"/%E6%84%9F%E7%9F%A5/e38qiahx/#sparse-tensor-quantization","386":"/%E6%84%9F%E7%9F%A5/xdnte8ex/#deformable-detr","387":"/%E6%84%9F%E7%9F%A5/occ/ekepu2n5/","388":"/VLN/3ec8oyvr/#_6-训练与评估策略","389":"/article/lhkmyeqo/#移动构造","390":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#第3-4节-kimera-pgmo-带有回路闭合的姿态图和网格优化","391":"/%E6%84%9F%E7%9F%A5/8daubjva/#_3-2基于点的网络","392":"/%E6%84%9F%E7%9F%A5/occ/52xxd530/#摘要","393":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/2gu6h6qk/#基于clip模型的多模态图像引导生成","394":"/%E6%84%9F%E7%9F%A5/6lykl9kg/#depthcontrast","395":"/%E6%84%9F%E7%9F%A5/occ/zkgf7k1b/#effocc-从最小标签中学习高效占据网络用于自动驾驶","396":"/%E6%84%9F%E7%9F%A5/9px4btak/#点块分割","397":"/%E6%84%9F%E7%9F%A5/qidw72m1/#模型","398":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/8deusd82/#总结","399":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/96xa12ja/#vqgan-clip","400":"/%E6%84%9F%E7%9F%A5/ysjzc8s9/#learnable-surface-subdivision","401":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/l60xc115/#unet","402":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/wa7eu24i/#指标","403":"/%E6%84%9F%E7%9F%A5/nkx8aw6d/#classifier","404":"/%E6%84%9F%E7%9F%A5/f025awky/#_2-2d-3d-特征融合","405":"/%E6%84%9F%E7%9F%A5/hy41uhht/#query-decoder","406":"/VLN/tfxszik8/#_3-3-地图中存储什么样的编码","407":"/%E6%84%9F%E7%9F%A5/89ng5ct4/#global-ordering","408":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/m8d6eifb/#v-快速思考与慢速思考-hydra架构","409":"/%E6%84%9F%E7%9F%A5/occ/otz54ixd/","410":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/cc7ucksh/#affinitynet","411":"/%E6%84%9F%E7%9F%A5/5gkchwm1/#生成代价体-cost-volume","412":"/%E6%84%9F%E7%9F%A5/4r1v104o/#sparse-3d-u-net","413":"/%E6%84%9F%E7%9F%A5/e38qiahx/#generalized-sparse-convolution","414":"/%E6%84%9F%E7%9F%A5/xdnte8ex/#detr-3d","415":"/%E6%84%9F%E7%9F%A5/occ/ekepu2n5/#摘要","416":"/%E6%84%9F%E7%9F%A5/occ/3byfb1am/","417":"/VLN/3ec8oyvr/#_6-1-训练范式","418":"/article/lhkmyeqo/#使用待处置的列表构造","419":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#第3-5节-kimera-humans-人体姿态估计和鲁棒跟踪","420":"/%E6%84%9F%E7%9F%A5/8daubjva/#_3-2-1-点式mlp网络","421":"/%E6%84%9F%E7%9F%A5/occ/52xxd530/#_1-intro","422":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/2gu6h6qk/#more-control-for-free-image-synthesis-with-semantic-diffusion-guidance","423":"/%E6%84%9F%E7%9F%A5/fusion/09ay8hzz/","424":"/%E6%84%9F%E7%9F%A5/6lykl9kg/#方法-1","425":"/%E6%84%9F%E7%9F%A5/occ/zkgf7k1b/#摘要","426":"/%E6%84%9F%E7%9F%A5/9px4btak/#排序","427":"/%E6%84%9F%E7%9F%A5/qidw72m1/#_3d-position-encoder","428":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/96xa12ja/#stable-diffusion","429":"/%E6%84%9F%E7%9F%A5/ysjzc8s9/#_3d-discriminator","430":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/l60xc115/#应用","431":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/wa7eu24i/#compared-techniques","432":"/%E6%84%9F%E7%9F%A5/nkx8aw6d/#roi-pooling","433":"/%E6%84%9F%E7%9F%A5/f025awky/#_2-1-特征提取","434":"/%E6%84%9F%E7%9F%A5/hy41uhht/#shared-prediction-head","435":"/VLN/tfxszik8/#_3-4-地图是如何构建的","436":"/%E6%84%9F%E7%9F%A5/89ng5ct4/#pooling","437":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/m8d6eifb/#vi-实验","438":"/%E6%84%9F%E7%9F%A5/occ/otz54ixd/#i-引言","439":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/cc7ucksh/#diffumasks","440":"/%E6%84%9F%E7%9F%A5/5gkchwm1/#代价体正则化","441":"/%E6%84%9F%E7%9F%A5/4r1v104o/#query-decoder","442":"/%E6%84%9F%E7%9F%A5/e38qiahx/#pooling","443":"/%E6%84%9F%E7%9F%A5/xdnte8ex/#多视角3d目标检测问题","444":"/%E6%84%9F%E7%9F%A5/occ/ekepu2n5/#_1-intro","445":"/%E6%84%9F%E7%9F%A5/occ/3byfb1am/#occfusion-multi-sensor-fusion-framework-for-3d-semantic-occupancy-prediction","446":"/%E6%84%9F%E7%9F%A5/rc0nrwf6/","447":"/VLN/3ec8oyvr/#_6-2-评估协议","448":"/article/lhkmyeqo/#unordered-set-常用函数","449":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#第3-6节-kimera-objects-对象姿态估计","450":"/%E6%84%9F%E7%9F%A5/8daubjva/#_3-2-2-基于卷积的网络","451":"/%E6%84%9F%E7%9F%A5/occ/52xxd530/#_2-相关工作","452":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/2gu6h6qk/#blended-diffusion-for-text-driven-editing-of-natural-images","453":"/%E6%84%9F%E7%9F%A5/fusion/09ay8hzz/#effocc","454":"/%E6%84%9F%E7%9F%A5/6lykl9kg/#结果-1","455":"/%E6%84%9F%E7%9F%A5/occ/zkgf7k1b/#i-引言","456":"/%E6%84%9F%E7%9F%A5/9px4btak/#嵌入","457":"/%E6%84%9F%E7%9F%A5/qidw72m1/#decoder","458":"/%E6%84%9F%E7%9F%A5/l2r6j7r9/","459":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/96xa12ja/#总结","460":"/%E6%84%9F%E7%9F%A5/ysjzc8s9/#损失函数","461":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/l60xc115/#text2image","462":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/wa7eu24i/#结果","463":"/%E6%84%9F%E7%9F%A5/nkx8aw6d/#分类和边框修正","464":"/%E6%84%9F%E7%9F%A5/f025awky/#_2-1-动态特征融合","465":"/VLN/tfxszik8/#_4-地图结构","466":"/%E6%84%9F%E7%9F%A5/89ng5ct4/#mesh-pooling","467":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/m8d6eifb/#vii-结论","468":"/%E6%84%9F%E7%9F%A5/occ/otz54ixd/#ii-相关工作","469":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/cc7ucksh/#reco","470":"/%E6%84%9F%E7%9F%A5/5gkchwm1/#深度图初始估计","471":"/%E6%84%9F%E7%9F%A5/4r1v104o/#query-selection","472":"/%E6%84%9F%E7%9F%A5/e38qiahx/#non-spatial-funtions","473":"/%E6%84%9F%E7%9F%A5/xdnte8ex/#创新点","474":"/%E6%84%9F%E7%9F%A5/occ/ekepu2n5/#_2-相关工作","475":"/%E6%84%9F%E7%9F%A5/occ/3byfb1am/#摘要","476":"/%E6%84%9F%E7%9F%A5/rc0nrwf6/#_1-基本结构","477":"/%E6%84%9F%E7%9F%A5/nfq4b8kf/","478":"/VLN/3ec8oyvr/#_7-开放挑战","479":"/article/lhkmyeqo/#empty","480":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#第3-7节-kimera-buildingparser-提取地点、房间和结构","481":"/%E6%84%9F%E7%9F%A5/8daubjva/#连续卷积","482":"/%E6%84%9F%E7%9F%A5/occ/52xxd530/#_3d-occupancy-prediction","483":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/2gu6h6qk/#基于隐式分类器的文生图大模型","484":"/%E6%84%9F%E7%9F%A5/fusion/09ay8hzz/#daocc","485":"/%E6%84%9F%E7%9F%A5/6lykl9kg/#总结","486":"/%E6%84%9F%E7%9F%A5/occ/%E6%A6%82%E8%A7%88/9d77057p/","487":"/%E6%84%9F%E7%9F%A5/occ/zkgf7k1b/#ii-相关工作","488":"/%E6%84%9F%E7%9F%A5/9px4btak/#transformer-decoder-with-a-dual-masking-strategy","489":"/%E6%84%9F%E7%9F%A5/qidw72m1/#query","490":"/%E6%84%9F%E7%9F%A5/l2r6j7r9/#摘要","491":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/l60xc115/#image2image","492":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/wa7eu24i/#b-封闭集对象评估","493":"/%E6%84%9F%E7%9F%A5/nkx8aw6d/#推理","494":"/%E6%84%9F%E7%9F%A5/f025awky/#_3-点云优化","495":"/VLN/tfxszik8/#_4-1-空间网格地图","496":"/%E6%84%9F%E7%9F%A5/89ng5ct4/#mesh-unpooling","497":"/%E6%84%9F%E7%9F%A5/occ/otz54ixd/#a-基于摄像头-雷达融合的3d语义占据预测","498":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/cc7ucksh/#network-free","499":"/%E6%84%9F%E7%9F%A5/5gkchwm1/#损失计算","500":"/%E6%84%9F%E7%9F%A5/e38qiahx/#_2-spconv","501":"/%E6%84%9F%E7%9F%A5/xdnte8ex/#overview","502":"/%E6%84%9F%E7%9F%A5/occ/ekepu2n5/#_3-方法","503":"/%E6%84%9F%E7%9F%A5/occ/3byfb1am/#i-引言","504":"/%E6%84%9F%E7%9F%A5/rc0nrwf6/#_1-1-nuscenes-devkit","505":"/%E6%84%9F%E7%9F%A5/nfq4b8kf/#摘要","506":"/%E6%84%9F%E7%9F%A5/occ/rjyln29i/","507":"/VLN/3ec8oyvr/#_8-未来方向","508":"/%E6%84%9F%E7%9F%A5/occ/7f4uq5ih/","509":"/article/lhkmyeqo/#find","510":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#第3-8节-调试工具","511":"/%E6%84%9F%E7%9F%A5/8daubjva/#离散卷积","512":"/%E6%84%9F%E7%9F%A5/occ/52xxd530/#multi-modal-3d-object-detection","513":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/2gu6h6qk/#classifier-free-diffusion-guidance","514":"/%E6%84%9F%E7%9F%A5/fusion/09ay8hzz/#gaussianformer3d","515":"/%E6%84%9F%E7%9F%A5/6lykl9kg/#masked-scene-contrast","516":"/%E6%84%9F%E7%9F%A5/occ/%E6%A6%82%E8%A7%88/9d77057p/#摘要","517":"/%E6%84%9F%E7%9F%A5/occ/zkgf7k1b/#a-计算高效的占据网络","518":"/%E6%84%9F%E7%9F%A5/9px4btak/#dual-masking-strategy","519":"/%E6%84%9F%E7%9F%A5/qidw72m1/#实验","520":"/%E6%84%9F%E7%9F%A5/l2r6j7r9/#_1-引言","521":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/l60xc115/#image-inpainting","522":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/wa7eu24i/#c-开放词汇地点聚类","523":"/%E6%84%9F%E7%9F%A5/nkx8aw6d/#mask-r-cnn","524":"/%E6%84%9F%E7%9F%A5/f025awky/#_3-1-假设点生成","525":"/VLN/tfxszik8/#_4-2-拓扑地图","526":"/%E6%84%9F%E7%9F%A5/89ng5ct4/#网络设置","527":"/%E6%84%9F%E7%9F%A5/occ/otz54ixd/#b-基于摄像头-激光雷达融合的3d语义占据预测","528":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/cc7ucksh/#toco","529":"/%E6%84%9F%E7%9F%A5/5gkchwm1/#后处理","530":"/%E6%84%9F%E7%9F%A5/e38qiahx/#建立输入哈希表","531":"/%E6%84%9F%E7%9F%A5/xdnte8ex/#结构","532":"/%E6%84%9F%E7%9F%A5/occ/ekepu2n5/#_3-1-基于3d高斯的场景表示","533":"/%E6%84%9F%E7%9F%A5/occ/3byfb1am/#ii-相关工作","534":"/%E6%84%9F%E7%9F%A5/rc0nrwf6/#_1-2-nuscenes-lidarseg","535":"/%E6%84%9F%E7%9F%A5/nfq4b8kf/#_1-引言","536":"/%E6%84%9F%E7%9F%A5/occ/rjyln29i/#摘要","537":"/%E6%84%9F%E7%9F%A5/d2qthpop/","538":"/VLN/3ec8oyvr/#_9-结论","539":"/%E6%84%9F%E7%9F%A5/occ/7f4uq5ih/#摘要","540":"/article/lhkmyeqo/#count","541":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#第4节-实验评估","542":"/%E6%84%9F%E7%9F%A5/8daubjva/#_3-2-3-基于图的网络","543":"/%E6%84%9F%E7%9F%A5/occ/52xxd530/#_3-提出的方法","544":"/%E6%84%9F%E7%9F%A5/occ/rr9mq2w1/","545":"/%E6%84%9F%E7%9F%A5/fusion/09ay8hzz/#occfusion","546":"/%E6%84%9F%E7%9F%A5/6lykl9kg/#approch","547":"/%E6%84%9F%E7%9F%A5/occ/%E6%A6%82%E8%A7%88/9d77057p/#_1-引言","548":"/%E6%84%9F%E7%9F%A5/occ/zkgf7k1b/#b-自动驾驶感知中的知识蒸馏","549":"/%E6%84%9F%E7%9F%A5/9px4btak/#extractor-generator","550":"/%E6%84%9F%E7%9F%A5/qidw72m1/#petrv2","551":"/%E6%84%9F%E7%9F%A5/l2r6j7r9/#_2-方法","552":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/l60xc115/#总结","553":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/wa7eu24i/#vii-限制","554":"/%E6%84%9F%E7%9F%A5/nkx8aw6d/#问题-1","555":"/%E6%84%9F%E7%9F%A5/f025awky/#_3-2-边缘卷积","556":"/VLN/tfxszik8/#_4-3-稠密几何地图-dense-geometric-map","557":"/%E6%84%9F%E7%9F%A5/89ng5ct4/#result","558":"/%E6%84%9F%E7%9F%A5/occ/otz54ixd/#iii-occcylindrical","559":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/cc7ucksh/#ptc-patch-token-contrast","560":"/%E6%84%9F%E7%9F%A5/5gkchwm1/#深度图滤波","561":"/%E6%84%9F%E7%9F%A5/e38qiahx/#建立rulebook","562":"/%E6%84%9F%E7%9F%A5/xdnte8ex/#model","563":"/%E6%84%9F%E7%9F%A5/occ/ekepu2n5/#_3-2-体素到高斯的初始化","564":"/%E6%84%9F%E7%9F%A5/occ/3byfb1am/#a-基于相机的环境感知","565":"/%E6%84%9F%E7%9F%A5/rc0nrwf6/#_2-标注需求-暂","566":"/%E6%84%9F%E7%9F%A5/nfq4b8kf/#_2-相关工作","567":"/%E6%84%9F%E7%9F%A5/occ/rjyln29i/#_1-引言","568":"/%E6%84%9F%E7%9F%A5/d2qthpop/#摘要","569":"/%E6%84%9F%E7%9F%A5/1bnnumnt/","570":"/%E6%84%9F%E7%9F%A5/occ/7f4uq5ih/#_1-引言","571":"/article/lhkmyeqo/#insert","572":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#_4-1-数据集","573":"/%E6%84%9F%E7%9F%A5/ggoqbqz5/","574":"/%E6%84%9F%E7%9F%A5/8daubjva/#基于图的空间域","575":"/%E6%84%9F%E7%9F%A5/abafkauz/","576":"/%E6%84%9F%E7%9F%A5/occ/52xxd530/#_3-1-总体框架","577":"/%E6%84%9F%E7%9F%A5/vfkfho9v/","578":"/%E6%84%9F%E7%9F%A5/fusion/09ay8hzz/#occcylindrical","579":"/%E6%84%9F%E7%9F%A5/6lykl9kg/#对比学习","580":"/%E6%84%9F%E7%9F%A5/occ/%E6%A6%82%E8%A7%88/9d77057p/#_2-相关工作","581":"/%E6%84%9F%E7%9F%A5/occ/zkgf7k1b/#iii-方法","582":"/%E6%84%9F%E7%9F%A5/9px4btak/#generation-target","583":"/%E6%84%9F%E7%9F%A5/qidw72m1/#时域对齐","584":"/%E6%84%9F%E7%9F%A5/j4q2bh9h/","585":"/%E6%84%9F%E7%9F%A5/l2r6j7r9/#模型设计","586":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/wa7eu24i/#viii-结论","587":"/%E6%84%9F%E7%9F%A5/f025awky/#_3-3-残差生成","588":"/VLN/tfxszik8/#_4-3-1-点云地图","589":"/%E6%84%9F%E7%9F%A5/89ng5ct4/#总结","590":"/%E6%84%9F%E7%9F%A5/occ/otz54ixd/#a-问题描述","591":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/cc7ucksh/#ctc-classtokencontrast","592":"/%E6%84%9F%E7%9F%A5/5gkchwm1/#几何约束","593":"/%E6%84%9F%E7%9F%A5/e38qiahx/#_3-torchsparse","594":"/%E6%84%9F%E7%9F%A5/xdnte8ex/#检测头","595":"/%E6%84%9F%E7%9F%A5/occ/ekepu2n5/#_3-3-激光雷达引导的3d可变形注意力","596":"/%E6%84%9F%E7%9F%A5/occ/3byfb1am/#b-基于激光雷达的环境感知","597":"/%E6%84%9F%E7%9F%A5/rc0nrwf6/#基本需求","598":"/%E6%84%9F%E7%9F%A5/nfq4b8kf/#_3-框架","599":"/%E6%84%9F%E7%9F%A5/occ/rjyln29i/#_2-相关工作","600":"/%E6%84%9F%E7%9F%A5/d2qthpop/#_1-引言","601":"/%E6%84%9F%E7%9F%A5/1bnnumnt/#多任务感知","602":"/%E6%84%9F%E7%9F%A5/ichxdy15/","603":"/%E6%84%9F%E7%9F%A5/occ/7f4uq5ih/#_2-相关工作","604":"/article/lhkmyeqo/#emplace","605":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#_4-1-2-uhumans和uhumans2。","606":"/%E6%84%9F%E7%9F%A5/ggoqbqz5/#室外","607":"/%E6%84%9F%E7%9F%A5/8daubjva/#基于图的谱域","608":"/%E6%84%9F%E7%9F%A5/abafkauz/#自动驾驶中的基于视觉的3d占用预测-回顾与展望","609":"/%E6%84%9F%E7%9F%A5/occ/52xxd530/#_3-2-基础网络","610":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#摘要","611":"/%E6%84%9F%E7%9F%A5/6lykl9kg/#数据增强","612":"/%E6%84%9F%E7%9F%A5/occ/%E6%A6%82%E8%A7%88/9d77057p/#_2-1-3d语义占用预测","613":"/%E6%84%9F%E7%9F%A5/occ/zkgf7k1b/#a-3d-占据预测的任务形式化","614":"/%E6%84%9F%E7%9F%A5/9px4btak/#experiment","615":"/%E6%84%9F%E7%9F%A5/qidw72m1/#特征引导的位置编码","616":"/%E6%84%9F%E7%9F%A5/j4q2bh9h/#deformable-convolutional-networks","617":"/%E6%84%9F%E7%9F%A5/l2r6j7r9/#规模化与预训练","618":"/%E6%84%9F%E7%9F%A5/f025awky/#_4-上采样与迭代优化","619":"/VLN/tfxszik8/#_4-3-2-神经场","620":"/%E6%84%9F%E7%9F%A5/gveehqsh/","621":"/%E6%84%9F%E7%9F%A5/occ/otz54ixd/#b-整体架构","622":"/%E6%84%9F%E7%9F%A5/5gkchwm1/#光度约束","623":"/%E6%84%9F%E7%9F%A5/xdnte8ex/#特征整合到目标查询","624":"/%E6%84%9F%E7%9F%A5/occ/ekepu2n5/#_4-实验","625":"/%E6%84%9F%E7%9F%A5/occ/3byfb1am/#c-基于相机-激光雷达融合的环境感知","626":"/%E6%84%9F%E7%9F%A5/rc0nrwf6/#_2-1-点云目标检测","627":"/%E6%84%9F%E7%9F%A5/nfq4b8kf/#_3-1-图像编码器","628":"/%E6%84%9F%E7%9F%A5/occ/rjyln29i/#_3-提出的方法","629":"/%E6%84%9F%E7%9F%A5/d2qthpop/#_2-相关工作","630":"/%E6%84%9F%E7%9F%A5/1bnnumnt/#bev","631":"/%E6%84%9F%E7%9F%A5/ichxdy15/#abstract","632":"/%E6%84%9F%E7%9F%A5/occ/7f4uq5ih/#_3-方法","633":"/article/lhkmyeqo/#erase","634":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#_4-2-姿态估计","635":"/%E6%84%9F%E7%9F%A5/ggoqbqz5/#fb-occ-开源、部署文档","636":"/%E6%84%9F%E7%9F%A5/8daubjva/#_3-2-4-基于数据索引的网络","637":"/%E6%84%9F%E7%9F%A5/abafkauz/#摘要","638":"/%E6%84%9F%E7%9F%A5/occ/52xxd530/#_3-3-bev视野范围扩展","639":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#_1-引言","640":"/%E6%84%9F%E7%9F%A5/6lykl9kg/#重建学习","641":"/%E6%84%9F%E7%9F%A5/occ/%E6%A6%82%E8%A7%88/9d77057p/#_2-2-3d高斯溅射","642":"/%E6%84%9F%E7%9F%A5/occ/zkgf7k1b/#b-架构","643":"/%E6%84%9F%E7%9F%A5/9px4btak/#结论","644":"/%E6%84%9F%E7%9F%A5/qidw72m1/#query-1","645":"/%E6%84%9F%E7%9F%A5/j4q2bh9h/#deformable-convolution","646":"/%E6%84%9F%E7%9F%A5/l2r6j7r9/#后处理","647":"/%E6%84%9F%E7%9F%A5/f025awky/#损失函数","648":"/VLN/tfxszik8/#_4-4-混合地图-hybrid-map","649":"/%E6%84%9F%E7%9F%A5/occ/otz54ixd/#c-深度估计模块","650":"/%E6%84%9F%E7%9F%A5/5gkchwm1/#深度图融合","651":"/%E6%84%9F%E7%9F%A5/xdnte8ex/#损失函数-1","652":"/%E6%84%9F%E7%9F%A5/occ/ekepu2n5/#_4-1-数据集","653":"/%E6%84%9F%E7%9F%A5/occ/3byfb1am/#d-基于相机-雷达融合的环境感知","654":"/%E6%84%9F%E7%9F%A5/rc0nrwf6/#_2-1-1-标注格式","655":"/%E6%84%9F%E7%9F%A5/nfq4b8kf/#_3-2-视图变换器","656":"/%E6%84%9F%E7%9F%A5/occ/rjyln29i/#_3-1-3d-语义高斯表示","657":"/%E6%84%9F%E7%9F%A5/d2qthpop/#_3-提出的方法","658":"/%E6%84%9F%E7%9F%A5/1bnnumnt/#occ","659":"/%E6%84%9F%E7%9F%A5/ichxdy15/#method","660":"/%E6%84%9F%E7%9F%A5/occ/7f4uq5ih/#_3-1-特征视线投影-flosp","661":"/article/lhkmyeqo/#bucket-count","662":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#_4-2-1-动态场景中姿态估计的鲁棒性。","663":"/%E6%84%9F%E7%9F%A5/ggoqbqz5/#flashocc","664":"/%E6%84%9F%E7%9F%A5/8daubjva/#_3-2-5-其他模型","665":"/%E6%84%9F%E7%9F%A5/abafkauz/#_1-引言","666":"/%E6%84%9F%E7%9F%A5/occ/52xxd530/#_3-4-可分离的辅助检测头","667":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#自动驾驶中的占用感知","668":"/%E6%84%9F%E7%9F%A5/6lykl9kg/#macarons","669":"/%E6%84%9F%E7%9F%A5/occ/%E6%A6%82%E8%A7%88/9d77057p/#_3-提出的方法","670":"/%E6%84%9F%E7%9F%A5/occ/zkgf7k1b/#c-高效融合网络","671":"/%E6%84%9F%E7%9F%A5/qidw72m1/#steam-petr","672":"/%E6%84%9F%E7%9F%A5/j4q2bh9h/#regular-conv","673":"/%E6%84%9F%E7%9F%A5/l2r6j7r9/#_2-3-1-测试时增强","674":"/%E6%84%9F%E7%9F%A5/f025awky/#实验结果","675":"/VLN/tfxszik8/#_5-地图编码-map-encoding","676":"/%E6%84%9F%E7%9F%A5/occ/otz54ixd/#d-tpv-polar-fusion","677":"/%E6%84%9F%E7%9F%A5/occ/ekepu2n5/#_4-2-实现和评估细节","678":"/%E6%84%9F%E7%9F%A5/occ/3byfb1am/#e-基于相机-激光雷达-雷达融合的环境感知","679":"/%E6%84%9F%E7%9F%A5/rc0nrwf6/#_2-1-2-目标类别","680":"/%E6%84%9F%E7%9F%A5/nfq4b8kf/#_3-3-bev编码器","681":"/%E6%84%9F%E7%9F%A5/occ/rjyln29i/#_3-2-概率高斯叠加","682":"/%E6%84%9F%E7%9F%A5/d2qthpop/#_3-1-具身三维空间占用预测","683":"/%E6%84%9F%E7%9F%A5/ichxdy15/#patch-embedding","684":"/%E6%84%9F%E7%9F%A5/occ/7f4uq5ih/#_3-2-3d-上下文关系先验-3d-crp","685":"/article/lhkmyeqo/#stack-栈","686":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#_4-3-几何重建","687":"/%E6%84%9F%E7%9F%A5/ggoqbqz5/#openocc","688":"/%E6%84%9F%E7%9F%A5/8daubjva/#小结","689":"/%E6%84%9F%E7%9F%A5/abafkauz/#_2-背景","690":"/%E6%84%9F%E7%9F%A5/occ/52xxd530/#_3-5-总体目标函数","691":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#信息融合研究的动机","692":"/%E6%84%9F%E7%9F%A5/6lykl9kg/#point-m2ae","693":"/%E6%84%9F%E7%9F%A5/occ/%E6%A6%82%E8%A7%88/9d77057p/#_3-1-以物体为中心的3d场景表示","694":"/%E6%84%9F%E7%9F%A5/occ/zkgf7k1b/#d-多阶段占据蒸馏","695":"/%E6%84%9F%E7%9F%A5/qidw72m1/#要解决的问题","696":"/%E6%84%9F%E7%9F%A5/j4q2bh9h/#deformable-conv","697":"/%E6%84%9F%E7%9F%A5/l2r6j7r9/#_2-3-2-集成","698":"/VLN/tfxszik8/#_5-1-显式编码-explicit-encoding","699":"/%E6%84%9F%E7%9F%A5/occ/otz54ixd/#e-共享编码器-解码器","700":"/%E6%84%9F%E7%9F%A5/occ/ekepu2n5/#_4-3-定量结果","701":"/%E6%84%9F%E7%9F%A5/occ/3byfb1am/#iii-occfusion","702":"/%E6%84%9F%E7%9F%A5/rc0nrwf6/#nuscenes-类别","703":"/%E6%84%9F%E7%9F%A5/nfq4b8kf/#_3-4-占据预测模块","704":"/%E6%84%9F%E7%9F%A5/occ/rjyln29i/#_3-3-基于分布的初始化","705":"/%E6%84%9F%E7%9F%A5/d2qthpop/#_3-2-局部空间占用预测模块","706":"/%E6%84%9F%E7%9F%A5/ichxdy15/#patch-merging","707":"/%E6%84%9F%E7%9F%A5/occ/7f4uq5ih/#体素体素关系","708":"/article/lhkmyeqo/#定义","709":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#_4-3-1-动态场景中网格重建的鲁棒性。","710":"/%E6%84%9F%E7%9F%A5/ggoqbqz5/#surroundocc","711":"/%E6%84%9F%E7%9F%A5/8daubjva/#_4-检测-跟踪","712":"/%E6%84%9F%E7%9F%A5/abafkauz/#_2-1-基于视觉的3d占用预测的定义","713":"/%E6%84%9F%E7%9F%A5/occ/52xxd530/#_4-实验","714":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#贡献","715":"/%E6%84%9F%E7%9F%A5/6lykl9kg/#geomae","716":"/%E6%84%9F%E7%9F%A5/occ/%E6%A6%82%E8%A7%88/9d77057p/#_3-2-gaussianformer-从图像到高斯分布","717":"/%E6%84%9F%E7%9F%A5/occ/zkgf7k1b/#iv-实验","718":"/%E6%84%9F%E7%9F%A5/qidw72m1/#history-memory-queue","719":"/%E6%84%9F%E7%9F%A5/j4q2bh9h/#defomable-roi-pooling","720":"/%E6%84%9F%E7%9F%A5/l2r6j7r9/#_3-实验","721":"/VLN/tfxszik8/#_5-2-隐式编码-implicit-encoding","722":"/%E6%84%9F%E7%9F%A5/occ/otz54ixd/#iv-实验结果","723":"/%E6%84%9F%E7%9F%A5/occ/ekepu2n5/#_4-4-消融研究","724":"/%E6%84%9F%E7%9F%A5/occ/3byfb1am/#a-问题陈述","725":"/%E6%84%9F%E7%9F%A5/rc0nrwf6/#_2-2-点云语义分割","726":"/%E6%84%9F%E7%9F%A5/nfq4b8kf/#_3-5-时间融合模块","727":"/%E6%84%9F%E7%9F%A5/occ/rjyln29i/#_4-实验","728":"/%E6%84%9F%E7%9F%A5/d2qthpop/#_3-3-在线更新高斯记忆","729":"/%E6%84%9F%E7%9F%A5/ichxdy15/#w-msa","730":"/%E6%84%9F%E7%9F%A5/occ/7f4uq5ih/#超体素体素关系","731":"/article/lhkmyeqo/#压入","732":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#_4-4-语义重建","733":"/%E6%84%9F%E7%9F%A5/ggoqbqz5/#occformer","734":"/%E6%84%9F%E7%9F%A5/8daubjva/#_4-1-3d-目标检测","735":"/%E6%84%9F%E7%9F%A5/abafkauz/#_2-2-真实标签生成","736":"/%E6%84%9F%E7%9F%A5/occ/52xxd530/#_4-1-数据集和评估指标","737":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#_2-背景","738":"/%E6%84%9F%E7%9F%A5/occ/%E6%A6%82%E8%A7%88/9d77057p/#_3-3-高斯到体素的溅射","739":"/%E6%84%9F%E7%9F%A5/occ/zkgf7k1b/#a-数据集和指标","740":"/%E6%84%9F%E7%9F%A5/qidw72m1/#propagation-transformer","741":"/%E6%84%9F%E7%9F%A5/j4q2bh9h/#roi-pooling-average","742":"/%E6%84%9F%E7%9F%A5/l2r6j7r9/#数据集与指标","743":"/VLN/tfxszik8/#_5-2-1-closed-vocabulary-encoding","744":"/%E6%84%9F%E7%9F%A5/occ/otz54ixd/#a-实现细节","745":"/%E6%84%9F%E7%9F%A5/occ/ekepu2n5/#_4-5-定性结果","746":"/%E6%84%9F%E7%9F%A5/occ/3byfb1am/#b-总体架构","747":"/%E6%84%9F%E7%9F%A5/rc0nrwf6/#_2-2-1-标注格式","748":"/%E6%84%9F%E7%9F%A5/nfq4b8kf/#_4-实验","749":"/%E6%84%9F%E7%9F%A5/occ/rjyln29i/#_4-1-数据集和评估指标","750":"/%E6%84%9F%E7%9F%A5/d2qthpop/#_3-4-embodiedocc-一个具身框架","751":"/%E6%84%9F%E7%9F%A5/ichxdy15/#masked-msa","752":"/%E6%84%9F%E7%9F%A5/occ/7f4uq5ih/#_3d-上下文关系先验层","753":"/article/lhkmyeqo/#弹出","754":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#_4-5-循环闭合和网格变形","755":"/%E6%84%9F%E7%9F%A5/ggoqbqz5/#renderocc-nerf","756":"/%E6%84%9F%E7%9F%A5/8daubjva/#_4-1-1-基于区域建议的方法","757":"/%E6%84%9F%E7%9F%A5/abafkauz/#_2-3-数据集","758":"/%E6%84%9F%E7%9F%A5/occ/52xxd530/#_4-2-实现细节","759":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#_2-1-占用感知的简要历史","760":"/%E6%84%9F%E7%9F%A5/occ/%E6%A6%82%E8%A7%88/9d77057p/#_4-实验","761":"/%E6%84%9F%E7%9F%A5/occ/zkgf7k1b/#b-实现细节","762":"/%E6%84%9F%E7%9F%A5/qidw72m1/#mln","763":"/%E6%84%9F%E7%9F%A5/j4q2bh9h/#position-sensitive-roi-pooling","764":"/%E6%84%9F%E7%9F%A5/l2r6j7r9/#实现细节","765":"/VLN/tfxszik8/#_5-2-2-open-vocabulary-encoding","766":"/%E6%84%9F%E7%9F%A5/occ/otz54ixd/#b-损失函数","767":"/%E6%84%9F%E7%9F%A5/occ/ekepu2n5/#_5-结论","768":"/%E6%84%9F%E7%9F%A5/occ/3byfb1am/#c-环视图像特征提取","769":"/%E6%84%9F%E7%9F%A5/rc0nrwf6/#_2-2-2-语义类别","770":"/%E6%84%9F%E7%9F%A5/nfq4b8kf/#_4-1-实验设置","771":"/%E6%84%9F%E7%9F%A5/occ/rjyln29i/#_4-2-实现细节","772":"/%E6%84%9F%E7%9F%A5/d2qthpop/#_4-实验","773":"/%E6%84%9F%E7%9F%A5/occ/7f4uq5ih/#_3-3-损失函数","774":"/article/lhkmyeqo/#栈顶元素","775":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#_4-6-解析人类和对象","776":"/%E6%84%9F%E7%9F%A5/ggoqbqz5/#sparseocc","777":"/%E6%84%9F%E7%9F%A5/8daubjva/#基于多视图的方法","778":"/%E6%84%9F%E7%9F%A5/abafkauz/#_2-4-评估指标","779":"/%E6%84%9F%E7%9F%A5/occ/52xxd530/#_4-3-与最新方法的比较","780":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#_2-2-任务定义","781":"/%E6%84%9F%E7%9F%A5/occ/%E6%A6%82%E8%A7%88/9d77057p/#_4-1-数据集","782":"/%E6%84%9F%E7%9F%A5/occ/zkgf7k1b/#c-有限标签下的高效学习结果","783":"/%E6%84%9F%E7%9F%A5/qidw72m1/#实验-1","784":"/%E6%84%9F%E7%9F%A5/j4q2bh9h/#visualization","785":"/%E6%84%9F%E7%9F%A5/l2r6j7r9/#消融研究","786":"/VLN/tfxszik8/#_6-评估方法-evaluation-methodologies","787":"/%E6%84%9F%E7%9F%A5/occ/otz54ixd/#c-数据集","788":"/%E6%84%9F%E7%9F%A5/occ/ekepu2n5/#补充材料","789":"/%E6%84%9F%E7%9F%A5/occ/3byfb1am/#d-激光雷达密集-3d-点云特征提取","790":"/%E6%84%9F%E7%9F%A5/rc0nrwf6/#nuscenes-lidarseg-类别","791":"/%E6%84%9F%E7%9F%A5/nfq4b8kf/#_4-2-与最先进方法的比较","792":"/%E6%84%9F%E7%9F%A5/occ/rjyln29i/#_4-3-主要结果","793":"/%E6%84%9F%E7%9F%A5/d2qthpop/#_4-1-embodiedocc-scannet基准测试","794":"/%E6%84%9F%E7%9F%A5/occ/7f4uq5ih/#_3-3-1-场景类别亲和力损失","795":"/article/lhkmyeqo/#是否为空","796":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#_4-7-解析地点和房间","797":"/%E6%84%9F%E7%9F%A5/ggoqbqz5/#fastocc","798":"/%E6%84%9F%E7%9F%A5/8daubjva/#基于分割的方法","799":"/%E6%84%9F%E7%9F%A5/abafkauz/#_2-5-关键挑战","800":"/%E6%84%9F%E7%9F%A5/occ/52xxd530/#_4-4-消融研究","801":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#_2-3-相关工作","802":"/%E6%84%9F%E7%9F%A5/occ/%E6%A6%82%E8%A7%88/9d77057p/#_4-2-评估指标","803":"/%E6%84%9F%E7%9F%A5/occ/zkgf7k1b/#d-提出的融合式占用网络的结果","804":"/%E6%84%9F%E7%9F%A5/j4q2bh9h/#deformable-convnets-v2-more-deformable-better-results","805":"/%E6%84%9F%E7%9F%A5/l2r6j7r9/#规模化","806":"/VLN/tfxszik8/#_6-1-extrinsic-evaluation","807":"/%E6%84%9F%E7%9F%A5/occ/otz54ixd/#d-性能评估指标","808":"/%E6%84%9F%E7%9F%A5/occ/ekepu2n5/#a-相关工作","809":"/%E6%84%9F%E7%9F%A5/occ/3byfb1am/#e-雷达稀疏-3d-点云特征提取","810":"/%E6%84%9F%E7%9F%A5/rc0nrwf6/#_3-nuscenes-数据转换到-occupancy-数据","811":"/%E6%84%9F%E7%9F%A5/nfq4b8kf/#_4-3-消融研究","812":"/%E6%84%9F%E7%9F%A5/occ/rjyln29i/#_4-4-消融研究","813":"/%E6%84%9F%E7%9F%A5/d2qthpop/#_4-2-实现细节","814":"/%E6%84%9F%E7%9F%A5/occ/7f4uq5ih/#_3-3-2-视锥比例损失","815":"/article/lhkmyeqo/#队列","816":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#_4-8-计时","817":"/%E6%84%9F%E7%9F%A5/ggoqbqz5/#gaussianformer","818":"/%E6%84%9F%E7%9F%A5/8daubjva/#基于视锥的方法","819":"/%E6%84%9F%E7%9F%A5/abafkauz/#_3-特征增强方法","820":"/%E6%84%9F%E7%9F%A5/occ/52xxd530/#_5-结论","821":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#_2-3-1-鸟瞰图感知","822":"/%E6%84%9F%E7%9F%A5/occ/%E6%A6%82%E8%A7%88/9d77057p/#_4-3-实现细节","823":"/%E6%84%9F%E7%9F%A5/occ/zkgf7k1b/#e-基于知识蒸馏的视觉-occnet-的结果","824":"/%E6%84%9F%E7%9F%A5/j4q2bh9h/#dcn-v3","825":"/%E6%84%9F%E7%9F%A5/l2r6j7r9/#后处理-1","826":"/VLN/tfxszik8/#_6-2-intrinsic-evaluation","827":"/%E6%84%9F%E7%9F%A5/occ/otz54ixd/#e-模型性能分析","828":"/%E6%84%9F%E7%9F%A5/occ/ekepu2n5/#b-wildocc-数据集","829":"/%E6%84%9F%E7%9F%A5/occ/3byfb1am/#f-动态融合-3d-2d","830":"/%E6%84%9F%E7%9F%A5/rc0nrwf6/#_3-1-方法","831":"/%E6%84%9F%E7%9F%A5/nfq4b8kf/#_5-结论","832":"/%E6%84%9F%E7%9F%A5/occ/rjyln29i/#_4-5-可视化","833":"/%E6%84%9F%E7%9F%A5/d2qthpop/#_4-3-结果与分析","834":"/%E6%84%9F%E7%9F%A5/occ/7f4uq5ih/#_3-4-训练策略","835":"/article/lhkmyeqo/#queue","836":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#_4-9-在nvidia-tx2嵌入式计算机上的计时","837":"/%E6%84%9F%E7%9F%A5/ggoqbqz5/#gaussianformer2","838":"/%E6%84%9F%E7%9F%A5/8daubjva/#其他方法","839":"/%E6%84%9F%E7%9F%A5/abafkauz/#_3-1-基于bev的方法","840":"/%E6%84%9F%E7%9F%A5/occ/52xxd530/#附加材料","841":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#_2-3-2-3d语义场景补全","842":"/%E6%84%9F%E7%9F%A5/occ/%E6%A6%82%E8%A7%88/9d77057p/#_4-4-结果与分析","843":"/%E6%84%9F%E7%9F%A5/occ/zkgf7k1b/#f-定性结果","844":"/%E6%84%9F%E7%9F%A5/j4q2bh9h/#dcnv2","845":"/%E6%84%9F%E7%9F%A5/l2r6j7r9/#_4-结论","846":"/VLN/tfxszik8/#_6-3-总结","847":"/%E6%84%9F%E7%9F%A5/occ/otz54ixd/#f-在具有挑战性的场景下的定性研究","848":"/%E6%84%9F%E7%9F%A5/occ/ekepu2n5/#c-评估指标","849":"/%E6%84%9F%E7%9F%A5/occ/3byfb1am/#iv-实验结果","850":"/%E6%84%9F%E7%9F%A5/rc0nrwf6/#_3-2-转换脚本","851":"/%E6%84%9F%E7%9F%A5/occ/rjyln29i/#_5-结论","852":"/%E6%84%9F%E7%9F%A5/d2qthpop/#_5-结论","853":"/%E6%84%9F%E7%9F%A5/occ/7f4uq5ih/#_4-实验","854":"/article/lhkmyeqo/#queue-其他操作","855":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#_4-10-真实生活实验","856":"/%E6%84%9F%E7%9F%A5/ggoqbqz5/#室内","857":"/%E6%84%9F%E7%9F%A5/8daubjva/#_4-1-2-single-shot-方法-end-to-end","858":"/%E6%84%9F%E7%9F%A5/abafkauz/#_3-2-基于tpv的方法","859":"/%E6%84%9F%E7%9F%A5/occ/52xxd530/#_6-运行时间比较","860":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#_2-3-3-基于图像的3d重建","861":"/%E6%84%9F%E7%9F%A5/occ/%E6%A6%82%E8%A7%88/9d77057p/#_5-结论与讨论","862":"/%E6%84%9F%E7%9F%A5/occ/zkgf7k1b/#v-结论","863":"/%E6%84%9F%E7%9F%A5/j4q2bh9h/#dcnv3","864":"/VLN/tfxszik8/#_7-开放挑战-open-challenges","865":"/%E6%84%9F%E7%9F%A5/occ/otz54ixd/#g-模型效率研究","866":"/%E6%84%9F%E7%9F%A5/occ/ekepu2n5/#d-实现细节","867":"/%E6%84%9F%E7%9F%A5/occ/3byfb1am/#a-实现细节","868":"/%E6%84%9F%E7%9F%A5/occ/rjyln29i/#补充材料","869":"/%E6%84%9F%E7%9F%A5/d2qthpop/#附录","870":"/%E6%84%9F%E7%9F%A5/occ/7f4uq5ih/#_4-1-基线方法","871":"/article/lhkmyeqo/#deque","872":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#_4-10-1-学校-和-航空宇航-。","873":"/%E6%84%9F%E7%9F%A5/ggoqbqz5/#monoscene","874":"/%E6%84%9F%E7%9F%A5/8daubjva/#基于bev的方法","875":"/%E6%84%9F%E7%9F%A5/abafkauz/#_3-3-基于体素的方法","876":"/%E6%84%9F%E7%9F%A5/occ/52xxd530/#_7-达到最终性能的消融实验","877":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#_3-方法论","878":"/%E6%84%9F%E7%9F%A5/occ/%E6%A6%82%E8%A7%88/9d77057p/#局限性","879":"/%E6%84%9F%E7%9F%A5/occ/zkgf7k1b/#参考文献","880":"/%E6%84%9F%E7%9F%A5/j4q2bh9h/#构建模型","881":"/VLN/tfxszik8/#_8-未来研究方向","882":"/%E6%84%9F%E7%9F%A5/occ/otz54ixd/#h-模型组件的消融研究","883":"/%E6%84%9F%E7%9F%A5/occ/ekepu2n5/#e-补充实验","884":"/%E6%84%9F%E7%9F%A5/occ/3byfb1am/#b-损失函数","885":"/%E6%84%9F%E7%9F%A5/occ/rjyln29i/#a-视频演示","886":"/%E6%84%9F%E7%9F%A5/d2qthpop/#a-embodiedocc-scannet-数据集细节","887":"/%E6%84%9F%E7%9F%A5/occ/7f4uq5ih/#_4-2-性能","888":"/article/lhkmyeqo/#初始化-1","889":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#_4-10-2-白猫头鹰-。","890":"/%E6%84%9F%E7%9F%A5/ggoqbqz5/#monocular-occupancy-prediction-for-scalable-indoor-scenes","891":"/%E6%84%9F%E7%9F%A5/8daubjva/#基于点云的方法","892":"/%E6%84%9F%E7%9F%A5/abafkauz/#_4-部署友好方法","893":"/%E6%84%9F%E7%9F%A5/occ/52xxd530/#_8-检测性能","894":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#_3-1-以激光雷达为中心的占用感知","895":"/%E6%84%9F%E7%9F%A5/occ/%E6%A6%82%E8%A7%88/9d77057p/#附录部分-appendix","896":"/%E6%84%9F%E7%9F%A5/j4q2bh9h/#stacking-rules","897":"/VLN/tfxszik8/#_8-1-通用型地图","898":"/%E6%84%9F%E7%9F%A5/occ/otz54ixd/#v-结论","899":"/%E6%84%9F%E7%9F%A5/occ/ekepu2n5/#e-1-定性结果","900":"/%E6%84%9F%E7%9F%A5/occ/3byfb1am/#c-数据集","901":"/%E6%84%9F%E7%9F%A5/occ/rjyln29i/#b-kitti-360-上的可视化","902":"/%E6%84%9F%E7%9F%A5/d2qthpop/#b-额外可视化","903":"/%E6%84%9F%E7%9F%A5/occ/7f4uq5ih/#_4-2-1-评估","904":"/article/lhkmyeqo/#操作函数","905":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#_5-激励示例","906":"/%E6%84%9F%E7%9F%A5/ggoqbqz5/#sliceocc","907":"/%E6%84%9F%E7%9F%A5/8daubjva/#_4-2-3d目标跟踪","908":"/%E6%84%9F%E7%9F%A5/abafkauz/#_4-1-视角分解方法","909":"/%E6%84%9F%E7%9F%A5/occ/52xxd530/#_9-可视化","910":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#_3-1-1-通用流程","911":"/%E6%84%9F%E7%9F%A5/occ/%E6%A6%82%E8%A7%88/9d77057p/#a-视频演示","912":"/%E6%84%9F%E7%9F%A5/j4q2bh9h/#scaling-rules","913":"/VLN/tfxszik8/#_8-2-稠密而高效的地图","914":"/%E6%84%9F%E7%9F%A5/occ/ekepu2n5/#e-2-定量结果","915":"/%E6%84%9F%E7%9F%A5/occ/3byfb1am/#d-性能评估指标","916":"/%E6%84%9F%E7%9F%A5/occ/rjyln29i/#c-评估指标细节","917":"/%E6%84%9F%E7%9F%A5/occ/7f4uq5ih/#_4-2-2-与-2-5-3d-输入基线的比较","918":"/article/lhkmyeqo/#迭代器算法","919":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#_6-应用","920":"/%E6%84%9F%E7%9F%A5/ggoqbqz5/#embodiedocc","921":"/%E6%84%9F%E7%9F%A5/8daubjva/#_4-3-3d场景流估计","922":"/%E6%84%9F%E7%9F%A5/abafkauz/#从粗到细的方法","923":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#_3-1-2-2d与3d分支的融合","924":"/%E6%84%9F%E7%9F%A5/occ/%E6%A6%82%E8%A7%88/9d77057p/#b-额外的可视化","925":"/%E6%84%9F%E7%9F%A5/j4q2bh9h/#result","926":"/VLN/tfxszik8/#_8-3-动态地图","927":"/%E6%84%9F%E7%9F%A5/occ/3byfb1am/#e-模型性能分析","928":"/%E6%84%9F%E7%9F%A5/occ/7f4uq5ih/#_4-3-消融研究","929":"/article/lhkmyeqo/#算法","930":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#_6-1-层次路径规划","931":"/%E6%84%9F%E7%9F%A5/8daubjva/#小结-1","932":"/%E6%84%9F%E7%9F%A5/abafkauz/#_5-标签高效方法","933":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#_3-2-以视觉为中心的占用感知","934":"/%E6%84%9F%E7%9F%A5/occ/%E6%A6%82%E8%A7%88/9d77057p/#c-额外的消融研究","935":"/VLN/tfxszik8/#_8-4-混合地图结构","936":"/%E6%84%9F%E7%9F%A5/occ/3byfb1am/#f-具有挑战性的场景性能分析","937":"/%E6%84%9F%E7%9F%A5/occ/7f4uq5ih/#_5-讨论","938":"/article/lhkmyeqo/#总结","939":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#_6-2-语义路径规划","940":"/%E6%84%9F%E7%9F%A5/8daubjva/#_5-分割","941":"/%E6%84%9F%E7%9F%A5/abafkauz/#无注释方法","942":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#_3-2-1-通用流程","943":"/VLN/tfxszik8/#_8-5-设计评估指标","944":"/%E6%84%9F%E7%9F%A5/occ/3byfb1am/#g-感知范围对模型性能的影响","945":"/%E6%84%9F%E7%9F%A5/occ/7f4uq5ih/#局限性","946":"/article/lhkmyeqo/#priority-queue","947":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#_6-3-dsg上的路径规划性能","948":"/%E6%84%9F%E7%9F%A5/8daubjva/#_5-1-3d-场景分割","949":"/%E6%84%9F%E7%9F%A5/abafkauz/#无lidar方法","950":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#_3-2-2-2d到3d的转换","951":"/VLN/tfxszik8/#_8-6-小结","952":"/%E6%84%9F%E7%9F%A5/occ/3byfb1am/#h-框架定性分析","953":"/%E6%84%9F%E7%9F%A5/occ/7f4uq5ih/#更广泛的影响与伦理问题","954":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#_7-相关工作","955":"/%E6%84%9F%E7%9F%A5/8daubjva/#_5-1-1-基于投影的网络","956":"/%E6%84%9F%E7%9F%A5/abafkauz/#_6-未来展望","957":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#_3-2-3-以视觉为中心的占用感知中的信息融合","958":"/VLN/tfxszik8/#_9-结论","959":"/%E6%84%9F%E7%9F%A5/occ/3byfb1am/#i-框架训练收敛速度研究","960":"/%E6%84%9F%E7%9F%A5/occ/7f4uq5ih/#致谢","961":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#_7-1-世界表示-场景图。","962":"/%E6%84%9F%E7%9F%A5/8daubjva/#_5-1-2-基于离散化的方法","963":"/%E6%84%9F%E7%9F%A5/abafkauz/#数据层面","964":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#_3-3-多模态占用感知","965":"/%E6%84%9F%E7%9F%A5/occ/3byfb1am/#j-框架效率研究","966":"/%E6%84%9F%E7%9F%A5/occ/7f4uq5ih/#附录","967":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#_7-2-感知算法-动态环境中的slam和vio。","968":"/%E6%84%9F%E7%9F%A5/8daubjva/#_5-1-3-混合方法","969":"/%E6%84%9F%E7%9F%A5/abafkauz/#方法层面","970":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#_3-3-1-通用流程","971":"/%E6%84%9F%E7%9F%A5/occ/3byfb1am/#k-框架消融研究","972":"/%E6%84%9F%E7%9F%A5/occ/7f4uq5ih/#a-架构细节","973":"/%E5%88%86%E5%B1%82%E8%AF%AD%E4%B9%89/faonhdtl/#_8-结论","974":"/%E6%84%9F%E7%9F%A5/8daubjva/#_5-1-4-基于点的方法","975":"/%E6%84%9F%E7%9F%A5/abafkauz/#任务层面","976":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#_3-3-2-多模态占用感知中的信息融合","977":"/%E6%84%9F%E7%9F%A5/occ/3byfb1am/#v-结论","978":"/%E6%84%9F%E7%9F%A5/occ/7f4uq5ih/#a-1-基线方法","979":"/%E6%84%9F%E7%9F%A5/8daubjva/#小结-2","980":"/%E6%84%9F%E7%9F%A5/abafkauz/#致谢","981":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#_3-4-网络训练","982":"/%E6%84%9F%E7%9F%A5/occ/7f4uq5ih/#a-2-monoscene","983":"/%E6%84%9F%E7%9F%A5/8daubjva/#_5-2-实例分割","984":"/%E6%84%9F%E7%9F%A5/abafkauz/#利益冲突","985":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#_3-4-1-强监督训练","986":"/%E6%84%9F%E7%9F%A5/occ/7f4uq5ih/#b-附加结果","987":"/%E6%84%9F%E7%9F%A5/8daubjva/#_5-2-1-基于proposal的方法","988":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#_3-4-2-其他监督训练","989":"/%E6%84%9F%E7%9F%A5/occ/7f4uq5ih/#b-1-semantickitti","990":"/%E6%84%9F%E7%9F%A5/8daubjva/#_5-2-2-proposal-free-methods","991":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#_4-评估","992":"/%E6%84%9F%E7%9F%A5/occ/7f4uq5ih/#b-2-nyuv2","993":"/%E6%84%9F%E7%9F%A5/8daubjva/#_5-3-部件分割","994":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#_4-1-数据集和指标","995":"/%E6%84%9F%E7%9F%A5/occ/7f4uq5ih/#b-3-泛化能力","996":"/%E6%84%9F%E7%9F%A5/8daubjva/#小结-3","997":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#_4-1-1-数据集","998":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#_4-1-2-评估指标","999":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#_4-2-性能","1000":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#_4-2-1-感知准确性","1001":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#_4-2-2-推理速度","1002":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#_5-挑战与机遇","1003":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#_5-1-基于占用的自动驾驶应用","1004":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#_5-2-部署效率","1005":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#_5-3-鲁棒的3d占用感知","1006":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#_5-4-广义3d占用感知","1007":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#_6-结论","1008":"/%E6%84%9F%E7%9F%A5/vfkfho9v/#致谢"},"fieldIds":{"title":0,"titles":1,"text":2},"fieldLength":{"0":[1,1,2],"1":[1,1,1],"2":[1,1,3],"3":[1,1,1],"4":[1,1,1],"5":[1,1,51],"6":[1,1,1],"7":[2,1,1],"8":[1,1,101],"9":[1,1,1],"10":[2,1,1],"11":[2,2,44],"12":[2,1,7],"13":[2,1,75],"14":[1,2,1],"15":[2,1,21],"16":[2,1,1],"17":[1,4,48],"18":[2,1,5],"19":[2,2,1],"20":[3,1,49],"21":[1,3,1],"22":[2,2,1],"23":[1,2,61],"24":[1,1,43],"25":[1,2,1],"26":[2,2,41],"27":[3,2,76],"28":[1,4,1],"29":[1,4,1],"30":[1,2,81],"31":[1,1,94],"32":[2,3,88],"33":[2,2,18],"34":[3,2,39],"35":[1,5,1],"36":[5,5,62],"37":[1,1,1],"38":[5,3,95],"39":[2,1,1],"40":[2,5,54],"41":[2,1,69],"42":[1,1,1],"43":[8,2,68],"44":[1,1,1],"45":[1,1,31],"46":[2,3,1],"47":[2,5,25],"48":[6,1,61],"49":[3,1,9],"50":[5,1,1],"51":[9,2,50],"52":[1,1,55],"53":[8,1,1],"54":[6,1,29],"55":[4,1,1],"56":[1,1,1],"57":[2,4,201],"58":[3,4,19],"59":[3,1,5],"60":[1,5,32],"61":[1,1,1],"62":[1,1,21],"63":[1,2,54],"64":[1,8,54],"65":[11,1,6],"66":[1,4,129],"67":[2,6,70],"68":[4,1,8],"69":[1,5,9],"70":[1,1,1],"71":[1,1,1],"72":[1,1,36],"73":[1,1,23],"74":[1,8,26],"75":[10,1,35],"76":[2,2,52],"77":[4,1,7],"78":[3,5,51],"79":[8,2,2],"80":[1,1,51],"81":[1,1,4],"82":[2,1,115],"83":[1,2,15],"84":[11,1,43],"85":[1,1,2],"86":[1,1,1],"87":[2,4,42],"88":[4,1,9],"89":[3,2,1],"90":[2,1,135],"91":[1,1,1],"92":[2,1,24],"93":[1,2,46],"94":[1,1,12],"95":[1,1,4],"96":[2,1,58],"97":[1,4,7],"98":[1,1,44],"99":[3,1,21],"100":[2,1,20],"101":[4,1,1],"102":[1,1,15],"103":[3,3,24],"104":[1,2,58],"105":[2,1,51],"106":[1,1,68],"107":[4,4,68],"108":[1,1,2],"109":[3,1,143],"110":[6,3,13],"111":[2,4,101],"112":[1,1,50],"113":[1,1,5],"114":[2,3,130],"115":[1,2,55],"116":[2,1,188],"117":[8,1,48],"118":[1,1,2],"119":[1,1,2],"120":[1,2,100],"121":[3,1,141],"122":[1,1,6],"123":[3,8,134],"124":[2,4,55],"125":[2,1,95],"126":[1,1,173],"127":[1,1,1],"128":[3,3,104],"129":[1,1,63],"130":[1,2,56],"131":[1,3,217],"132":[7,1,36],"133":[1,1,60],"134":[1,1,1],"135":[1,1,34],"136":[1,2,71],"137":[5,1,169],"138":[1,1,34],"139":[3,8,107],"140":[2,4,162],"141":[1,3,81],"142":[1,1,1],"143":[2,1,26],"144":[1,1,1],"145":[3,3,70],"146":[1,2,58],"147":[2,1,43],"148":[4,1,12],"149":[2,1,80],"150":[1,1,1],"151":[1,1,7],"152":[1,2,33],"153":[2,1,364],"154":[2,1,1],"155":[8,3,33],"156":[2,1,1],"157":[1,2,34],"158":[2,1,32],"159":[1,1,15],"160":[2,1,5],"161":[1,2,42],"162":[5,3,86],"163":[1,1,10],"164":[2,4,16],"165":[3,1,10],"166":[1,1,1],"167":[1,1,9],"168":[3,1,22],"169":[2,3,14],"170":[1,1,16],"171":[4,10,102],"172":[1,3,97],"173":[1,2,113],"174":[1,1,65],"175":[1,1,61],"176":[3,3,92],"177":[1,1,36],"178":[3,1,65],"179":[2,1,10],"180":[1,4,22],"181":[2,1,80],"182":[1,1,1],"183":[4,1,23],"184":[1,1,107],"185":[1,1,18],"186":[2,3,1],"187":[2,3,5],"188":[3,1,40],"189":[3,10,95],"190":[1,3,62],"191":[1,2,26],"192":[1,1,1],"193":[1,1,27],"194":[1,1,1],"195":[3,3,72],"196":[2,1,121],"197":[4,4,64],"198":[1,4,14],"199":[2,1,8],"200":[1,1,1],"201":[1,1,36],"202":[1,1,1],"203":[2,4,16],"204":[1,1,35],"205":[1,1,55],"206":[2,5,35],"207":[2,3,26],"208":[4,1,194],"209":[4,10,157],"210":[2,1,46],"211":[1,2,21],"212":[1,2,1],"213":[1,2,26],"214":[4,1,1],"215":[1,1,12],"216":[2,3,41],"217":[2,1,33],"218":[4,4,28],"219":[1,1,2],"220":[1,4,85],"221":[3,1,44],"222":[1,1,1],"223":[1,1,14],"224":[2,1,10],"225":[1,4,42],"226":[1,1,1],"227":[4,2,12],"228":[1,5,15],"229":[3,1,1],"230":[1,1,1],"231":[3,3,22],"232":[5,3,1],"233":[1,2,11],"234":[3,3,9],"235":[3,2,192],"236":[2,4,101],"237":[1,1,11],"238":[2,1,15],"239":[1,3,5],"240":[4,4,15],"241":[2,1,1],"242":[1,1,1],"243":[1,1,22],"244":[8,1,14],"245":[1,5,1],"246":[1,1,1],"247":[1,1,38],"248":[2,2,12],"249":[2,3,1],"250":[1,4,12],"251":[2,2,28],"252":[4,5,74],"253":[1,8,58],"254":[1,1,244],"255":[3,3,7],"256":[2,2,33],"257":[2,4,55],"258":[1,1,18],"259":[1,1,3],"260":[5,3,42],"261":[1,3,26],"262":[3,4,45],"263":[2,1,32],"264":[8,2,58],"265":[1,2,29],"266":[8,1,41],"267":[2,6,7],"268":[1,1,56],"269":[2,1,4],"270":[1,1,17],"271":[2,5,71],"272":[1,4,12],"273":[2,2,127],"274":[3,5,166],"275":[1,1,23],"276":[1,8,89],"277":[1,1,271],"278":[2,2,42],"279":[1,2,25],"280":[2,4,162],"281":[1,1,1],"282":[1,1,1],"283":[3,3,59],"284":[1,4,6],"285":[3,1,210],"286":[2,1,1],"287":[1,2,27],"288":[1,2,1],"289":[1,9,20],"290":[1,1,23],"291":[2,6,10],"292":[2,1,16],"293":[1,1,1],"294":[1,1,9],"295":[2,5,6],"296":[3,1,30],"297":[1,1,1],"298":[1,1,1],"299":[3,5,12],"300":[1,1,1],"301":[3,3,85],"302":[1,1,101],"303":[2,2,13],"304":[1,2,28],"305":[1,2,32],"306":[1,1,47],"307":[1,1,1],"308":[3,3,47],"309":[1,4,7],"310":[6,3,96],"311":[2,3,6],"312":[7,2,63],"313":[2,3,36],"314":[8,1,33],"315":[2,1,103],"316":[2,6,49],"317":[1,1,11],"318":[2,2,12],"319":[1,1,8],"320":[2,1,17],"321":[3,4,35],"322":[1,1,4],"323":[1,1,14],"324":[2,1,12],"325":[2,2,65],"326":[3,1,10],"327":[3,1,58],"328":[3,2,53],"329":[1,2,15],"330":[3,2,1],"331":[2,1,34],"332":[1,1,5],"333":[1,1,138],"334":[2,3,178],"335":[1,4,9],"336":[5,3,50],"337":[3,4,28],"338":[1,1,17],"339":[1,3,17],"340":[3,1,42],"341":[2,1,23],"342":[2,5,34],"343":[1,1,25],"344":[4,2,14],"345":[1,2,95],"346":[2,3,1],"347":[2,7,11],"348":[1,1,1],"349":[1,1,54],"350":[4,3,41],"351":[2,4,145],"352":[2,4,88],"353":[1,1,1],"354":[1,2,10],"355":[2,5,72],"356":[2,1,17],"357":[2,1,43],"358":[1,1,31],"359":[1,1,3],"360":[2,1,171],"361":[1,4,8],"362":[6,3,89],"363":[4,4,42],"364":[1,1,1],"365":[7,2,13],"366":[1,2,65],"367":[1,1,6],"368":[1,4,10],"369":[1,2,56],"370":[2,5,1],"371":[1,1,15],"372":[5,2,109],"373":[3,2,91],"374":[1,5,19],"375":[2,7,13],"376":[2,2,2],"377":[1,1,24],"378":[4,3,68],"379":[1,2,95],"380":[2,4,114],"381":[1,1,1],"382":[1,2,80],"383":[1,5,9],"384":[1,1,120],"385":[3,3,4],"386":[2,1,22],"387":[1,1,25],"388":[2,1,14],"389":[1,4,8],"390":[5,3,426],"391":[2,3,6],"392":[1,1,30],"393":[1,1,1],"394":[1,1,40],"395":[2,1,33],"396":[1,4,21],"397":[1,2,1],"398":[1,4,8],"399":[2,1,21],"400":[3,2,20],"401":[1,2,8],"402":[1,5,29],"403":[1,4,1],"404":[4,2,1],"405":[2,2,69],"406":[3,3,34],"407":[2,2,12],"408":[3,1,64],"409":[1,1,32],"410":[1,2,53],"411":[3,2,29],"412":[5,2,27],"413":[3,3,8],"414":[2,1,24],"415":[1,1,24],"416":[1,1,1],"417":[3,3,133],"418":[1,4,9],"419":[5,3,201],"420":[4,4,91],"421":[2,1,171],"422":[10,2,44],"423":[1,1,30],"424":[1,2,30],"425":[1,2,71],"426":[1,4,23],"427":[3,3,15],"428":[2,1,22],"429":[2,2,47],"430":[1,1,1],"431":[2,5,54],"432":[2,5,11],"433":[3,6,4],"434":[3,4,40],"435":[4,3,206],"436":[1,2,29],"437":[2,1,333],"438":[2,1,67],"439":[1,2,22],"440":[1,2,42],"441":[2,2,27],"442":[1,3,1],"443":[2,2,3],"444":[2,1,105],"445":[10,1,13],"446":[1,1,1],"447":[3,3,75],"448":[3,3,1],"449":[5,3,72],"450":[3,4,17],"451":[2,1,1],"452":[9,2,50],"453":[1,1,11],"454":[1,2,5],"455":[2,2,87],"456":[1,4,35],"457":[1,3,4],"458":[1,1,22],"459":[1,2,6],"460":[1,1,4],"461":[1,2,1],"462":[1,5,57],"463":[1,5,17],"464":[3,6,87],"465":[2,1,35],"466":[2,3,34],"467":[2,1,63],"468":[2,1,1],"469":[1,2,49],"470":[1,2,38],"471":[2,2,35],"472":[3,3,1],"473":[2,2,7],"474":[2,1,66],"475":[1,1,28],"476":[2,1,40],"477":[1,1,23],"478":[2,1,88],"479":[2,4,10],"480":[6,3,129],"481":[1,6,117],"482":[3,3,96],"483":[1,1,1],"484":[1,1,1],"485":[1,2,12],"486":[1,1,21],"487":[2,2,1],"488":[7,1,29],"489":[1,3,21],"490":[1,1,29],"491":[1,2,1],"492":[2,3,36],"493":[1,4,16],"494":[2,2,1],"495":[3,3,176],"496":[2,3,106],"497":[3,3,19],"498":[2,2,19],"499":[1,2,10],"500":[2,1,53],"501":[1,2,1],"502":[2,1,27],"503":[2,1,106],"504":[3,3,46],"505":[1,1,31],"506":[1,1,1],"507":[2,1,82],"508":[1,1,14],"509":[2,4,10],"510":[3,3,30],"511":[1,6,65],"512":[5,3,35],"513":[4,2,72],"514":[1,1,24],"515":[3,1,18],"516":[1,1,33],"517":[2,4,50],"518":[4,8,52],"519":[1,2,28],"520":[2,1,30],"521":[2,2,1],"522":[2,3,145],"523":[3,1,1],"524":[3,4,27],"525":[3,3,229],"526":[1,1,13],"527":[3,3,37],"528":[1,2,32],"529":[1,1,1],"530":[1,3,22],"531":[1,2,1],"532":[3,3,181],"533":[2,1,2],"534":[4,3,278],"535":[2,1,77],"536":[1,1,35],"537":[1,1,12],"538":[2,1,34],"539":[1,1,42],"540":[2,4,8],"541":[2,1,28],"542":[3,4,4],"543":[2,1,1],"544":[1,1,39],"545":[1,1,90],"546":[1,4,1],"547":[2,1,99],"548":[2,4,26],"549":[2,8,57],"550":[1,2,63],"551":[2,1,7],"552":[1,1,62],"553":[2,1,26],"554":[1,4,52],"555":[3,4,1],"556":[7,3,50],"557":[1,1,13],"558":[2,1,1],"559":[4,3,12],"560":[1,2,4],"561":[1,3,42],"562":[1,3,36],"563":[3,3,122],"564":[2,3,61],"565":[4,1,1],"566":[2,1,76],"567":[2,1,95],"568":[1,1,59],"569":[1,1,1],"570":[2,1,109],"571":[2,4,77],"572":[3,3,43],"573":[2,1,7],"574":[1,6,89],"575":[1,1,2],"576":[3,8,48],"577":[3,1,16],"578":[1,1,45],"579":[1,5,50],"580":[2,1,1],"581":[2,2,1],"582":[2,1,48],"583":[1,3,13],"584":[1,1,28],"585":[1,3,92],"586":[2,1,14],"587":[2,4,1],"588":[4,9,167],"589":[1,1,67],"590":[2,3,41],"591":[2,3,32],"592":[1,3,40],"593":[2,1,34],"594":[1,3,23],"595":[2,3,129],"596":[2,3,35],"597":[1,5,12],"598":[2,1,25],"599":[2,1,68],"600":[2,1,44],"601":[1,1,21],"602":[2,1,1],"603":[2,1,150],"604":[2,4,8],"605":[5,6,158],"606":[1,2,1],"607":[1,6,51],"608":[2,1,10],"609":[3,8,134],"610":[1,3,38],"611":[1,6,2],"612":[3,3,71],"613":[3,4,8],"614":[1,1,1],"615":[1,3,5],"616":[3,1,61],"617":[1,3,67],"618":[2,2,10],"619":[4,9,117],"620":[1,1,4],"621":[2,3,180],"622":[1,3,50],"623":[1,4,148],"624":[2,1,1],"625":[3,3,31],"626":[3,5,1],"627":[3,3,35],"628":[2,1,17],"629":[2,1,41],"630":[1,1,50],"631":[1,2,79],"632":[2,1,142],"633":[2,4,14],"634":[3,3,81],"635":[4,3,11],"636":[4,4,60],"637":[1,2,33],"638":[4,8,62],"639":[2,4,1],"640":[1,5,25],"641":[2,3,46],"642":[2,4,28],"643":[1,1,18],"644":[1,3,14],"645":[2,4,1],"646":[1,3,1],"647":[1,1,43],"648":[5,3,141],"649":[2,3,78],"650":[1,2,12],"651":[1,3,39],"652":[3,3,100],"653":[3,3,38],"654":[3,6,97],"655":[3,3,23],"656":[4,3,158],"657":[2,1,1],"658":[1,1,19],"659":[1,2,138],"660":[5,3,149],"661":[3,4,6],"662":[5,6,23],"663":[1,3,15],"664":[4,4,89],"665":[2,2,135],"666":[3,8,109],"667":[1,6,60],"668":[1,1,23],"669":[2,1,17],"670":[2,4,136],"671":[2,2,40],"672":[2,5,20],"673":[4,4,12],"674":[1,1,1],"675":[5,1,15],"676":[4,3,136],"677":[3,3,79],"678":[4,3,46],"679":[3,6,1],"680":[2,3,15],"681":[3,3,176],"682":[3,3,112],"683":[2,3,1],"684":[6,3,32],"685":[2,1,50],"686":[3,3,182],"687":[1,3,12],"688":[1,4,36],"689":[2,2,5],"690":[3,8,37],"691":[1,6,56],"692":[3,1,24],"693":[3,3,221],"694":[2,4,153],"695":[1,3,27],"696":[2,5,27],"697":[3,4,8],"698":[6,6,149],"699":[3,3,78],"700":[3,3,164],"701":[2,1,1],"702":[2,7,48],"703":[3,3,30],"704":[2,3,86],"705":[3,1,182],"706":[2,3,1],"707":[2,8,57],"708":[1,3,6],"709":[5,6,108],"710":[1,3,9],"711":[3,1,1],"712":[3,4,109],"713":[2,1,1],"714":[1,6,51],"715":[1,1,48],"716":[4,3,182],"717":[2,2,1],"718":[3,3,19],"719":[3,4,1],"720":[2,1,1],"721":[6,6,29],"722":[2,1,1],"723":[2,3,41],"724":[2,3,60],"725":[2,5,1],"726":[3,3,13],"727":[2,1,1],"728":[2,1,142],"729":[2,3,49],"730":[2,8,44],"731":[1,3,6],"732":[2,3,85],"733":[1,3,9],"734":[4,4,1],"735":[2,4,106],"736":[3,8,80],"737":[2,4,1],"738":[2,3,160],"739":[2,4,107],"740":[2,3,4],"741":[4,7,85],"742":[1,3,45],"743":[6,9,70],"744":[2,3,45],"745":[3,3,36],"746":[2,3,139],"747":[3,5,7],"748":[2,1,12],"749":[3,3,139],"750":[4,1,75],"751":[2,3,8],"752":[2,8,97],"753":[1,3,11],"754":[3,3,59],"755":[3,3,2],"756":[3,7,19],"757":[3,4,77],"758":[3,8,49],"759":[3,6,65],"760":[2,1,12],"761":[2,4,47],"762":[1,5,7],"763":[4,7,18],"764":[1,3,36],"765":[5,9,195],"766":[2,3,73],"767":[2,1,22],"768":[2,3,38],"769":[2,5,1],"770":[3,3,55],"771":[3,3,56],"772":[2,1,1],"773":[2,3,10],"774":[1,3,12],"775":[3,3,57],"776":[1,3,26],"777":[1,8,12],"778":[3,4,70],"779":[3,8,87],"780":[2,6,107],"781":[3,3,49],"782":[2,4,85],"783":[1,3,5],"784":[1,4,1],"785":[1,3,21],"786":[5,1,24],"787":[2,3,33],"788":[1,1,1],"789":[4,3,76],"790":[3,6,72],"791":[3,3,54],"792":[3,3,41],"793":[4,3,109],"794":[3,4,107],"795":[1,3,13],"796":[3,3,83],"797":[1,3,3],"798":[1,8,13],"799":[3,4,32],"800":[2,8,102],"801":[3,6,1],"802":[3,1,42],"803":[2,4,144],"804":[6,1,18],"805":[1,3,18],"806":[4,6,111],"807":[2,3,34],"808":[2,2,100],"809":[4,3,63],"810":[5,1,1],"811":[3,3,125],"812":[2,3,44],"813":[3,3,46],"814":[3,4,84],"815":[1,1,1],"816":[3,3,97],"817":[1,3,3],"818":[1,8,11],"819":[2,2,10],"820":[2,1,12],"821":[4,8,42],"822":[3,1,42],"823":[4,4,68],"824":[2,1,87],"825":[1,3,8],"826":[4,6,211],"827":[2,3,58],"828":[3,2,94],"829":[4,3,40],"830":[3,6,1],"831":[2,1,20],"832":[3,3,30],"833":[3,3,77],"834":[3,3,45],"835":[1,2,41],"836":[4,3,61],"837":[1,3,3],"838":[1,8,1],"839":[3,4,85],"840":[1,1,44],"841":[3,8,56],"842":[2,4,119],"843":[2,4,8],"844":[1,3,76],"845":[2,1,6],"846":[3,6,30],"847":[2,3,29],"848":[2,2,47],"849":[2,1,1],"850":[3,6,31],"851":[2,1,25],"852":[2,1,11],"853":[2,1,167],"854":[2,3,20],"855":[3,3,15],"856":[1,2,1],"857":[9,7,11],"858":[3,4,61],"859":[2,2,15],"860":[3,8,41],"861":[2,1,23],"862":[2,2,12],"863":[1,3,142],"864":[5,1,224],"865":[2,3,36],"866":[2,2,25],"867":[2,3,79],"868":[1,1,1],"869":[1,1,1],"870":[3,5,95],"871":[1,2,14],"872":[7,6,67],"873":[1,3,1],"874":[1,14,1],"875":[2,4,209],"876":[2,2,32],"877":[2,4,79],"878":[1,3,12],"879":[1,2,2],"880":[1,3,12],"881":[2,1,39],"882":[2,3,42],"883":[2,2,1],"884":[2,3,40],"885":[2,2,17],"886":[4,2,60],"887":[3,5,1],"888":[1,3,45],"889":[5,6,34],"890":[7,3,8],"891":[1,14,1],"892":[2,2,12],"893":[2,2,97],"894":[3,6,1],"895":[3,1,1],"896":[2,4,3],"897":[3,3,29],"898":[2,1,26],"899":[3,4,72],"900":[2,3,81],"901":[4,2,23],"902":[2,2,19],"903":[4,7,114],"904":[1,3,71],"905":[2,1,86],"906":[2,3,19],"907":[3,4,1],"908":[3,4,56],"909":[2,2,10],"910":[3,8,122],"911":[2,4,7],"912":[2,4,17],"913":[3,3,28],"914":[3,4,59],"915":[2,3,45],"916":[2,2,227],"917":[6,7,105],"918":[1,3,20],"919":[2,1,5],"920":[1,3,6],"921":[3,4,1],"922":[1,4,99],"923":[4,8,31],"924":[2,4,31],"925":[1,1,1],"926":[3,3,30],"927":[2,3,39],"928":[3,5,225],"929":[1,3,42],"930":[3,3,41],"931":[1,4,50],"932":[2,2,18],"933":[3,6,1],"934":[2,4,22],"935":[3,3,38],"936":[2,3,52],"937":[2,1,21],"938":[1,3,31],"939":[3,3,22],"940":[2,1,10],"941":[1,4,75],"942":[4,8,137],"943":[3,3,20],"944":[2,3,58],"945":[1,6,40],"946":[2,2,7],"947":[3,3,149],"948":[4,3,37],"949":[1,4,64],"950":[3,8,226],"951":[3,3,13],"952":[2,3,64],"953":[1,6,10],"954":[2,1,6],"955":[3,6,77],"956":[2,2,5],"957":[3,8,261],"958":[2,1,66],"959":[2,3,29],"960":[1,6,16],"961":[5,3,102],"962":[4,6,120],"963":[1,4,50],"964":[2,6,1],"965":[2,3,59],"966":[1,1,1],"967":[5,3,291],"968":[4,6,33],"969":[1,4,34],"970":[3,7,42],"971":[2,3,93],"972":[2,2,1],"973":[2,1,49],"974":[4,6,21],"975":[1,4,66],"976":[3,7,105],"977":[2,1,40],"978":[3,4,56],"979":[1,6,30],"980":[1,2,4],"981":[3,4,9],"982":[3,4,64],"983":[3,3,12],"984":[1,2,2],"985":[4,7,164],"986":[2,2,1],"987":[4,5,1],"988":[4,7,115],"989":[3,4,84],"990":[5,5,1],"991":[2,4,7],"992":[3,4,39],"993":[3,3,1],"994":[3,6,1],"995":[3,4,31],"996":[1,3,58],"997":[3,8,137],"998":[4,8,116],"999":[3,4,10],"1000":[4,7,233],"1001":[3,7,43],"1002":[2,4,11],"1003":[3,6,91],"1004":[3,6,45],"1005":[3,6,63],"1006":[3,6,49],"1007":[2,4,13],"1008":[1,4,7]},"averageFieldLength":[2.235877106045593,2.7908820614469754,45.4449950445986],"storedFields":{"0":{"title":"README~","titles":[]},"1":{"title":"评价指标","titles":[]},"2":{"title":"笔记","titles":[]},"3":{"title":"生成模型的几种评价指标","titles":["评价指标"]},"4":{"title":"自定义组件","titles":[]},"5":{"title":"PSNR","titles":[]},"6":{"title":"Markdown","titles":[]},"7":{"title":"ESAM 部署","titles":[]},"8":{"title":"SSIM","titles":[]},"9":{"title":"标题H2","titles":["Markdown"]},"10":{"title":"ros部署orbslam2算法使用Astra pro相机输入","titles":[]},"11":{"title":"开启 docker","titles":["ESAM 部署"]},"12":{"title":"部署 Clio","titles":[]},"13":{"title":"Inception Score","titles":[]},"14":{"title":"标题H3","titles":["Markdown","标题H2"]},"15":{"title":"ros 中部署ORBslam2","titles":[]},"16":{"title":"3D 目标检测","titles":[]},"17":{"title":"一些错误","titles":["ESAM 部署","开启 docker"]},"18":{"title":"Ubuntu-设置虚拟内存","titles":[]},"19":{"title":"安装 ros","titles":["部署 Clio"]},"20":{"title":"Fréchet Inception Distance","titles":[]},"21":{"title":"标题H4","titles":["Markdown","标题H2","标题H3"]},"22":{"title":"ORBSLAM2 编译","titles":["ros 中部署ORBslam2"]},"23":{"title":"DFM","titles":["3D 目标检测"]},"24":{"title":"Ubuntu挂载多个硬盘并赋予权限","titles":[]},"25":{"title":"准备数据集","titles":["ESAM 部署"]},"26":{"title":"设置 swap","titles":["Ubuntu-设置虚拟内存"]},"27":{"title":"安装 ros-clio","titles":["部署 Clio"]},"28":{"title":"标题H5","titles":["Markdown","标题H2","标题H3","标题H4"]},"29":{"title":"安装依赖","titles":["ros 中部署ORBslam2","ORBSLAM2 编译"]},"30":{"title":"重点关注","titles":["3D 目标检测"]},"31":{"title":"Voxblox","titles":[]},"32":{"title":"准备 3RScan","titles":["ESAM 部署","准备数据集"]},"33":{"title":"删除 swap","titles":["Ubuntu-设置虚拟内存"]},"34":{"title":"运行 clio-ros","titles":["部署 Clio"]},"35":{"title":"标题H6","titles":["Markdown","标题H2","标题H3","标题H4","标题H5"]},"36":{"title":"编译 OpenCV 3.4.5","titles":["ros 中部署ORBslam2","ORBSLAM2 编译","安装依赖"]},"37":{"title":"bash脚本问题","titles":[]},"38":{"title":"准备 3RScan-mv 和 3RScan-mv_fast","titles":["ESAM 部署","准备数据集"]},"39":{"title":"标题2 Badge","titles":["Markdown"]},"40":{"title":"编译 Pangolin","titles":["ros 中部署ORBslam2","ORBSLAM2 编译","安装依赖"]},"41":{"title":"bad interpreter","titles":["bash脚本问题"]},"42":{"title":"screen安装与使用","titles":[]},"43":{"title":"Evaluate ESAM on 3RScan-MV (Class Agnostic):","titles":["ESAM 部署"]},"44":{"title":"C++STL","titles":[]},"45":{"title":"交互式分割","titles":[]},"46":{"title":"标题3 Badge","titles":["Markdown","标题2 Badge"]},"47":{"title":"编译 eigen","titles":["ros 中部署ORBslam2","ORBSLAM2 编译","安装依赖"]},"48":{"title":"“-usr-bin-env-bashr-没有那个文件或目录","titles":["bash脚本问题"]},"49":{"title":"1.检查是否已安装 screen","titles":["screen安装与使用"]},"50":{"title":"使用-MobaXterm-连接-Docker-内环境","titles":[]},"51":{"title":"Evaluate ESAM-E on 3RScan-MV (Class Agnostic):","titles":["ESAM 部署"]},"52":{"title":"String","titles":["C++STL"]},"53":{"title":"解决qt-qpa-xcb-could-not-connect-to-display问题","titles":[]},"54":{"title":"Deep Interactive Object Selection. CVPR 2016","titles":["交互式分割"]},"55":{"title":"重装Ubuntu-的-Nvidia-驱动","titles":[]},"56":{"title":"SLAM","titles":[]},"57":{"title":"标题4 Badge","titles":["Markdown","标题2 Badge","标题3 Badge"]},"58":{"title":"编译 libORBSLAM2.so","titles":["ros 中部署ORBslam2","ORBSLAM2 编译"]},"59":{"title":"2.安装 screen","titles":["screen安装与使用"]},"60":{"title":"创建容器","titles":["使用-MobaXterm-连接-Docker-内环境"]},"61":{"title":"VLN","titles":[]},"62":{"title":"VLN综述","titles":[]},"63":{"title":"字符串类型转换函数","titles":["C++STL","String"]},"64":{"title":"出现原因","titles":["解决qt-qpa-xcb-could-not-connect-to-display问题"]},"65":{"title":"Interactive image segmentation with first click attention. In CVPR, 2020.","titles":["交互式分割"]},"66":{"title":"安装自定义显卡驱动版本号","titles":["重装Ubuntu-的-Nvidia-驱动"]},"67":{"title":"ORLBSLAM2 中的定义错误","titles":["ros 中部署ORBslam2","ORBSLAM2 编译","编译 libORBSLAM2.so"]},"68":{"title":"3.创建一个 screen 会话","titles":["screen安装与使用"]},"69":{"title":"安装常用软件","titles":["使用-MobaXterm-连接-Docker-内环境"]},"70":{"title":"综述","titles":["VLN"]},"71":{"title":"Semanticmap综述","titles":[]},"72":{"title":"摘要","titles":["VLN综述"]},"73":{"title":"Vector","titles":["C++STL"]},"74":{"title":"解决方法","titles":["解决qt-qpa-xcb-could-not-connect-to-display问题"]},"75":{"title":"Interactive image segmentation via backpropagating refinement scheme. CVPR, 2019.","titles":["交互式分割"]},"76":{"title":"ROS 安装","titles":["ros 中部署ORBslam2"]},"77":{"title":"4.断开与当前 screen 连接","titles":["screen安装与使用"]},"78":{"title":"配置 SSH 链接","titles":["使用-MobaXterm-连接-Docker-内环境"]},"79":{"title":"Awesome Vision–Language–Action Models for Autonomous Driving","titles":["VLN","综述"]},"80":{"title":"摘要","titles":["Semanticmap综述"]},"81":{"title":"Demo","titles":[]},"82":{"title":"1 引言","titles":["VLN综述"]},"83":{"title":"概念","titles":["C++STL","Vector"]},"84":{"title":"f-brs: Rethinking backpropagating refinement for interactive segmentation. CVPR, 2020.","titles":["交互式分割"]},"85":{"title":"bar","titles":[]},"86":{"title":"foo","titles":[]},"87":{"title":"rosdep 安装","titles":["ros 中部署ORBslam2","ROS 安装"]},"88":{"title":"5.恢复某 screen 会话","titles":["screen安装与使用"]},"89":{"title":"Semantic Map 综述","titles":["VLN","综述"]},"90":{"title":"1 引言","titles":["Semanticmap综述"]},"91":{"title":"DDPM","titles":[]},"92":{"title":"2 自动驾驶发展历程","titles":["VLN综述"]},"93":{"title":"vector构造函数","titles":["C++STL","Vector"]},"94":{"title":"Kimera","titles":[]},"95":{"title":"分层语义","titles":[]},"96":{"title":"EdgeFlow. ICCV2021","titles":["交互式分割"]},"97":{"title":"验证安装","titles":["ros 中部署ORBslam2","ROS 安装"]},"98":{"title":"Clio","titles":[]},"99":{"title":"6.删除不需要的 screen","titles":["screen安装与使用"]},"100":{"title":"2 背景知识","titles":["Semanticmap综述"]},"101":{"title":"Denoising Diffusion Probabilistic Models","titles":[]},"102":{"title":"Hydro","titles":[]},"103":{"title":"2.1 经典模块化流水线","titles":["VLN综述","2 自动驾驶发展历程"]},"104":{"title":"vector增加函数","titles":["C++STL","Vector"]},"105":{"title":"摘要：","titles":["Kimera"]},"106":{"title":"RITM","titles":["交互式分割"]},"107":{"title":"ros 中安装 ORBSLAM2 节点","titles":["ros 中部署ORBslam2","ROS 安装"]},"108":{"title":"数据集","titles":[]},"109":{"title":"1. 引言：","titles":["Clio"]},"110":{"title":"2.1 具身任务（Embodied Tasks）","titles":["Semanticmap综述","2 背景知识"]},"111":{"title":"1. Difussion","titles":["Denoising Diffusion Probabilistic Models"]},"112":{"title":"摘要","titles":["Hydro"]},"113":{"title":"NuScenes","titles":[]},"114":{"title":"2.2 端到端自动驾驶","titles":["VLN综述","2 自动驾驶发展历程"]},"115":{"title":"vector删除函数","titles":["C++STL","Vector"]},"116":{"title":"1 引言","titles":["Kimera"]},"117":{"title":"FocalClick: Towards Practical Interactive Image Segmentation (CVPR2022)","titles":["交互式分割"]},"118":{"title":"生成模型","titles":[]},"119":{"title":"感知","titles":[]},"120":{"title":"相机驱动安装","titles":["ros 中部署ORBslam2"]},"121":{"title":"2. 相关工作：","titles":["Clio"]},"122":{"title":"实例分割","titles":[]},"123":{"title":"2.1.1 机器人学任务","titles":["Semanticmap综述","2 背景知识","2.1 具身任务（Embodied Tasks）"]},"124":{"title":"2. Training","titles":["Denoising Diffusion Probabilistic Models"]},"125":{"title":"I. 引言","titles":["Hydro"]},"126":{"title":"概述","titles":["NuScenes"]},"127":{"title":"DragGan","titles":[]},"128":{"title":"2.3 自动驾驶中的VLM","titles":["VLN综述","2 自动驾驶发展历程"]},"129":{"title":"GAN生成对抗模型","titles":[]},"130":{"title":"vector遍历函数","titles":["C++STL","Vector"]},"131":{"title":"贡献","titles":["Kimera","1 引言"]},"132":{"title":"Interactive Object Segmentation in 3D Point Clouds","titles":["交互式分割"]},"133":{"title":"StyleGAN","titles":[]},"134":{"title":"Backbone","titles":["感知"]},"135":{"title":"CLIP引导生成","titles":[]},"136":{"title":"相机标定","titles":["ros 中部署ORBslam2"]},"137":{"title":"3. 问题表述：任务感知 3D 场景理解","titles":["Clio"]},"138":{"title":"实例分割","titles":[]},"139":{"title":"2.1.2 具身智能任务","titles":["Semanticmap综述","2 背景知识","2.1 具身任务（Embodied Tasks）"]},"140":{"title":"3. Sampling","titles":["Denoising Diffusion Probabilistic Models"]},"141":{"title":"前作的缺点","titles":["Hydro","I. 引言"]},"142":{"title":"数据收集","titles":["NuScenes"]},"143":{"title":"Motion Supervision","titles":["DragGan"]},"144":{"title":"DDIM","titles":[]},"145":{"title":"2.4 从VLM到自动驾驶VLA","titles":["VLN综述","2 自动驾驶发展历程"]},"146":{"title":"vector关于元素数量函数","titles":["C++STL","Vector"]},"147":{"title":"2 3D动态场景图","titles":["Kimera"]},"148":{"title":"Deblurring-via-Stochastic-Refinement","titles":[]},"149":{"title":"Mapping Network","titles":["StyleGAN"]},"150":{"title":"3D","titles":["感知"]},"151":{"title":"出发点","titles":["CLIP引导生成"]},"152":{"title":"运行","titles":["ros 中部署ORBslam2"]},"153":{"title":"4. 任务驱动聚类","titles":["Clio"]},"154":{"title":"R-CNN","titles":["实例分割"]},"155":{"title":"2.2 同时定位与建图（Simultaneous Localization and Mapping, SLAM）","titles":["Semanticmap综述","2 背景知识"]},"156":{"title":"II. 相关工作","titles":["Hydro"]},"157":{"title":"场景规划","titles":["NuScenes","数据收集"]},"158":{"title":"Point Tracking","titles":["DragGan"]},"159":{"title":"DiffSeg","titles":[]},"160":{"title":"3 VLA4AD架构范式","titles":["VLN综述"]},"161":{"title":"vector其他函数","titles":["C++STL","Vector"]},"162":{"title":"2.1 第1层：度量-语义网格","titles":["Kimera","2 3D动态场景图"]},"163":{"title":"PoseDiffusion","titles":[]},"164":{"title":"related work","titles":["Deblurring-via-Stochastic-Refinement"]},"165":{"title":"Latent space interpolations","titles":["StyleGAN"]},"166":{"title":"BEV","titles":["感知"]},"167":{"title":"成果","titles":["CLIP引导生成"]},"168":{"title":"5. Clio: 实时任务驱动开放集3D场景图","titles":["Clio"]},"169":{"title":"流程：","titles":["实例分割","R-CNN"]},"170":{"title":"SDE","titles":[]},"171":{"title":"2.2.1 SLAM 基础","titles":["Semanticmap综述","2 背景知识","2.2 同时定位与建图（Simultaneous Localization and Mapping, SLAM）"]},"172":{"title":"度量语义和层次化映射","titles":["Hydro","II. 相关工作"]},"173":{"title":"车辆配置","titles":["NuScenes","数据收集"]},"174":{"title":"相关工作","titles":["DiffSeg"]},"175":{"title":"SR3","titles":[]},"176":{"title":"3.1 多模态输入与语言指令","titles":["VLN综述","3 VLA4AD架构范式"]},"177":{"title":"Map","titles":["C++STL"]},"178":{"title":"2.2 第2层：对象和代理","titles":["Kimera"]},"179":{"title":"Bundle Adjustment","titles":[]},"180":{"title":"method","titles":["Deblurring-via-Stochastic-Refinement"]},"181":{"title":"Style Mixing","titles":["StyleGAN"]},"182":{"title":"OCC","titles":["感知"]},"183":{"title":"Score based Diffusion model","titles":[]},"184":{"title":"Train","titles":["CLIP引导生成"]},"185":{"title":"StableDiffusion","titles":[]},"186":{"title":"A. Clio前端","titles":["Clio","5. Clio: 实时任务驱动开放集3D场景图"]},"187":{"title":"贡献：","titles":["实例分割","R-CNN"]},"188":{"title":"用 SDE 描述扩散模型","titles":["SDE"]},"189":{"title":"2.2.2 SLAM 技术","titles":["Semanticmap综述","2 背景知识","2.2 同时定位与建图（Simultaneous Localization and Mapping, SLAM）"]},"190":{"title":"环路闭合检测和优化","titles":["Hydro","II. 相关工作"]},"191":{"title":"传感器校准","titles":["NuScenes","数据收集"]},"192":{"title":"方法","titles":["DiffSeg"]},"193":{"title":"生成模型","titles":["SR3"]},"194":{"title":"DDPM","titles":[]},"195":{"title":"3.2 核心架构模块","titles":["VLN综述","3 VLA4AD架构范式"]},"196":{"title":"unordered_map","titles":["C++STL"]},"197":{"title":"2.3 第3层：地点和结构","titles":["Kimera","2.2 第2层：对象和代理"]},"198":{"title":"网络架构","titles":["Deblurring-via-Stochastic-Refinement"]},"199":{"title":"Stochastic variation","titles":["StyleGAN"]},"200":{"title":"融合OCC","titles":["感知"]},"201":{"title":"扩散模型与受控图像生成","titles":[]},"202":{"title":"条件扩散","titles":[]},"203":{"title":"生成模型分类：","titles":["Score based Diffusion model"]},"204":{"title":"infer","titles":["CLIP引导生成"]},"205":{"title":"Intro","titles":["StableDiffusion"]},"206":{"title":"3D对象原语。","titles":["Clio","5. Clio: 实时任务驱动开放集3D场景图","A. Clio前端"]},"207":{"title":"问题：","titles":["实例分割","R-CNN"]},"208":{"title":"SDE-based diffusion process","titles":["SDE"]},"209":{"title":"2.2.3 语义 SLAM","titles":["Semanticmap综述","2 背景知识","2.2 同时定位与建图（Simultaneous Localization and Mapping, SLAM）"]},"210":{"title":"III. 实时增量3D场景图层构建","titles":["Hydro"]},"211":{"title":"传感器同步","titles":["NuScenes","数据收集"]},"212":{"title":"理论依据","titles":["DiffSeg","方法"]},"213":{"title":"概率密度函数","titles":["SR3","生成模型"]},"214":{"title":"Denoising Diffusion Probabilistic Models","titles":[]},"215":{"title":"3D概览","titles":[]},"216":{"title":"3.3 驾驶输出","titles":["VLN综述","3 VLA4AD架构范式"]},"217":{"title":"unordered_set","titles":["C++STL"]},"218":{"title":"2.4 第4层：房间","titles":["Kimera","2.2 第2层：对象和代理"]},"219":{"title":"3D点云学习综述","titles":[]},"220":{"title":"result","titles":["Deblurring-via-Stochastic-Refinement"]},"221":{"title":"Perceptual path length","titles":["StyleGAN"]},"222":{"title":"扩散模型与受控图像生成","titles":[]},"223":{"title":"3d自监督","titles":[]},"224":{"title":"unconditional DDPM","titles":["条件扩散"]},"225":{"title":"方法","titles":["Score based Diffusion model"]},"226":{"title":"结果","titles":["CLIP引导生成"]},"227":{"title":"潜在空间(Lantent Space)","titles":["StableDiffusion","Intro"]},"228":{"title":"3D地点原语","titles":["Clio","5. Clio: 实时任务驱动开放集3D场景图","A. Clio前端"]},"229":{"title":"Fast R-CNN","titles":["实例分割"]},"230":{"title":"与之前工作的联系","titles":["SDE"]},"231":{"title":"2.3 系统设计策略","titles":["Semanticmap综述","2 背景知识"]},"232":{"title":"A. 第1-3层：网格、对象和地点","titles":["Hydro","III. 实时增量3D场景图层构建"]},"233":{"title":"隐私保护","titles":["NuScenes","数据收集"]},"234":{"title":"Intra-Attention Similarity","titles":["DiffSeg","方法","理论依据"]},"235":{"title":"score-based models","titles":["SR3","生成模型"]},"236":{"title":"1. Difussion","titles":["Denoising Diffusion Probabilistic Models"]},"237":{"title":"DGCNN","titles":[]},"238":{"title":"4 VLA4AD范式进展","titles":["VLN综述"]},"239":{"title":"头文件","titles":["C++STL","unordered_set"]},"240":{"title":"2.5 第5层：建筑物","titles":["Kimera","2.2 第2层：对象和代理"]},"241":{"title":"1. 数据集","titles":["3D点云学习综述"]},"242":{"title":"基于迭代去噪过程的图像编辑","titles":["扩散模型与受控图像生成"]},"243":{"title":"PointContrast","titles":["3d自监督"]},"244":{"title":"Guided Diffusion/Diffusion Models Beat GANs on Image Synthesis","titles":["条件扩散"]},"245":{"title":"问题","titles":["Score based Diffusion model","方法"]},"246":{"title":"CLIP损失引导生成","titles":[]},"247":{"title":"DMTet","titles":[]},"248":{"title":"Latent Diffusion","titles":["StableDiffusion","Intro"]},"249":{"title":"B. Clio后端","titles":["Clio","5. Clio: 实时任务驱动开放集3D场景图"]},"250":{"title":"流程","titles":["实例分割","Fast R-CNN"]},"251":{"title":"VE-SDE","titles":["SDE","与之前工作的联系"]},"252":{"title":"2.3.1 端到端方法","titles":["Semanticmap综述","2 背景知识","2.3 系统设计策略"]},"253":{"title":"网格和对象","titles":["Hydro","III. 实时增量3D场景图层构建","A. 第1-3层：网格、对象和地点"]},"254":{"title":"数据格式","titles":["NuScenes"]},"255":{"title":"Inter-Attention Similarity","titles":["DiffSeg","方法","理论依据"]},"256":{"title":"Langevin dynamics","titles":["SR3","生成模型"]},"257":{"title":"2. Training","titles":["Denoising Diffusion Probabilistic Models"]},"258":{"title":"创新点","titles":["DGCNN"]},"259":{"title":"MVSNet","titles":[]},"260":{"title":"4.1 Pre-VLA：语言模型作为解释器","titles":["VLN综述","4 VLA4AD范式进展"]},"261":{"title":"初始化","titles":["C++STL","unordered_set"]},"262":{"title":"2.6 组合和查询","titles":["Kimera","2.2 第2层：对象和代理"]},"263":{"title":"2. 评价指标","titles":["3D点云学习综述"]},"264":{"title":"IVLR：Conditioning Method for Denoising Diffusion Probabilistic Models","titles":["扩散模型与受控图像生成","基于迭代去噪过程的图像编辑"]},"265":{"title":"Motivation","titles":["3d自监督","PointContrast"]},"266":{"title":"ILVR: Conditioning Method for Denoising Diffusion Probabilistic Models","titles":["条件扩散"]},"267":{"title":"在数据密度较低的位置，score的估计往往是不准确的","titles":["Score based Diffusion model","方法","问题"]},"268":{"title":"DiffusionCLlP","titles":["CLIP损失引导生成"]},"269":{"title":"3D Representation","titles":["DMTet"]},"270":{"title":"感知压缩","titles":["StableDiffusion"]},"271":{"title":"任务驱动对象检测。","titles":["Clio","5. Clio: 实时任务驱动开放集3D场景图","B. Clio后端"]},"272":{"title":"贡献","titles":["实例分割","Fast R-CNN"]},"273":{"title":"VP-SDE","titles":["SDE","与之前工作的联系"]},"274":{"title":"2.3.2 模块化流水线","titles":["Semanticmap综述","2 背景知识","2.3 系统设计策略"]},"275":{"title":"MeshCNN","titles":[]},"276":{"title":"地点","titles":["Hydro","III. 实时增量3D场景图层构建","A. 第1-3层：网格、对象和地点"]},"277":{"title":"数据标注","titles":["NuScenes"]},"278":{"title":"attention map","titles":["DiffSeg","方法"]},"279":{"title":"DDPM","titles":["SR3","生成模型"]},"280":{"title":"3. Sampling","titles":["Denoising Diffusion Probabilistic Models"]},"281":{"title":"训练","titles":["MVSNet"]},"282":{"title":"OneFormer3D","titles":[]},"283":{"title":"4.2 自动驾驶模块化VLA模型","titles":["VLN综述","4 VLA4AD范式进展"]},"284":{"title":"创建空的set","titles":["C++STL","unordered_set","初始化"]},"285":{"title":"3 Kimera：空间感知引擎","titles":["Kimera"]},"286":{"title":"3. 分类","titles":["3D点云学习综述"]},"287":{"title":"SDEdit","titles":["扩散模型与受控图像生成","基于迭代去噪过程的图像编辑"]},"288":{"title":"方法","titles":["3d自监督","PointContrast"]},"289":{"title":"创新点","titles":["条件扩散","ILVR: Conditioning Method for Denoising Diffusion Probabilistic Models"]},"290":{"title":"PointGPT","titles":[]},"291":{"title":"要加少强度的噪声？","titles":["Score based Diffusion model","方法","问题"]},"292":{"title":"VQ-VAE","titles":[]},"293":{"title":"Model","titles":["DMTet"]},"294":{"title":"语义压缩","titles":["StableDiffusion"]},"295":{"title":"任务驱动地点聚类。","titles":["Clio","5. Clio: 实时任务驱动开放集3D场景图","B. Clio后端"]},"296":{"title":"Faster R-CNN","titles":["实例分割"]},"297":{"title":"PointMVS","titles":[]},"298":{"title":"SPFormer","titles":[]},"299":{"title":"2.3.3 权衡","titles":["Semanticmap综述","2 背景知识","2.3 系统设计策略"]},"300":{"title":"Overview","titles":["MeshCNN"]},"301":{"title":"B. 第4层：房间检测","titles":["Hydro","III. 实时增量3D场景图层构建"]},"302":{"title":"全景","titles":["NuScenes"]},"303":{"title":"Attention Aggregation","titles":["DiffSeg","方法"]},"304":{"title":"SR3","titles":["SR3","生成模型"]},"305":{"title":"特征提取","titles":["MVSNet","训练"]},"306":{"title":"OneFormer3D","titles":["OneFormer3D"]},"307":{"title":"稀疏卷积","titles":[]},"308":{"title":"4.3 自动驾驶统一端到端VLA模型","titles":["VLN综述","4 VLA4AD范式进展"]},"309":{"title":"拷贝构造","titles":["C++STL","unordered_set","初始化"]},"310":{"title":"第3.1节 Kimera-VIO：视觉-惯性里程计","titles":["Kimera","3 Kimera：空间感知引擎"]},"311":{"title":"3.1基于投影的网络","titles":["3D点云学习综述","3. 分类"]},"312":{"title":"RePaint: Inpainting using Denoising Diffusion Probabilistic Models","titles":["扩散模型与受控图像生成","基于迭代去噪过程的图像编辑"]},"313":{"title":"shapenet 有监督预训练测试","titles":["3d自监督","PointContrast","方法"]},"314":{"title":"Diffusion Probabilistic Models for 3D Point Cloud Generation","titles":["条件扩散"]},"315":{"title":"PointGPT 的整体架构","titles":["PointGPT"]},"316":{"title":"求 score","titles":["Score based Diffusion model","方法","问题"]},"317":{"title":"VQGAN","titles":[]},"318":{"title":"Input encoder","titles":["DMTet","Model"]},"319":{"title":"Method","titles":["StableDiffusion"]},"320":{"title":"6. 实验","titles":["Clio"]},"321":{"title":"Region Proposal Network","titles":["实例分割","Faster R-CNN"]},"322":{"title":"Abstract","titles":["PointMVS"]},"323":{"title":"SPFormer","titles":["SPFormer"]},"324":{"title":"3 语义地图","titles":["Semanticmap综述"]},"325":{"title":"Invariant convolution","titles":["MeshCNN","Overview"]},"326":{"title":"IV. 持久表示：环路闭合检测和3D场景图优化","titles":["Hydro"]},"327":{"title":"如何使用 nuScenes 数据集","titles":[]},"328":{"title":"Iterative Attention Merging","titles":["DiffSeg","方法"]},"329":{"title":"训练过程","titles":["SR3","生成模型","SR3"]},"330":{"title":"构建特征体 Feature Volume","titles":["MVSNet","训练"]},"331":{"title":"解决的问题：","titles":["OneFormer3D","OneFormer3D"]},"332":{"title":"稀疏卷积","titles":["稀疏卷积"]},"333":{"title":"DETR","titles":[]},"334":{"title":"4.4 自动驾驶推理增强VLA模型","titles":["VLN综述","4 VLA4AD范式进展"]},"335":{"title":"使用迭代器构造","titles":["C++STL","unordered_set","初始化"]},"336":{"title":"第3.2节 Kimera-Mesher：3D网格重建","titles":["Kimera","3 Kimera：空间感知引擎"]},"337":{"title":"3.1.1 多视图表示","titles":["3D点云学习综述","3. 分类","3.1基于投影的网络"]},"338":{"title":"基于显式分类器的图像引导生成","titles":["扩散模型与受控图像生成"]},"339":{"title":"算法","titles":["3d自监督","PointContrast","方法"]},"340":{"title":"Point Cloud Sequencer","titles":["PointGPT"]},"341":{"title":"PETR 系列","titles":[]},"342":{"title":"目标函数：","titles":["Score based Diffusion model","方法"]},"343":{"title":"问题","titles":["VQGAN"]},"344":{"title":"Initial Prediction of SDF","titles":["DMTet","Model"]},"345":{"title":"autoencoder","titles":["StableDiffusion","Method"]},"346":{"title":"A. 开放集对象聚类评估","titles":["Clio","6. 实验"]},"347":{"title":"cls layer","titles":["实例分割","Faster R-CNN","Region Proposal Network"]},"348":{"title":"方法","titles":["PointMVS"]},"349":{"title":"摘要","titles":["SPFormer","SPFormer"]},"350":{"title":"3.1 什么是语义地图？","titles":["Semanticmap综述","3 语义地图"]},"351":{"title":"Mesh convolution","titles":["MeshCNN","Overview","Invariant convolution"]},"352":{"title":"A. 环路闭合检测和几何验证","titles":["Hydro","IV. 持久表示：环路闭合检测和3D场景图优化"]},"353":{"title":"结果","titles":["DiffSeg"]},"354":{"title":"推理过程","titles":["SR3","生成模型","SR3"]},"355":{"title":"Differentiable Homography","titles":["MVSNet","训练","构建特征体 Feature Volume"]},"356":{"title":"主要贡献：","titles":["OneFormer3D","OneFormer3D"]},"357":{"title":"1. MinkEngine","titles":["稀疏卷积","稀疏卷积"]},"358":{"title":"损失函数","titles":["DETR"]},"359":{"title":"概览","titles":[]},"360":{"title":"5 数据集与基准","titles":["VLN综述"]},"361":{"title":"使用数组作为初值构造","titles":["C++STL","unordered_set","初始化"]},"362":{"title":"第3.3节 Kimera-Semantics：3D度量-语义重建","titles":["Kimera","3 Kimera：空间感知引擎"]},"363":{"title":"3.1.2 体素化表示","titles":["3D点云学习综述","3. 分类","3.1基于投影的网络"]},"364":{"title":"DAOcc","titles":[]},"365":{"title":"Diffusion Models Beat GANs on Image Synthesis","titles":["扩散模型与受控图像生成","基于显式分类器的图像引导生成"]},"366":{"title":"结果","titles":["3d自监督","PointContrast"]},"367":{"title":"EFFOcc","titles":[]},"368":{"title":"点云序列","titles":["PointGPT","Point Cloud Sequencer"]},"369":{"title":"PETR","titles":["PETR 系列"]},"370":{"title":"image inpainting","titles":["Score based Diffusion model","方法"]},"371":{"title":"方法","titles":["VQGAN"]},"372":{"title":"Surface Refinement with Volume Subdivision","titles":["DMTet","Model"]},"373":{"title":"CLIP text encder","titles":["StableDiffusion","Method"]},"374":{"title":"实验设置","titles":["Clio","6. 实验","A. 开放集对象聚类评估"]},"375":{"title":"reg layer","titles":["实例分割","Faster R-CNN","Region Proposal Network"]},"376":{"title":"1. 初始深度图生成","titles":["PointMVS","方法"]},"377":{"title":"Method","titles":["SPFormer","SPFormer"]},"378":{"title":"3.2 地图的结构是什么？","titles":["Semanticmap综述","3 语义地图"]},"379":{"title":"输入特征","titles":["MeshCNN","Overview"]},"380":{"title":"B. 3D场景图优化","titles":["Hydro","IV. 持久表示：环路闭合检测和3D场景图优化"]},"381":{"title":"类似工作","titles":["DiffSeg"]},"382":{"title":"实验结果","titles":["SR3","生成模型"]},"383":{"title":"特征体构建","titles":["MVSNet","训练","构建特征体 Feature Volume"]},"384":{"title":"架构","titles":["OneFormer3D","OneFormer3D"]},"385":{"title":"Sparse Tensor Quantization","titles":["稀疏卷积","稀疏卷积","1. MinkEngine"]},"386":{"title":"Deformable DETR","titles":[]},"387":{"title":"GaussianFormer3D","titles":[]},"388":{"title":"6 训练与评估策略","titles":["VLN综述"]},"389":{"title":"移动构造","titles":["C++STL","unordered_set","初始化"]},"390":{"title":"第3.4节 Kimera-PGMO：带有回路闭合的姿态图和网格优化","titles":["Kimera","3 Kimera：空间感知引擎"]},"391":{"title":"3.2基于点的网络","titles":["3D点云学习综述","3. 分类"]},"392":{"title":"摘要","titles":["DAOcc"]},"393":{"title":"基于CLIP模型的多模态图像引导生成","titles":["扩散模型与受控图像生成"]},"394":{"title":"DepthContrast","titles":["3d自监督"]},"395":{"title":"EFFOcc：从最小标签中学习高效占据网络用于自动驾驶","titles":[]},"396":{"title":"点块分割","titles":["PointGPT","Point Cloud Sequencer"]},"397":{"title":"模型","titles":["PETR 系列","PETR"]},"398":{"title":"总结","titles":["Score based Diffusion model"]},"399":{"title":"VQGAN-CLIP","titles":[]},"400":{"title":"Learnable Surface Subdivision","titles":["DMTet","Model"]},"401":{"title":"UNet","titles":["StableDiffusion","Method"]},"402":{"title":"指标","titles":["Clio","6. 实验","A. 开放集对象聚类评估"]},"403":{"title":"Classifier","titles":["实例分割","Faster R-CNN"]},"404":{"title":"2. 2D-3D 特征融合","titles":["PointMVS","方法"]},"405":{"title":"Query Decoder","titles":["SPFormer","SPFormer","Method"]},"406":{"title":"3.3 地图中存储什么样的编码？","titles":["Semanticmap综述","3 语义地图"]},"407":{"title":"Global ordering","titles":["MeshCNN","Overview"]},"408":{"title":"V. 快速思考与慢速思考：Hydra架构","titles":["Hydro"]},"409":{"title":"OccCylindrical","titles":[]},"410":{"title":"AffinityNet","titles":["DiffSeg","类似工作"]},"411":{"title":"生成代价体 cost volume","titles":["MVSNet","训练"]},"412":{"title":"Sparse 3D U-Net.","titles":["OneFormer3D","OneFormer3D","架构"]},"413":{"title":"Generalized Sparse Convolution","titles":["稀疏卷积","稀疏卷积","1. MinkEngine"]},"414":{"title":"DETR 3D","titles":[]},"415":{"title":"摘要","titles":["GaussianFormer3D"]},"416":{"title":"OccFusion","titles":[]},"417":{"title":"6.1 训练范式","titles":["VLN综述","6 训练与评估策略"]},"418":{"title":"使用待处置的列表构造","titles":["C++STL","unordered_set","初始化"]},"419":{"title":"第3.5节 Kimera-Humans：人体姿态估计和鲁棒跟踪","titles":["Kimera","3 Kimera：空间感知引擎"]},"420":{"title":"3.2.1 点式MLP网络","titles":["3D点云学习综述","3. 分类","3.2基于点的网络"]},"421":{"title":"1. Intro","titles":["DAOcc"]},"422":{"title":"More Control for Free! Image Synthesis with Semantic Diffusion Guidance","titles":["扩散模型与受控图像生成","基于CLIP模型的多模态图像引导生成"]},"423":{"title":"概览","titles":[]},"424":{"title":"方法","titles":["3d自监督","DepthContrast"]},"425":{"title":"摘要","titles":["EFFOcc：从最小标签中学习高效占据网络用于自动驾驶"]},"426":{"title":"排序","titles":["PointGPT","Point Cloud Sequencer"]},"427":{"title":"3D Position Encoder","titles":["PETR 系列","PETR","模型"]},"428":{"title":"Stable-Diffusion","titles":[]},"429":{"title":"3D discriminator","titles":["DMTet","Model"]},"430":{"title":"应用","titles":["StableDiffusion"]},"431":{"title":"Compared Techniques","titles":["Clio","6. 实验","A. 开放集对象聚类评估"]},"432":{"title":"RoI Pooling","titles":["实例分割","Faster R-CNN","Classifier"]},"433":{"title":"2.1 特征提取","titles":["PointMVS","方法","2. 2D-3D 特征融合"]},"434":{"title":"Shared Prediction Head","titles":["SPFormer","SPFormer","Method","Query Decoder"]},"435":{"title":"3.4 地图是如何构建的？","titles":["Semanticmap综述","3 语义地图"]},"436":{"title":"Pooling","titles":["MeshCNN","Overview"]},"437":{"title":"VI. 实验","titles":["Hydro"]},"438":{"title":"I. 引言","titles":["OccCylindrical"]},"439":{"title":"DiffuMasks","titles":["DiffSeg","类似工作"]},"440":{"title":"代价体正则化","titles":["MVSNet","训练"]},"441":{"title":"Query Decoder","titles":["OneFormer3D","OneFormer3D","架构"]},"442":{"title":"Pooling","titles":["稀疏卷积","稀疏卷积","1. MinkEngine"]},"443":{"title":"多视角3D目标检测问题：","titles":["DETR 3D"]},"444":{"title":"1. Intro","titles":["GaussianFormer3D"]},"445":{"title":"OCCFusion: Multi-Sensor Fusion Framework for 3D Semantic Occupancy Prediction","titles":["OccFusion"]},"446":{"title":"数据集构建需求","titles":[]},"447":{"title":"6.2 评估协议","titles":["VLN综述","6 训练与评估策略"]},"448":{"title":"unordered_set 常用函数","titles":["C++STL","unordered_set"]},"449":{"title":"第3.6节 Kimera-Objects：对象姿态估计","titles":["Kimera","3 Kimera：空间感知引擎"]},"450":{"title":"3.2.2 基于卷积的网络","titles":["3D点云学习综述","3. 分类","3.2基于点的网络"]},"451":{"title":"2. 相关工作","titles":["DAOcc"]},"452":{"title":"Blended Diffusion for Text-driven Editing of Natural Images","titles":["扩散模型与受控图像生成","基于CLIP模型的多模态图像引导生成"]},"453":{"title":"EFFOcc","titles":["概览"]},"454":{"title":"结果","titles":["3d自监督","DepthContrast"]},"455":{"title":"I 引言","titles":["EFFOcc：从最小标签中学习高效占据网络用于自动驾驶"]},"456":{"title":"嵌入","titles":["PointGPT","Point Cloud Sequencer"]},"457":{"title":"Decoder","titles":["PETR 系列","PETR","模型"]},"458":{"title":"FBOCC","titles":[]},"459":{"title":"总结","titles":["Stable-Diffusion"]},"460":{"title":"损失函数","titles":["DMTet"]},"461":{"title":"text2image","titles":["StableDiffusion","应用"]},"462":{"title":"结果","titles":["Clio","6. 实验","A. 开放集对象聚类评估"]},"463":{"title":"分类和边框修正","titles":["实例分割","Faster R-CNN","Classifier"]},"464":{"title":"2.1 动态特征融合","titles":["PointMVS","方法","2. 2D-3D 特征融合"]},"465":{"title":"4 地图结构","titles":["Semanticmap综述"]},"466":{"title":"Mesh Pooling","titles":["MeshCNN","Overview","Pooling"]},"467":{"title":"VII. 结论","titles":["Hydro"]},"468":{"title":"II. 相关工作","titles":["OccCylindrical"]},"469":{"title":"ReCo","titles":["DiffSeg","类似工作"]},"470":{"title":"深度图初始估计","titles":["MVSNet","训练"]},"471":{"title":"Query selection","titles":["OneFormer3D","OneFormer3D","架构"]},"472":{"title":"Non-spatial Funtions","titles":["稀疏卷积","稀疏卷积","1. MinkEngine"]},"473":{"title":"创新点：","titles":["DETR 3D"]},"474":{"title":"2. 相关工作","titles":["GaussianFormer3D"]},"475":{"title":"摘要","titles":["OccFusion"]},"476":{"title":"1. 基本结构","titles":["数据集构建需求"]},"477":{"title":"FlashOcc","titles":[]},"478":{"title":"7 开放挑战","titles":["VLN综述"]},"479":{"title":"empty()","titles":["C++STL","unordered_set","unordered_set 常用函数"]},"480":{"title":"第3.7节 Kimera-BuildingParser：提取地点、房间和结构","titles":["Kimera","3 Kimera：空间感知引擎"]},"481":{"title":"连续卷积","titles":["3D点云学习综述","3. 分类","3.2基于点的网络","3.2.2 基于卷积的网络"]},"482":{"title":"3D Occupancy Prediction","titles":["DAOcc","2. 相关工作"]},"483":{"title":"基于隐式分类器的文生图大模型","titles":["扩散模型与受控图像生成"]},"484":{"title":"DAOcc","titles":["概览"]},"485":{"title":"总结","titles":["3d自监督","DepthContrast"]},"486":{"title":"GaussianFormer","titles":[]},"487":{"title":"II 相关工作","titles":["EFFOcc：从最小标签中学习高效占据网络用于自动驾驶"]},"488":{"title":"Transformer Decoder with a Dual Masking Strategy","titles":["PointGPT"]},"489":{"title":"Query","titles":["PETR 系列","PETR","模型"]},"490":{"title":"摘要","titles":["FBOCC"]},"491":{"title":"image2image","titles":["StableDiffusion","应用"]},"492":{"title":"B. 封闭集对象评估","titles":["Clio","6. 实验"]},"493":{"title":"推理","titles":["实例分割","Faster R-CNN"]},"494":{"title":"3. 点云优化","titles":["PointMVS","方法"]},"495":{"title":"4.1 空间网格地图","titles":["Semanticmap综述","4 地图结构"]},"496":{"title":"Mesh UnPooling","titles":["MeshCNN","Overview","Pooling"]},"497":{"title":"A. 基于摄像头-雷达融合的3D语义占据预测","titles":["OccCylindrical","II. 相关工作"]},"498":{"title":"Network-free","titles":["DiffSeg","类似工作"]},"499":{"title":"损失计算","titles":["MVSNet","训练"]},"500":{"title":"2. SpConv","titles":["稀疏卷积","稀疏卷积"]},"501":{"title":"Overview","titles":["DETR 3D"]},"502":{"title":"3. 方法","titles":["GaussianFormer3D"]},"503":{"title":"I. 引言","titles":["OccFusion"]},"504":{"title":"1.1 nuScenes devkit","titles":["数据集构建需求","1. 基本结构"]},"505":{"title":"摘要","titles":["FlashOcc"]},"506":{"title":"GaussianFormer2","titles":[]},"507":{"title":"8 未来方向","titles":["VLN综述"]},"508":{"title":"MonoScene","titles":[]},"509":{"title":"find()","titles":["C++STL","unordered_set","unordered_set 常用函数"]},"510":{"title":"第3.8节 调试工具","titles":["Kimera","3 Kimera：空间感知引擎"]},"511":{"title":"离散卷积","titles":["3D点云学习综述","3. 分类","3.2基于点的网络","3.2.2 基于卷积的网络"]},"512":{"title":"Multi-Modal 3D Object Detection","titles":["DAOcc","2. 相关工作"]},"513":{"title":"Classifier-Free Diffusion Guidance","titles":["扩散模型与受控图像生成","基于隐式分类器的文生图大模型"]},"514":{"title":"GaussianFormer3D","titles":["概览"]},"515":{"title":"Masked Scene Contrast","titles":["3d自监督"]},"516":{"title":"摘要","titles":["GaussianFormer"]},"517":{"title":"A. 计算高效的占据网络","titles":["EFFOcc：从最小标签中学习高效占据网络用于自动驾驶","II 相关工作"]},"518":{"title":"Dual masking strategy?????","titles":["PointGPT","Transformer Decoder with a Dual Masking Strategy"]},"519":{"title":"实验","titles":["PETR 系列","PETR"]},"520":{"title":"1 引言","titles":["FBOCC"]},"521":{"title":"image inpainting","titles":["StableDiffusion","应用"]},"522":{"title":"C. 开放词汇地点聚类","titles":["Clio","6. 实验"]},"523":{"title":"Mask R-CNN","titles":["实例分割"]},"524":{"title":"3.1 假设点生成","titles":["PointMVS","方法","3. 点云优化"]},"525":{"title":"4.2 拓扑地图","titles":["Semanticmap综述","4 地图结构"]},"526":{"title":"网络设置","titles":["MeshCNN"]},"527":{"title":"B. 基于摄像头-激光雷达融合的3D语义占据预测","titles":["OccCylindrical","II. 相关工作"]},"528":{"title":"ToCo","titles":["DiffSeg","类似工作"]},"529":{"title":"后处理","titles":["MVSNet"]},"530":{"title":"建立输入哈希表","titles":["稀疏卷积","稀疏卷积","2. SpConv"]},"531":{"title":"结构","titles":["DETR 3D"]},"532":{"title":"3.1 基于3D高斯的场景表示","titles":["GaussianFormer3D","3. 方法"]},"533":{"title":"II. 相关工作","titles":["OccFusion"]},"534":{"title":"1.2 nuScenes lidarseg","titles":["数据集构建需求","1. 基本结构"]},"535":{"title":"1 引言","titles":["FlashOcc"]},"536":{"title":"摘要","titles":["GaussianFormer2"]},"537":{"title":"EmbodiedOcc","titles":[]},"538":{"title":"9 结论","titles":["VLN综述"]},"539":{"title":"摘要","titles":["MonoScene"]},"540":{"title":"count()","titles":["C++STL","unordered_set","unordered_set 常用函数"]},"541":{"title":"第4节 实验评估","titles":["Kimera"]},"542":{"title":"3.2.3 基于图的网络","titles":["3D点云学习综述","3. 分类","3.2基于点的网络"]},"543":{"title":"3. 提出的方法","titles":["DAOcc"]},"544":{"title":"ISO","titles":[]},"545":{"title":"OCCFusion","titles":["概览"]},"546":{"title":"Approch","titles":["3d自监督","Masked Scene Contrast"]},"547":{"title":"1 引言","titles":["GaussianFormer"]},"548":{"title":"B. 自动驾驶感知中的知识蒸馏","titles":["EFFOcc：从最小标签中学习高效占据网络用于自动驾驶","II 相关工作"]},"549":{"title":"Extractor-generator","titles":["PointGPT","Transformer Decoder with a Dual Masking Strategy"]},"550":{"title":"PETRv2","titles":["PETR 系列"]},"551":{"title":"2 方法","titles":["FBOCC"]},"552":{"title":"总结","titles":["StableDiffusion"]},"553":{"title":"VII. 限制","titles":["Clio"]},"554":{"title":"问题","titles":["实例分割","Mask R-CNN"]},"555":{"title":"3.2 边缘卷积","titles":["PointMVS","方法","3. 点云优化"]},"556":{"title":"4.3 稠密几何地图（Dense Geometric Map）","titles":["Semanticmap综述","4 地图结构"]},"557":{"title":"Result","titles":["MeshCNN"]},"558":{"title":"III. OCCCYLINDRICAL","titles":["OccCylindrical"]},"559":{"title":"PTC：Patch Token Contrast","titles":["DiffSeg","类似工作","ToCo"]},"560":{"title":"深度图滤波","titles":["MVSNet","后处理"]},"561":{"title":"建立RuleBook","titles":["稀疏卷积","稀疏卷积","2. SpConv"]},"562":{"title":"Model","titles":["DETR 3D","结构"]},"563":{"title":"3.2 体素到高斯的初始化","titles":["GaussianFormer3D","3. 方法"]},"564":{"title":"A. 基于相机的环境感知","titles":["OccFusion","II. 相关工作"]},"565":{"title":"2. 标注需求（暂）","titles":["数据集构建需求"]},"566":{"title":"2 相关工作","titles":["FlashOcc"]},"567":{"title":"1. 引言","titles":["GaussianFormer2"]},"568":{"title":"摘要","titles":["EmbodiedOcc"]},"569":{"title":"为什么选择OCC","titles":[]},"570":{"title":"1. 引言","titles":["MonoScene"]},"571":{"title":"insert()","titles":["C++STL","unordered_set","unordered_set 常用函数"]},"572":{"title":"4.1 数据集","titles":["Kimera","第4节 实验评估"]},"573":{"title":"Occ 概览","titles":[]},"574":{"title":"基于图的空间域","titles":["3D点云学习综述","3. 分类","3.2基于点的网络","3.2.3 基于图的网络"]},"575":{"title":"视觉OCC综述","titles":[]},"576":{"title":"3.1 总体框架","titles":["DAOcc","3. 提出的方法","Multi-Modal 3D Object Detection"]},"577":{"title":"Occ 综述-模态融合视角","titles":[]},"578":{"title":"OccCylindrical","titles":["概览"]},"579":{"title":"对比学习","titles":["3d自监督","Masked Scene Contrast","Approch"]},"580":{"title":"2 相关工作","titles":["GaussianFormer"]},"581":{"title":"III 方法","titles":["EFFOcc：从最小标签中学习高效占据网络用于自动驾驶"]},"582":{"title":"Generation Target","titles":["PointGPT"]},"583":{"title":"时域对齐","titles":["PETR 系列","PETRv2"]},"584":{"title":"InternImage","titles":[]},"585":{"title":"模型设计","titles":["FBOCC","2 方法"]},"586":{"title":"VIII. 结论","titles":["Clio"]},"587":{"title":"3.3 残差生成","titles":["PointMVS","方法","3. 点云优化"]},"588":{"title":"4.3.1 点云地图","titles":["Semanticmap综述","4 地图结构","4.3 稠密几何地图（Dense Geometric Map）"]},"589":{"title":"总结","titles":["MeshCNN"]},"590":{"title":"A. 问题描述","titles":["OccCylindrical","III. OCCCYLINDRICAL"]},"591":{"title":"CTC：ClassTokenContrast","titles":["DiffSeg","类似工作","ToCo"]},"592":{"title":"几何约束","titles":["MVSNet","后处理","深度图滤波"]},"593":{"title":"3. TorchSparse","titles":["稀疏卷积","稀疏卷积"]},"594":{"title":"检测头","titles":["DETR 3D","结构"]},"595":{"title":"3.3 激光雷达引导的3D可变形注意力","titles":["GaussianFormer3D","3. 方法"]},"596":{"title":"B. 基于激光雷达的环境感知","titles":["OccFusion","II. 相关工作"]},"597":{"title":"基本需求","titles":["数据集构建需求","2. 标注需求（暂）"]},"598":{"title":"3 框架","titles":["FlashOcc"]},"599":{"title":"2. 相关工作","titles":["GaussianFormer2"]},"600":{"title":"1. 引言","titles":["EmbodiedOcc"]},"601":{"title":"多任务感知","titles":["为什么选择OCC"]},"602":{"title":"Swin Transformer","titles":[]},"603":{"title":"2. 相关工作","titles":["MonoScene"]},"604":{"title":"emplace()","titles":["C++STL","unordered_set","unordered_set 常用函数"]},"605":{"title":"4.1.2 uHumans和uHumans2。","titles":["Kimera","第4节 实验评估","4.1 数据集"]},"606":{"title":"室外","titles":["Occ 概览"]},"607":{"title":"基于图的谱域","titles":["3D点云学习综述","3. 分类","3.2基于点的网络","3.2.3 基于图的网络"]},"608":{"title":"自动驾驶中的基于视觉的3D占用预测：回顾与展望","titles":[]},"609":{"title":"3.2 基础网络","titles":["DAOcc","3. 提出的方法","Multi-Modal 3D Object Detection"]},"610":{"title":"摘要","titles":["Occ 综述-模态融合视角"]},"611":{"title":"数据增强","titles":["3d自监督","Masked Scene Contrast","Approch","对比学习"]},"612":{"title":"2.1 3D语义占用预测","titles":["GaussianFormer","2 相关工作"]},"613":{"title":"A. 3D 占据预测的任务形式化","titles":["EFFOcc：从最小标签中学习高效占据网络用于自动驾驶","III 方法"]},"614":{"title":"Experiment","titles":["PointGPT"]},"615":{"title":"特征引导的位置编码","titles":["PETR 系列","PETRv2"]},"616":{"title":"Deformable Convolutional Networks","titles":["InternImage"]},"617":{"title":"规模化与预训练","titles":["FBOCC","2 方法"]},"618":{"title":"4. 上采样与迭代优化","titles":["PointMVS","方法"]},"619":{"title":"4.3.2 神经场","titles":["Semanticmap综述","4 地图结构","4.3 稠密几何地图（Dense Geometric Map）"]},"620":{"title":"概览","titles":[]},"621":{"title":"B. 整体架构","titles":["OccCylindrical","III. OCCCYLINDRICAL"]},"622":{"title":"光度约束","titles":["MVSNet","后处理","深度图滤波"]},"623":{"title":"特征整合到目标查询","titles":["DETR 3D","结构","检测头"]},"624":{"title":"4. 实验","titles":["GaussianFormer3D"]},"625":{"title":"C. 基于相机 - 激光雷达融合的环境感知","titles":["OccFusion","II. 相关工作"]},"626":{"title":"2.1 点云目标检测","titles":["数据集构建需求","2. 标注需求（暂）"]},"627":{"title":"3.1 图像编码器","titles":["FlashOcc","3 框架"]},"628":{"title":"3. 提出的方法","titles":["GaussianFormer2"]},"629":{"title":"2. 相关工作","titles":["EmbodiedOcc"]},"630":{"title":"bev","titles":["为什么选择OCC"]},"631":{"title":"Abstract","titles":["Swin Transformer"]},"632":{"title":"3. 方法","titles":["MonoScene"]},"633":{"title":"erase()","titles":["C++STL","unordered_set","unordered_set 常用函数"]},"634":{"title":"4.2 姿态估计","titles":["Kimera","第4节 实验评估"]},"635":{"title":"FB-occ 开源、部署文档","titles":["Occ 概览","室外"]},"636":{"title":"3.2.4 基于数据索引的网络","titles":["3D点云学习综述","3. 分类","3.2基于点的网络"]},"637":{"title":"摘要","titles":["自动驾驶中的基于视觉的3D占用预测：回顾与展望"]},"638":{"title":"3.3 BEV视野范围扩展（ BVRE ）","titles":["DAOcc","3. 提出的方法","Multi-Modal 3D Object Detection"]},"639":{"title":"1 引言","titles":["Occ 综述-模态融合视角","摘要"]},"640":{"title":"重建学习","titles":["3d自监督","Masked Scene Contrast","Approch"]},"641":{"title":"2.2 3D高斯溅射","titles":["GaussianFormer","2 相关工作"]},"642":{"title":"B. 架构","titles":["EFFOcc：从最小标签中学习高效占据网络用于自动驾驶","III 方法"]},"643":{"title":"结论","titles":["PointGPT"]},"644":{"title":"Query","titles":["PETR 系列","PETRv2"]},"645":{"title":"Deformable Convolution","titles":["InternImage","Deformable Convolutional Networks"]},"646":{"title":"后处理","titles":["FBOCC","2 方法"]},"647":{"title":"损失函数","titles":["PointMVS"]},"648":{"title":"4.4 混合地图（Hybrid Map）","titles":["Semanticmap综述","4 地图结构"]},"649":{"title":"C. 深度估计模块","titles":["OccCylindrical","III. OCCCYLINDRICAL"]},"650":{"title":"深度图融合","titles":["MVSNet","后处理"]},"651":{"title":"损失函数","titles":["DETR 3D","结构"]},"652":{"title":"4.1. 数据集","titles":["GaussianFormer3D","4. 实验"]},"653":{"title":"D. 基于相机 - 雷达融合的环境感知","titles":["OccFusion","II. 相关工作"]},"654":{"title":"2.1.1 标注格式","titles":["数据集构建需求","2. 标注需求（暂）","2.1 点云目标检测"]},"655":{"title":"3.2 视图变换器","titles":["FlashOcc","3 框架"]},"656":{"title":"3.1 3D 语义高斯表示","titles":["GaussianFormer2","3. 提出的方法"]},"657":{"title":"3. 提出的方法","titles":["EmbodiedOcc"]},"658":{"title":"occ","titles":["为什么选择OCC"]},"659":{"title":"Method","titles":["Swin Transformer"]},"660":{"title":"3.1 特征视线投影（FLoSP）","titles":["MonoScene","3. 方法"]},"661":{"title":"bucket_count()","titles":["C++STL","unordered_set","unordered_set 常用函数"]},"662":{"title":"4.2.1 动态场景中姿态估计的鲁棒性。","titles":["Kimera","第4节 实验评估","4.2 姿态估计"]},"663":{"title":"FlashOcc","titles":["Occ 概览","室外"]},"664":{"title":"3.2.5 其他模型","titles":["3D点云学习综述","3. 分类","3.2基于点的网络"]},"665":{"title":"1 引言","titles":["自动驾驶中的基于视觉的3D占用预测：回顾与展望"]},"666":{"title":"3.4 可分离的辅助检测头","titles":["DAOcc","3. 提出的方法","Multi-Modal 3D Object Detection"]},"667":{"title":"自动驾驶中的占用感知","titles":["Occ 综述-模态融合视角","摘要","1 引言"]},"668":{"title":"MACARONS","titles":["3d自监督"]},"669":{"title":"3 提出的方法","titles":["GaussianFormer"]},"670":{"title":"C. 高效融合网络","titles":["EFFOcc：从最小标签中学习高效占据网络用于自动驾驶","III 方法"]},"671":{"title":"STEAM PETR","titles":["PETR 系列"]},"672":{"title":"Regular conv","titles":["InternImage","Deformable Convolutional Networks","Deformable Convolution"]},"673":{"title":"2.3.1 测试时增强","titles":["FBOCC","2 方法","后处理"]},"674":{"title":"实验结果","titles":["PointMVS"]},"675":{"title":"5 地图编码（Map Encoding）","titles":["Semanticmap综述"]},"676":{"title":"D. TPV-Polar-Fusion","titles":["OccCylindrical","III. OCCCYLINDRICAL"]},"677":{"title":"4.2. 实现和评估细节","titles":["GaussianFormer3D","4. 实验"]},"678":{"title":"E. 基于相机 - 激光雷达 - 雷达融合的环境感知","titles":["OccFusion","II. 相关工作"]},"679":{"title":"2.1.2 目标类别","titles":["数据集构建需求","2. 标注需求（暂）","2.1 点云目标检测"]},"680":{"title":"3.3 BEV编码器","titles":["FlashOcc","3 框架"]},"681":{"title":"3.2 概率高斯叠加","titles":["GaussianFormer2","3. 提出的方法"]},"682":{"title":"3.1 具身三维空间占用预测","titles":["EmbodiedOcc","3. 提出的方法"]},"683":{"title":"Patch Embedding","titles":["Swin Transformer","Method"]},"684":{"title":"3.2 3D 上下文关系先验（3D CRP）","titles":["MonoScene","3. 方法"]},"685":{"title":"Stack 栈","titles":["C++STL"]},"686":{"title":"4.3 几何重建","titles":["Kimera","第4节 实验评估"]},"687":{"title":"OpenOcc","titles":["Occ 概览","室外"]},"688":{"title":"小结","titles":["3D点云学习综述","3. 分类","3.2基于点的网络"]},"689":{"title":"2 背景","titles":["自动驾驶中的基于视觉的3D占用预测：回顾与展望"]},"690":{"title":"3.5 总体目标函数","titles":["DAOcc","3. 提出的方法","Multi-Modal 3D Object Detection"]},"691":{"title":"信息融合研究的动机","titles":["Occ 综述-模态融合视角","摘要","1 引言"]},"692":{"title":"Point-M2AE:","titles":["3d自监督"]},"693":{"title":"3.1 以物体为中心的3D场景表示","titles":["GaussianFormer","3 提出的方法"]},"694":{"title":"D. 多阶段占据蒸馏","titles":["EFFOcc：从最小标签中学习高效占据网络用于自动驾驶","III 方法"]},"695":{"title":"要解决的问题","titles":["PETR 系列","STEAM PETR"]},"696":{"title":"Deformable conv","titles":["InternImage","Deformable Convolutional Networks","Deformable Convolution"]},"697":{"title":"2.3.2 集成","titles":["FBOCC","2 方法","后处理"]},"698":{"title":"5.1 显式编码（Explicit Encoding）","titles":["Semanticmap综述","5 地图编码（Map Encoding）"]},"699":{"title":"E. 共享编码器-解码器","titles":["OccCylindrical","III. OCCCYLINDRICAL"]},"700":{"title":"4.3. 定量结果","titles":["GaussianFormer3D","4. 实验"]},"701":{"title":"III. OCCFUSION","titles":["OccFusion"]},"702":{"title":"nuscenes 类别","titles":["数据集构建需求","2. 标注需求（暂）","2.1 点云目标检测","2.1.2 目标类别"]},"703":{"title":"3.4 占据预测模块","titles":["FlashOcc","3 框架"]},"704":{"title":"3.3 基于分布的初始化","titles":["GaussianFormer2","3. 提出的方法"]},"705":{"title":"3.2 局部空间占用预测模块","titles":["EmbodiedOcc"]},"706":{"title":"Patch Merging","titles":["Swin Transformer","Method"]},"707":{"title":"体素↔\\\\leftrightarrow↔体素关系","titles":["MonoScene","3. 方法","3.2 3D 上下文关系先验（3D CRP）"]},"708":{"title":"定义","titles":["C++STL","Stack 栈"]},"709":{"title":"4.3.1 动态场景中网格重建的鲁棒性。","titles":["Kimera","第4节 实验评估","4.3 几何重建"]},"710":{"title":"Surroundocc","titles":["Occ 概览","室外"]},"711":{"title":"4. 检测/跟踪","titles":["3D点云学习综述"]},"712":{"title":"2.1 基于视觉的3D占用预测的定义","titles":["自动驾驶中的基于视觉的3D占用预测：回顾与展望","2 背景"]},"713":{"title":"4. 实验","titles":["DAOcc"]},"714":{"title":"贡献","titles":["Occ 综述-模态融合视角","摘要","1 引言"]},"715":{"title":"GeoMAE","titles":["3d自监督"]},"716":{"title":"3.2 GaussianFormer：从图像到高斯分布","titles":["GaussianFormer","3 提出的方法"]},"717":{"title":"IV 实验","titles":["EFFOcc：从最小标签中学习高效占据网络用于自动驾驶"]},"718":{"title":"History Memory Queue","titles":["PETR 系列","STEAM PETR"]},"719":{"title":"Defomable RoI Pooling","titles":["InternImage","Deformable Convolutional Networks"]},"720":{"title":"3 实验","titles":["FBOCC"]},"721":{"title":"5.2 隐式编码（Implicit Encoding）","titles":["Semanticmap综述","5 地图编码（Map Encoding）"]},"722":{"title":"IV. 实验结果","titles":["OccCylindrical"]},"723":{"title":"4.4. 消融研究","titles":["GaussianFormer3D","4. 实验"]},"724":{"title":"A. 问题陈述","titles":["OccFusion","III. OCCFUSION"]},"725":{"title":"2.2 点云语义分割","titles":["数据集构建需求","2. 标注需求（暂）"]},"726":{"title":"3.5 时间融合模块","titles":["FlashOcc","3 框架"]},"727":{"title":"4. 实验","titles":["GaussianFormer2"]},"728":{"title":"3.3 在线更新高斯记忆","titles":["EmbodiedOcc"]},"729":{"title":"W-MSA","titles":["Swin Transformer","Method"]},"730":{"title":"超体素↔\\\\leftrightarrow↔体素关系","titles":["MonoScene","3. 方法","3.2 3D 上下文关系先验（3D CRP）"]},"731":{"title":"压入","titles":["C++STL","Stack 栈"]},"732":{"title":"4.4 语义重建","titles":["Kimera","第4节 实验评估"]},"733":{"title":"OccFormer","titles":["Occ 概览","室外"]},"734":{"title":"4.1 3D 目标检测","titles":["3D点云学习综述","4. 检测/跟踪"]},"735":{"title":"2.2 真实标签生成","titles":["自动驾驶中的基于视觉的3D占用预测：回顾与展望","2 背景"]},"736":{"title":"4.1 数据集和评估指标","titles":["DAOcc","4. 实验","Multi-Modal 3D Object Detection"]},"737":{"title":"2 背景","titles":["Occ 综述-模态融合视角","摘要"]},"738":{"title":"3.3 高斯到体素的溅射","titles":["GaussianFormer","3 提出的方法"]},"739":{"title":"A. 数据集和指标","titles":["EFFOcc：从最小标签中学习高效占据网络用于自动驾驶","IV 实验"]},"740":{"title":"Propagation Transformer","titles":["PETR 系列","STEAM PETR"]},"741":{"title":"RoI Pooling （average）","titles":["InternImage","Deformable Convolutional Networks","Defomable RoI Pooling"]},"742":{"title":"数据集与指标","titles":["FBOCC","3 实验"]},"743":{"title":"5.2.1 Closed-vocabulary encoding","titles":["Semanticmap综述","5 地图编码（Map Encoding）","5.2 隐式编码（Implicit Encoding）"]},"744":{"title":"A. 实现细节","titles":["OccCylindrical","IV. 实验结果"]},"745":{"title":"4.5. 定性结果","titles":["GaussianFormer3D","4. 实验"]},"746":{"title":"B. 总体架构","titles":["OccFusion","III. OCCFUSION"]},"747":{"title":"2.2.1 标注格式","titles":["数据集构建需求","2. 标注需求（暂）","2.2 点云语义分割"]},"748":{"title":"4 实验","titles":["FlashOcc"]},"749":{"title":"4.1 数据集和评估指标","titles":["GaussianFormer2","4. 实验"]},"750":{"title":"3.4 EmbodiedOcc：一个具身框架","titles":["EmbodiedOcc"]},"751":{"title":"Masked MSA","titles":["Swin Transformer","Method"]},"752":{"title":"3D 上下文关系先验层","titles":["MonoScene","3. 方法","3.2 3D 上下文关系先验（3D CRP）"]},"753":{"title":"弹出","titles":["C++STL","Stack 栈"]},"754":{"title":"4.5 循环闭合和网格变形","titles":["Kimera","第4节 实验评估"]},"755":{"title":"Renderocc （nerf）","titles":["Occ 概览","室外"]},"756":{"title":"4.1.1 基于区域建议的方法","titles":["3D点云学习综述","4. 检测/跟踪","4.1 3D 目标检测"]},"757":{"title":"2.3 数据集","titles":["自动驾驶中的基于视觉的3D占用预测：回顾与展望","2 背景"]},"758":{"title":"4.2 实现细节","titles":["DAOcc","4. 实验","Multi-Modal 3D Object Detection"]},"759":{"title":"2.1 占用感知的简要历史","titles":["Occ 综述-模态融合视角","摘要","2 背景"]},"760":{"title":"4 实验","titles":["GaussianFormer"]},"761":{"title":"B. 实现细节","titles":["EFFOcc：从最小标签中学习高效占据网络用于自动驾驶","IV 实验"]},"762":{"title":"MLN","titles":["PETR 系列","STEAM PETR","Propagation Transformer"]},"763":{"title":"Position-Sensitive Roi Pooling","titles":["InternImage","Deformable Convolutional Networks","Defomable RoI Pooling"]},"764":{"title":"实现细节","titles":["FBOCC","3 实验"]},"765":{"title":"5.2.2 Open-vocabulary encoding","titles":["Semanticmap综述","5 地图编码（Map Encoding）","5.2 隐式编码（Implicit Encoding）"]},"766":{"title":"B. 损失函数","titles":["OccCylindrical","IV. 实验结果"]},"767":{"title":"5. 结论","titles":["GaussianFormer3D"]},"768":{"title":"C. 环视图像特征提取","titles":["OccFusion","III. OCCFUSION"]},"769":{"title":"2.2.2 语义类别","titles":["数据集构建需求","2. 标注需求（暂）","2.2 点云语义分割"]},"770":{"title":"4.1 实验设置","titles":["FlashOcc","4 实验"]},"771":{"title":"4.2 实现细节","titles":["GaussianFormer2","4. 实验"]},"772":{"title":"4. 实验","titles":["EmbodiedOcc"]},"773":{"title":"3.3 损失函数","titles":["MonoScene","3. 方法"]},"774":{"title":"栈顶元素","titles":["C++STL","Stack 栈"]},"775":{"title":"4.6 解析人类和对象","titles":["Kimera","第4节 实验评估"]},"776":{"title":"Sparseocc","titles":["Occ 概览","室外"]},"777":{"title":"基于多视图的方法","titles":["3D点云学习综述","4. 检测/跟踪","4.1 3D 目标检测","4.1.1 基于区域建议的方法"]},"778":{"title":"2.4 评估指标","titles":["自动驾驶中的基于视觉的3D占用预测：回顾与展望","2 背景"]},"779":{"title":"4.3 与最新方法的比较","titles":["DAOcc","4. 实验","Multi-Modal 3D Object Detection"]},"780":{"title":"2.2 任务定义","titles":["Occ 综述-模态融合视角","摘要","2 背景"]},"781":{"title":"4.1 数据集","titles":["GaussianFormer","4 实验"]},"782":{"title":"C. 有限标签下的高效学习结果","titles":["EFFOcc：从最小标签中学习高效占据网络用于自动驾驶","IV 实验"]},"783":{"title":"实验","titles":["PETR 系列","STEAM PETR"]},"784":{"title":"Visualization","titles":["InternImage","Deformable Convolutional Networks"]},"785":{"title":"消融研究","titles":["FBOCC","3 实验"]},"786":{"title":"6 评估方法（Evaluation Methodologies）","titles":["Semanticmap综述"]},"787":{"title":"C. 数据集","titles":["OccCylindrical","IV. 实验结果"]},"788":{"title":"补充材料","titles":["GaussianFormer3D"]},"789":{"title":"D. 激光雷达密集 3D 点云特征提取","titles":["OccFusion","III. OCCFUSION"]},"790":{"title":"nuscenes lidarseg 类别","titles":["数据集构建需求","2. 标注需求（暂）","2.2 点云语义分割","2.2.2 语义类别"]},"791":{"title":"4.2 与最先进方法的比较","titles":["FlashOcc","4 实验"]},"792":{"title":"4.3 主要结果","titles":["GaussianFormer2","4. 实验"]},"793":{"title":"4.1 EmbodiedOcc-ScanNet基准测试","titles":["EmbodiedOcc","4. 实验"]},"794":{"title":"3.3.1 场景类别亲和力损失","titles":["MonoScene","3. 方法","3.3 损失函数"]},"795":{"title":"是否为空","titles":["C++STL","Stack 栈"]},"796":{"title":"4.7 解析地点和房间","titles":["Kimera","第4节 实验评估"]},"797":{"title":"Fastocc","titles":["Occ 概览","室外"]},"798":{"title":"基于分割的方法","titles":["3D点云学习综述","4. 检测/跟踪","4.1 3D 目标检测","4.1.1 基于区域建议的方法"]},"799":{"title":"2.5 关键挑战","titles":["自动驾驶中的基于视觉的3D占用预测：回顾与展望","2 背景"]},"800":{"title":"4.4 消融研究","titles":["DAOcc","4. 实验","Multi-Modal 3D Object Detection"]},"801":{"title":"2.3 相关工作","titles":["Occ 综述-模态融合视角","摘要","2 背景"]},"802":{"title":"4.2 评估指标","titles":["GaussianFormer"]},"803":{"title":"D. 提出的融合式占用网络的结果","titles":["EFFOcc：从最小标签中学习高效占据网络用于自动驾驶","IV 实验"]},"804":{"title":"Deformable ConvNets v2: More Deformable, Better Results","titles":["InternImage"]},"805":{"title":"规模化","titles":["FBOCC","3 实验"]},"806":{"title":"6.1 Extrinsic evaluation","titles":["Semanticmap综述","6 评估方法（Evaluation Methodologies）"]},"807":{"title":"D. 性能评估指标","titles":["OccCylindrical","IV. 实验结果"]},"808":{"title":"A. 相关工作","titles":["GaussianFormer3D","补充材料"]},"809":{"title":"E. 雷达稀疏 3D 点云特征提取","titles":["OccFusion","III. OCCFUSION"]},"810":{"title":"3. nuScenes 数据转换到 Occupancy 数据","titles":["数据集构建需求"]},"811":{"title":"4.3 消融研究","titles":["FlashOcc","4 实验"]},"812":{"title":"4.4 消融研究","titles":["GaussianFormer2","4. 实验"]},"813":{"title":"4.2 实现细节","titles":["EmbodiedOcc","4. 实验"]},"814":{"title":"3.3.2 视锥比例损失","titles":["MonoScene","3. 方法","3.3 损失函数"]},"815":{"title":"队列","titles":["C++STL"]},"816":{"title":"4.8 计时","titles":["Kimera","第4节 实验评估"]},"817":{"title":"GaussianFormer","titles":["Occ 概览","室外"]},"818":{"title":"基于视锥的方法","titles":["3D点云学习综述","4. 检测/跟踪","4.1 3D 目标检测","4.1.1 基于区域建议的方法"]},"819":{"title":"3 特征增强方法","titles":["自动驾驶中的基于视觉的3D占用预测：回顾与展望"]},"820":{"title":"5. 结论","titles":["DAOcc"]},"821":{"title":"2.3.1 鸟瞰图感知","titles":["Occ 综述-模态融合视角","摘要","2 背景","2.3 相关工作"]},"822":{"title":"4.3 实现细节","titles":["GaussianFormer"]},"823":{"title":"E. 基于知识蒸馏的视觉 OccNet 的结果","titles":["EFFOcc：从最小标签中学习高效占据网络用于自动驾驶","IV 实验"]},"824":{"title":"DCN v3","titles":["InternImage"]},"825":{"title":"后处理","titles":["FBOCC","3 实验"]},"826":{"title":"6.2 Intrinsic evaluation","titles":["Semanticmap综述","6 评估方法（Evaluation Methodologies）"]},"827":{"title":"E. 模型性能分析","titles":["OccCylindrical","IV. 实验结果"]},"828":{"title":"B. WildOcc 数据集","titles":["GaussianFormer3D","补充材料"]},"829":{"title":"F. 动态融合 3D/2D","titles":["OccFusion","III. OCCFUSION"]},"830":{"title":"3.1 方法","titles":["数据集构建需求","3. nuScenes 数据转换到 Occupancy 数据"]},"831":{"title":"5 结论","titles":["FlashOcc"]},"832":{"title":"4.5 可视化","titles":["GaussianFormer2","4. 实验"]},"833":{"title":"4.3 结果与分析","titles":["EmbodiedOcc","4. 实验"]},"834":{"title":"3.4 训练策略","titles":["MonoScene","3. 方法"]},"835":{"title":"queue","titles":["C++STL","队列"]},"836":{"title":"4.9 在NVIDIA TX2嵌入式计算机上的计时","titles":["Kimera","第4节 实验评估"]},"837":{"title":"GaussianFormer2","titles":["Occ 概览","室外"]},"838":{"title":"其他方法","titles":["3D点云学习综述","4. 检测/跟踪","4.1 3D 目标检测","4.1.1 基于区域建议的方法"]},"839":{"title":"3.1 基于BEV的方法","titles":["自动驾驶中的基于视觉的3D占用预测：回顾与展望","3 特征增强方法"]},"840":{"title":"附加材料","titles":["DAOcc"]},"841":{"title":"2.3.2 3D语义场景补全","titles":["Occ 综述-模态融合视角","摘要","2 背景","2.3 相关工作"]},"842":{"title":"4.4 结果与分析","titles":["GaussianFormer","4.3 实现细节"]},"843":{"title":"F. 定性结果","titles":["EFFOcc：从最小标签中学习高效占据网络用于自动驾驶","IV 实验"]},"844":{"title":"DCNv2","titles":["InternImage","DCN v3"]},"845":{"title":"4 结论","titles":["FBOCC"]},"846":{"title":"6.3 总结","titles":["Semanticmap综述","6 评估方法（Evaluation Methodologies）"]},"847":{"title":"F. 在具有挑战性的场景下的定性研究","titles":["OccCylindrical","IV. 实验结果"]},"848":{"title":"C. 评估指标","titles":["GaussianFormer3D","补充材料"]},"849":{"title":"IV. 实验结果","titles":["OccFusion"]},"850":{"title":"3.2 转换脚本","titles":["数据集构建需求","3. nuScenes 数据转换到 Occupancy 数据"]},"851":{"title":"5. 结论","titles":["GaussianFormer2"]},"852":{"title":"5. 结论","titles":["EmbodiedOcc"]},"853":{"title":"4. 实验","titles":["MonoScene"]},"854":{"title":"queue 其他操作","titles":["C++STL","队列","queue"]},"855":{"title":"4.10 真实生活实验","titles":["Kimera","第4节 实验评估"]},"856":{"title":"室内","titles":["Occ 概览"]},"857":{"title":"4.1.2 Single-Shot 方法（end-to-end）","titles":["3D点云学习综述","4. 检测/跟踪","4.1 3D 目标检测"]},"858":{"title":"3.2 基于TPV的方法","titles":["自动驾驶中的基于视觉的3D占用预测：回顾与展望","3 特征增强方法"]},"859":{"title":"6. 运行时间比较","titles":["DAOcc","附加材料"]},"860":{"title":"2.3.3 基于图像的3D重建","titles":["Occ 综述-模态融合视角","摘要","2 背景","2.3 相关工作"]},"861":{"title":"5 结论与讨论","titles":["GaussianFormer"]},"862":{"title":"V 结论","titles":["EFFOcc：从最小标签中学习高效占据网络用于自动驾驶"]},"863":{"title":"DCNv3","titles":["InternImage","DCN v3"]},"864":{"title":"7 开放挑战（Open Challenges）","titles":["Semanticmap综述"]},"865":{"title":"G. 模型效率研究","titles":["OccCylindrical","IV. 实验结果"]},"866":{"title":"D. 实现细节","titles":["GaussianFormer3D","补充材料"]},"867":{"title":"A. 实现细节","titles":["OccFusion","IV. 实验结果"]},"868":{"title":"补充材料","titles":["GaussianFormer2"]},"869":{"title":"附录","titles":["EmbodiedOcc"]},"870":{"title":"4.1 基线方法","titles":["MonoScene","4. 实验","3.4 训练策略"]},"871":{"title":"deque","titles":["C++STL","队列"]},"872":{"title":"4.10.1 “学校”和“航空宇航”。","titles":["Kimera","第4节 实验评估","4.10 真实生活实验"]},"873":{"title":"MonoScene","titles":["Occ 概览","室内"]},"874":{"title":"基于BEV的方法","titles":["3D点云学习综述","4. 检测/跟踪","4.1 3D 目标检测","4.1.2 Single-Shot 方法（end-to-end）"]},"875":{"title":"3.3 基于体素的方法","titles":["自动驾驶中的基于视觉的3D占用预测：回顾与展望","3 特征增强方法"]},"876":{"title":"7. 达到最终性能的消融实验","titles":["DAOcc","附加材料"]},"877":{"title":"3 方法论","titles":["Occ 综述-模态融合视角","摘要"]},"878":{"title":"局限性","titles":["GaussianFormer","5 结论与讨论"]},"879":{"title":"参考文献","titles":["EFFOcc：从最小标签中学习高效占据网络用于自动驾驶"]},"880":{"title":"构建模型","titles":["InternImage","DCN v3"]},"881":{"title":"8. 未来研究方向","titles":["Semanticmap综述"]},"882":{"title":"H. 模型组件的消融研究","titles":["OccCylindrical","IV. 实验结果"]},"883":{"title":"E. 补充实验","titles":["GaussianFormer3D","补充材料"]},"884":{"title":"B. 损失函数","titles":["OccFusion","IV. 实验结果"]},"885":{"title":"A. 视频演示","titles":["GaussianFormer2","补充材料"]},"886":{"title":"A. EmbodiedOcc-ScanNet 数据集细节","titles":["EmbodiedOcc","附录"]},"887":{"title":"4.2 性能","titles":["MonoScene","4. 实验","3.4 训练策略"]},"888":{"title":"初始化","titles":["C++STL","队列","deque"]},"889":{"title":"4.10.2 “白猫头鹰”。","titles":["Kimera","第4节 实验评估","4.10 真实生活实验"]},"890":{"title":"Monocular Occupancy Prediction for Scalable Indoor Scenes","titles":["Occ 概览","室内"]},"891":{"title":"基于点云的方法","titles":["3D点云学习综述","4. 检测/跟踪","4.1 3D 目标检测","4.1.2 Single-Shot 方法（end-to-end）"]},"892":{"title":"4 部署友好方法","titles":["自动驾驶中的基于视觉的3D占用预测：回顾与展望"]},"893":{"title":"8. 检测性能","titles":["DAOcc","附加材料"]},"894":{"title":"3.1 以激光雷达为中心的占用感知","titles":["Occ 综述-模态融合视角","摘要","3 方法论"]},"895":{"title":"附录部分（Appendix）","titles":["GaussianFormer"]},"896":{"title":"Stacking Rules","titles":["InternImage","DCN v3","构建模型"]},"897":{"title":"8.1 通用型地图","titles":["Semanticmap综述","8. 未来研究方向"]},"898":{"title":"V. 结论","titles":["OccCylindrical"]},"899":{"title":"E.1. 定性结果","titles":["GaussianFormer3D","补充材料","E. 补充实验"]},"900":{"title":"C. 数据集","titles":["OccFusion","IV. 实验结果"]},"901":{"title":"B. KITTI-360 上的可视化","titles":["GaussianFormer2","补充材料"]},"902":{"title":"B. 额外可视化","titles":["EmbodiedOcc","附录"]},"903":{"title":"4.2.1 评估","titles":["MonoScene","4. 实验","3.4 训练策略","4.2 性能"]},"904":{"title":"操作函数","titles":["C++STL","队列","deque"]},"905":{"title":"5 激励示例","titles":["Kimera"]},"906":{"title":"SliceOcc:","titles":["Occ 概览","室内"]},"907":{"title":"4.2 3D目标跟踪","titles":["3D点云学习综述","4. 检测/跟踪"]},"908":{"title":"4.1 视角分解方法","titles":["自动驾驶中的基于视觉的3D占用预测：回顾与展望","4 部署友好方法"]},"909":{"title":"9. 可视化","titles":["DAOcc","附加材料"]},"910":{"title":"3.1.1 通用流程","titles":["Occ 综述-模态融合视角","摘要","3 方法论","3.1 以激光雷达为中心的占用感知"]},"911":{"title":"A 视频演示","titles":["GaussianFormer","附录部分（Appendix）"]},"912":{"title":"Scaling Rules","titles":["InternImage","DCN v3","构建模型"]},"913":{"title":"8.2 稠密而高效的地图","titles":["Semanticmap综述","8. 未来研究方向"]},"914":{"title":"E.2. 定量结果","titles":["GaussianFormer3D","补充材料","E. 补充实验"]},"915":{"title":"D. 性能评估指标","titles":["OccFusion","IV. 实验结果"]},"916":{"title":"C. 评估指标细节","titles":["GaussianFormer2","补充材料"]},"917":{"title":"4.2.2 与 2.5/3D 输入基线的比较","titles":["MonoScene","4. 实验","3.4 训练策略","4.2 性能"]},"918":{"title":"迭代器算法","titles":["C++STL","队列","deque"]},"919":{"title":"6 应用","titles":["Kimera"]},"920":{"title":"EmbodiedOcc","titles":["Occ 概览","室内"]},"921":{"title":"4.3 3D场景流估计","titles":["3D点云学习综述","4. 检测/跟踪"]},"922":{"title":"从粗到细的方法","titles":["自动驾驶中的基于视觉的3D占用预测：回顾与展望","4 部署友好方法"]},"923":{"title":"3.1.2 2D与3D分支的融合","titles":["Occ 综述-模态融合视角","摘要","3 方法论","3.1 以激光雷达为中心的占用感知"]},"924":{"title":"B 额外的可视化","titles":["GaussianFormer","附录部分（Appendix）"]},"925":{"title":"Result","titles":["InternImage"]},"926":{"title":"8.3 动态地图","titles":["Semanticmap综述","8. 未来研究方向"]},"927":{"title":"E. 模型性能分析","titles":["OccFusion","IV. 实验结果"]},"928":{"title":"4.3 消融研究","titles":["MonoScene","4. 实验","3.4 训练策略"]},"929":{"title":"算法","titles":["C++STL","队列","deque"]},"930":{"title":"6.1 层次路径规划","titles":["Kimera","6 应用"]},"931":{"title":"小结","titles":["3D点云学习综述","4. 检测/跟踪"]},"932":{"title":"5 标签高效方法","titles":["自动驾驶中的基于视觉的3D占用预测：回顾与展望"]},"933":{"title":"3.2 以视觉为中心的占用感知","titles":["Occ 综述-模态融合视角","摘要","3 方法论"]},"934":{"title":"C 额外的消融研究","titles":["GaussianFormer","附录部分（Appendix）"]},"935":{"title":"8.4 混合地图结构","titles":["Semanticmap综述","8. 未来研究方向"]},"936":{"title":"F. 具有挑战性的场景性能分析","titles":["OccFusion","IV. 实验结果"]},"937":{"title":"5. 讨论","titles":["MonoScene"]},"938":{"title":"总结","titles":["C++STL","队列","deque"]},"939":{"title":"6.2 语义路径规划","titles":["Kimera","6 应用"]},"940":{"title":"5. 分割","titles":["3D点云学习综述"]},"941":{"title":"无注释方法","titles":["自动驾驶中的基于视觉的3D占用预测：回顾与展望","5 标签高效方法"]},"942":{"title":"3.2.1 通用流程","titles":["Occ 综述-模态融合视角","摘要","3 方法论","3.2 以视觉为中心的占用感知"]},"943":{"title":"8.5 设计评估指标","titles":["Semanticmap综述","8. 未来研究方向"]},"944":{"title":"G. 感知范围对模型性能的影响","titles":["OccFusion","IV. 实验结果"]},"945":{"title":"局限性","titles":["MonoScene","5. 讨论","3.4 训练策略"]},"946":{"title":"priority_queue","titles":["C++STL","队列"]},"947":{"title":"6.3 DSG上的路径规划性能","titles":["Kimera","6 应用"]},"948":{"title":"5.1 3D 场景分割","titles":["3D点云学习综述","5. 分割"]},"949":{"title":"无LiDAR方法","titles":["自动驾驶中的基于视觉的3D占用预测：回顾与展望","5 标签高效方法"]},"950":{"title":"3.2.2 2D到3D的转换","titles":["Occ 综述-模态融合视角","摘要","3 方法论","3.2 以视觉为中心的占用感知"]},"951":{"title":"8.6 小结","titles":["Semanticmap综述","8. 未来研究方向"]},"952":{"title":"H. 框架定性分析","titles":["OccFusion","IV. 实验结果"]},"953":{"title":"更广泛的影响与伦理问题","titles":["MonoScene","5. 讨论","3.4 训练策略"]},"954":{"title":"7 相关工作","titles":["Kimera"]},"955":{"title":"5.1.1 基于投影的网络","titles":["3D点云学习综述","5. 分割","5.1 3D 场景分割"]},"956":{"title":"6 未来展望","titles":["自动驾驶中的基于视觉的3D占用预测：回顾与展望"]},"957":{"title":"3.2.3 以视觉为中心的占用感知中的信息融合","titles":["Occ 综述-模态融合视角","摘要","3 方法论","3.2 以视觉为中心的占用感知"]},"958":{"title":"9 结论","titles":["Semanticmap综述"]},"959":{"title":"I. 框架训练收敛速度研究","titles":["OccFusion","IV. 实验结果"]},"960":{"title":"致谢","titles":["MonoScene","5. 讨论","3.4 训练策略"]},"961":{"title":"7.1 世界表示 场景图。","titles":["Kimera","7 相关工作"]},"962":{"title":"5.1.2 基于离散化的方法","titles":["3D点云学习综述","5. 分割","5.1 3D 场景分割"]},"963":{"title":"数据层面","titles":["自动驾驶中的基于视觉的3D占用预测：回顾与展望","6 未来展望"]},"964":{"title":"3.3 多模态占用感知","titles":["Occ 综述-模态融合视角","摘要","3 方法论"]},"965":{"title":"J. 框架效率研究","titles":["OccFusion","IV. 实验结果"]},"966":{"title":"附录","titles":["MonoScene"]},"967":{"title":"7.2 感知算法 动态环境中的SLAM和VIO。","titles":["Kimera","7 相关工作"]},"968":{"title":"5.1.3 混合方法","titles":["3D点云学习综述","5. 分割","5.1 3D 场景分割"]},"969":{"title":"方法层面","titles":["自动驾驶中的基于视觉的3D占用预测：回顾与展望","6 未来展望"]},"970":{"title":"3.3.1 通用流程","titles":["Occ 综述-模态融合视角","摘要","3 方法论","3.3 多模态占用感知"]},"971":{"title":"K. 框架消融研究","titles":["OccFusion","IV. 实验结果"]},"972":{"title":"A. 架构细节","titles":["MonoScene","附录"]},"973":{"title":"8 结论","titles":["Kimera"]},"974":{"title":"5.1.4 基于点的方法","titles":["3D点云学习综述","5. 分割","5.1 3D 场景分割"]},"975":{"title":"任务层面","titles":["自动驾驶中的基于视觉的3D占用预测：回顾与展望","6 未来展望"]},"976":{"title":"3.3.2 多模态占用感知中的信息融合","titles":["Occ 综述-模态融合视角","摘要","3 方法论","3.3 多模态占用感知"]},"977":{"title":"V. 结论","titles":["OccFusion"]},"978":{"title":"A.1 基线方法","titles":["MonoScene","附录","A. 架构细节"]},"979":{"title":"小结","titles":["3D点云学习综述","5. 分割","5.1 3D 场景分割"]},"980":{"title":"致谢","titles":["自动驾驶中的基于视觉的3D占用预测：回顾与展望"]},"981":{"title":"3.4 网络训练","titles":["Occ 综述-模态融合视角","摘要"]},"982":{"title":"A.2 MonoScene","titles":["MonoScene","附录","A. 架构细节"]},"983":{"title":"5.2 实例分割","titles":["3D点云学习综述","5. 分割"]},"984":{"title":"利益冲突","titles":["自动驾驶中的基于视觉的3D占用预测：回顾与展望"]},"985":{"title":"3.4.1 强监督训练","titles":["Occ 综述-模态融合视角","摘要","3.4 网络训练"]},"986":{"title":"B. 附加结果","titles":["MonoScene","附录"]},"987":{"title":"5.2.1 基于proposal的方法","titles":["3D点云学习综述","5. 分割","5.2 实例分割"]},"988":{"title":"3.4.2 其他监督训练","titles":["Occ 综述-模态融合视角","摘要","3.4 网络训练"]},"989":{"title":"B.1 SemanticKITTI","titles":["MonoScene","附录","B. 附加结果"]},"990":{"title":"5.2.2 Proposal-free Methods","titles":["3D点云学习综述","5. 分割","5.2 实例分割"]},"991":{"title":"4 评估","titles":["Occ 综述-模态融合视角","摘要"]},"992":{"title":"B.2 NYUv2","titles":["MonoScene","附录","B. 附加结果"]},"993":{"title":"5.3 部件分割","titles":["3D点云学习综述","5. 分割"]},"994":{"title":"4.1 数据集和指标","titles":["Occ 综述-模态融合视角","摘要","4 评估"]},"995":{"title":"B.3 泛化能力","titles":["MonoScene","附录","B. 附加结果"]},"996":{"title":"小结","titles":["3D点云学习综述","5. 分割"]},"997":{"title":"4.1.1 数据集","titles":["Occ 综述-模态融合视角","摘要","4 评估","4.1 数据集和指标"]},"998":{"title":"4.1.2 评估指标","titles":["Occ 综述-模态融合视角","摘要","4 评估","4.1 数据集和指标"]},"999":{"title":"4.2 性能","titles":["Occ 综述-模态融合视角","摘要"]},"1000":{"title":"4.2.1 感知准确性","titles":["Occ 综述-模态融合视角","摘要","4.2 性能"]},"1001":{"title":"4.2.2 推理速度","titles":["Occ 综述-模态融合视角","摘要","4.2 性能"]},"1002":{"title":"5 挑战与机遇","titles":["Occ 综述-模态融合视角","摘要"]},"1003":{"title":"5.1 基于占用的自动驾驶应用","titles":["Occ 综述-模态融合视角","摘要","5 挑战与机遇"]},"1004":{"title":"5.2 部署效率","titles":["Occ 综述-模态融合视角","摘要","5 挑战与机遇"]},"1005":{"title":"5.3 鲁棒的3D占用感知","titles":["Occ 综述-模态融合视角","摘要","5 挑战与机遇"]},"1006":{"title":"5.4 广义3D占用感知","titles":["Occ 综述-模态融合视角","摘要","5 挑战与机遇"]},"1007":{"title":"6 结论","titles":["Occ 综述-模态融合视角","摘要"]},"1008":{"title":"致谢","titles":["Occ 综述-模态融合视角","摘要"]}},"dirtCount":0,"index":[["雾和雪花等小颗粒",{"2":{"1005":1}}],["挑战与机遇",{"0":{"1002":1},"1":{"1003":1,"1004":1,"1005":1,"1006":1}}],["挑战赛主要基于miou评估模型",{"2":{"742":1}}],["挑战赛道要求参赛者仅使用相机输入开发占据预测算法",{"2":{"520":1}}],["骑摩托车者",{"2":{"1000":1}}],["骑自行车者",{"2":{"1000":1}}],["骑车人",{"2":{"630":1}}],["射线级miou评估每个查询射线",{"2":{"998":1}}],["射线级miou的公式与公式17在形式上一致",{"2":{"998":1}}],["射线级指标",{"2":{"998":1}}],["射击",{"2":{"612":1}}],["剪辑数量",{"2":{"997":1}}],["元数据集",{"2":{"997":1}}],["元素排序",{"2":{"929":1}}],["元素翻转",{"2":{"929":1}}],["元素",{"2":{"572":1,"888":1}}],["元素值为0",{"2":{"93":1}}],["乡村等",{"2":{"995":1}}],["弱监督意味着不使用占用标签",{"2":{"988":1}}],["弱监督",{"2":{"988":2}}],["弱光物体",{"2":{"864":1}}],["鼓励学生模型从教师模型提供的在线软标签中学习更准确的占用",{"2":{"985":1}}],["利益冲突",{"0":{"984":1}}],["利用强大的预训练视觉语言模型",{"2":{"1006":1}}],["利用强化学习",{"2":{"252":1}}],["利用成像雷达实现了鲁棒的占用感知",{"2":{"1005":1}}],["利用对象进行联合对象和地点分类",{"2":{"967":1}}],["利用对应的点云语义分割标签",{"2":{"617":1}}],["利用现成的基于bev的3d占用模型",{"2":{"963":1}}],["利用现有的标注3d感知数据集",{"2":{"757":1}}],["利用3d占用作为世界模型中的环境观察具有明显优势",{"2":{"963":1}}],["利用3d分割网络",{"2":{"492":1}}],["利用文本等提示来控制生成的驾驶数据内容",{"2":{"963":1}}],["利用轻量级mlp在特征通道维度上生成占用状态和语义",{"2":{"957":1}}],["利用更强大的多模态模型来指导基于视觉的模型训练",{"2":{"941":1}}],["利用相邻帧的光线来增强当前帧的多视角一致性约束",{"2":{"941":1}}],["利用相机和激光雷达输入",{"2":{"779":1}}],["利用相机投影矩阵将这些centers投影到所有的feature",{"2":{"594":1}}],["利用语义地图和不同的抽象层次",{"2":{"939":1}}],["利用语义信息初始化和迭代细化八叉树结构",{"2":{"922":1}}],["利用语言派生键的多尺度融合在精细空间层面提升定位",{"2":{"195":1}}],["利用八叉树结构为不同区域提供不同的建模粒度",{"2":{"922":1}}],["利用稀疏实例查询预测稀疏空间中每个对象的掩码和标签",{"2":{"922":1}}],["利用稀疏体素解码器重建场景的稀疏几何结构",{"2":{"482":1}}],["利用特征透视投影将2d特征投影到3d空间",{"2":{"875":1}}],["利用内在校准",{"2":{"870":1}}],["利用大模型的强大性能",{"2":{"759":1}}],["利用靠近自车的前帧预测体素替换当前帧同位置体素",{"2":{"673":1}}],["利用占用网格映射来确定网格是否被占用",{"2":{"665":1}}],["利用标准rnn和2dcnn构造一个置换不变的三维点云处理网络",{"2":{"664":1}}],["利用激光雷达3d点云对深度分布特征",{"2":{"621":1}}],["利用体渲染将",{"2":{"619":1}}],["利用高斯核和学习的距离对图的邻接矩阵进行归一化",{"2":{"607":1}}],["利用双线性插值",{"2":{"594":1}}],["利用注意力捕获长程依赖",{"2":{"588":1}}],["利用点云生成精确深度真值",{"2":{"585":1}}],["利用depthnet基于这些视觉特征生成深度分布特征",{"2":{"578":1}}],["利用严格的旋转不变",{"2":{"574":1}}],["利用滤波器生成网络",{"2":{"574":1}}],["利用2",{"2":{"566":1}}],["利用中间层",{"2":{"559":1}}],["利用ref图的边界信息优化深度图",{"2":{"470":1}}],["利用上一步的概率体",{"2":{"470":1}}],["利用mlp学习不同局部结构之间的关系特征",{"2":{"420":1}}],["利用knn算法从x中选择k个最近的点构建n个点块p",{"2":{"396":1}}],["利用bit来对八叉树结构进行有效编码",{"2":{"363":1}}],["利用自注意力机制和跨注意力机制",{"2":{"331":1}}],["利用网格的拓扑结构",{"2":{"275":1}}],["利用互联网规模视觉与语言数据预训练的基础模型",{"2":{"145":1}}],["利用互联网规模语料的常识先验在罕见或不可预见场景中进行推断",{"2":{"82":1}}],["利用视觉提示增强空间推理",{"2":{"128":1}}],["利用聚合",{"2":{"121":1}}],["利用实例级视觉特征",{"2":{"114":1}}],["利用实例级结构信息作为规划约束与指导",{"2":{"114":1}}],["利用",{"2":{"96":1,"444":1,"588":1,"632":1,"765":2}}],["软件开发环境国家重点实验室研究计划和中央高校基本科研业务费的资助",{"2":{"980":1}}],["搜索",{"2":{"976":1}}],["搜救任务",{"2":{"90":1}}],["拼接",{"2":{"976":2}}],["拼合成一张完整的图后我们开始迭代去噪",{"2":{"312":1}}],["丰富dsg与物理属性",{"2":{"973":1}}],["↑",{"2":{"971":2}}],["√",{"2":{"971":12}}],["扫描中学习多模态特征",{"2":{"968":1}}],["扫描完成和每体素语义标记",{"2":{"962":1}}],["格雷厄姆等人",{"2":{"962":1}}],["格式以保留相关空间信息",{"2":{"497":1}}],["格式并压缩为",{"2":{"173":1}}],["格式",{"2":{"173":1}}],["格式化需要挂载的硬盘",{"2":{"24":1}}],["戴等",{"2":{"962":1}}],["良好的可扩展性",{"2":{"962":1}}],["△pij​",{"2":{"950":1}}],["△pij",{"2":{"950":1}}],["ψs​",{"2":{"950":1,"957":1}}],["ψs",{"2":{"950":1,"957":1}}],["ψρ−1​",{"2":{"950":2}}],["ψρ−1",{"2":{"950":2}}],["ψρ​",{"2":{"950":2}}],["ψρ",{"2":{"950":2}}],["ψv​",{"2":{"910":2,"950":2}}],["ψv",{"2":{"910":2,"950":2}}],["∗",{"2":{"950":2}}],["充分证明了无注释机制可以促进提取额外的有价值信息",{"2":{"949":1}}],["充分挖掘了点云的空间分布",{"2":{"636":1}}],["置换面晶格",{"2":{"948":1}}],["置信水平下",{"2":{"916":1}}],["置信水平的卡方值",{"2":{"916":1}}],["置信区域对应于满足以下条件的点集",{"2":{"916":1}}],["置信区域的椭球体体积的推导",{"2":{"916":1}}],["置信椭球体内的采样点数量和总采样点数量",{"2":{"916":1}}],["置信椭球体内",{"2":{"916":1}}],["置信体积",{"2":{"916":1}}],["置信度优化的分析",{"2":{"833":1}}],["置信度优化",{"2":{"728":1}}],["答案是",{"2":{"938":1}}],["答案是在fast",{"2":{"741":1}}],["照片编辑和移动机器人等领域带来了新的机遇",{"2":{"937":1,"953":1}}],["何地切换表示",{"2":{"935":1}}],["何时终止探索",{"2":{"826":1}}],["何时把两次观测视为同一节点",{"2":{"525":1}}],["阈值对于汽车为",{"2":{"931":1}}],["意味着只有部分场景的占用被标注",{"2":{"988":1}}],["意思就是不能通过这个指针来修改所指的内容",{"2":{"918":1}}],["意义为假设各个像素点真实深度都为",{"2":{"355":1}}],["夜间",{"2":{"914":1}}],["夜间场景子集的类别分布",{"2":{"900":1}}],["足够稠密",{"2":{"913":1}}],["足以构建远距离特征间的连接关系",{"2":{"824":1}}],["足以完成给定的任务",{"2":{"109":1}}],["太阳花的小绿豆的博客",{"2":{"912":1}}],["缩放规则由",{"2":{"912":1}}],["圆柱坐标系更符合激光雷达点云的空间分布",{"2":{"910":1}}],["忘记",{"2":{"905":2}}],["访问最后一个元素",{"2":{"904":1}}],["访问第一个元素",{"2":{"904":1}}],["访问函数",{"2":{"904":1}}],["异常",{"2":{"904":1}}],["异常值",{"2":{"449":1}}],["异常值拒绝",{"2":{"390":1}}],["末尾迭代器指针",{"2":{"918":1}}],["末尾删除元素",{"2":{"904":1}}],["末尾添加元素",{"2":{"904":1}}],["末尾指针都是指结束元素的下一个元素",{"2":{"888":1}}],["额外的消融研究",{"0":{"934":1}}],["额外的可视化",{"0":{"924":1}}],["额外可视化",{"0":{"902":1}}],["额外两个通道",{"2":{"132":1}}],["碎石和障碍物",{"2":{"899":1}}],["碎片",{"2":{"277":1,"534":1}}],["资源受限",{"2":{"897":1}}],["资源效率",{"2":{"897":1}}],["资源消耗分析",{"2":{"811":1}}],["薄",{"2":{"897":1}}],["✗",{"2":{"893":1}}],["✓",{"2":{"893":1}}],["观察到约",{"2":{"936":1}}],["观察到的性能相当",{"2":{"893":1}}],["观测噪声与缺失",{"2":{"864":1}}],["观测投影到",{"2":{"435":1}}],["观测数据的对数密度梯度",{"2":{"235":1}}],["观测预测值与实际值之间的差异称为残差",{"2":{"171":1}}],["讨论",{"0":{"937":1},"1":{"945":1,"953":1,"960":1}}],["讨论的技术包括视角分解和从粗到细的细化",{"2":{"892":1}}],["讨论编码策略",{"2":{"90":1}}],["级",{"2":{"884":1}}],["级的监督应用了衰减损失权重",{"2":{"884":1}}],["补充实验",{"0":{"883":1},"1":{"899":1,"914":1}}],["补充材料",{"0":{"788":1,"868":1},"1":{"808":1,"828":1,"848":1,"866":1,"883":1,"885":1,"899":1,"901":1,"914":1,"916":1}}],["伪",{"2":{"882":1}}],["打造灵活",{"2":{"881":1}}],["打开门",{"2":{"123":1}}],["打开终端",{"2":{"24":1}}],["缓解占用特征的稀疏性",{"2":{"875":1}}],["缓解了像素级问题",{"2":{"765":1}}],["刘小雨的博客",{"2":{"871":1}}],["亟需研究",{"2":{"926":1}}],["亟需一种",{"2":{"913":1}}],["亟需发展通用",{"2":{"864":1}}],["亟需轻量",{"2":{"864":1}}],["仓库或户外环境的长期变化",{"2":{"864":1}}],["防灾难遗忘",{"2":{"864":1}}],["淘汰过时信息",{"2":{"864":1}}],["持续更新",{"2":{"864":1}}],["持久变化",{"2":{"864":1}}],["持久的3d场景图",{"2":{"408":1}}],["持久表示",{"0":{"326":1},"1":{"352":1,"380":1}}],["季节变化",{"2":{"864":1}}],["果盘后面的杯子",{"2":{"864":1}}],["脚步声",{"2":{"864":1}}],["脚注文字",{"2":{"57":1}}],["脚注",{"2":{"57":4}}],["迁移到真实机器人时性能骤降",{"2":{"864":1}}],["危及安全",{"2":{"864":1}}],["家用机器人在多个凌乱房间中长期运行",{"2":{"864":1}}],["家具重排",{"2":{"864":1}}],["家具移动",{"2":{"864":1}}],["家具",{"2":{"793":1}}],["街区",{"2":{"864":1}}],["试图折中",{"2":{"864":1}}],["试图通过丰富的表示",{"2":{"116":1}}],["促进与",{"2":{"971":1}}],["促进对3d环境的更全面理解",{"2":{"922":1}}],["促进3d占用预测表示",{"2":{"875":1}}],["促进从2d感知视图图像特征到3d",{"2":{"598":1}}],["促使不同组具有不同的空域聚合模式",{"2":{"863":1}}],["型方面的高效性",{"2":{"863":1}}],["型状稳定的通用几何目标的检测识别",{"2":{"630":1}}],["枚举采样点",{"2":{"844":1}}],["稍微快一些",{"2":{"842":1}}],["周围采样一些参考特征",{"2":{"950":1}}],["周围相机的视野重叠较少",{"2":{"934":1}}],["周围相机的3d语义占用预测",{"2":{"842":1}}],["周围的体素化区域计算出",{"2":{"429":1}}],["向队尾添加元素",{"2":{"835":2}}],["向量化和局部性感知的内存访问",{"2":{"593":1}}],["向量中",{"2":{"161":1}}],["向量",{"2":{"153":1}}],["借鉴",{"2":{"829":1}}],["借助",{"2":{"826":1}}],["借助2d图像语义掩码标签和深度真值图",{"2":{"617":1}}],["借助树形动态数据结构显著降低内存占用并加速",{"2":{"588":1}}],["借助三维目标检测来辅助实现卓越性能",{"2":{"421":2}}],["借助三维目标检测监督来辅助实现卓越性能",{"2":{"392":1}}],["借助大型多模态基础模型",{"2":{"308":1}}],["借助专业标注人员和多步验证流程",{"2":{"277":1}}],["泥泞和碎石等语义类别",{"2":{"828":1}}],["水壶与盘子之间的花瓶",{"2":{"864":1}}],["水坑",{"2":{"828":1}}],["水平",{"2":{"480":1}}],["水平视场角",{"2":{"173":1}}],["灌木",{"2":{"828":1}}],["期望地图信息",{"2":{"826":1}}],["期间",{"2":{"276":1}}],["量化机器人位姿与地图的总不确定度",{"2":{"826":1}}],["量化",{"2":{"826":1}}],["累计位姿误差",{"2":{"826":1}}],["累积",{"2":{"435":2}}],["累积到对应地图结构",{"2":{"435":1}}],["角度",{"2":{"826":1}}],["巡检等任务中尤其关键",{"2":{"826":1}}],["供开放词汇表征评估",{"2":{"826":1}}],["统一了以视觉为中心的3d感知中的两个关键任务",{"2":{"875":1}}],["统一使用的标准化评估指标",{"2":{"846":1}}],["统一使用的标准化指标",{"2":{"826":1}}],["统一的体素",{"2":{"839":1}}],["统一性和可扩展性而越来越受欢迎",{"2":{"600":1}}],["堆叠规则以及缩放策略进行了探索",{"2":{"824":1}}],["余弦损失显示出最佳的",{"2":{"823":1}}],["余弦相似度",{"2":{"823":1}}],["余弦相似度得分的任务最相似对象的总正确检测数除以总检测数",{"2":{"402":1}}],["好",{"2":{"823":1}}],["好处是我们的输入不受任何控制",{"2":{"224":1}}],["队列",{"0":{"815":1},"1":{"835":1,"854":1,"871":1,"888":1,"904":1,"918":1,"929":1,"938":1,"946":1}}],["队列底层实现缺省情况下一样使用deque实现的",{"2":{"685":1}}],["散度损失",{"2":{"823":1,"985":1}}],["散度",{"2":{"814":1}}],["散度在局部上无法定义",{"2":{"814":1}}],["散度之和",{"2":{"814":1}}],["散度不是距离指标",{"2":{"328":1}}],["明确优化视锥中的类别分布",{"2":{"814":1}}],["明显优于",{"2":{"792":1}}],["明显趋势是gpt式",{"2":{"507":1}}],["冻结",{"2":{"813":1}}],["冻结vlm可处理多视角图像与文本提示",{"2":{"128":1}}],["涉及使用占用标签来训练占用网络",{"2":{"985":1}}],["涉及平移和旋转",{"2":{"957":1}}],["涉及图像特征与bev表示之间的转换",{"2":{"839":1}}],["涉及复杂的3d计算",{"2":{"811":1}}],["涉及一个智能代理",{"2":{"100":1}}],["迫切需要在",{"2":{"806":1}}],["迫切需要对相机",{"2":{"625":1}}],["灵活且通用型地图",{"2":{"806":1}}],["灵感",{"2":{"574":1}}],["灵感来自最近关于去噪扩散概率模型",{"2":{"175":1}}],["抓取",{"2":{"806":1}}],["桌面操作等",{"2":{"806":1}}],["桌子",{"2":{"162":1,"178":1,"793":1,"992":1}}],["衡量未来观测后地图不确定度的预期下降",{"2":{"826":1}}],["衡量生成地图对环境的覆盖程度",{"2":{"826":1}}],["衡量最终与目标位姿的偏差",{"2":{"806":1}}],["衡量轨迹与参考路径的贴合度",{"2":{"806":1}}],["衡量路径效率",{"2":{"806":1}}],["终身自主的核心在于无需人工重配置即可适应家庭",{"2":{"864":1}}],["终身学习",{"2":{"864":1}}],["终身运行",{"2":{"864":1}}],["终点与目标之间的欧氏距离",{"2":{"806":1}}],["终端2",{"2":{"120":1}}],["终端1",{"2":{"120":1}}],["暴露的天花板梁以一种方式扭曲了2d",{"2":{"796":1}}],["航空宇航",{"0":{"872":1},"2":{"796":3,"855":1,"872":1}}],["航点",{"2":{"308":1}}],["电视",{"2":{"793":1}}],["床",{"2":{"793":1}}],["窗户",{"2":{"793":1}}],["胸部向前突出的体素表示该人手持的移动设备",{"2":{"791":1}}],["横跨道路的交通信号横杆",{"2":{"791":1}}],["横滚和俯仰精度",{"2":{"173":1}}],["绝大多数工作把语义地图仅视为完成下游任务",{"2":{"786":1}}],["绝对平移误差",{"2":{"686":1}}],["绝对能在方方面面上取代卷积神经网络",{"2":{"631":1}}],["⋯",{"2":{"780":4,"976":4}}],["沙发",{"2":{"775":1,"793":1,"945":1}}],["骨盆估计位置与地面真实的不匹配",{"2":{"775":1}}],["骨干架构以及在occ3d",{"2":{"1001":1}}],["骨干网络",{"2":{"632":1,"922":1}}],["骨干网络可以替换为其他先进模型",{"2":{"627":1}}],["骨干网的早期层侧重于低层特征提取",{"2":{"96":1}}],["骨干",{"2":{"619":1}}],["五个雷达和六个相机",{"2":{"770":1}}],["五个边缘转换为两个",{"2":{"436":1}}],["某些类别具有明确的语义",{"2":{"975":1}}],["某些方法优先使用较少但更具影响力的查询以减少计算需求",{"2":{"922":1}}],["某些区域可能由于遮挡或其他原因而无法被相机捕捉到",{"2":{"800":1}}],["某些具体任务无需完整地图即可完成",{"2":{"435":1}}],["某比例的点落在给定距离阈值内",{"2":{"765":1}}],["翻转",{"2":{"764":1}}],["详细展示了我们的",{"2":{"982":1}}],["详细信息见附录",{"2":{"853":1}}],["详解r",{"2":{"763":1}}],["详见论文",{"2":{"611":1}}],["详见下节",{"2":{"585":1}}],["详见表",{"2":{"465":1}}],["详见",{"2":{"336":1}}],["详见第",{"2":{"274":1,"864":1}}],["测量",{"2":{"761":1}}],["测试",{"2":{"931":1}}],["测试分割",{"2":{"853":1}}],["测试集",{"2":{"903":1,"928":1}}],["测试集仅包含",{"2":{"828":1}}],["测试集最初包含",{"2":{"828":1}}],["测试时增强",{"0":{"673":1},"2":{"673":1}}],["测试形状的语义分割结果",{"2":{"557":1}}],["测试的时候用整张图",{"2":{"180":1}}],["测试和改进",{"2":{"103":1}}],["测试小乌龟",{"2":{"97":1}}],["测试过",{"2":{"27":1}}],["批次大小为",{"2":{"771":2}}],["批次大小32",{"2":{"764":1}}],["批次大小设置为",{"2":{"761":1}}],["批量大小为8",{"2":{"822":1}}],["批量大小为4",{"2":{"758":1}}],["批量大小为",{"2":{"677":2,"853":1}}],["批量方法",{"2":{"437":1}}],["钩子以获得更好的精度",{"2":{"761":1}}],["填充和多尺度翻转以进行图像增强",{"2":{"761":1}}],["填补感知专用基准空白",{"2":{"360":1}}],["辅以激光雷达为中心的方法和多模态方法",{"2":{"759":2}}],["辅助检测分支实现了较低的性能",{"2":{"893":1}}],["辅助检测分支实现了59",{"2":{"893":1}}],["辅助检测分支旨在识别10个目标类别",{"2":{"893":1}}],["辅助检测头的消融研究",{"2":{"800":1}}],["辅助检测头的消融",{"2":{"800":1}}],["辅助检测头的总损失可以表示为",{"2":{"666":1}}],["辅助检测任务与占据预测任务相关",{"2":{"666":1}}],["辅助loss主要是为了确保重建的图像局部真实性以及避免模糊",{"2":{"345":1}}],["弹出的函数是pop",{"2":{"753":1}}],["弹出",{"0":{"753":1}}],["样本效率高",{"2":{"743":1}}],["真值被体素化为",{"2":{"900":1}}],["真值标签以",{"2":{"739":1}}],["真正例表示实际占用的体素被正确预测",{"2":{"998":1}}],["真正例",{"2":{"802":1}}],["真实生活实验",{"0":{"855":1},"1":{"872":1,"889":1}}],["真实标签ygeoy",{"2":{"834":1}}],["真实标签生成",{"0":{"735":1},"2":{"689":1}}],["真实世界中的建图",{"2":{"435":1}}],["真实场景要求机器人长期运行并持续适应动态环境",{"2":{"864":1}}],["真实场景中的传感器缺陷",{"2":{"864":1}}],["真实场景",{"2":{"360":1}}],["真实+仿真",{"2":{"360":1}}],["真实",{"2":{"360":6}}],["真实带噪数据",{"2":{"235":1}}],["真实应用场景是不可能像训练集那样完美的",{"2":{"220":1}}],["真实的",{"2":{"129":1}}],["真实图片的协方差矩阵",{"2":{"20":1}}],["真实图片的特征均值",{"2":{"20":1}}],["管道生成粗略的3d占用标签",{"2":{"757":1}}],["管道",{"2":{"735":1}}],["手动标注每个体素非常困难",{"2":{"735":1}}],["手工算法处理激光雷达",{"2":{"103":1}}],["专门用于分别评估一般可移动对象",{"2":{"975":1}}],["专注于表示实例间语义有意义的关系",{"2":{"967":1}}],["专注于3d网格",{"2":{"967":1}}],["专注于使用稀疏的lidar点云分割标签生成密集的3d占用注释",{"2":{"735":1}}],["专家混合路由",{"2":{"507":1}}],["专家混合路由使推理时仅部分专家运行",{"2":{"417":1}}],["专家混合",{"2":{"334":1}}],["混淆矩阵中的大型值出现在wall",{"2":{"732":1}}],["混合方法",{"0":{"968":1}}],["混合",{"2":{"864":1,"935":1}}],["混合地图的构建",{"2":{"935":1}}],["混合地图结构",{"0":{"935":1}}],["混合地图",{"0":{"648":1},"2":{"378":1,"465":1}}],["混合扩散",{"2":{"334":1}}],["混合微调",{"2":{"334":1}}],["压入",{"0":{"731":1}}],["压缩且表达力强",{"2":{"864":1}}],["压缩了高度维度",{"2":{"547":1}}],["压缩表示",{"2":{"153":2}}],["压缩量",{"2":{"137":1}}],["压缩",{"2":{"137":1}}],["压缩成任务相关概念的簇",{"2":{"137":1}}],["≠",{"2":{"730":1}}],["≠v",{"2":{"730":1}}],["=​返回集合中不同的元素",{"2":{"730":1}}],["=​",{"2":{"730":1}}],["ν",{"2":{"957":1}}],["νs3↔ν",{"2":{"730":2}}],["νs3​↔ν",{"2":{"730":2}}],["νs3​",{"2":{"730":1}}],["νs3",{"2":{"730":1}}],["ν1↔ν",{"2":{"730":2}}],["ν1​↔ν",{"2":{"730":2}}],["ν1​",{"2":{"730":1}}],["ν1",{"2":{"730":1}}],["替换对应的旧属性",{"2":{"716":1}}],["π",{"2":{"716":4}}],["πc​",{"2":{"595":2}}],["πc",{"2":{"595":2}}],["跟踪的最大特征数",{"2":{"836":1}}],["跟踪在cpu上以毫秒级",{"2":{"816":1}}],["跟踪",{"0":{"711":1},"1":{"734":1,"756":1,"777":1,"798":1,"818":1,"838":1,"857":1,"874":1,"891":1,"907":1,"921":1,"931":1}}],["跟踪和规划",{"2":{"759":1}}],["跟踪和预测",{"2":{"455":1}}],["跟踪和关联同一实例",{"2":{"125":1}}],["青色",{"2":{"709":1}}],["尾迹",{"2":{"709":1}}],["颜色",{"2":{"765":1}}],["颜色表示语义",{"2":{"707":1}}],["颜色编码为与地面真实点云的距离",{"2":{"686":1}}],["颜色编码为与地面真实云的距离",{"2":{"686":1}}],["颜色编码为与估计云的最近点的距离",{"2":{"686":2}}],["彩色表示",{"2":{"707":1}}],["彩虹色编码的人类网格",{"2":{"419":1}}],["灰色表示",{"2":{"707":1}}],["⊗m",{"2":{"712":2}}],["⊗",{"2":{"705":1,"950":1}}],["施工车辆",{"2":{"700":1}}],["施加的一致性约束来改善语义分割精度",{"2":{"209":1}}],["笛卡尔坐标系",{"2":{"699":1}}],["哪里可坐",{"2":{"864":1}}],["哪类信息对下游任务最有帮助",{"2":{"698":1}}],["哪些物品易碎",{"2":{"864":1}}],["哪些区域是相机无法看到的",{"2":{"800":1}}],["哪些部分保持不变",{"2":{"436":1}}],["哪些尚未探索",{"2":{"435":1}}],["循环记忆随时间聚合",{"2":{"698":1}}],["循环闭合不会直接影响点云地图",{"2":{"967":1}}],["循环闭合与密集表示",{"2":{"967":1}}],["循环闭合检测",{"2":{"816":1}}],["循环闭合在kimera",{"2":{"754":1}}],["循环闭合之前和kimera",{"2":{"754":1}}],["循环闭合和网格变形",{"0":{"754":1}}],["循环闭合",{"2":{"686":1}}],["帮助模型捕捉图像中的局部细节和全局上下文信息",{"2":{"875":1}}],["帮助模型更好地进行训练",{"2":{"456":1}}],["帮助",{"2":{"698":1}}],["仍是自主导航领域亟待突破的开放问题",{"2":{"926":1}}],["仍是实际部署的主要瓶颈",{"2":{"864":1}}],["仍是开放难题",{"2":{"864":1}}],["仍能描述3d场景的细粒度结构",{"2":{"693":1}}],["仍然会在复杂场景",{"2":{"992":1}}],["仍然能够合理地推测出视野范围之外的场景",{"2":{"903":1}}],["仍然存在一些识别能力较弱的难以区分的对象区域",{"2":{"591":1}}],["仍然是一个未被探索的问题",{"2":{"444":1}}],["稳定的占用感知需求至关重要",{"2":{"691":1}}],["稳健的自动驾驶系统至关重要",{"2":{"520":1}}],["粗体显示了每个类别的最佳结果",{"2":{"686":1}}],["粗粒度拓扑地图擅长刻画环境中的显著地标",{"2":{"648":1}}],["栈是容器适配器",{"2":{"938":1}}],["栈是以底层容器完成其所有的工作",{"2":{"685":1}}],["栈里面的元素在内存中是连续分布的么",{"2":{"938":1}}],["栈不为空",{"2":{"795":1}}],["栈不能为空",{"2":{"774":1}}],["栈为空",{"2":{"795":1}}],["栈顶元素",{"0":{"774":1}}],["栈的底层实现可以是vector",{"2":{"685":1}}],["栈的内部结构",{"2":{"685":1}}],["栈提供push",{"2":{"685":1}}],["栈",{"0":{"685":1},"1":{"708":1,"731":1,"753":1,"774":1,"795":1},"2":{"835":1}}],["栈通过手工级联的感知",{"2":{"82":1}}],["↔",{"2":{"684":1,"707":2,"730":1}}],["≥τif",{"2":{"957":1}}],["≥τemptyif",{"2":{"957":1}}],["≥α",{"2":{"681":2}}],["≥4",{"2":{"276":1}}],["案例",{"2":{"670":1}}],["亲和力损失",{"2":{"670":2}}],["砾石和垃圾等未知类别的障碍物",{"2":{"665":1}}],["🌟",{"2":{"663":1}}],["🇨🇦",{"2":{"23":1}}],["篮子数目",{"2":{"661":1}}],["ρ",{"2":{"660":4}}],["φt​",{"2":{"950":1}}],["φt",{"2":{"950":1}}],["φf​",{"2":{"942":1}}],["φf",{"2":{"942":1}}],["φv​",{"2":{"910":1}}],["φv",{"2":{"910":1}}],["φo​",{"2":{"780":1}}],["φo",{"2":{"780":1}}],["φa​",{"2":{"660":1}}],["φa",{"2":{"660":1}}],["φ",{"2":{"660":2}}],["消歧更为重要",{"2":{"928":1}}],["消歧的自由度",{"2":{"660":1}}],["消融研究结果如表",{"2":{"971":1}}],["消融研究表明",{"2":{"923":1}}],["消融研究则来自验证集",{"2":{"853":1}}],["消融研究",{"0":{"723":1,"785":1,"800":1,"811":1,"812":1,"928":1}}],["消除了从高维特征中解码的昂贵过程",{"2":{"842":1}}],["消除了在特征融合过程中对复杂可变形注意力",{"2":{"421":1,"482":1}}],["消除邻居排序对偶的歧义",{"2":{"589":1}}],["跳跃连接",{"2":{"660":1}}],["跳步生成过程",{"2":{"175":1}}],["争取能做视觉里密集预测的任务",{"2":{"659":1}}],["究动机就是想要有一个层级式的",{"2":{"659":1}}],["剩下三个stage都是先通过一个patch",{"2":{"659":1}}],["剩余的图片是对",{"2":{"181":1}}],["匹配上的为正样本",{"2":{"651":1}}],["匹配成功",{"2":{"358":1}}],["思想与",{"2":{"651":1}}],["思维链式问答",{"2":{"360":1}}],["思维链推理",{"2":{"176":1}}],["λ=3",{"2":{"766":1}}],["λ1",{"2":{"750":1}}],["λ",{"2":{"647":4,"766":1}}],["λl",{"2":{"417":1}}],["根节点",{"2":{"636":1}}],["根据fastocc",{"2":{"1001":1}}],["根据可变形注意力机制对这些采样特征进行加权求和",{"2":{"950":1}}],["根据分割粒度的不同",{"2":{"940":1}}],["根据搜索到的最佳超参配置",{"2":{"912":1}}],["根据构造",{"2":{"905":1}}],["根据它们的对象建议生成方法",{"2":{"756":1}}],["根据它们的2d",{"2":{"480":1}}],["根据几何原理生成了相应的lidar可见性和相机可见性掩码",{"2":{"735":1}}],["根据对应的高斯查询",{"2":{"716":1}}],["根据网格上定义的一组高斯混合模型的似然性提取fisher矢量",{"2":{"664":1}}],["根据这个性质",{"2":{"571":1}}],["根据这些标准",{"2":{"157":1}}],["根据输入观察数据",{"2":{"1003":1}}],["根据输入数据的模态",{"2":{"877":1}}],["根据输入数据的类型",{"2":{"857":1}}],["根据输入数据",{"2":{"821":1}}],["根据输入像素序号",{"2":{"561":1}}],["根据输入坐标",{"2":{"413":1}}],["根据当前观测与位姿实时增删节点与边",{"2":{"525":1}}],["根据给定点及其相邻点形成的角度聚集这些方向的相关特征",{"2":{"511":1}}],["根据给定的图像和生成的cam",{"2":{"410":1}}],["根据是否先做语义分割",{"2":{"495":1}}],["根据消融实验",{"2":{"489":1}}],["根据边的特征强度对边折叠进行优先级排序",{"2":{"466":1}}],["根据边缘特征的大小对边折叠顺序",{"2":{"466":1}}],["根据卷积核的类型",{"2":{"450":1}}],["根据用于每个点特征学习的网络结构",{"2":{"391":1}}],["根据新变形网格中相应顶点的位置",{"2":{"380":1}}],["根据相似程度",{"2":{"328":1}}],["根据郎之万动力方程的推导",{"2":{"224":1}}],["根据上述计算出的激光雷达到车辆自身坐标系的变换",{"2":{"191":1}}],["根据所用传感器的不同",{"2":{"189":1}}],["根据交叉点选取位置的不同",{"2":{"181":1}}],["根据测量的不确定性对残差加权",{"2":{"171":1}}],["根据",{"2":{"152":1,"296":1}}],["根据贝叶斯理论",{"2":{"140":1,"280":1}}],["根据任务类型",{"2":{"139":1}}],["根据自然语言指令找到目标",{"2":{"139":1}}],["根据高斯分布的叠加方法",{"2":{"111":1,"236":1}}],["根据你的需求来指定文件夹",{"2":{"60":1}}],["拥有了像卷积神经网络一样分层的结构",{"2":{"631":1}}],["铺平了道路",{"2":{"631":1}}],["序列及对应位姿端到端训练",{"2":{"743":1}}],["序列的长度就变得高不可攀",{"2":{"631":1}}],["序列中所有的张量都应该为相同形状",{"2":{"351":1}}],["里面的物体都大大小小",{"2":{"631":1}}],["里面有很多车和行人",{"2":{"631":1}}],["里程计版本的",{"2":{"408":1}}],["里程计检查验证每个回路闭合",{"2":{"390":1}}],["里程计",{"2":{"326":1}}],["叫做",{"2":{"631":1}}],["难区分静态和动态目标",{"2":{"630":1}}],["难以观察和检测",{"2":{"1000":1}}],["难以区分远处连续的汽车",{"2":{"989":1}}],["难以实现全面的环境感知",{"2":{"969":1}}],["难以在不同任务",{"2":{"864":1}}],["难以扩展",{"2":{"864":1}}],["难以扩展到大场景",{"2":{"864":1}}],["难以胜任操作或精确定位",{"2":{"864":1}}],["难以完成精细的空间推理",{"2":{"765":1}}],["难以泛化到未见类别",{"2":{"743":1}}],["难以监督密集的3d占用预测任务",{"2":{"735":1}}],["难以识别悬挂或者悬空的障碍物",{"2":{"630":1}}],["难以对应到真实3d场景",{"2":{"630":1}}],["难以应用于多尺度特征",{"2":{"595":1}}],["难以应对持续演化的开放世界",{"2":{"864":1}}],["难以应对未见环境",{"2":{"525":1}}],["难以应对需要高层推理或细致人类判断的长尾极端场景",{"2":{"82":1}}],["难以满足具身应用的实时需求",{"2":{"588":1}}],["难以直接迁移到真实场景",{"2":{"435":1}}],["垃圾",{"2":{"630":1}}],["禁用全局",{"2":{"971":1}}],["禁用系统自带的",{"2":{"66":1}}],["禁停标志等等",{"2":{"630":1}}],["货车",{"2":{"630":1}}],["颈部模块也可以替换为其他竞争性变体",{"2":{"627":1}}],["ℓ×ℓ",{"2":{"928":2}}],["ℓ×ℓ=8×8",{"2":{"853":1}}],["ℓ",{"2":{"623":1}}],["红线为软边界结果",{"2":{"622":1}}],["红色线条",{"2":{"594":1}}],["红色顶点是具有相关变换",{"2":{"390":1}}],["红色",{"2":{"384":1,"390":1}}],["红色边连接不同的房间",{"2":{"162":1}}],["划分为多个离散的区间",{"2":{"621":1}}],["划分的点块按照",{"2":{"340":1}}],["便于可控的数据生成和空间信息显示",{"2":{"963":1}}],["便于推理物体与区域之间的复杂空间关系",{"2":{"935":1}}],["便于模型学习和预测",{"2":{"621":1}}],["便于智能体推理空间结构",{"2":{"495":1}}],["质量良好",{"2":{"617":1}}],["故在nuscenes数据集上以深度估计为重点进行大规模预训练",{"2":{"617":1}}],["故set内不会出现重复元素",{"2":{"571":1}}],["鸟瞰图感知和前视感知",{"2":{"1003":1}}],["鸟瞰图感知将3d场景表示在bev平面上",{"2":{"821":1}}],["鸟瞰图感知",{"0":{"821":1}}],["鸟瞰图或点云的感知方法",{"2":{"691":1}}],["鸟瞰图",{"2":{"637":1,"642":1,"665":2,"667":1,"693":1,"777":1,"808":1,"877":1,"942":1}}],["鸟瞰图编码器",{"2":{"609":1}}],["鸟瞰图分割图",{"2":{"550":1}}],["黄迪",{"2":{"608":1}}],["黄色线条",{"2":{"594":1}}],["黄色边是连接姿态顶点和网格顶点的边",{"2":{"390":1}}],["徐俊豪",{"2":{"608":1}}],["透视图",{"2":{"605":1,"877":1}}],["透明度",{"2":{"532":1}}],["透明",{"2":{"478":1}}],["底层容器使用不同的容器",{"2":{"938":1}}],["底层容器是可插拔的",{"2":{"685":1}}],["底行",{"2":{"605":1}}],["底部所示",{"2":{"952":1}}],["底部场景被合理地猜测出来",{"2":{"903":1}}],["底部是我们的方法",{"2":{"409":1}}],["底部",{"2":{"197":1,"503":1}}],["穿过三个房间",{"2":{"605":1}}],["穿过空间的内部",{"2":{"605":1}}],["穿过长长的走廊以及三楼的学生公寓",{"2":{"437":1}}],["校准了所有相机的内参和外参",{"2":{"605":1}}],["校正地图",{"2":{"190":1}}],["白猫头鹰",{"0":{"889":1},"2":{"605":4,"796":2,"816":1,"855":1,"889":2,"947":1}}],["邻里",{"2":{"605":1,"709":1,"754":1,"796":1}}],["邻域内的高斯数量",{"2":{"532":1}}],["凭借其准确的深度估计能力",{"2":{"596":1}}],["绿色节点",{"2":{"889":1}}],["绿色线条",{"2":{"594":1}}],["绿色边是描述简化网格连通性的边",{"2":{"390":1}}],["整个模型通过专门设计的图像重建损失进行训练",{"2":{"949":1}}],["整个验证集的类别分布",{"2":{"900":1}}],["整个框架是一个两阶段级联",{"2":{"875":1}}],["整个网络用",{"2":{"743":1}}],["整个ctc",{"2":{"591":1}}],["整体比较",{"2":{"999":1,"1000":2}}],["整体可视化结果如图",{"2":{"952":1}}],["整体损失函数为",{"2":{"738":1}}],["整体流程如图3所示",{"2":{"716":1}}],["整体研究背景以及方法",{"2":{"714":1}}],["整体架构如图2所示",{"2":{"621":1}}],["整体架构",{"0":{"621":1}}],["整体三维理解试图预测场景和物体的布局",{"2":{"603":1}}],["整合这些预训练的大模型已被证明可以增强感知的泛化能力",{"2":{"1006":1}}],["整合这些互补资产对训练与基准测试下一代vla4ad至关重要",{"2":{"360":1}}],["整合环视雷达和激光雷达可以显著增强模型的长距离感知能力以及对恶劣天气条件的鲁棒性",{"2":{"977":1}}],["整合了雷达信息与相机",{"2":{"959":1}}],["整合时间信息可以显著提高感知性能",{"2":{"957":1}}],["整合来自环视雷达的信息显著提升了模型的性能",{"2":{"936":1}}],["整合来自二维和三维分支的信息可以显著改进占用预测",{"2":{"923":1}}],["整合多帧观察是有益的",{"2":{"691":1}}],["整合雷达信息可以改善模型在具有挑战性的场景中的性能",{"2":{"653":1}}],["整合其多模态接口",{"2":{"160":1}}],["残差生成",{"0":{"587":1}}],["残差值",{"2":{"372":1}}],["融入更强语义先验",{"2":{"585":1}}],["融合后的表示通过可选的细化模块和占用头部",{"2":{"970":1}}],["融合后的深度图直接投影到空间",{"2":{"650":1}}],["融合模型的变体",{"2":{"782":1}}],["融合网络仅使用相对较少的标注就能实现相当的性能",{"2":{"782":1}}],["融合过程结合了历史特征和当前感知输入的相关信息",{"2":{"726":1}}],["融合来自激光雷达",{"2":{"691":1}}],["融合层后",{"2":{"670":1}}],["融合层",{"2":{"670":1}}],["融合多模态特征并提升对动态场景的鲁棒性",{"2":{"588":1}}],["融合实时感知与符号规则及语境以落地非语言线索",{"2":{"507":1}}],["融合特征空间",{"2":{"502":1}}],["融合双流",{"2":{"447":1}}],["融合型语义占据预测方法包括激光雷达",{"2":{"444":1}}],["融合cot推理与轨迹规划于单一自回归transformer",{"2":{"334":1}}],["融合处理后的测量数据以获得传感器状态",{"2":{"310":1}}],["融合视觉与激光雷达token及可选文本提示",{"2":{"283":1}}],["融合相机与激光雷达输入及文本路线指令",{"2":{"283":1}}],["融合occ",{"0":{"200":1}}],["克服各自局限",{"2":{"585":1}}],["港中文",{"2":{"584":1}}],["南大",{"2":{"584":1}}],["南京大学",{"2":{"458":1,"517":1}}],["清空所有元素",{"2":{"904":1}}],["清华",{"2":{"584":1}}],["清除容器内所有元素",{"2":{"115":1}}],["倒角距离",{"2":{"582":1}}],["倒是文档字符与linux文档字符不匹配导致",{"2":{"41":1}}],["ˆfk",{"2":{"579":1}}],["ˆfr",{"2":{"579":1}}],["ζ",{"2":{"579":1}}],["共3个",{"2":{"888":1}}],["共享编码器",{"0":{"699":1}}],["共享的编码器",{"2":{"578":1,"621":1}}],["共生成每帧八种预测结果",{"2":{"673":1}}],["共同推动了这一领域进入更具挑战性的阶段",{"2":{"629":1}}],["共同解决了所有这些任务",{"2":{"306":1}}],["恢复",{"2":{"632":1}}],["恢复bev表示的高度",{"2":{"576":1}}],["恢复某",{"0":{"88":1}}],["池化被定义为拉普拉斯矩阵和粗化矩阵的顶点矩阵相乘",{"2":{"574":1}}],["译码器则由聚类",{"2":{"574":1}}],["移除",{"2":{"971":1}}],["移除当前队首元素",{"2":{"835":1}}],["移除了变换网络",{"2":{"574":1}}],["移动的这个操作",{"2":{"631":1}}],["移动的车辆",{"2":{"254":1}}],["移动窗口的好处",{"2":{"631":1}}],["移动",{"2":{"277":2}}],["移动构造",{"0":{"389":1},"2":{"261":1}}],["机器厅场景",{"2":{"572":1}}],["机器人可先用拓扑图做",{"2":{"935":1}}],["机器人可以直接推断出它必须到达dsg中的最近地点以完成任务",{"2":{"939":1}}],["机器人可以有选择地决定保留哪些信息",{"2":{"905":1}}],["机器人可以通过简单地修剪dsg中的相应分支来",{"2":{"905":1}}],["机器人需理解并预测物体轨迹",{"2":{"926":1}}],["机器人在杂乱室内可能将凳子误判为椅子",{"2":{"864":1}}],["机器人导航与操作任务",{"2":{"765":1}}],["机器人走廊行走时维护全局拓扑图",{"2":{"648":1}}],["机器人实时构建clio地图",{"2":{"522":1}}],["机器人节点",{"2":{"419":1}}],["机器人本身是唯一的代理",{"2":{"210":1}}],["机器人中视觉环路闭合检测的成熟方法可以追溯到计算机视觉中的地点识别和图像检索技术",{"2":{"190":1}}],["机器人",{"2":{"178":1}}],["机器人观测环境中的路标",{"2":{"171":1}}],["机器人的3d姿态",{"2":{"285":1}}],["机器人的运动可用状态转移函数建模",{"2":{"171":1}}],["机器人的地图表示中应该包含的对象",{"2":{"98":1}}],["机器人操作成为核心议题",{"2":{"123":1}}],["机器人学中的表示和抽象",{"2":{"961":1}}],["机器人学中的不确定性推理可为设计地图鲁棒性指标提供借鉴",{"2":{"826":1}}],["机器人学中的一个基本问题是如何创建一个对机器人有用的场景地图表示",{"2":{"109":1}}],["机器人学的这些进展共同体现了从反应式",{"2":{"123":1}}],["机器人学的另一快速发展领域是自动驾驶",{"2":{"123":1}}],["机器人学任务",{"0":{"123":1}}],["机器人视觉和视觉",{"2":{"121":1}}],["机器人通过移动观测",{"2":{"525":1}}],["机器人通过在多个抽象层次上进行规划来分解决策的复杂性",{"2":{"116":1}}],["机器人通常被发出几何命令",{"2":{"116":1}}],["机器人感知",{"2":{"112":1}}],["机器人几乎不需要通过区分所有的琴键和琴弦的位置来获得价值",{"2":{"109":1}}],["装有立体相机和imu",{"2":{"572":1}}],["待插入元素",{"2":{"571":1}}],["待连接的张量序列",{"2":{"351":1}}],["插入另一个向量的",{"2":{"904":1}}],["插入的函数是push",{"2":{"731":1}}],["插入到3d",{"2":{"875":1}}],["插入到",{"2":{"684":1}}],["插入初始化表中的元素",{"2":{"571":1}}],["插入元素",{"2":{"571":2,"604":1}}],["插装与物品重排",{"2":{"123":1}}],["既保留高分辨率与细节",{"2":{"881":1}}],["既用于追踪研究进展",{"2":{"864":1}}],["既包括全局范围",{"2":{"570":1}}],["既计算量大又需要大量标注数据",{"2":{"425":1}}],["占有率预测的性能",{"2":{"977":1}}],["占有率预测的多传感器信息融合框架",{"2":{"724":1}}],["占有率预测结果用",{"2":{"724":1}}],["占用作为3d世界的几何和语义表示",{"2":{"1002":1}}],["占用网络的miou分数在50",{"2":{"1000":1}}],["占用网络的语义感知能力",{"2":{"1000":1}}],["占用网络的iou分数低于60",{"2":{"1000":1}}],["占用网格",{"2":{"603":1}}],["占用分数",{"2":{"998":1}}],["占用体素中心的集合",{"2":{"916":1}}],["占用预测和运动规划",{"2":{"1003":1}}],["占用预测和物体检测",{"2":{"875":1}}],["占用预测以及自监督",{"2":{"567":1}}],["占用图",{"2":{"826":1}}],["占用空间上进行蒸馏",{"2":{"823":1}}],["占用注释在",{"2":{"749":1}}],["占用",{"2":{"698":1}}],["占用表示起源于机器人领域",{"2":{"665":1}}],["占用率或语义特征等信号",{"2":{"619":1}}],["占用感知构建的是3d体积空间",{"2":{"821":1}}],["占用感知可以被视为bev感知的扩展",{"2":{"821":1}}],["占用感知可以作为端到端自动驾驶框架中3d物理世界的统一表示",{"2":{"759":1}}],["占用感知网络",{"2":{"780":1}}],["占用感知网络的训练严重依赖于密集的3d占用标签",{"2":{"759":1}}],["占用感知旨在从多源输入中提取观察到的3d场景的体素级表示",{"2":{"780":1}}],["占用感知研究的一个主导趋势是以视觉为中心的解决方案",{"2":{"759":1}}],["占用感知领域发展迅速",{"2":{"759":1}}],["占用感知引起了广泛关注",{"2":{"759":1}}],["占用感知源自占用栅格地图",{"2":{"759":1}}],["占用感知的研究呈现出爆炸性增长",{"2":{"759":1}}],["占用感知的简要历史",{"0":{"759":1}}],["占用感知的核心在于理解完整且密集的3d场景",{"2":{"691":1}}],["占用感知在三维语义占用感知",{"2":{"691":1}}],["占用感知具有3d属性",{"2":{"667":1}}],["占用感知",{"2":{"610":1}}],["占用构建",{"2":{"599":1}}],["占用的空间分辨率和输入视图的数量",{"2":{"656":1}}],["占用的空间稀疏性下",{"2":{"567":1}}],["占用的空间冗余性",{"2":{"567":1}}],["占据标签使用0",{"2":{"770":1}}],["占据任务训练约50轮",{"2":{"764":1}}],["占据任务比检测任务更具挑战性",{"2":{"548":1}}],["占据数据集基于现有nuscenes数据集",{"2":{"742":1}}],["占据头产生的bev特征随后通过通道到高度模块",{"2":{"703":1}}],["占据头由两个",{"2":{"670":1}}],["占据头利用通道到高度操作",{"2":{"576":1}}],["占据池化替换为bev池化",{"2":{"670":1}}],["占据编码器替换为",{"2":{"670":1}}],["占据网络",{"2":{"425":1,"455":1,"517":1}}],["占据网格在自动驾驶感知中重新兴起",{"2":{"455":1}}],["占据网格",{"2":{"308":1,"613":1}}],["占据预测性能",{"2":{"782":2}}],["占据预测范围设置为激光雷达坐标系中x和y轴的",{"2":{"736":1}}],["占据预测任务形式化为构建具有固定感知范围和分辨率的语义",{"2":{"613":1}}],["占据预测模块",{"0":{"703":1},"2":{"598":1}}],["占据预测的主要指标是所有语义类别的平均交并比",{"2":{"739":1}}],["占据预测的任务形式化",{"0":{"613":1}}],["占据预测的核心在于有效构建3d场景",{"2":{"535":1}}],["占据预测的准确性和鲁棒性得到了显著增强",{"2":{"421":1}}],["占据预测这一新兴任务通过预测3d空间中每个体素的语义类别",{"2":{"535":1}}],["占据预测可表示为",{"2":{"532":1}}],["占据预测已成为自动驾驶系统中的关键组成部分",{"2":{"505":1}}],["占据预测提供了一种简单的融合",{"2":{"455":1}}],["占据预测",{"2":{"425":1}}],["占据图",{"2":{"114":1}}],["暂",{"0":{"565":1},"1":{"597":1,"626":1,"654":1,"679":1,"702":1,"725":1,"747":1,"769":1,"790":1}}],["众所周知",{"2":{"564":1}}],["汇总了相关先前工作",{"2":{"556":1}}],["汇总了不同工作的聚合方式",{"2":{"495":1}}],["易于使用而最为普及",{"2":{"556":1}}],["∼",{"2":{"552":1}}],["∼n",{"2":{"140":5,"208":1,"280":5}}],["忠实和详细的重建可以有效地应用于百万像素图像的高分辨率合成",{"2":{"552":1}}],["块实现",{"2":{"829":1}}],["块级嵌入",{"2":{"765":1}}],["块在",{"2":{"743":1}}],["块和一个",{"2":{"632":1}}],["块对其进行进一步细化",{"2":{"609":1}}],["块",{"2":{"549":1,"761":2,"971":1,"982":2}}],["块中添加位置编码",{"2":{"549":1}}],["块来提取三维局部邻域中的相位",{"2":{"511":1}}],["↓",{"2":{"545":3,"965":3}}],["式",{"2":{"532":1}}],["处评估了每个模型和不同的传感器融合策略",{"2":{"944":1}}],["处的邻近高斯分布集合",{"2":{"738":1}}],["处的一个点",{"2":{"716":1}}],["处的占用预测结果可以表示为各个高斯分布在该位置的贡献之和",{"2":{"693":1}}],["处的值为",{"2":{"693":1}}],["处的值可通过以下公式计算",{"2":{"532":1}}],["处的预测分数和真实值",{"2":{"666":1}}],["处的贡献",{"2":{"532":1}}],["处理移动对象的方法",{"2":{"967":1}}],["处理多尺度图像特征以生成多尺度体素特征",{"2":{"922":1}}],["处理速度",{"2":{"864":1}}],["处理第",{"2":{"780":1}}],["处理全景视频与自由文本",{"2":{"507":1}}],["处理",{"2":{"195":1,"260":1,"502":1,"982":2}}],["处理fcn得到的概率图",{"2":{"54":1}}],["尺度不变对数损失",{"2":{"985":1}}],["尺度解耦",{"2":{"928":1}}],["尺度下",{"2":{"928":1}}],["尺度下的3d特征体积",{"2":{"699":1}}],["尺度可以显著提升性能",{"2":{"928":1}}],["尺度能够持续提高",{"2":{"928":2}}],["尺度投影",{"2":{"928":1}}],["尺度",{"2":{"532":1,"656":1,"681":1,"693":1,"705":1,"928":1}}],["尺寸的图像",{"2":{"205":1}}],["炼丹技巧",{"2":{"528":1}}],["细化高斯属性的策略对性能有显著影响",{"2":{"842":1}}],["细化模块",{"2":{"716":1}}],["细节丰富",{"2":{"897":1}}],["细节",{"2":{"702":1}}],["细粒度",{"2":{"846":1}}],["细粒度度量地图能够精确描述几何",{"2":{"648":1}}],["细粒度问题",{"2":{"630":1}}],["细粒度几何细节丢失",{"2":{"527":1}}],["细腻的认知",{"2":{"350":1}}],["需融合",{"2":{"926":1}}],["需在",{"2":{"897":1}}],["需在众多地标",{"2":{"525":1}}],["需使用",{"2":{"888":1}}],["需支持复杂空间查询",{"2":{"864":1}}],["需注意深度预训练缺乏语义级监督",{"2":{"617":1}}],["需要几分钟的时间来解析整个场景",{"2":{"973":1}}],["需要大约10分钟",{"2":{"816":1}}],["需要在",{"2":{"753":1}}],["需要进一步处理",{"2":{"735":1}}],["需要联合预测场景中每个体素在范围",{"2":{"712":1}}],["需要",{"2":{"700":1,"959":1}}],["需要预先定义类别集合",{"2":{"698":1}}],["需要研究相机",{"2":{"678":1}}],["需要被整合到目标查询中",{"2":{"623":1}}],["需要更多的可训练参数",{"2":{"965":1}}],["需要更强大的硬件支持",{"2":{"601":1}}],["需要更可靠的深度信息参考",{"2":{"564":1}}],["需要辅助信息来提供全面的语义信息指导",{"2":{"596":1}}],["需要对",{"2":{"567":1}}],["需要对数据的特征进行表示",{"2":{"149":1}}],["需要语义知识才能检测",{"2":{"522":1}}],["需要记录哪些位置已到访",{"2":{"435":1}}],["需要从共享卷积层上摘取对应的特征",{"2":{"432":1,"741":1}}],["需要昂贵的大规模密集体素标签进行监督",{"2":{"425":1}}],["需要很长时间去学习",{"2":{"386":1}}],["需要相应的任务和框架",{"2":{"313":1}}],["需要相应地校正地图",{"2":{"190":1}}],["需要调控的超参不多",{"2":{"264":1}}],["需要两者来结合",{"2":{"220":1}}],["需要注意的是",{"2":{"211":1,"735":2,"757":1,"778":1,"853":1}}],["需要花费2s",{"2":{"207":1}}],["需要使用层次地图来捕获丰富的空间和语义信息的需求已经在kuipers",{"2":{"961":1}}],["需要使用",{"2":{"107":1}}],["需要其他软件的",{"2":{"87":1}}],["需要上面设置的账号和密码",{"2":{"78":1}}],["需要加上对应头文件",{"2":{"67":1}}],["需要一点时间",{"2":{"26":1}}],["影响下游任务表现",{"2":{"525":1}}],["影响的图的连通分量进行更新和计算",{"2":{"153":1}}],["阶段",{"2":{"525":1}}],["阶跃函数通过对局部测地距离进行编码来捕获粗略几何形状",{"2":{"481":1}}],["门口",{"2":{"525":1}}],["找路",{"2":{"525":1}}],["找到信号的比例",{"2":{"806":1}}],["找到卷积核权重f0",{"2":{"561":1}}],["找到返回迭代器",{"2":{"509":1}}],["找到和正确的对象",{"2":{"437":1}}],["找到",{"2":{"437":1}}],["失败返回0",{"2":{"633":1}}],["失败返回end",{"2":{"509":2}}],["失败类别",{"2":{"522":1}}],["报告了仅考虑视野内",{"2":{"989":1}}],["报告了",{"2":{"903":1}}],["报告了所有指标的标准差",{"2":{"522":1}}],["报错信息",{"2":{"48":1}}],["精确地出现在物体占据区域的长距离和短距离区域内",{"2":{"745":1}}],["精确度↑",{"2":{"522":1}}],["精度与鲁棒性",{"2":{"864":1}}],["精度与批量离线方法相当",{"2":{"112":1}}],["精度是视觉方法的两倍多",{"2":{"803":1}}],["精度的情况下",{"2":{"803":1}}],["精度和召回率一致",{"2":{"437":1}}],["精度和成功度通常用于评估",{"2":{"263":1}}],["精度为0",{"2":{"437":1}}],["精度然后测量每个估计房间与地面真实房间的最大重叠体素",{"2":{"437":1}}],["精度=1",{"2":{"437":2}}],["精度",{"2":{"173":1,"437":1,"823":1}}],["溅射",{"2":{"516":1}}],["区分瞬态",{"2":{"864":1}}],["区别只在于生成时是否将条件向量置为零即可",{"2":{"513":1}}],["区域间的全局连接",{"2":{"525":1}}],["区域的特征蒸馏",{"2":{"455":1}}],["区域的数据",{"2":{"157":1}}],["区域和",{"2":{"455":1}}],["区域",{"2":{"455":1}}],["区域关系",{"2":{"337":1}}],["⏟unconditional",{"2":{"513":1}}],["⏟conditional",{"2":{"513":1}}],["浅谈扩散模型的有分类器引导和无分类器引导",{"2":{"513":1}}],["浅显说法",{"2":{"351":1}}],["位于相机前方",{"2":{"793":1}}],["位于同一网格上的所有相邻点的平均特征都是从上一层计算出来的",{"2":{"511":1}}],["位姿图轨迹",{"2":{"775":1}}],["位同样重要",{"2":{"698":1}}],["位置正确性和重叠比率方面也展现了更高的效率",{"2":{"851":1}}],["位置和反射率",{"2":{"789":1}}],["位置与尺寸存入",{"2":{"765":1}}],["位置嵌入",{"2":{"623":1}}],["位置方面表现出色",{"2":{"596":1}}],["位置进行标记",{"2":{"480":1}}],["位置误差",{"2":{"437":1}}],["位置编码",{"2":{"427":1}}],["位置编码器中",{"2":{"369":1}}],["位置坐标可以以离线方式生成",{"2":{"369":1}}],["位置感知特征将在",{"2":{"369":1}}],["位置感知特征",{"2":{"369":1}}],["位置信息",{"2":{"96":1}}],["位置",{"2":{"24":1,"262":1,"564":1,"632":1,"916":1}}],["安全审计并无缝融入全球交通生态系统",{"2":{"507":1}}],["安装新的",{"2":{"107":1}}],["安装rosdep依赖项管理工具",{"2":{"87":1}}],["安装ros",{"2":{"76":1}}],["安装常用软件",{"0":{"69":1}}],["安装自定义显卡驱动版本号",{"0":{"66":1}}],["安装依赖项",{"2":{"36":1}}],["安装依赖",{"0":{"29":1},"1":{"36":1,"40":1,"47":1},"2":{"120":1}}],["安装开放词汇集",{"2":{"27":1}}],["安装",{"0":{"19":1,"27":1,"59":1,"76":1,"87":1},"1":{"87":1,"97":1,"107":1},"2":{"27":1,"66":1,"74":1,"120":2}}],["喇叭",{"2":{"507":1}}],["灯光",{"2":{"507":1}}],["广义3d占用感知",{"0":{"1006":1}}],["广义而言",{"2":{"139":1}}],["广泛的实验表明",{"2":{"767":1}}],["广域协调需受控",{"2":{"507":1}}],["云代理甚至可实时回答不确定车辆查询",{"2":{"507":1}}],["桥接灵活性与可认证性",{"2":{"507":1}}],["神经辐射场",{"2":{"860":1,"932":1}}],["神经符号距离场",{"2":{"619":1}}],["神经符号安全内核",{"2":{"507":1}}],["神经场因其连续",{"2":{"619":1}}],["神经场逐步融入语义",{"2":{"619":1}}],["神经场把整个",{"2":{"619":1}}],["神经场",{"0":{"619":1},"2":{"556":1,"619":1}}],["神经网络解空间巨大",{"2":{"114":1}}],["纯端到端网络难保障安全",{"2":{"507":1}}],["纯视觉中心算法在这些场景中的表现较差",{"2":{"952":1}}],["纯视觉中心算法在预测远处叠加物体方面存在困难",{"2":{"952":1}}],["纯视觉中心方法",{"2":{"503":1}}],["纯视觉中心的方法",{"2":{"503":1}}],["纯粹数据规模扩展不足以实现l4+",{"2":{"114":1}}],["省去额外去噪步骤",{"2":{"495":1}}],["栅格",{"2":{"495":1}}],["张郊区图像",{"2":{"749":1}}],["张金清",{"2":{"608":1}}],["张亚南",{"2":{"608":1}}],["张",{"2":{"495":1}}],["张量场网络",{"2":{"481":1}}],["俯视",{"2":{"913":1}}],["俯视栅格",{"2":{"495":1}}],["俯视图",{"2":{"162":1,"495":1}}],["遗忘",{"2":{"495":1}}],["局限性",{"0":{"878":1,"945":1},"2":{"495":1}}],["局部体素原点的选择与",{"2":{"886":1}}],["局部",{"2":{"875":1}}],["局部路径沿每个2d",{"2":{"875":1}}],["局部投影模块在特征图和投影矩阵之间执行矩阵乘法",{"2":{"875":1}}],["局部注意力机制缺乏远距离特征依赖",{"2":{"824":1}}],["局部注意力融合模块以获得最终的3d体积表示",{"2":{"875":1}}],["局部注意力融合模块",{"2":{"545":1,"746":2,"971":1}}],["局部空间占用预测",{"2":{"833":1}}],["局部空间占用预测与之前工作的设置相同",{"2":{"793":1}}],["局部空间占用预测和具身空间占用预测",{"2":{"793":1}}],["局部空间占用预测模块",{"0":{"705":1},"2":{"813":1}}],["局部策略",{"2":{"525":1}}],["局部可决策的小区域",{"2":{"525":1}}],["局部卷积滤波器是通过在球面调和域中参数化带锚定点的谱得到的",{"2":{"481":1}}],["局部性等",{"2":{"343":1}}],["局部的特征",{"2":{"313":1}}],["局部的特征表示是非常重要",{"2":{"313":1}}],["局部的",{"2":{"123":1}}],["局部映射",{"2":{"112":1,"141":1}}],["少于",{"2":{"694":1}}],["少于10个节点的位姿图在人类位置误差方面存在极端误差",{"2":{"419":1}}],["少数工作为捕捉高度信息而构建",{"2":{"495":1}}],["≤30像素",{"2":{"775":1}}],["≤",{"2":{"741":1}}],["≤1000",{"2":{"495":1}}],["≤0",{"2":{"480":1}}],["倍交叉验证",{"2":{"979":1}}],["倍",{"2":{"495":1,"803":1,"853":1}}],["倍多的目标标注",{"2":{"126":1}}],["效果更好",{"2":{"489":1}}],["效率",{"2":{"864":1}}],["效率提升",{"2":{"153":1}}],["效率高于push",{"2":{"104":1}}],["球面投影保留了更多信息",{"2":{"955":1}}],["球面表示",{"2":{"955":1}}],["球形",{"2":{"948":1}}],["球谐函数局部等价于点的三维旋转",{"2":{"481":1}}],["球员区域的预测保留",{"2":{"117":1}}],["泰勒展开式通过在立方体顶点处插值任意值来捕获固有的局部几何变化",{"2":{"481":1}}],["核聚集特征来显式地建模点的空间分布",{"2":{"664":1}}],["核元素是在单位球体中随机选择的",{"2":{"481":1}}],["核心维度包括",{"2":{"943":1}}],["核心难点包括",{"2":{"926":1}}],["核心架构组件与输出格式",{"2":{"538":1}}],["核心架构模块",{"0":{"195":1}}],["核心idea",{"2":{"498":1}}],["核心贡献",{"2":{"334":1,"695":1}}],["核心构成",{"2":{"247":1}}],["核心组件与输出",{"2":{"160":1}}],["核心是大规模多模态预训练",{"2":{"128":1}}],["核心思想也非常接近",{"2":{"312":1}}],["核心思想",{"2":{"106":1,"117":1,"287":1}}],["核心思想都是",{"2":{"84":1}}],["核心思想是",{"2":{"65":1}}],["靠近墙壁或门内开口的地方",{"2":{"480":1}}],["靠近传感器的物体看起来更大",{"2":{"438":1}}],["截断符号距离函数",{"2":{"603":1}}],["截面中的体素几乎到处都是0",{"2":{"480":1}}],["截取len长度的字符",{"2":{"52":1}}],["隔离这三个结构元素是直接的",{"2":{"480":1}}],["隔间和大型大学建筑",{"2":{"374":1}}],["黑色边",{"2":{"480":1}}],["黑白灰",{"2":{"227":1}}],["揭示了房间的轮廓",{"2":{"480":1}}],["欧几里得距离从红色",{"2":{"480":1}}],["欧几里得聚类的结果被用来估计每个假定对象的质心和边界框",{"2":{"253":1}}],["社区对更细致",{"2":{"806":1}}],["社区基准",{"2":{"478":1}}],["社会合规",{"2":{"478":1}}],["社会对齐的自动驾驶车辆研究提供简明而完整的参考",{"2":{"72":1}}],["认为不比较渲染图像的原因是室外场景的大规模和少量视角监督会使体积渲染网络难以收敛",{"2":{"988":1}}],["认为当前的聚类已经足够好",{"2":{"153":1}}],["认证与恶意消息鲁棒性是开放问题",{"2":{"478":1}}],["尚缺原则性",{"2":{"478":1}}],["稀缺且昂贵",{"2":{"478":1}}],["稀疏离散化表示",{"2":{"962":1}}],["稀疏离散表示",{"2":{"962":1}}],["稀疏",{"2":{"875":1}}],["稀疏感知类别从激光雷达点云中获得直接监督",{"2":{"566":1}}],["稀疏占据表示",{"2":{"535":1}}],["稀疏专家混合路由或师生蒸馏",{"2":{"417":1}}],["稀疏数据中的均匀采样方法",{"2":{"396":1}}],["稀疏3d",{"2":{"377":1}}],["稀疏的query",{"2":{"341":1}}],["稀疏卷积能够有效地利用高斯分布的稀疏性",{"2":{"716":1}}],["稀疏卷积在gpu中的运算是通过查询rulebook实现的",{"2":{"561":1}}],["稀疏卷积操作会将输入转化为hash",{"2":{"530":1}}],["稀疏卷积",{"0":{"307":1,"332":1},"1":{"332":1,"357":2,"385":2,"413":2,"442":2,"472":2,"500":2,"530":2,"561":2,"593":2},"2":{"215":1,"502":1,"589":2}}],["稀疏表示",{"2":{"209":1}}],["眩光遮挡关键信息的场景中尤为重要",{"2":{"691":1}}],["眩光",{"2":{"478":1}}],["雪",{"2":{"478":1}}],["雨天",{"2":{"914":1}}],["雨天场景子集的类别分布",{"2":{"900":1}}],["雨天场景子集和夜间场景子集的类别分布如图",{"2":{"900":1}}],["雨",{"2":{"478":1}}],["³阿德莱德大学",{"2":{"477":1}}],["³kargobot",{"2":{"395":1}}],["¹大连理工大学",{"2":{"477":1}}],["¹清华大学车辆与运载学院",{"2":{"395":1}}],["忽略被占用体素的语义类别",{"2":{"915":1}}],["忽略了场景中各物体的空间位置",{"2":{"765":1}}],["忽略了通用物体类别",{"2":{"739":1}}],["忽略了这种多样性",{"2":{"693":1}}],["忽略了对",{"2":{"678":1}}],["忽略了驾驶场景的空间稀疏性",{"2":{"536":1}}],["忽略了多模态数据在高斯初始化和更新中的潜力",{"2":{"474":1}}],["忽略掉长或者宽太小的proposal",{"2":{"493":1}}],["忽略点之间关系的问题",{"2":{"258":1}}],["感受野变大",{"2":{"470":1}}],["感知的鲁棒性对自动驾驶车辆的安全至关重要",{"2":{"1005":1}}],["感知准确性",{"0":{"1000":1}}],["感知周围环境的动态变化对于自动驾驶下游任务的安全可靠执行至关重要",{"2":{"975":1}}],["感知算法",{"0":{"967":1}}],["感知范围对模型性能的影响",{"0":{"944":1}}],["感知范围为",{"2":{"739":1}}],["感知是主流的感知模式",{"2":{"667":1}}],["感知类似",{"2":{"610":1}}],["感知任务中表现非常出色",{"2":{"599":1}}],["感知域在模型表面空间",{"2":{"589":1}}],["感知解决方案达到顶尖性能",{"2":{"520":1}}],["感知中的重要任务",{"2":{"520":1}}],["感知分数分别",{"2":{"434":1}}],["感知环境",{"2":{"350":1}}],["感知→语言→规划→控制",{"2":{"283":1}}],["感知压缩",{"0":{"270":1}}],["感知及与现实世界的物理交互",{"2":{"139":1}}],["感知并与环境互动",{"2":{"100":1}}],["感知",{"0":{"119":1},"1":{"134":1,"150":1,"166":1,"182":1,"200":1},"2":{"2":1}}],["逆归一化",{"2":{"470":1}}],["过去数十年",{"2":{"881":1}}],["过滤掉这些检测提高了定位性能",{"2":{"775":1}}],["过高",{"2":{"738":1}}],["过程可微",{"2":{"470":1}}],["过使扩散生成时的图像和目标文本的多模态clip损失尽可能小",{"2":{"268":1}}],["沿池化轴",{"2":{"676":1}}],["沿垂直维度",{"2":{"655":1}}],["沿射线的最远深度bin位于射线起点50米处",{"2":{"649":1}}],["沿一个轴压缩",{"2":{"567":1}}],["沿边全局搜索",{"2":{"525":1}}],["沿着视线方向",{"2":{"950":1}}],["沿着特定射线",{"2":{"705":1}}],["沿着每个视觉特征网格的射线方向",{"2":{"621":1}}],["沿着参考相机的方向生成",{"2":{"524":1}}],["沿着一个新维度对输入张量序列进行连接",{"2":{"351":1}}],["沿深度d方向求期望",{"2":{"470":1}}],["致谢",{"0":{"960":1,"980":1,"1008":1},"2":{"467":1,"958":1,"973":1}}],["致力于让无人驾驶车辆变得安全",{"2":{"126":1}}],["免责声明",{"2":{"467":1,"973":1}}],["免费使用",{"2":{"126":1,"302":1}}],["卧室",{"2":{"467":1,"605":1}}],["马氏距离满足",{"2":{"916":1}}],["马等等",{"2":{"463":1}}],["马尔科夫链蒙特卡洛",{"2":{"256":1}}],["订书机",{"2":{"462":1}}],["步骤来提取每个点块的丰富几何信息",{"2":{"456":1}}],["步长",{"2":{"225":1}}],["略有下降",{"2":{"917":1}}],["略",{"2":{"454":1,"457":1}}],["⊙",{"2":{"452":1,"970":1}}],["半监督使用占用标签",{"2":{"988":1}}],["半监督",{"2":{"988":1}}],["半监督和自监督训练则更加标签高效",{"2":{"988":1}}],["半监督或自监督进行训练",{"2":{"981":1}}],["半轴长度由",{"2":{"916":1}}],["半径为0",{"2":{"449":1}}],["半全局匹配",{"2":{"362":1}}],["凸显需要统一",{"2":{"447":1}}],["习语",{"2":{"447":1}}],["丢帧",{"2":{"447":1}}],["丢弃那些也未能通过对象注册的环路闭合",{"2":{"352":1}}],["延迟和内存消耗也与3d高斯分布的数量呈线性相关",{"2":{"842":1}}],["延迟和内存消耗上升",{"2":{"700":1}}],["延迟",{"2":{"447":2,"545":1,"965":1}}],["延迟降低",{"2":{"128":1}}],["驶离道路",{"2":{"447":1}}],["闯红灯",{"2":{"447":1}}],["碰撞检测和路径规划提供可微距离度量",{"2":{"619":1}}],["碰撞",{"2":{"447":1}}],["违规",{"2":{"447":1}}],["路标和交通灯",{"2":{"691":1}}],["路线成功率",{"2":{"447":1}}],["路径长度",{"2":{"947":1}}],["路径由智能体可直接执行的低级动作序列组成",{"2":{"274":1}}],["路径的方法没有效果",{"2":{"17":1}}],["据我们所知",{"2":{"444":1,"471":1,"566":1,"653":1,"665":1,"779":1,"831":1,"967":1}}],["据说是线性代数中的一维数组就是叫做向量",{"2":{"83":1}}],["遮挡等问题",{"2":{"955":1}}],["遮挡等原因是包含噪声的",{"2":{"440":1}}],["遮挡物体识别不足",{"2":{"897":1}}],["遮挡",{"2":{"665":1}}],["遮挡行人",{"2":{"417":1}}],["跨楼",{"2":{"935":1}}],["跨视角解决冲突数据",{"2":{"864":1}}],["跨时段",{"2":{"864":1}}],["跨越euroc",{"2":{"836":1}}],["跨越vio固定滞后平滑器中的关键帧的多帧3d网格",{"2":{"336":1}}],["跨车队引导知识",{"2":{"507":1}}],["跨输入格式",{"2":{"485":1}}],["跨区域泛化与无灾难性遗忘持续学习未解决",{"2":{"478":1}}],["跨模态社会智能",{"2":{"507":1}}],["跨模态",{"2":{"439":1}}],["召回率和特异性",{"2":{"985":1}}],["召回率↑",{"2":{"522":1}}],["召回率仅为0",{"2":{"437":1}}],["召回率测量每个地面真实房间与估计房间的最大重叠体素",{"2":{"437":1}}],["召回率",{"2":{"437":1}}],["召回率曲线下的面积",{"2":{"263":1}}],["∩",{"2":{"437":2}}],["证明对任务至关重要",{"2":{"698":1}}],["证明",{"2":{"648":1}}],["证明了网络可以在没有任何标签的情况下学习3d占用感知",{"2":{"1000":1}}],["证明了更好的利用率",{"2":{"812":1}}],["证明了我们提出的概率高斯叠加在建模小物体方面的灵活性",{"2":{"792":1}}],["证明了我们方法的有效性",{"2":{"438":1}}],["证明了其模型的优越性和通用性",{"2":{"356":1}}],["证实了在没有动态代理的情况下",{"2":{"662":1}}],["证实了我们的传感器融合策略在不同感知范围内的卓越性能",{"2":{"475":1}}],["证实了提出的场景图环路闭合检测方法可以带来更可靠的环路闭合结果",{"2":{"437":1}}],["差异特别显著",{"2":{"437":1}}],["差异在标准差内",{"2":{"437":1}}],["差异来得到的",{"2":{"153":1}}],["漂移很小",{"2":{"437":1}}],["办公室场景中的小隔间或建筑场景中的楼梯井",{"2":{"522":1}}],["办公室和建筑场景包含标记的开放式平面房间",{"2":{"522":1}}],["办公室数据集中的许多对象",{"2":{"462":1}}],["办公室",{"2":{"437":1,"522":2,"605":2,"709":2,"796":2,"947":3}}],["办公楼和地铁站",{"2":{"141":1}}],["办公楼",{"2":{"131":1,"240":1}}],["亚25厘米地点位置误差",{"2":{"437":1}}],["玻璃和强烈阳光在场景区域的普遍存在",{"2":{"437":1}}],["音频",{"2":{"698":1,"864":2}}],["音频的模型",{"2":{"382":1}}],["音乐室和娱乐室",{"2":{"437":1}}],["四个入射边缘",{"2":{"436":1}}],["四个贡献点",{"2":{"394":1}}],["子集",{"2":{"979":1}}],["子图可以用来向机器人发出高级命令",{"2":{"939":1}}],["子像素卷积层最初在图像超分辨率",{"2":{"566":1}}],["子流形",{"2":{"500":2}}],["子算法可识别曾到访的位置",{"2":{"435":1}}],["子类别由句点划分",{"2":{"254":1}}],["子类别由一个点划分",{"2":{"254":1}}],["完成头包含一个",{"2":{"982":1}}],["完成头模块包含一个",{"2":{"982":1}}],["完成语义分割与物体分类",{"2":{"588":1}}],["完全重建了人体的smpl形状",{"2":{"967":1}}],["完全避免了使用3d可变形卷积或transformer模块",{"2":{"908":1}}],["完美执行",{"2":{"435":1}}],["完美定位",{"2":{"435":1}}],["完整度高度依赖于智能体在下游任务中的探索程度",{"2":{"826":1}}],["完整的几何与语义信息可减少对不准确数据的依赖",{"2":{"826":1}}],["完整的数据集包括大约",{"2":{"126":1}}],["完整性在搜救",{"2":{"826":1}}],["完整性",{"2":{"686":1,"786":1,"826":1,"881":1,"943":1}}],["完整网格的顶点位置作为变形图中节点的仿射变换进行更新",{"2":{"390":1}}],["完整版",{"2":{"185":1}}],["什么都没有返回",{"2":{"571":1}}],["什么地图对什么任务有用",{"2":{"435":1}}],["什么是",{"2":{"500":1}}],["什么是语义地图",{"0":{"350":1}}],["什么是流形",{"2":{"325":1}}],["什么是swap",{"2":{"18":1}}],["始终保持最新状态",{"2":{"435":1}}],["←",{"2":{"435":4}}],["投资可扩展记忆与因果推理骨干",{"2":{"538":1}}],["投票",{"2":{"435":1}}],["投影的",{"2":{"945":1}}],["投影确实是最佳选择",{"2":{"928":2}}],["投影和插值",{"2":{"609":1}}],["投影和特征采样",{"2":{"369":1}}],["投影到2d特征图上",{"2":{"950":1}}],["投影到像素坐标系中",{"2":{"705":1}}],["投影到图像外的体素",{"2":{"660":1}}],["投影到",{"2":{"660":3}}],["投影到与",{"2":{"649":1}}],["投影到另一个视图中的像素",{"2":{"592":1}}],["投影到向量空间",{"2":{"549":1}}],["投影",{"2":{"435":2,"612":1,"950":1}}],["⎡i",{"2":{"435":1}}],["⎡x",{"2":{"435":3}}],["希尔伯特曲线",{"2":{"426":1}}],["希望支持计算机视觉和自动驾驶领域的公共研究",{"2":{"126":1}}],["莫顿码",{"2":{"426":1}}],["莫顿码是将多维数据转化为一维数据的编码",{"2":{"426":1}}],["莫顿编码定义了一条",{"2":{"426":1}}],["达到最终性能的消融实验",{"0":{"876":1},"2":{"876":1}}],["达到实现全局注意力效果的同时不过多浪费计算和存储资源",{"2":{"824":1}}],["达到先进水平的训练技术",{"2":{"803":1}}],["达到",{"2":{"425":1}}],["达bleu",{"2":{"360":1}}],["算3d特征空间中每个点在2d特征上的坐标",{"2":{"875":1}}],["算子的轻量级融合网络设计",{"2":{"642":1}}],["算子按",{"2":{"436":1}}],["算子",{"2":{"425":1,"481":1,"824":2}}],["算法在",{"2":{"915":1}}],["算法在具有挑战性的场景",{"2":{"847":1}}],["算法从全局空间占用中获得当前局部空间占用",{"2":{"886":1}}],["算法从",{"2":{"886":1}}],["算法相同",{"2":{"867":1}}],["算法高出约",{"2":{"865":1}}],["算法运行速度更快",{"2":{"865":1}}],["算法为密集体素分配语义标签",{"2":{"850":1}}],["算法通过将每种模态的特征编码为",{"2":{"625":1}}],["算法进行了比较",{"2":{"503":1,"865":1,"965":1}}],["算法进行比较",{"2":{"438":1}}],["算法实现",{"2":{"481":1}}],["算法详解",{"2":{"396":1}}],["算法处理",{"2":{"396":1}}],["算法流程如下",{"2":{"339":1}}],["算法",{"0":{"339":1,"929":1},"2":{"564":1,"865":1}}],["算法就会认为它们之间存在关系",{"2":{"271":1}}],["算法会在它们之间添加边",{"2":{"271":1}}],["算法中图的构建过程",{"2":{"271":1}}],["算法不需要重新计算它们的聚类或更新它们的表示",{"2":{"153":1}}],["算法只会对那些受到新测量",{"2":{"153":1}}],["算法的预测结果进行比较",{"2":{"952":1}}],["算法的进步而持续演进",{"2":{"588":1}}],["算法的增量版本中",{"2":{"153":1}}],["算法的上下文中",{"2":{"153":1}}],["算法的伪代码在附录a中给出",{"2":{"153":1}}],["算法迭代合并具有最小权重的聚类",{"2":{"153":1}}],["严重阻碍了",{"2":{"425":1}}],["❌",{"2":{"423":1}}],["想要使用一个文本来引导图像生成",{"2":{"422":1}}],["想要保证准确率只能从头开始训练",{"2":{"151":1}}],["被",{"2":{"998":1}}],["被证明是最关键的",{"2":{"928":1}}],["被计算为所有高斯的",{"2":{"916":1}}],["被用于主动",{"2":{"826":1}}],["被用于捕获点之间的关系",{"2":{"420":1}}],["被跳过",{"2":{"796":1}}],["被输入到深度感知层",{"2":{"705":1}}],["被占用",{"2":{"658":1}}],["被设置为1米",{"2":{"621":1}}],["被加入到视觉特征",{"2":{"621":1}}],["被研究以节省内存资源",{"2":{"535":1}}],["被提出将卷积定义为阶跃函数和在",{"2":{"481":1}}],["被定义为一组自由空间体素",{"2":{"437":1}}],["被跟踪角点的位置",{"2":{"310":1}}],["他们在执行多时间步长的数据关联后才重建形状",{"2":{"967":1}}],["他们建立了occ3d基准",{"2":{"757":1}}],["他们引入了一种半自动标签生成管道",{"2":{"757":1}}],["他们引入了一种图像引导的体素细化方法",{"2":{"735":1}}],["他们还基于3d框的速度标注了前景体素的流速",{"2":{"735":1}}],["他们还提出了一种通过检查2d像素和3d体素之间的语义一致性来定量评估生成标签质量的方法",{"2":{"735":1}}],["他们还设计了一个基础架构deepsets",{"2":{"420":1}}],["他们利用k近邻投票来确定体素的语义标签",{"2":{"735":1}}],["他们设计了一个标注软件",{"2":{"735":1}}],["他们使用",{"2":{"955":1}}],["他们使用模型输出补充初始标签中标记为空的体素以进行增强",{"2":{"735":1}}],["他们使用步骤3中获得的相对密集注释作为初始标签",{"2":{"735":1}}],["他们发现雷达数据对性能提升有很大帮助",{"2":{"678":1}}],["他们学习的特征图位于每个点的k",{"2":{"607":1}}],["他们实现了显著的",{"2":{"517":1}}],["他们把",{"2":{"435":1}}],["他们的工作使用了一个学习到的码本模块",{"2":{"121":1}}],["蓝线",{"2":{"419":1}}],["蓝色",{"2":{"384":1,"436":2}}],["监管",{"2":{"478":1}}],["监控graphcmr位置和姿态估计以确定哪些估计不准确",{"2":{"419":1}}],["监督比较",{"2":{"1000":1}}],["监督信号训练的多模态",{"2":{"827":1}}],["监督模型为占用场赋予语义信息",{"2":{"949":1}}],["监督模型深度预测以提高准确性",{"2":{"585":1}}],["监督模仿学习",{"2":{"417":1}}],["监督分类网络",{"2":{"525":1}}],["监督不足",{"2":{"417":1}}],["维向量表示",{"2":{"693":1}}],["维护实例级地图",{"2":{"698":1}}],["维护稠密点云地图往往内存开销大",{"2":{"588":1}}],["维护有关人类轨迹的持久信息",{"2":{"419":1}}],["维度降低会丢失一部分信息",{"2":{"227":1}}],["微秒进行预积分",{"2":{"816":1}}],["微型vla",{"2":{"417":1}}],["微调流水线所用流匹配",{"2":{"195":1}}],["蒸馏的权重相等",{"2":{"823":1}}],["蒸馏之间不同的权重",{"2":{"823":1}}],["蒸馏和",{"2":{"823":1}}],["蒸馏过程将融合",{"2":{"694":1}}],["蒸馏或专家混合稀疏性将随模型规模扩大至数十亿参数必需",{"2":{"478":1}}],["蒸馏",{"2":{"417":1,"619":1}}],["事故预测",{"2":{"1003":1}}],["事实上",{"2":{"728":1,"814":1}}],["事实证明",{"2":{"471":1}}],["事件驱动调度仅在新场景时调用重型模型",{"2":{"417":1}}],["事物",{"2":{"277":1,"302":1,"534":1}}],["降低持续的全局处理开销",{"2":{"935":1}}],["降低了工程复杂度",{"2":{"593":1}}],["降低了得分阈值和更少限制性的几何验证设置",{"2":{"437":1}}],["降低计算复杂性",{"2":{"908":1}}],["降低计算",{"2":{"417":1}}],["降维不是件坏事",{"2":{"227":1}}],["于广泛图文语料与视频数据集",{"2":{"417":1}}],["于是",{"2":{"184":1}}],["于是该篇文章使用第一个点击生成attention对feature进行加权",{"2":{"65":1}}],["于是出现了那个莫名其妙的出错信息了",{"2":{"48":1}}],["于是终端虽然输出了",{"2":{"48":1}}],["避碍和规划",{"2":{"905":1}}],["避碰与交规合规",{"2":{"417":1}}],["避免在最高分辨率层直接交互耗时的2d和3d信息",{"2":{"922":1}}],["避免了重复计数",{"2":{"916":1}}],["避免了通过降低",{"2":{"903":1}}],["避免了复杂的",{"2":{"517":1}}],["避免了深度估计",{"2":{"482":1}}],["避免缺点并同时从两种类型的方法中受益",{"2":{"349":1}}],["避免损害原本的数据分布",{"2":{"291":1}}],["避免除零",{"2":{"8":1}}],["罕见危险",{"2":{"417":1}}],["越高越好",{"2":{"971":2}}],["越来越多的方法引入了多摄像头和时间信息",{"2":{"841":1}}],["越低越好",{"2":{"545":1,"965":1}}],["越多模型效果越好",{"2":{"489":1}}],["越相似",{"2":{"411":1}}],["越早终止施加",{"2":{"264":1}}],["静态地图与实际状态可能失配",{"2":{"435":1}}],["静如脱兔的博客",{"2":{"410":1}}],["静止物体",{"2":{"277":5,"534":4}}],["≡ຶ̑ꀬ≡ຶ̑",{"2":{"410":1}}],["逻辑",{"2":{"408":1}}],["唯一依赖gpu计算的模块是2d语义分割",{"2":{"408":1}}],["唯一的单层场景",{"2":{"437":1}}],["唯一的机器人代理是收集数据的机器人",{"2":{"419":1}}],["唯一的表示符",{"2":{"254":1}}],["唯一的标识符",{"2":{"254":14,"534":1,"654":1}}],["唯一的区别就在于",{"2":{"217":1}}],["快速和更快的配置分别需要关键帧的75",{"2":{"836":1}}],["快速",{"2":{"836":1}}],["快速思考与慢速思考",{"0":{"408":1}}],["快速的索引到与其对应的value",{"2":{"196":1}}],["任何感知或地图更新延迟都可能引发事故",{"2":{"864":1}}],["任一前沿进展",{"2":{"478":1}}],["任意位置删除一个元素",{"2":{"904":1}}],["任意位置插入",{"2":{"904":1}}],["任意位置插入一个元素",{"2":{"904":1}}],["任意",{"2":{"406":1,"765":1}}],["任务层面",{"0":{"975":1}}],["任务层是简单的全局平均池化",{"2":{"526":1}}],["任务完成",{"2":{"826":1}}],["任务是否成功",{"2":{"806":1}}],["任务是预测语义占据网格",{"2":{"532":1}}],["任务专属性能指标的需求催生了更鲁棒",{"2":{"806":1}}],["任务成功率",{"2":{"806":1}}],["任务级",{"2":{"806":2,"846":1}}],["任务描述",{"2":{"793":2}}],["任务定义",{"0":{"780":1}}],["任务中",{"2":{"765":1}}],["任务中联合训练",{"2":{"743":1}}],["任务的所有语义类别的平均交并比",{"2":{"853":1}}],["任务的占用体素的交并比",{"2":{"853":1}}],["任务的评估指标",{"2":{"736":1}}],["任务的完整列表在附录d至g中提供",{"2":{"374":1}}],["任务至关重要",{"2":{"603":1}}],["任务上取得当前最优性能",{"2":{"588":1}}],["任务",{"2":{"252":1,"360":1,"588":1,"603":1,"877":1}}],["任务相关条件分布",{"2":{"153":1}}],["任务不可知原语具有几何属性",{"2":{"153":1}}],["任务驱动地点聚类",{"0":{"295":1}}],["任务驱动对象检测",{"0":{"271":1}}],["任务驱动聚类",{"0":{"153":1}}],["任务驱动的表示",{"2":{"121":1}}],["任务还可根据提供给智能体的目标说明进一步细分",{"2":{"139":1}}],["任务根据智能体与环境交互方式的不同而有所差异",{"2":{"139":1}}],["任务感知3d场景理解作为信息瓶颈",{"2":{"137":1}}],["任务感知",{"0":{"137":1}}],["任务包括抓取",{"2":{"123":1}}],["任务无关的评估指标",{"2":{"864":1}}],["任务无关表示的需求正在快速增长",{"2":{"90":1}}],["任务无关",{"2":{"80":1}}],["任务列表4",{"2":{"57":1}}],["任务列表3",{"2":{"57":1}}],["任务列表2",{"2":{"57":1}}],["任务列表1",{"2":{"57":1}}],["封闭集对象评估",{"0":{"492":1}}],["封闭集检测在概念集的表示上存在固有的局限性",{"2":{"109":1}}],["封闭词汇编码的局限",{"2":{"765":1}}],["封闭词汇",{"2":{"406":1}}],["宽度和高度",{"2":{"780":1,"910":1}}],["宽容",{"2":{"437":1}}],["宽松的检测可以用无限大的估计边界框满足",{"2":{"402":1}}],["宽高为w",{"2":{"305":1}}],["生信小兔的博客",{"2":{"396":1}}],["生成输入点云",{"2":{"978":1}}],["生成输出坐标",{"2":{"413":1}}],["生成更真实的场景数据",{"2":{"963":1}}],["生成数据与真实数据之间不可避免地存在领域差距",{"2":{"963":1}}],["生成环境的3d占用预测",{"2":{"942":1}}],["生成高质量的伪3d点云",{"2":{"898":1}}],["生成具有前所未有的细节和保真度的结果",{"2":{"860":1}}],["生成具有4",{"2":{"822":1}}],["生成状态估计",{"2":{"816":1}}],["生成密集3d占用注释通常包括以下四个步骤",{"2":{"735":1}}],["生成真实标签是3d占用预测的一个挑战",{"2":{"735":1}}],["生成真实信号与标准高斯分布噪音之间多余的那部分噪音信号",{"2":{"279":1}}],["生成一个全面的",{"2":{"977":1}}],["生成一个全局一致的",{"2":{"285":1}}],["生成一组置信度值",{"2":{"728":1}}],["生成动态物体或属性的全面表示",{"2":{"726":1}}],["生成周围场景的密集",{"2":{"724":1}}],["生成周围环境的密集3d语义占据网格",{"2":{"590":1}}],["生成最终的占用表示",{"2":{"976":1}}],["生成最终的伪3d点云",{"2":{"649":1}}],["生成最终融合的tpv",{"2":{"676":1}}],["生成三维点云",{"2":{"650":1}}],["生成三视图",{"2":{"621":1}}],["生成单尺度视觉特征",{"2":{"649":1,"744":1}}],["生成绝对尺度和无遮挡的环境描述",{"2":{"630":1}}],["生成多尺度tpv",{"2":{"621":1}}],["生成深度分布特征",{"2":{"621":1}}],["生成深度感知上下文特征",{"2":{"621":2,"649":1}}],["生成伪3d点云",{"2":{"621":2}}],["生成空间压缩后的激光雷达体素特征",{"2":{"609":1}}],["生成效果不错的辅助cam",{"2":{"591":1}}],["生成任务无关",{"2":{"588":1}}],["生成损失",{"2":{"582":3}}],["生成原始点云的查询视图",{"2":{"579":1}}],["生成对应的鸟瞰图",{"2":{"576":1}}],["生成初始的3d特征体",{"2":{"527":1}}],["生成3d位置感知特征",{"2":{"427":1}}],["生成3d网格",{"2":{"336":1}}],["生成代价体",{"0":{"411":1}}],["生成器的架构与提取器类似",{"2":{"549":1}}],["生成器的变换器解码器以及用于点patches的自回归预测的双掩蔽策略",{"2":{"315":1}}],["生成器自回归生成点块序列",{"2":{"368":1}}],["生成器被舍弃",{"2":{"315":1,"368":1}}],["生成器被丢弃",{"2":{"315":1}}],["生成器根据前面的点块生成下一个点块",{"2":{"315":1}}],["生成器",{"2":{"315":1,"488":2}}],["生成剩余的三层",{"2":{"285":1}}],["生成第3层",{"2":{"285":1}}],["生成第",{"2":{"285":1,"780":1}}],["生成中间人类可读航点",{"2":{"283":1}}],["生成来自所有邻近节点id的假定边集",{"2":{"276":1}}],["生成的粗体素预测映射回点云",{"2":{"962":1}}],["生成的关系描述",{"2":{"765":1}}],["生成的物体描述一并保存",{"2":{"765":1}}],["生成的",{"2":{"765":1}}],["生成的3d体素特征分辨率为200×200×16",{"2":{"764":1}}],["生成的分割标签用于训练分割模型",{"2":{"410":1}}],["生成的噪音信号",{"2":{"279":1}}],["生成的图像应该同时具有",{"2":{"181":1}}],["生成的骨架",{"2":{"162":1}}],["生成的中间",{"2":{"143":1}}],["生成图像的点运动之前还没有太多探索",{"2":{"143":1}}],["生成图片的同时生成mask",{"2":{"439":1}}],["生成图片的协方差矩阵",{"2":{"20":1}}],["生成图片的特征均值",{"2":{"20":1}}],["生成",{"2":{"133":1,"181":1,"621":1,"886":1}}],["生成逐步决策理由",{"2":{"128":1}}],["生成轨迹计划或低层控制token",{"2":{"128":1}}],["生成随机噪音eps",{"2":{"124":1,"257":1}}],["生成了一个语义3d点云",{"2":{"121":1}}],["生成模型之vq",{"2":{"292":1}}],["生成模型不同",{"2":{"247":1}}],["生成模型分类",{"0":{"203":1}}],["生成模型新方向",{"2":{"183":1,"382":1}}],["生成模型",{"0":{"118":1,"193":1},"1":{"213":1,"235":1,"256":1,"279":1,"304":1,"329":1,"354":1,"382":1}}],["生成模型的目的是能够完美的建模这个数据分$p",{"2":{"193":1}}],["生成模型的训练集可以和",{"2":{"20":1}}],["生成模型的几种评价指标",{"0":{"3":1}}],["姜坤",{"2":{"395":1}}],["姜坤¹",{"2":{"395":1}}],["石一宁在",{"2":{"395":1}}],["石一宁¹",{"2":{"395":1}}],["⁴纵目科技",{"2":{"395":1}}],["北京航空航天大学计算机科学与工程学院智能识别与图像处理实验室",{"2":{"608":1}}],["北京",{"2":{"395":1,"608":1}}],["杨",{"2":{"395":2}}],["杨梦梦¹",{"2":{"395":1}}],["许一良⁴",{"2":{"395":1}}],["许多研究人员基于nuscenes和waymo等元数据集开发了3d占用数据集",{"2":{"997":1}}],["许多新数据集如monoscene",{"2":{"997":1}}],["许多占用感知方法",{"2":{"957":1}}],["许多转换方法",{"2":{"950":1}}],["许多室外ssc方法应运而生",{"2":{"841":1}}],["许多早期工作采用显式编码",{"2":{"698":1}}],["许多最近的方法都专注于赋予模型相同的竞争力",{"2":{"682":1}}],["许多任务",{"2":{"629":1}}],["许多近期工作采用稀疏表示",{"2":{"599":1}}],["许多算法依赖于专用的深度传感器",{"2":{"570":1}}],["许多工作由于单目深度估计问题",{"2":{"482":1}}],["许多工作调查了基础模型的现状及其局限性",{"2":{"121":1}}],["许多网络均基于pointnet",{"2":{"420":1}}],["许多vla系统采用bev投影",{"2":{"195":1}}],["温拓朴¹",{"2":{"395":1}}],["李久思¹",{"2":{"395":1}}],["李群",{"2":{"325":1}}],["王增然",{"2":{"608":1}}],["王云龙¹",{"2":{"395":1}}],["王珂³",{"2":{"395":1}}],["钱康安¹",{"2":{"395":1}}],["苗金玉¹",{"2":{"395":1}}],["室外",{"0":{"606":1},"1":{"635":1,"663":1,"687":1,"710":1,"733":1,"755":1,"776":1,"797":1,"817":1,"837":1}}],["室外场景的道路",{"2":{"903":1}}],["室外场景",{"2":{"605":1}}],["室外的3d数据",{"2":{"394":1}}],["室内评估仅在观察到的表面和遮挡体素上进行",{"2":{"853":1}}],["室内的外参不断变化",{"2":{"705":1}}],["室内研究仍处于初步探索阶段",{"2":{"600":1}}],["室内场景的核心差异在于场景尺度的复杂性和物体尺寸的变化性",{"2":{"544":1}}],["室内和室外设置的训练和评估实践有所不同",{"2":{"853":1}}],["室内和室外",{"2":{"541":1,"605":1}}],["室内",{"0":{"856":1},"1":{"873":1,"890":1,"906":1,"920":1},"2":{"394":1}}],["远处点云稀疏",{"2":{"858":1}}],["远小于",{"2":{"716":1}}],["远胜于当前具身智能中常用的建图技术",{"2":{"435":1}}],["远优于使用单个输入表示",{"2":{"394":1}}],["远程调用",{"2":{"64":1}}],["卷积或变换器模块的研究者",{"2":{"831":1}}],["卷积模型同样是一个值得探索的方向",{"2":{"824":1}}],["卷积网络作为一种标准的深度学习结构",{"2":{"688":1}}],["卷积滤波器被定义为图谱域中的切比雪夫多项式",{"2":{"607":1}}],["卷积和池首先交错进行",{"2":{"574":1}}],["卷积通常是通过空间邻域上mlp来实现的",{"2":{"574":1}}],["卷积",{"2":{"535":1,"752":2,"957":1,"962":2}}],["卷积计算",{"2":{"517":1}}],["卷积算子支持的自适应体素融合模块以及具有从粗到细查询的多尺度分割头组成",{"2":{"670":1}}],["卷积算子",{"2":{"517":1,"598":1}}],["卷积被认为是依赖于样本密度函数",{"2":{"481":1}}],["卷积被定义为邻接矩阵多项式的一种变体",{"2":{"574":1}}],["卷积被定义为关于重要性采样的连续",{"2":{"481":1}}],["卷积被定义为具有非线性激活器的单层感知器",{"2":{"481":1}}],["卷积核由加权函数",{"2":{"481":1}}],["卷积的蒙特卡洛估计",{"2":{"481":1}}],["卷积可以解释为给定子集的加权和",{"2":{"481":1}}],["卷积组成的类似",{"2":{"412":1}}],["卷积式",{"2":{"391":1}}],["卷积应用于新的对称特征",{"2":{"325":1}}],["¯g是连接姿态顶点和网格顶点的所有边的集合",{"2":{"390":1}}],["¯gij||2",{"2":{"390":1}}],["¯gij",{"2":{"390":2}}],["¯",{"2":{"390":3}}],["˜r−1",{"2":{"390":1}}],["世界模型",{"2":{"1003":1}}],["世界模型和自动驾驶算法框架",{"2":{"1003":1}}],["世界建模和地图表示问题自机器人学诞生以来就一直是中心议题",{"2":{"961":1}}],["世界表示",{"0":{"961":1}}],["世界结构细节的能力",{"2":{"952":1}}],["世界的建模能力",{"2":{"952":1}}],["世界坐标系中的在线预测",{"2":{"728":1}}],["世界坐标系位置",{"2":{"390":1}}],["世界坐标映射到",{"2":{"435":1}}],["世界坐标",{"2":{"435":2}}],["世界空间的坐标",{"2":{"369":1}}],["∑c",{"2":{"985":1}}],["∑j≠ibci",{"2":{"916":1}}],["∑i​",{"2":{"794":1}}],["∑i",{"2":{"794":1}}],["∑iam",{"2":{"752":1}}],["∑i=1lλ",{"2":{"342":1}}],["∑​tpi​+fpi​+fni​tpi​​",{"2":{"749":1,"802":1,"848":1}}],["∑​x",{"2":{"741":1}}],["∑​gi​",{"2":{"738":1}}],["∑​∣∣rxi​g~​il​+txi​−tml​∣∣2ωil​",{"2":{"390":1}}],["∑​∣∣rmk​",{"2":{"390":1}}],["∑p∈pvalid∥dgt",{"2":{"647":1}}],["∑",{"2":{"390":6}}],["∑zij∈z∣∣x−1ixj−zij∣∣2ωzij+∑gij∈g∣∣m−1imj−gij∣∣2ωgij+∑¯gij∈¯g∣∣x−1imj−¯gij∣∣2ω¯gij",{"2":{"390":2}}],["∑zij∣∣xi−1xj−zij∣∣2ωij+∑k=0m∑l∈nm",{"2":{"390":1}}],["紫色顶点是具有相关变换",{"2":{"390":1}}],["八叉树中相同体素的顶点被合并",{"2":{"390":1}}],["八叉树和点云",{"2":{"331":1}}],["拒绝错误回路闭合",{"2":{"390":1}}],["拒绝摆烂的博客",{"2":{"73":1}}],["胜任的驾驶控制器",{"2":{"388":1}}],["收集的",{"2":{"652":1,"855":1}}],["收集数据的机器人也在这一层被建模为代理",{"2":{"178":1}}],["收敛比较慢",{"2":{"386":1}}],["收敛慢",{"2":{"386":1}}],["虚线表示额外的前视特征图融合",{"2":{"970":1}}],["虚线边缘折叠成一个点",{"2":{"436":1}}],["虚线描绘了仅在训练期间应用的组件",{"2":{"384":1}}],["虚拟机中usb",{"2":{"120":1}}],["虚拟环境",{"2":{"27":1}}],["架构细节",{"0":{"972":1},"1":{"978":1,"982":1}}],["架构组件",{"2":{"928":1}}],["架构作为特征桥接的载体",{"2":{"875":1}}],["架构进行处理",{"2":{"780":1}}],["架构",{"0":{"384":1,"642":1},"1":{"412":1,"441":1,"471":1},"2":{"488":2}}],["架构带来了许多优势",{"2":{"369":1}}],["另提供相机掩码指示体素是否被任一相机可见",{"2":{"742":1}}],["另外一个挑战是图像的",{"2":{"631":1}}],["另辟蹊径",{"2":{"382":1}}],["另一类工作采用隐式转换",{"2":{"821":1}}],["另一条研究路线利用鸟瞰图",{"2":{"612":1}}],["另一条研究路线则尝试将复杂的导航任务拆解为一组",{"2":{"274":1}}],["另一种从3d空间学习的方法是生成一组查询以捕捉场景的表示",{"2":{"875":1}}],["另一种方法是结合领域适应方法以缩小领域差距",{"2":{"963":1}}],["另一种方法是",{"2":{"599":1}}],["另一种方法利用点表示",{"2":{"599":1}}],["另一种做法",{"2":{"495":1}}],["另一个原因是",{"2":{"936":1}}],["另一个研究方向采用基于体素的表示",{"2":{"599":1}}],["另一个是基于条件生成的梯度预估模型",{"2":{"513":1}}],["另一些工作",{"2":{"274":1}}],["另一些工作则利用",{"2":{"209":1}}],["另一项工作基于可供性",{"2":{"121":1}}],["另一方面",{"2":{"109":1,"116":1,"437":2,"522":1,"564":1,"691":1,"716":1,"842":1,"900":1,"922":1,"950":1,"962":1,"1000":1}}],["适合激光雷达点云的标注",{"2":{"955":1}}],["适合现成的求解器",{"2":{"380":1}}],["适应捕捉3d空间中的有价值信息",{"2":{"922":1}}],["适应不同的视角变换",{"2":{"908":1}}],["适应不同的训练和推理工作负载",{"2":{"593":1}}],["适应性",{"2":{"619":1}}],["适应物体稀疏性",{"2":{"517":1}}],["适用于车联网或多机器人协作",{"2":{"700":1}}],["适用于成本效益高的自动驾驶感知系统",{"2":{"637":1}}],["适用于首次进入",{"2":{"435":1}}],["适用于与pid或端到端控制流水线集成",{"2":{"216":1}}],["适用于资源有限的代理",{"2":{"121":1}}],["轴的速度",{"2":{"809":2}}],["轴应用平均池化操作",{"2":{"789":1}}],["轴范围为",{"2":{"787":2}}],["轴和",{"2":{"787":1}}],["轴上的体素数量",{"2":{"712":1}}],["轴离散化为若干高度槽",{"2":{"378":1}}],["轴",{"2":{"378":1}}],["映射到颜色",{"2":{"619":1}}],["映射阶段结束后",{"2":{"522":1}}],["映射关系为",{"2":{"378":1}}],["映射至对应轨迹",{"2":{"283":1}}],["拓扑",{"2":{"846":1}}],["拓扑与稠密几何地图在大规模环境中的可扩展性优于网格地图",{"2":{"648":1}}],["拓扑地图虽缺乏几何细节",{"2":{"935":1}}],["拓扑地图最小",{"2":{"648":1}}],["拓扑地图以节点",{"2":{"525":1}}],["拓扑地图设计的关键在于",{"2":{"525":1}}],["拓扑地图在传统机器人",{"2":{"525":1}}],["拓扑地图采用图状结构",{"2":{"525":1}}],["拓扑地图",{"0":{"525":1},"2":{"378":2,"465":2,"967":1}}],["拓扑图计算轻量",{"2":{"935":1}}],["拓扑图过于稀疏",{"2":{"913":1}}],["拓扑图和对象实例分割是最耗时的操作",{"2":{"816":1}}],["拓扑图中每个节点的邻域的多数投票",{"2":{"480":1}}],["拓扑图",{"2":{"80":1,"90":1,"125":1,"864":1,"958":1}}],["初始属性",{"2":{"716":1}}],["初始时",{"2":{"621":1}}],["初始深度图由于正则化",{"2":{"470":1}}],["初始深度图生成",{"0":{"376":1}}],["初始",{"2":{"390":1}}],["初始化策略能够为",{"2":{"899":1}}],["初始化过于稀疏的高斯分布可能导致空间占用预测中出现空洞",{"2":{"833":1}}],["初始化语句如下",{"2":{"685":1}}],["初始化在鸟瞰图",{"2":{"644":1}}],["初始化后",{"2":{"563":1}}],["初始化生成",{"2":{"489":1}}],["初始化为任务不可知原语",{"2":{"153":1}}],["初始化",{"0":{"261":1,"888":1},"1":{"284":1,"309":1,"335":1,"361":1,"389":1,"418":1},"2":{"27":1}}],["杂乱的工作区和飞机库",{"2":{"374":1}}],["休息室",{"2":{"374":1}}],["教师",{"2":{"694":1}}],["教师模型",{"2":{"642":1}}],["教程示例",{"2":{"504":1}}],["教室",{"2":{"374":1}}],["教育使用",{"2":{"126":1,"302":1}}],["涵盖了波士顿和新加坡的环绕视图驾驶场景",{"2":{"749":1}}],["涵盖了动机分析",{"2":{"714":1}}],["涵盖了深度分支",{"2":{"544":1}}],["涵盖",{"2":{"652":1}}],["涵盖以下方面",{"2":{"551":1}}],["涵盖输入模态",{"2":{"538":1}}],["涵盖办公室",{"2":{"374":1}}],["涵盖感知→预测→动作",{"2":{"360":1}}],["送入clip",{"2":{"373":1}}],["送入模型",{"2":{"124":1,"257":1}}],["紧密相关",{"2":{"826":1}}],["紧密关联激光雷达真值",{"2":{"360":1}}],["紧凑的几何",{"2":{"619":1}}],["紧凑的图结构",{"2":{"363":1}}],["介绍常用的评估数据集和指标",{"2":{"991":1}}],["介绍",{"2":{"426":1}}],["介绍了一个称为voxnet的体素占据网络",{"2":{"363":1}}],["介绍语义地图及其核心组成部分",{"2":{"90":1}}],["恶劣天气",{"2":{"360":1}}],["筛选极端交通场景",{"2":{"360":1}}],["约70毫秒",{"2":{"842":1}}],["约7k片段",{"2":{"360":1}}],["约",{"2":{"694":1}}],["约1亿参数",{"2":{"617":1}}],["约3亿参数",{"2":{"617":1}}],["约200万帧",{"2":{"360":1}}],["惩罚不一致多步问答",{"2":{"360":1}}],["切入等",{"2":{"360":1}}],["虽可跨模态对齐与推理",{"2":{"864":1}}],["虽含环境信息",{"2":{"864":1}}],["虽无语言",{"2":{"360":1}}],["虽然3d占用预测可以基于当前观察提供大规模场景的密集占用表示",{"2":{"975":1}}],["虽然度量",{"2":{"973":1}}],["虽然一些方法",{"2":{"963":1}}],["虽然对象和地点层被正确估计",{"2":{"872":1}}],["虽然对常识推理和极端场景理解有效",{"2":{"128":1}}],["虽然这些方法可以有效地提取三维物体的可能位置",{"2":{"818":1}}],["虽然基于bev的表示相较于图像具有一定的优势",{"2":{"858":1}}],["虽然基于平面表示的方法",{"2":{"842":1}}],["虽然基于lidar和多模态的方法可以实现相对较强的检测性能",{"2":{"665":1}}],["虽然基线方法在引入时间信息时仅实现了4",{"2":{"811":1}}],["虽然主要用于室内场景",{"2":{"757":1}}],["虽然可以缓解冗余问题",{"2":{"693":1}}],["虽然多尺度",{"2":{"622":1}}],["虽然单个intel",{"2":{"605":1}}],["虽然它们可以捕捉到物体的相对深度位置",{"2":{"564":1}}],["虽然我们的方法可以零样本学习",{"2":{"553":1}}],["虽然我们认为提出的方法为机器人的高级3d场景理解迈出了重要一步",{"2":{"467":1}}],["虽然以视觉为中心的系统具有经济优势",{"2":{"547":1}}],["虽然环视摄像头具有成本效益",{"2":{"503":1}}],["虽然clio旨在进行开放集检测",{"2":{"492":1}}],["虽然在游戏应用中",{"2":{"961":1}}],["虽然在体积esdf层面上查询路径需要几分钟",{"2":{"930":1}}],["虽然在一般情况下计算楼层平面图是具有挑战性的",{"2":{"480":1}}],["虽然在稀疏",{"2":{"190":1}}],["虽然仍有优化计算的空间",{"2":{"437":1}}],["虽然表i中的计时结果是基于相对强大的工作站获得的",{"2":{"437":1}}],["虽然存在更新和更高性能的网络",{"2":{"437":1}}],["虽然大多数开源slam算法",{"2":{"390":1}}],["虽然相比于cnn",{"2":{"343":1}}],["虽然每帧网格旨在提供低延迟障碍物检测",{"2":{"336":1}}],["虽然该公式实现细粒度控制",{"2":{"216":1}}],["虽然本文没有调查",{"2":{"178":1}}],["虽然二者都致力于用语义信息丰富空间表示",{"2":{"155":1}}],["虽然设计和实现一个有效地包含所有这些要素的机器人感知系统只能是一个长期研究议程的目标",{"2":{"131":1}}],["虽然",{"2":{"116":1,"765":1}}],["虽然传统的封闭集度量",{"2":{"98":1}}],["虽然现有的具身智能综述大多集中在整体进展或具体任务",{"2":{"80":1}}],["含流标注",{"2":{"997":1}}],["含3d占用标注",{"2":{"997":1}}],["含标注",{"2":{"997":1}}],["含200万图像的2d目标检测数据集",{"2":{"617":1}}],["含2600驾驶场景与16200视觉语言qa对",{"2":{"360":1}}],["含密集描述与多轮3d",{"2":{"360":1}}],["含1000多视角场景",{"2":{"360":1}}],["含丰富描述与时间戳qa",{"2":{"360":1}}],["含44种场景类型",{"2":{"360":1}}],["含6相机",{"2":{"360":1}}],["含噪图像",{"2":{"329":1}}],["闭环驾驶",{"2":{"447":1}}],["闭环carla基准",{"2":{"360":1}}],["闭环控制",{"2":{"360":1}}],["闭环评估显示",{"2":{"114":1}}],["种室外设计方法",{"2":{"870":1}}],["种室内设计方法",{"2":{"870":1}}],["种主要的",{"2":{"870":1}}],["种关系",{"2":{"752":1,"928":1}}],["种场景",{"2":{"360":1}}],["种可能的语义标签",{"2":{"126":1}}],["条件生成可以建模为unet+cross",{"2":{"513":1}}],["条件扩散",{"0":{"202":1},"1":{"224":1,"244":1,"266":1,"289":1,"314":1}}],["条路线",{"2":{"360":1}}],["仿真到真实迁移",{"2":{"478":1}}],["仿真环境中构建的地图往往因过于理想化的假设而噪声大",{"2":{"435":1}}],["仿真",{"2":{"360":1}}],["波士顿",{"2":{"360":2,"995":1}}],["波士顿海港",{"2":{"157":1}}],["片段",{"2":{"360":2}}],["美国政府被授权为政府目的复制和分发重印本",{"2":{"467":1}}],["美国",{"2":{"360":1}}],["美丽心灵的永恒阳光的博客",{"2":{"177":1}}],["规定了一个堆叠规则",{"2":{"896":1}}],["规模化",{"0":{"805":1}}],["规模化与预训练",{"0":{"617":1}}],["规模",{"2":{"360":1}}],["规划和决策的含义大多未被探索",{"2":{"467":1}}],["规划和多模态学习的需求",{"2":{"139":1}}],["规划器直接规划路径前往该处",{"2":{"765":1}}],["规划器",{"2":{"274":1,"334":1,"417":1,"765":1}}],["规划查询",{"2":{"262":1}}],["规划延迟高",{"2":{"128":1}}],["规划与轨迹预测等任务",{"2":{"123":1}}],["规划长距离",{"2":{"116":1}}],["规划任务间关系",{"2":{"114":1}}],["规划级数据稀疏",{"2":{"114":1}}],["规划模块间存在误差传播和信息损失",{"2":{"114":1}}],["规划",{"2":{"82":1,"103":1}}],["矩阵乘法和2d卷积",{"2":{"481":1}}],["矩阵",{"2":{"358":1}}],["矩阵对角线上的内积是匹配图文的内积",{"2":{"184":1}}],["匈牙利算法的输入就是每条边的cost",{"2":{"358":1}}],["匈牙利算法的目标就是找到最大匹配",{"2":{"358":1}}],["匈牙利算法是用于解决二分图匹配的问题",{"2":{"358":1}}],["匈牙利算法",{"2":{"358":1}}],["锥形视锥",{"2":{"355":1}}],["各像素点的深度越集中在某个深度附近",{"2":{"622":1}}],["各图像特征图的各通道各特征点的差异情况",{"2":{"411":1}}],["各图代表了其像素点真实深度为当前深度时变换对应的特征值",{"2":{"355":1}}],["各特征图上各像素经过变换后的特征值",{"2":{"411":1}}],["各模块的性能",{"2":{"209":1}}],["尝试注册",{"2":{"352":1}}],["寻找匹配项",{"2":{"352":1}}],["举例",{"2":{"351":1}}],["举个例子",{"2":{"117":1}}],["→",{"2":{"351":1,"378":1,"382":1,"897":2}}],["官方基准测试结果",{"2":{"989":1}}],["官方基准",{"2":{"903":1}}],["官方分为7",{"2":{"781":1}}],["官方分为700",{"2":{"781":1}}],["官方划分是",{"2":{"749":1}}],["官方划分为",{"2":{"749":1}}],["官方解释",{"2":{"351":1}}],["官方驱动",{"2":{"66":1}}],["承载含义与情境的增强地图",{"2":{"350":1}}],["掩码分类损失源自maskformer",{"2":{"985":1}}],["掩码解码器头部",{"2":{"957":1}}],["掩码投影得到的点云",{"2":{"765":1}}],["掩码的二分匹配",{"2":{"349":1}}],["掩码",{"2":{"349":1}}],["命名为spformer",{"2":{"349":1}}],["命名为hydra",{"2":{"141":1,"408":1}}],["命名为hydra1",{"2":{"112":1}}],["～10e",{"2":{"345":1}}],["又需要不规则的内存访问",{"2":{"996":1}}],["又要在内存与计算上可扩展",{"2":{"926":1}}],["又能智能剔除空白区域",{"2":{"913":1}}],["又能在动态",{"2":{"881":1}}],["又带来了额外的0",{"2":{"876":1}}],["又用到了取整",{"2":{"554":1}}],["又采用了取整操作",{"2":{"554":1}}],["又兼具transformer建模序列的泛化性",{"2":{"343":1}}],["又因为",{"2":{"140":1,"280":1}}],["复杂现实驾驶环境中鲁棒性的必要性",{"2":{"1002":1}}],["复杂性比较",{"2":{"779":1}}],["复杂的模型结构带来了沉重的计算负担",{"2":{"601":1}}],["复杂的任务将是可取的",{"2":{"553":1}}],["复杂的特征采样过程会阻碍检测器的实际应用",{"2":{"341":1}}],["复制一个数组区间为",{"2":{"93":1}}],["复制另一个vector容器内容到该容器中",{"2":{"93":1}}],["系数",{"2":{"916":2}}],["系数的平均值得出的",{"2":{"812":1}}],["系",{"2":{"654":1}}],["系列模型主要依靠多头自注意力机制实现大模型构建",{"2":{"824":1}}],["系列方法中所采用的",{"2":{"564":1}}],["系列",{"0":{"341":1},"1":{"369":1,"397":1,"427":1,"457":1,"489":1,"519":1,"550":1,"583":1,"615":1,"644":1,"671":1,"695":1,"718":1,"740":1,"762":1,"783":1}}],["系统考量地图的准确性",{"2":{"881":1}}],["系统则根本不依赖",{"2":{"435":1}}],["系统设计策略",{"0":{"231":1},"1":{"252":1,"274":1,"299":1}}],["系统中的几何地图足以支持简单导航与控制",{"2":{"209":1}}],["系统演进至立体相机",{"2":{"176":1}}],["系统",{"2":{"114":1,"189":1,"588":1,"619":1,"648":1}}],["嵌入和",{"2":{"968":1}}],["嵌入稠密且冗余",{"2":{"765":1}}],["嵌入空间共嵌",{"2":{"588":1}}],["嵌入式变形图方法将局部框架",{"2":{"380":1}}],["嵌入可以将点块的几何信息转化为模型能够理解和处理的向量表示",{"2":{"340":1}}],["嵌入",{"0":{"456":1},"2":{"340":1}}],["极少有人关注对已构建地图本身的评估",{"2":{"786":1}}],["极坐标平面",{"2":{"438":1,"621":2,"898":1}}],["极端欠分割",{"2":{"437":1}}],["极端案例问答",{"2":{"334":1}}],["极大的增强了",{"2":{"57":1}}],["视野内的性能更高",{"2":{"989":1}}],["视野外",{"2":{"989":1}}],["视为残差",{"2":{"716":1}}],["视锥数量的增加意味着视锥尺寸的减小",{"2":{"928":1}}],["视锥中只包含场景的小部分",{"2":{"814":1}}],["视锥",{"2":{"814":1}}],["视锥比例损失的效果",{"2":{"928":1}}],["视锥比例损失",{"0":{"814":1},"2":{"632":2,"928":1,"985":1}}],["视锥体内的高斯分布从记忆中取出",{"2":{"600":1}}],["视角转换模块和预测头来加速预测推理速度",{"2":{"1004":1}}],["视角分解策略和从粗到细策略都在不断追求减少计算负载的同时保持3d占用预测的准确性",{"2":{"922":1}}],["视角分解方法",{"0":{"908":1}}],["视角变换是生成bev表示的关键步骤",{"2":{"839":1}}],["视角扩大感知范围来丰富空间上下文信息",{"2":{"576":1,"800":1}}],["视角选择",{"2":{"435":1}}],["视图生成",{"2":{"579":1}}],["视图变换器是环绕视角3d感知系统中的关键组件",{"2":{"655":1}}],["视图变换器",{"0":{"655":1}}],["视图变换模块",{"2":{"598":1}}],["视图变换是基于相机的3d感知的核心模块",{"2":{"585":1}}],["视图变换",{"2":{"458":1}}],["视图关系",{"2":{"337":1}}],["视图",{"2":{"337":1}}],["视频感知",{"2":{"962":1}}],["视频演示和我们的实现代码都包含在附加的文件夹中",{"2":{"902":1}}],["视频演示",{"0":{"885":1,"911":1}}],["视频附件还展示了一个涉及4次拾放动作的更大区域的拾放实验",{"2":{"522":1}}],["视频",{"2":{"334":1,"360":5}}],["视频帧",{"2":{"334":1}}],["视觉特征表示为",{"2":{"976":1}}],["视觉问题回答",{"2":{"961":1}}],["视觉提供空间与外观线索",{"2":{"864":1}}],["视觉前端模块显示出双峰分布",{"2":{"816":1}}],["视觉前端检测shi",{"2":{"310":1}}],["视觉覆盖不完全以及激光雷达与视觉之间的冲突",{"2":{"803":1}}],["视觉导航中",{"2":{"698":1}}],["视觉为中心的占用感知确实是一种降低车辆设备制造成本的经济有效解决方案",{"2":{"667":1}}],["视觉occ综述",{"0":{"575":1}}],["视觉occ",{"2":{"573":1}}],["视觉保真度更高",{"2":{"495":1}}],["视觉transformer",{"2":{"417":1}}],["视觉到动作",{"2":{"334":1}}],["视觉输入",{"2":{"334":1}}],["视觉输入可来自相机或激光雷达",{"2":{"114":1}}],["视觉和惯性",{"2":{"310":1}}],["视觉编码器的选择决定了特征中包含的信息类型",{"2":{"274":1}}],["视觉编码器",{"2":{"195":1,"274":2}}],["视觉数据",{"2":{"176":1}}],["视觉",{"0":{"310":1},"2":{"82":1,"137":1,"139":1,"189":3,"285":1,"334":1,"408":2,"478":1}}],["历史和当前特征将被输入到特征融合模块中",{"2":{"957":1}}],["历史特征和当前特征经过时间空间对齐后",{"2":{"942":1}}],["历史观测",{"2":{"495":1}}],["历史帧",{"2":{"334":1}}],["历史上",{"2":{"139":1}}],["私有数据",{"2":{"334":1}}],["协作",{"2":{"507":1}}],["协作智能体",{"2":{"334":1}}],["协方差矩阵和协方差矩阵的行列式",{"2":{"916":1}}],["协方差矩阵",{"2":{"693":1}}],["协方差矩阵的逆",{"2":{"171":1}}],["协方差",{"2":{"567":1}}],["协方差及其语义类别",{"2":{"547":1}}],["协方差和语义组成",{"2":{"861":1}}],["协方差和语义对数几率组成",{"2":{"693":1}}],["协方差和语义",{"2":{"516":1,"716":1}}],["协方差和语义标签组成",{"2":{"444":1}}],["协调重叠的节点",{"2":{"380":1}}],["做图像",{"2":{"698":1}}],["做文本",{"2":{"698":1}}],["做间闭环稳步闭合",{"2":{"334":1}}],["做法如下图所示",{"2":{"312":1}}],["说到底仍旧是在2d特征中进行交互",{"2":{"341":1}}],["说",{"2":{"334":1}}],["说明了节省显式3d占用注释成本的可行性",{"2":{"949":1}}],["说明其性能更加稳定",{"2":{"928":1}}],["说明",{"2":{"888":1}}],["说明这些多阶段工作流程如何产生既表达丰富又可部署的模型",{"2":{"538":1}}],["说明合并操作导致的信息损失越小",{"2":{"153":1}}],["说明容器内没有安装",{"2":{"49":1}}],["索引城市规模记忆",{"2":{"334":1}}],["索引术语",{"2":{"112":1}}],["耦合transformer",{"2":{"334":1}}],["耦合性较高",{"2":{"149":1}}],["记为",{"2":{"609":1}}],["记录在两个不同的静态场景中",{"2":{"572":1}}],["记录需要挂载硬盘的",{"2":{"24":1}}],["记住地标",{"2":{"525":1}}],["记忆",{"2":{"334":1,"698":1}}],["记忆与交互",{"2":{"334":1}}],["迈向长时域推理",{"2":{"334":1}}],["迈向语言使能协作",{"2":{"283":1}}],["集中在离线处理",{"2":{"967":1}}],["集成了实例查询以协调2d到3d重建和3d场景建模",{"2":{"875":1}}],["集成",{"0":{"697":1}}],["集成高级规划模块",{"2":{"145":1}}],["集合和anchors的作用类似",{"2":{"333":1}}],["满足特征的稀疏性",{"2":{"332":1}}],["τ",{"2":{"328":1,"957":3}}],["τττ",{"2":{"206":2}}],["群",{"2":{"325":1}}],["孙小鸟",{"2":{"325":1}}],["曲面表示法",{"2":{"325":1}}],["曲线",{"2":{"164":1,"806":1}}],["梧桐雪的博客",{"2":{"325":1}}],["旋转和翻转",{"2":{"758":1}}],["旋转四元数",{"2":{"705":1}}],["旋转向量和语义对数几率",{"2":{"693":1}}],["旋转矩阵和尺度矩阵",{"2":{"532":1}}],["旋转的检测",{"2":{"419":1}}],["旋转",{"2":{"325":1,"339":1,"435":1,"532":1,"656":1}}],["阻碍了实际部署",{"2":{"799":1}}],["阻碍了",{"2":{"656":1}}],["阻碍了当前占据预测方法的部署",{"2":{"505":1}}],["阻碍了不变特征的形成",{"2":{"325":1}}],["阻碍安全审计与验证",{"2":{"114":1}}],["驯化transformer来生成高解析度图像",{"2":{"317":1}}],["求和",{"2":{"976":1}}],["求和和交叉注意力",{"2":{"976":1}}],["求逆",{"2":{"654":2}}],["求解器",{"2":{"380":1}}],["求",{"0":{"316":1}}],["求平均值",{"2":{"13":1,"124":1,"257":1}}],["排除",{"2":{"998":1}}],["排除掉",{"2":{"235":1}}],["排列信息",{"2":{"913":1}}],["排序以保持顺序不变性",{"2":{"379":1}}],["排序后的点块序列被嵌入到模型中",{"2":{"340":1}}],["排序是一种用于多维数据的排序方法",{"2":{"340":1}}],["排序进行排序",{"2":{"340":1}}],["排序",{"0":{"426":1},"2":{"340":2}}],["排序和嵌入",{"2":{"340":1}}],["排序将它们排列起来",{"2":{"315":1}}],["干净",{"2":{"313":1}}],["针对于此",{"2":{"863":1}}],["针对这些关键挑战",{"2":{"799":1}}],["针对室内感知特性量身定制的精巧设计将充分利用这种表示所固有的灵活性和可扩展性",{"2":{"705":1}}],["针对室内场景提出了密集的可见全景重建",{"2":{"603":1}}],["针对问题2",{"2":{"554":1}}],["针对问题1",{"2":{"554":1}}],["针对上一步剩下的proposal",{"2":{"493":1}}],["针对三维卷积网络面临的旋转不变问题",{"2":{"481":1}}],["针对性增广注入特殊交通场景与指令",{"2":{"417":1}}],["针对每一个类别",{"2":{"410":1}}],["针对匹配成功的predictions",{"2":{"358":1}}],["针对所有predictions",{"2":{"358":1}}],["针对domain",{"2":{"313":1}}],["针对之前工作只关注点特征",{"2":{"258":1}}],["限制直接比较",{"2":{"826":1}}],["限制直观人机交互",{"2":{"114":1}}],["限制",{"0":{"553":1}}],["限制了它们在动态设置中的适用性",{"2":{"958":1}}],["限制了它们对3d空间进行准确深度信息和细粒度几何结构建模的能力",{"2":{"444":1}}],["限制了占用网络利用自动驾驶场景中大量多视图图像的能力",{"2":{"932":1}}],["限制了其对新类别或开放词汇场景的适应能力",{"2":{"698":1}}],["限制了其在实际场景中的应用",{"2":{"392":1}}],["限制了实时应用",{"2":{"492":1}}],["限制了直接使用密集bev",{"2":{"341":1}}],["限于其框架依然是基于迭代去噪过程的无条件生成的ddpm模型",{"2":{"312":1}}],["依赖于手动定义的自然语言标题",{"2":{"961":1}}],["依赖于深度估计来生成伪",{"2":{"564":1}}],["依赖数据集的类别标注",{"2":{"630":1}}],["依然记录每一步的噪声图像",{"2":{"312":1}}],["依据语境",{"2":{"283":1}}],["立体匹配和几何验证",{"2":{"816":1}}],["立体匹配和几何验证在每个关键帧上执行",{"2":{"310":1}}],["立体图像",{"2":{"652":1}}],["立体",{"2":{"310":1}}],["立方体比例",{"2":{"277":1,"534":2}}],["立方体",{"2":{"277":1,"534":2}}],["εεε",{"2":{"304":1}}],["ε∼n",{"2":{"208":2}}],["继全景",{"2":{"302":1}}],["度传感器真值",{"2":{"749":1}}],["度激光雷达",{"2":{"613":1}}],["度视图",{"2":{"302":2}}],["度量到拓扑场景解析",{"2":{"967":1}}],["度量预测区域与真值的重合比例",{"2":{"826":1}}],["度量子目标完成比例",{"2":{"806":1}}],["度量空间地图",{"2":{"648":1}}],["度量语义3d网格",{"2":{"253":1}}],["度量语义映射的兴趣激增",{"2":{"172":1}}],["度量语义和层次化映射",{"0":{"172":1}}],["度量学习等手段区分不同的实例",{"2":{"138":1}}],["度量地图",{"2":{"116":1}}],["度量",{"0":{"162":1},"2":{"105":1,"116":2,"147":1,"162":1,"285":2,"362":1,"967":1}}],["覆盖完整",{"2":{"913":1}}],["覆盖的空间范围为",{"2":{"828":1}}],["覆盖体积中的体积总和得出的",{"2":{"812":1}}],["覆盖了73",{"2":{"781":1}}],["覆盖2m至42m",{"2":{"764":1}}],["覆盖整个",{"2":{"302":1}}],["覆盖",{"2":{"302":1}}],["亿个激光雷达点每个都标注了语义标签",{"2":{"302":1}}],["亿个标注点",{"2":{"126":1}}],["谱聚类是聚类图的流行方法",{"2":{"301":1}}],["组中第",{"2":{"863":1}}],["组柱坐标体积进行最大池化操作",{"2":{"676":1}}],["组特征沿通道维度进行拼接",{"2":{"676":1}}],["组",{"2":{"676":1,"863":1}}],["组件",{"2":{"550":1}}],["组件可复用",{"2":{"299":1}}],["组成",{"2":{"425":1,"481":1,"549":1,"562":1,"703":1,"705":1}}],["组装",{"2":{"380":1}}],["组合来生成一组3d参考点",{"2":{"716":1}}],["组合和查询",{"0":{"262":1}}],["组合成区域",{"2":{"137":1}}],["权衡",{"0":{"299":1}}],["权重衰减0",{"2":{"764":1}}],["权重衰减为0",{"2":{"813":1,"822":1}}],["权重衰减为",{"2":{"677":1,"744":1,"761":1,"771":1,"853":1,"867":1}}],["权重由两个乘积因子决定",{"2":{"697":1}}],["权重为",{"2":{"694":1}}],["权重函数是通过一个简单的mlp来学习的",{"2":{"481":1}}],["权重函数是通过简单的",{"2":{"481":1}}],["权重wj定义为",{"2":{"390":1}}],["权重",{"2":{"153":1}}],["科学空间|scientific",{"2":{"292":2}}],["损失是优化占用语义的首选损失",{"2":{"985":1}}],["损失是最常用的",{"2":{"985":1}}],["损失和",{"2":{"823":1}}],["损失和亲和力损失消耗更多",{"2":{"670":1}}],["损失权重配置为λl=0",{"2":{"758":1}}],["损失学习预测占用与已探索两张二值图",{"2":{"698":1}}],["损失进行监督",{"2":{"666":1}}],["损失计算",{"0":{"499":1},"2":{"579":1}}],["损失函数组成",{"2":{"651":1}}],["损失函数",{"0":{"358":1,"460":1,"647":1,"651":1,"766":1,"773":1,"884":1},"1":{"794":1,"814":1},"2":{"570":2,"603":1,"877":1}}],["损失函数添加条件项",{"2":{"175":1}}],["损失",{"2":{"334":1,"499":1,"670":3,"694":1,"738":1,"766":1,"782":1,"823":1,"884":1,"928":1,"988":1}}],["损害原本的数据分布",{"2":{"291":1}}],["较差",{"2":{"1006":1}}],["较少涉及决策层面",{"2":{"1003":1}}],["较高的iou并不保证较高的miou",{"2":{"1000":1}}],["较高的",{"2":{"916":2}}],["较高的百分比表明高斯与空间中的占用或有意义区域更好地对齐",{"2":{"916":1}}],["较暗的体素",{"2":{"903":1}}],["较大分辨率的特征提供丰富的空间信息",{"2":{"768":1}}],["较大时",{"2":{"345":1}}],["较小的间隔会导致更密集的伪",{"2":{"882":1}}],["较小的α值会导致更多的循环闭合检测",{"2":{"634":1}}],["较小分辨率的全局和局部特征包含有价值的语义信息",{"2":{"768":1}}],["较小和",{"2":{"345":1}}],["较强的噪声",{"2":{"291":1}}],["较弱的噪声",{"2":{"291":1}}],["帧丢失和摄像头视角丢失",{"2":{"1005":1}}],["帧转换到当前帧",{"2":{"957":1}}],["帧之后",{"2":{"833":1}}],["帧的体素级表示",{"2":{"780":1}}],["帧的信息",{"2":{"780":1}}],["帧的多摄像头图像",{"2":{"780":1}}],["帧和前",{"2":{"780":1}}],["帧激光雷达扫描合并为点云",{"2":{"563":1}}],["帧",{"2":{"285":1,"652":1,"833":1,"997":1}}],["体积渲染",{"2":{"988":1}}],["体积表示自然是稀疏的",{"2":{"962":1}}],["体积表示自然地保留了",{"2":{"962":1}}],["体积表示不适合高级路径规划查询",{"2":{"939":1}}],["体积被近似为",{"2":{"916":1}}],["体积的重要性高于低分辨率",{"2":{"884":1}}],["体积的重要性高于低分辨率体积",{"2":{"766":1}}],["体积语义预测的热门选择",{"2":{"599":1}}],["体积更大且更具侵入性",{"2":{"570":1}}],["体积进行上采样",{"2":{"545":1,"746":1}}],["体积",{"2":{"545":1,"746":2,"766":1,"884":1,"948":1,"977":1}}],["体积方法",{"2":{"285":1}}],["体素内的所有点都被分配与该体素相同的语义标签",{"2":{"962":1}}],["体素特征被上采样以进行语义分割",{"2":{"875":1}}],["体素特征以细化粗占据预测",{"2":{"474":1}}],["体素查询是3d网格形状的可学习参数",{"2":{"875":1}}],["体素级指标过于严格",{"2":{"998":1}}],["体素级指标",{"2":{"998":1}}],["体素级占用感知对分辨率和视觉外观的要求较低",{"2":{"860":1}}],["体素级3d占据预测",{"2":{"566":1}}],["体素尺寸为",{"2":{"853":1}}],["体素的表示",{"2":{"808":1}}],["体素分辨率为",{"2":{"828":1}}],["体素分辨率为0",{"2":{"742":1}}],["体素分辨率0",{"2":{"805":1}}],["体素高度为0",{"2":{"800":1}}],["体素大小为",{"2":{"787":1,"900":1}}],["体素大小设置为",{"2":{"739":2,"758":1}}],["体素大小根据环境或数据集调整",{"2":{"390":1}}],["体素到高斯初始化显著提高了模型检测小物体",{"2":{"723":1}}],["体素到高斯的初始化",{"0":{"563":1}}],["体素关系矩阵",{"2":{"730":1}}],["体素关系",{"2":{"707":1}}],["体素关系图示",{"2":{"707":1}}],["体素↔",{"0":{"707":1}}],["体素语义场景关系图",{"2":{"684":1}}],["体素质心",{"2":{"660":3}}],["体素网格在车辆前方跨越51",{"2":{"781":1}}],["体素网格区域覆盖了自车前方",{"2":{"749":1}}],["体素网格",{"2":{"596":1,"739":1}}],["体素编码器和占据预测头如图1和图2所示",{"2":{"585":1}}],["体素化步骤本质上会引入离散化伪影和信息丢失",{"2":{"962":1}}],["体素化为",{"2":{"853":1}}],["体素化",{"2":{"716":1}}],["体素化语义场景",{"2":{"570":1}}],["体素化表示",{"0":{"363":1}}],["体素作为表示来描述场景的最细细节",{"2":{"567":1}}],["体素计算量",{"2":{"517":1}}],["体素描述世界",{"2":{"517":1}}],["体素中",{"2":{"455":1}}],["体素表示在描述复杂3d结构方面的能力使其在3d语义占用预测中具有优势",{"2":{"612":1}}],["体素表示",{"2":{"311":1,"693":1}}],["体素",{"2":{"105":1,"967":1}}],["速率为关键帧速率",{"2":{"437":1}}],["速率的状态估计",{"2":{"285":1}}],["速度加快了",{"2":{"803":1}}],["速度",{"2":{"718":1}}],["速度和传感器偏差",{"2":{"310":1}}],["速度精度",{"2":{"173":1}}],["验证了我们模型的有效性和鲁棒性",{"2":{"914":1}}],["验证了我们的方法的效率和有效性",{"2":{"792":1}}],["验证分割",{"2":{"853":1}}],["验证集以及专注于夜间和雨天场景的子集进行综合评估",{"2":{"977":1}}],["验证集上评估不同的传感器融合策略",{"2":{"927":1}}],["验证集上gaussianformer的可视化结果",{"2":{"924":1}}],["验证集上",{"2":{"917":1,"944":1}}],["验证集上进行3d语义占用预测的样本图像",{"2":{"911":1}}],["验证集上的可视化结果",{"2":{"899":1}}],["验证集上的结果",{"2":{"803":3}}],["验证集上的",{"2":{"782":2}}],["验证集上的三维语义占位预测结果",{"2":{"700":1}}],["验证集",{"2":{"900":1,"928":1}}],["验证集中选择了特定的帧",{"2":{"900":1}}],["验证集的多分辨率语义占据预测",{"2":{"899":1}}],["验证集的定性结果",{"2":{"899":1}}],["验证集和测试集中的所有序列在训练过程中均未见过",{"2":{"899":1}}],["验证集和测试集上的可视化结果",{"2":{"899":1}}],["验证集和测试集的定性结果",{"2":{"899":1}}],["验证集与测试集之间存在显著的分布差异",{"2":{"828":1}}],["验证帧",{"2":{"793":1}}],["验证场景",{"2":{"793":2}}],["验证和测试",{"2":{"652":1,"749":2,"781":2,"828":1}}],["验证",{"2":{"310":1}}],["验证或否决语言驱动计划",{"2":{"283":1}}],["验证安装",{"0":{"97":1},"2":{"40":1}}],["合作项目中完成的",{"2":{"960":1}}],["合成增广",{"2":{"478":1}}],["合成信号",{"2":{"279":1}}],["合并后的",{"2":{"971":1}}],["合并新观测",{"2":{"864":1}}],["合并前景和背景点云",{"2":{"735":1}}],["合并每个池化区域中的特征",{"2":{"466":1}}],["合并为",{"2":{"436":1}}],["合并其特征或预测",{"2":{"435":1}}],["合并节点",{"2":{"380":1}}],["合并操作的信息损失分数度量的计算公式如下",{"2":{"153":1}}],["合并操作对应的信息损失的分数度量是ib算法中一个关键的评估指标",{"2":{"153":1}}],["合并操作对应的信息损失的分数度量",{"2":{"153":1}}],["合并成一个聚类时",{"2":{"153":1}}],["合并相邻聚类",{"2":{"153":1}}],["减轻了经典环形细分法的近似误差",{"2":{"400":1}}],["减少容器大小到满足元素所占存储空间的大小",{"2":{"904":1}}],["减少高斯分布的数量或增加其尺度会导致局部和具身空间占用预测性能的下降",{"2":{"833":1}}],["减少这个图片的",{"2":{"631":1}}],["减少映射操作的延迟",{"2":{"593":1}}],["减少数据移动的开销",{"2":{"593":1}}],["减少",{"2":{"517":1}}],["减少信息丢失并提升整体性能",{"2":{"497":1}}],["减少不必要的运算量",{"2":{"332":1}}],["减少anchor数量",{"2":{"328":1}}],["减去",{"2":{"279":1}}],["减速",{"2":{"260":1}}],["起到去噪的效果",{"2":{"279":1}}],["噪音将原始输入信号完全淹没",{"2":{"279":1}}],["噪声与不确定性",{"2":{"864":1}}],["噪声",{"2":{"277":1,"534":1}}],["噪声为高斯噪声时",{"2":{"235":1}}],["站立",{"2":{"277":1}}],["坐标",{"2":{"550":1}}],["坐标一起",{"2":{"369":1}}],["坐标系的变换",{"2":{"595":1}}],["坐标系原点以米为单位",{"2":{"254":1}}],["坐标系方向为四元数",{"2":{"254":2}}],["坐卧",{"2":{"277":1}}],["卡车或椅子",{"2":{"945":1}}],["卡车货架顶上的人梯等",{"2":{"630":1}}],["卡车",{"2":{"277":1,"534":1,"700":1,"723":1,"893":2,"975":1}}],["拖车",{"2":{"277":1,"534":1,"723":1,"893":1}}],["摩托车和行人",{"2":{"827":1}}],["摩托车",{"2":{"277":1,"534":1,"723":1,"800":1,"893":2,"903":1,"1000":1}}],["警车",{"2":{"277":1,"534":1}}],["警察",{"2":{"277":1,"534":1}}],["救护车",{"2":{"277":1,"360":1,"534":1}}],["应细分为更细粒度的类别",{"2":{"975":1}}],["应该是图21右侧dsg中的一个房间节点",{"2":{"796":1}}],["应对这些挑战需可扩展训练",{"2":{"478":1}}],["应用损失函数相比时",{"2":{"928":1}}],["应用反卷积细化体素的粒度",{"2":{"922":1}}],["应用图像上的交叉注意力和自注意力机制来细化和增强学习到的表示",{"2":{"875":1}}],["应用3d反卷积进行上采样",{"2":{"875":1}}],["应用残差细化",{"2":{"842":1}}],["应用于占据任务并完全避免使用计算密集型3d",{"2":{"831":1}}],["应用池化操作以获得扁平化的bev表示",{"2":{"655":1}}],["应用depthnet生成基于这些视觉特征的深度分布特征",{"2":{"621":1}}],["应用文献",{"2":{"527":1}}],["应用该分割器时无需对感兴趣的目标分布中的图像进行微调",{"2":{"469":1}}],["应用",{"0":{"430":1,"919":1},"1":{"461":1,"491":1,"521":1,"930":1,"939":1,"947":1},"2":{"829":1}}],["应用到深度学习神经网络上来说",{"2":{"129":1}}],["应急车",{"2":{"277":2,"534":2}}],["工程车",{"2":{"277":1,"534":1}}],["工作进一步拓展到",{"2":{"469":1}}],["工作重新梳理与归类",{"2":{"209":1}}],["工作区",{"2":{"109":1}}],["工作环境",{"2":{"27":1}}],["汽车可能会遮挡道路",{"2":{"814":1}}],["汽车等设备中",{"2":{"570":1}}],["汽车",{"2":{"277":1,"534":1,"723":1,"775":1,"893":1,"903":1,"975":1}}],["汽车在波士顿和新加坡进行驾驶",{"2":{"173":1}}],["刚性",{"2":{"277":1,"534":1}}],["铰接式",{"2":{"277":1,"534":1}}],["公共汽车",{"2":{"893":2}}],["公式如下",{"2":{"742":1}}],["公司",{"2":{"395":1}}],["公寓的dsg",{"2":{"947":1}}],["公寓环境有许多镜面反射",{"2":{"775":1}}],["公寓主要包含几何上不同的房间",{"2":{"522":1}}],["公寓和建筑中标记房间",{"2":{"522":1}}],["公寓和隔间数据集",{"2":{"374":1}}],["公寓",{"2":{"374":1,"437":1,"522":1,"605":1,"709":1,"796":3,"889":1,"947":1}}],["公交车",{"2":{"277":2,"534":2,"723":1}}],["公里",{"2":{"173":1}}],["轮椅",{"2":{"277":1,"534":1}}],["婴儿车",{"2":{"277":1,"534":1}}],["儿童",{"2":{"277":1,"534":1}}],["橙色和红色",{"2":{"276":1}}],["橙色块",{"2":{"276":1}}],["膨胀后消失的地方以黑色显示",{"2":{"276":1}}],["膨胀的墙壁以虚线显示",{"2":{"276":1}}],["经批准公开发布",{"2":{"973":1}}],["经深度投影到",{"2":{"765":1}}],["经深度投影后",{"2":{"698":1}}],["经mlp解码以细化高斯属性",{"2":{"595":1}}],["经验表明",{"2":{"495":1}}],["经kimera",{"2":{"449":1}}],["经过空间和时间信息融合的特征由各种类型的头部处理",{"2":{"957":1}}],["经过空间分组池化处理后",{"2":{"676":1}}],["经过线性投影",{"2":{"957":1}}],["经过线性投影后的",{"2":{"405":1}}],["经过蒸馏的模型与融合式教师模型更好地对齐",{"2":{"843":1}}],["经过蒸馏的",{"2":{"782":1}}],["经过这样的训练流程训练后",{"2":{"750":1}}],["经过四个隔间组和一个小厨房",{"2":{"605":1}}],["经过特征提取网络获取得多尺度深度特征表示为",{"2":{"464":1}}],["经过训练的",{"2":{"384":1}}],["经过固定次数的两个阶段迭代后",{"2":{"276":1}}],["经典机器人学中",{"2":{"826":1}}],["经典",{"2":{"423":1}}],["经典的resnet",{"2":{"627":1}}],["经典的分类训练只关心模型是否可以正确预测图像的分类标签",{"2":{"204":1}}],["经典的信息瓶颈",{"2":{"121":1}}],["经典模块化流水线",{"0":{"103":1}}],["经典自动驾驶",{"2":{"82":1}}],["洪水填充",{"2":{"276":1}}],["三角网格或表面元素相关联来创建稠密几何地图",{"2":{"958":1}}],["三角形",{"2":{"325":1}}],["三种传感器融合不仅扩展了模型的感知范围",{"2":{"952":1}}],["三视图",{"2":{"877":1,"942":1}}],["三视角将3d空间投影到三个正交的2d平面上",{"2":{"950":1}}],["三视角",{"2":{"665":1,"693":1,"819":1}}],["三模态监督",{"2":{"478":1}}],["三个验证集的类别分布情况",{"2":{"900":1}}],["三个tpv",{"2":{"699":1}}],["三个维度均与实际",{"2":{"465":1}}],["三个模块是分别训练的",{"2":{"207":1}}],["三维目标跟踪和场景流估计是新兴的研究课题",{"2":{"931":1}}],["三维目标检测监督仅在训练期间作为辅助分支使用",{"2":{"421":1}}],["三维分支不压缩任何维度的数据",{"2":{"923":1}}],["三维尺寸和偏航角",{"2":{"666":1}}],["三维高斯溅射使用各向异性的三维高斯分布来建模三维场景",{"2":{"629":1}}],["三维高斯溅射",{"2":{"629":1}}],["三维语义场景补全",{"2":{"603":1,"632":1}}],["三维语义占据预测",{"2":{"421":1}}],["三维场景感知已成为计算机视觉中的一个关键任务",{"2":{"600":1}}],["三维空间占用预测在过去几年中在室内外场景中都获得了极大的关注",{"2":{"629":1}}],["三维空间占用预测",{"2":{"629":1}}],["三维空间占用预测为周围场景提供了全面的描述",{"2":{"568":1}}],["三维空间中的图像和点云特征沿高度维度压缩",{"2":{"576":1}}],["三维体素级表示的处理不可避免地引入了巨大的内存和计算开销",{"2":{"505":1}}],["三维占据预测旨在映射环境中所有被占据的体素",{"2":{"482":1}}],["三维点云的分割方法可以分为三类",{"2":{"940":1}}],["三维点云的卷积核由于点云的不规则性而难以设计",{"2":{"450":1}}],["三维点云分割需要了解全局几何结构和每个点的细粒度细节",{"2":{"940":1}}],["三维点之间的几何关系并没有得到充分的考虑",{"2":{"420":1}}],["三维形状通常用体素网格上二元变量的概率分布来表示",{"2":{"363":1}}],["三维网格的5个输入特征类似于输入图像的rgb特征",{"2":{"275":1}}],["比例为",{"2":{"853":3}}],["比例为1",{"2":{"660":1}}],["比swinv2",{"2":{"824":1}}],["比其他cnn方案至少高出1",{"2":{"824":1}}],["比",{"2":{"803":1}}],["比使用",{"2":{"782":1}}],["比纯",{"2":{"765":1}}],["比insert效率高",{"2":{"604":1}}],["比conceptgraphs快约6倍",{"2":{"462":1}}],["比faster",{"2":{"386":1}}],["比回归差",{"2":{"382":1}}],["比较结果如表4所示",{"2":{"811":1}}],["比较",{"2":{"800":2}}],["比较了我们提出的3d高斯表示与现有的基于网格的场景表示方法",{"2":{"693":1}}],["比较了常见模块化方法在四大模块中采用的启发式或学习式策略",{"2":{"274":1}}],["比较描述符",{"2":{"352":1}}],["比旧方法更高效",{"2":{"275":1}}],["比如说行人或者汽车就有非常不同的尺寸",{"2":{"631":1}}],["比如说i和j",{"2":{"352":1}}],["比如挂车",{"2":{"630":1}}],["比如截断目标",{"2":{"630":1}}],["比如小轿车",{"2":{"630":1}}],["比如原图上的的roi大小是280×480",{"2":{"554":1}}],["比如点云和体素",{"2":{"394":1}}],["比如谷歌的imagen采用纯文本模型t5",{"2":{"373":1}}],["比如openai的glide和latent",{"2":{"373":1}}],["比如openai的dall",{"2":{"205":1}}],["比如1和2",{"2":{"345":1}}],["比如以下这个例子",{"2":{"312":1}}],["比如我们用一个颜色通道",{"2":{"227":1}}],["比如上图蓝色虚线",{"2":{"221":1}}],["比如眼镜",{"2":{"181":1}}],["比如特征",{"2":{"149":1}}],["比如人物的姿态等信息",{"2":{"133":1}}],["比如交互部位在最后的分割结果中依然会被分割错",{"2":{"75":1}}],["比如",{"2":{"60":1,"109":1}}],["策略必须安全驾驶且忠实交流",{"2":{"447":1}}],["策略与仿真器",{"2":{"417":1}}],["策略",{"2":{"274":1,"576":1,"800":1,"842":1}}],["策略梯度专家",{"2":{"195":1}}],["距离来获得",{"2":{"582":1}}],["距离减少到0m",{"2":{"480":1}}],["距离阈值是kimera",{"2":{"449":1}}],["距离",{"2":{"378":1,"582":4,"826":1}}],["距离差值最小",{"2":{"279":1}}],["距离或接触",{"2":{"178":1}}],["距智能体最近点",{"2":{"274":1}}],["双路径transformer编码器通过局部和全局路径有效捕捉细粒度细节和场景级布局",{"2":{"875":1}}],["双端队列",{"2":{"871":1}}],["双重屏蔽策略",{"2":{"518":1}}],["双线性插值",{"2":{"328":1,"696":1}}],["双模块",{"2":{"274":1}}],["双系统架构",{"2":{"128":1}}],["擅长感知压缩",{"2":{"270":1}}],["符号",{"2":{"688":1,"931":1,"979":1}}],["符号距离场",{"2":{"269":1}}],["符号安全检查与多模态扩散规划",{"2":{"145":1}}],["∥i",{"2":{"988":1}}],["∥mi−v∥1",{"2":{"916":1}}],["∥1",{"2":{"647":1}}],["∥d∥^2",{"2":{"480":1}}],["∥∇x​logpσi​​",{"2":{"342":1}}],["∥∇xlog⁡pσi",{"2":{"342":1}}],["∥22​",{"2":{"342":1}}],["∥22",{"2":{"342":1}}],["∥δi∥∥δt∥",{"2":{"268":1}}],["∥xt+δt−xt−f",{"2":{"208":1}}],["扩充数据资源以更有效训练大规模模型",{"2":{"617":1}}],["扩展了",{"2":{"961":1}}],["扩展至大规模实时应用",{"2":{"935":1}}],["扩展至鲁棒手势",{"2":{"507":1}}],["扩展dcnv3",{"2":{"824":1}}],["扩展后的点云数据在bev中覆盖一个矩形区域",{"2":{"638":1}}],["扩展点云处理范围所带来的计算成本增加与提高图像分辨率相比微不足道",{"2":{"638":1}}],["扩展到",{"2":{"800":1}}],["扩展到摄像头",{"2":{"482":1}}],["扩展到占据网络",{"2":{"455":1}}],["扩展nuscenes",{"2":{"360":1}}],["扩大化了p",{"2":{"422":1}}],["扩大数据范围",{"2":{"267":1,"398":1}}],["扩散世界模型",{"2":{"334":1}}],["扩散预测",{"2":{"308":1}}],["扩散的过程是人为拟定好的过程",{"2":{"304":1}}],["扩散的前向过程实际是个图像语义信息不断被噪声掩盖的过程",{"2":{"287":1}}],["扩散头在融合嵌入条件下采样连续控制",{"2":{"195":1}}],["扩散模型将合成相应的新驾驶场景",{"2":{"963":1}}],["扩散模型需要较长的学习",{"2":{"345":1}}],["扩散模型最大的问题是它的时间成本和经济成本都极其",{"2":{"205":1}}],["扩散模型与受控图像生成",{"0":{"201":1,"222":1},"1":{"242":1,"264":1,"287":1,"312":1,"338":1,"365":1,"393":1,"422":1,"452":1,"483":1,"513":1},"2":{"201":1}}],["扩散模型的优化目标本质上是在数据空间拟合一个前往目标数据分布的最优梯度方向",{"2":{"338":1}}],["扩散模型的细节保存能力和transformer的语义能力三者结合",{"2":{"248":1}}],["扩散模型的",{"2":{"180":1}}],["扩散模型发展过程中最重要的工作",{"2":{"170":1}}],["扩散超参",{"2":{"111":1,"236":1}}],["扩散过程就是从初始状态也是观测值",{"2":{"279":1}}],["扩散过程与采样过程",{"2":{"208":1}}],["扩散过程",{"2":{"111":1,"236":1}}],["选取前300个proposal进行分类和第二次边框修正",{"2":{"493":1}}],["选取前6000个proposal",{"2":{"493":1}}],["选定一个待探索的点或区域",{"2":{"274":1}}],["选用了一个可以用于多种下游任务的backbone",{"2":{"265":1}}],["选择3d占用作为世界模型的输入",{"2":{"963":1}}],["选择占用的体素",{"2":{"957":1}}],["选择了简洁的fpn",{"2":{"627":1}}],["选择了一个大型数据集用于预训练",{"2":{"265":1}}],["选择的任务是对于构成任务最佳对象集有明确定义的",{"2":{"374":1}}],["选择使用了随机丢弃的方式来强迫网络学习到局部特征",{"2":{"313":1}}],["选择这个半径是为了限制esdf使用的内存量",{"2":{"253":1}}],["选择性搜索算法",{"2":{"207":1}}],["选择",{"2":{"107":1}}],["选择安装其他软件",{"2":{"87":1}}],["选择一键安装rosdepc那一项对应的数字",{"2":{"87":1}}],["且大规模的真实世界3d标注是不现实的",{"2":{"1006":1}}],["且缺乏精确的几何细节",{"2":{"970":1}}],["且缺乏物体级语义与空间关系",{"2":{"765":1}}],["且随着感知范围的扩大",{"2":{"944":1}}],["且在训练期间使用相机可见掩码时",{"2":{"893":1}}],["且部署在机器人端面临计算与能耗瓶颈",{"2":{"864":1}}],["且effocc尚未发布其实现",{"2":{"859":1}}],["且effocc使用了更大的输入图像分辨率512×1408",{"2":{"779":1}}],["且弹出的是顶部元素",{"2":{"753":1}}],["且c",{"2":{"703":1}}],["且具有不同的景观",{"2":{"995":1}}],["且具有不规则和无序的特点",{"2":{"331":1}}],["且具有",{"2":{"638":1}}],["且环境扩大时只需增加节点即可扩展",{"2":{"525":1}}],["且需要预探索",{"2":{"525":1}}],["且对光照变化具有鲁棒性",{"2":{"503":1}}],["且占用内存大",{"2":{"495":1}}],["且",{"2":{"489":1,"495":1,"638":1}}],["且可变形注意力模块过于复杂",{"2":{"421":1}}],["且采样密度可以随场景复杂度而变化",{"2":{"378":1}}],["且必须tensor",{"2":{"351":1}}],["且序列内部的张量元素",{"2":{"351":1}}],["且受到噪声和遮挡的影响",{"2":{"331":1}}],["且仅限于非商业用途",{"2":{"302":1}}],["且能灵活结合学习式与传统方法",{"2":{"299":1}}],["且难以复用已有组件",{"2":{"299":1}}],["且无法精细化地控制生成的图像的性质",{"2":{"264":1}}],["且不能被修改",{"2":{"217":1}}],["且不同场景类型性能差异显著",{"2":{"114":1}}],["很难实现高效训练和快速收敛",{"2":{"824":1}}],["很好地更新",{"2":{"728":1}}],["很明显",{"2":{"264":1}}],["很多同学在使用迭代器遍历vector删除指定元素时",{"2":{"115":1}}],["平行",{"2":{"961":1}}],["平行的走廊",{"2":{"796":1}}],["平滑的时间范围",{"2":{"836":1}}],["平等地更新这些高斯分布是不合理的",{"2":{"728":1}}],["平坦区域",{"2":{"723":1}}],["平方米的均匀密度对网格进行采样来计算点云",{"2":{"686":1}}],["平衡语言与控制",{"2":{"417":1}}],["平移和置换",{"2":{"481":1}}],["平移和尺度缩放",{"2":{"339":1}}],["平移和缩放",{"2":{"325":1}}],["平移和缩放不变性",{"2":{"275":1}}],["平均操作计算多个特征的平均值",{"2":{"957":1}}],["平均高度",{"2":{"910":1}}],["平均需要0",{"2":{"816":1}}],["平均需要7",{"2":{"816":1}}],["平均会丢失信息",{"2":{"765":1}}],["平均误差在0",{"2":{"686":1}}],["平均",{"2":{"495":1,"522":4,"957":1}}],["平均或学习网络",{"2":{"495":1}}],["平均行走约400米",{"2":{"437":1}}],["平均交并比",{"2":{"425":1,"998":1}}],["平均交并集",{"2":{"263":1}}],["平均多目标跟踪精度",{"2":{"263":1}}],["平均精度",{"2":{"263":2}}],["平面并密集使用基于",{"2":{"865":1}}],["平面上",{"2":{"660":1,"955":1}}],["平面上的位置",{"2":{"660":1}}],["平面的每个点沿",{"2":{"622":1}}],["平面表示已成为自动驾驶场景感知任务中的有力竞争者",{"2":{"599":1}}],["平面表示",{"2":{"567":1}}],["平面",{"2":{"105":1,"116":1,"125":1,"277":4,"534":4}}],["楼层",{"2":{"262":1}}],["层上采样",{"2":{"982":1}}],["层下采样",{"2":{"982":1}}],["层面进行规划",{"2":{"947":1}}],["层次",{"2":{"947":1}}],["层次路径规划在几个数量级上优于在体积esdf层面上规划的计时性能",{"2":{"947":1}}],["层次路径规划的运行时间仍将保持在毫秒级",{"2":{"930":1}}],["层次路径规划",{"0":{"930":1},"2":{"947":1}}],["层次化场景表征比扁平表征更具可扩展性",{"2":{"648":1}}],["层次化地图自从机器人学的诞生以来就普遍存在",{"2":{"172":1}}],["层来降低特征通道维度",{"2":{"829":1}}],["层来学习层次特征",{"2":{"420":1}}],["层计算如何",{"2":{"696":1}}],["层组成",{"2":{"670":1}}],["层以提取几何特征",{"2":{"621":1}}],["层和修正线性单元",{"2":{"549":1}}],["层解码器",{"2":{"489":1}}],["层学习",{"2":{"481":2}}],["层数为12",{"2":{"373":1}}],["层",{"2":{"262":1,"285":1,"570":1,"632":1,"670":1,"684":1,"875":1,"982":1}}],["层之间包含一个",{"2":{"262":1}}],["拷贝构造",{"0":{"309":1},"2":{"261":1}}],["弥合该鸿沟成为下一步逻辑步骤",{"2":{"260":1}}],["弥合了现代具身智能体中感知与任务级推理之间的鸿沟",{"2":{"209":1}}],["叙述或标注场景不等同于生成精确转向或制动命令",{"2":{"260":1}}],["特性和细粒度的方法",{"2":{"599":1}}],["特斯拉提出的占用网络引领了自动驾驶中基于3d占用的感知趋势",{"2":{"997":1}}],["特斯拉发布了其基于bev感知的系统化管道",{"2":{"821":1}}],["特斯拉在cvpr",{"2":{"759":1}}],["特斯拉将占用网络引入自动驾驶",{"2":{"665":1}}],["特斯拉的基于视觉的占据网络",{"2":{"455":1}}],["特斯拉率先将占据网格地图",{"2":{"455":1}}],["特征作为一个激励信号发挥着关键作用",{"2":{"971":1}}],["特征作为统一的场景表示",{"2":{"599":1}}],["特征后",{"2":{"971":1}}],["特征对于",{"2":{"928":1}}],["特征格式",{"2":{"877":1}}],["特征和几何特征",{"2":{"968":1}}],["特征和两个",{"2":{"829":1}}],["特征和局部",{"2":{"545":2,"746":2,"768":1}}],["特征空间中的三线性插值可以转换为深度加权的双线性插值",{"2":{"866":1}}],["特征空间中相关联",{"2":{"723":1}}],["特征空间中通过激光雷达",{"2":{"444":1}}],["特征蒸馏损失",{"2":{"694":2}}],["特征之间进行全空间特征对齐",{"2":{"694":1}}],["特征展开为",{"2":{"670":1}}],["特征增强方法需要在显著提高性能的同时保持可控的计算资源消耗",{"2":{"969":1}}],["特征增强方法通过优化网络的特征表示能力来缓解3d空间输出与2d空间输入之间的差异",{"2":{"799":1}}],["特征增强方法",{"0":{"819":1},"1":{"839":1,"858":1,"875":1},"2":{"665":1}}],["特征是相关的",{"2":{"660":1}}],["特征进行细粒度",{"2":{"660":1}}],["特征投影的效果",{"2":{"928":1}}],["特征投影到给定的",{"2":{"660":1}}],["特征投影模块",{"2":{"539":1}}],["特征的",{"2":{"971":1}}],["特征的视线方向进行投影",{"2":{"660":1}}],["特征的指导",{"2":{"660":1}}],["特征的算法",{"2":{"564":1}}],["特征反向投影到所有可能的",{"2":{"660":1}}],["特征视线投影",{"0":{"660":1},"2":{"660":1}}],["特征视线投影机制",{"2":{"570":1}}],["特征并执行特征融合",{"2":{"625":1}}],["特征整合到目标查询",{"0":{"623":1}}],["特征实现语言监督的神经场",{"2":{"619":1}}],["特征与",{"2":{"619":1}}],["特征相近的结果",{"2":{"619":1}}],["特征引导的位置编码",{"0":{"615":1}}],["特征向量是从",{"2":{"607":1}}],["特征不适合用于",{"2":{"599":1}}],["特征用于下游任务",{"2":{"599":1}}],["特征沿视线方向投影",{"2":{"570":1}}],["特征提升到单个",{"2":{"660":1}}],["特征提升到可能的",{"2":{"632":1}}],["特征提升到",{"2":{"564":1}}],["特征提取是语义建图的核心环节",{"2":{"435":1}}],["特征提取不用",{"2":{"351":1}}],["特征提取",{"0":{"305":1,"433":1},"2":{"435":2,"579":1}}],["特征体积的交互",{"2":{"971":1}}],["特征体积的",{"2":{"789":1,"971":1}}],["特征体积输入全局",{"2":{"545":1,"746":1}}],["特征体积和全局",{"2":{"545":1,"746":1}}],["特征体积",{"2":{"545":1,"564":3,"746":4,"768":1,"789":1,"809":1,"829":1,"867":1}}],["特征体构建",{"0":{"383":1}}],["特征轨迹的质量",{"2":{"510":1}}],["特征保持在鸟瞰图",{"2":{"505":1}}],["特征图计算余弦相似性损失",{"2":{"694":1}}],["特征图计算均方误差",{"2":{"694":1}}],["特征图的宽度",{"2":{"694":1}}],["特征图的统计发现",{"2":{"694":1}}],["特征图上的坐标索引",{"2":{"694":1}}],["特征图应用1×11",{"2":{"660":1}}],["特征图f3df^",{"2":{"660":1}}],["特征图",{"2":{"495":1,"567":1,"660":3}}],["特征被聚合",{"2":{"466":1}}],["特征被共享卷积层一次性提取",{"2":{"432":1,"741":1}}],["特征s",{"2":{"405":1}}],["特征融合主要有三种主流方式",{"2":{"957":1}}],["特征融合",{"0":{"404":1},"1":{"433":1,"464":1}}],["特征充当transformer解码器的key和value",{"2":{"384":1}}],["特征维度为768",{"2":{"373":1}}],["特征维度为c=4c=4c=4",{"2":{"345":1}}],["特征",{"2":{"341":1,"377":1,"406":2,"421":1,"545":1,"570":1,"576":1,"588":1,"670":1,"678":1,"716":1,"743":1,"746":4,"789":1,"809":1,"928":1,"971":1}}],["特征检测",{"2":{"310":1}}],["特定的传感器类型",{"2":{"254":1,"597":1}}],["特别是增强对被遮挡区域的推理能力和对运动物体的识别能力",{"2":{"957":1}}],["特别是利用bev级特征",{"2":{"908":1}}],["特别是体素大小为0",{"2":{"836":1}}],["特别是对于",{"2":{"796":1}}],["特别是在利用这样的地图来提高复杂空间推理任务的性能方面",{"2":{"958":1}}],["特别是在多摄像头设置中",{"2":{"950":1}}],["特别是在保留各种地形类型的几何结构方面",{"2":{"899":1}}],["特别是在检测不规则物体和空间占据状态预测方面",{"2":{"503":1}}],["特别是在自动驾驶和机器人领域",{"2":{"482":1}}],["特别是在人类部分遮挡时",{"2":{"419":1}}],["特别是在动态环境中",{"2":{"153":1}}],["特别是人类",{"2":{"116":1,"131":1}}],["特别是",{"2":{"109":1,"131":2,"141":1,"153":1,"197":1,"276":1,"372":1,"380":1,"462":1,"471":1,"535":1,"605":1,"828":1,"847":1,"872":2,"936":1,"983":1}}],["短字符串标识符",{"2":{"254":1}}],["磁盘上data",{"2":{"254":1}}],["长距离感知能力不足和视野有限",{"2":{"969":1}}],["长途导航",{"2":{"935":1}}],["长期自主性",{"2":{"905":1}}],["长期",{"2":{"864":1}}],["长期时间信息被逐帧传播",{"2":{"695":1}}],["长度和高度",{"2":{"694":1}}],["长尾效应",{"2":{"630":1}}],["长尾场景鲁棒泛化及无缝仿真到真实迁移",{"2":{"538":1}}],["长",{"2":{"254":1,"654":1}}],["长时记忆",{"2":{"145":1}}],["空军合同号fa8702",{"2":{"973":1}}],["空闲",{"2":{"878":1}}],["空闲类别",{"2":{"802":1}}],["空类别以及真正例",{"2":{"749":1}}],["空或占用",{"2":{"712":1}}],["空",{"2":{"362":1,"998":1}}],["空任务可以被视为背景任务无关对象",{"2":{"271":1}}],["空如果场景结束",{"2":{"254":2}}],["空间一致性损失通过最小化给定点和空间中一些支持点之间的语义推理的jensen",{"2":{"985":1}}],["空间是空的",{"2":{"958":1}}],["空间信息融合",{"2":{"942":1,"957":1}}],["空间信息融合以及可选的时间信息融合",{"2":{"942":1}}],["空间图仅在高精度需求区域启用",{"2":{"935":1}}],["空间尺度扩大",{"2":{"864":1}}],["空间保真与可扩展性之间取得高效平衡仍是亟待突破的开放问题",{"2":{"864":1}}],["空间的",{"2":{"823":2}}],["空间的推广",{"2":{"599":1}}],["空间中用激光雷达",{"2":{"767":1}}],["空间中聚合激光雷达",{"2":{"444":1}}],["空间蒸馏损失的加权和",{"2":{"694":1}}],["空间上进行蒸馏",{"2":{"694":1}}],["空间和",{"2":{"694":3}}],["空间和采样增强",{"2":{"579":1}}],["空间下",{"2":{"644":1}}],["空间冗余仍然存在",{"2":{"599":1}}],["空间地图能够捕获",{"2":{"935":1}}],["空间地图",{"2":{"765":1}}],["空间地图可有不同构建方式",{"2":{"495":1}}],["空间地图初始化为空张量",{"2":{"495":1}}],["空间部分的位置是从一个单位球体中随机选择的",{"2":{"481":1}}],["空间部分的位置是从单位球体中随机选择的",{"2":{"481":1}}],["空间对齐",{"2":{"465":1}}],["空间关系等",{"2":{"378":1}}],["空间推理与决策",{"2":{"252":1}}],["空间感知引擎",{"0":{"285":1},"1":{"310":1,"336":1,"362":1,"390":1,"419":1,"449":1,"480":1,"510":1}}],["空间感知引擎的概念扩展了slam",{"2":{"131":1}}],["空间感知差",{"2":{"128":1}}],["空间概念是空间基础的语义概念",{"2":{"131":1,"147":1}}],["空间理解增强",{"2":{"128":1}}],["空间网格地图能捕获环境的稠密信息",{"2":{"495":1}}],["空间网格地图",{"0":{"495":1},"2":{"378":1,"465":2,"495":1}}],["空间网格",{"2":{"80":1,"90":1,"648":1,"846":1,"864":1}}],["空间",{"2":{"33":1,"435":1,"567":1,"595":1,"694":1,"808":1,"913":1,"978":1}}],["日期",{"2":{"254":1}}],["日志文件名",{"2":{"254":1}}],["外部",{"2":{"806":1,"846":1}}],["外部链接",{"2":{"57":1}}],["外在评估",{"2":{"786":1}}],["外",{"2":{"277":1,"302":1,"495":1,"534":1,"875":1}}],["外键",{"2":{"254":20,"534":1,"654":6}}],["摄像机",{"2":{"254":1}}],["摄像头捕获的rgb图像提供了丰富且密集的语义信息",{"2":{"970":1}}],["摄像头在大规模车辆部署中具有成本效益",{"2":{"942":1}}],["摄像头方法",{"2":{"700":1}}],["摄像头数据擅长捕捉详细的视觉纹理",{"2":{"691":1}}],["摄像头编码器",{"2":{"609":1}}],["摄像头+激光雷达以及摄像头+激光雷达+雷达",{"2":{"503":1}}],["摄像头+雷达",{"2":{"503":1}}],["摄像头占据网络主要基于体素表示或",{"2":{"474":1}}],["摄像头占据网络采用基于3d体素或基于2d鸟瞰图",{"2":{"444":1}}],["摄像头是最优的配置",{"2":{"474":1}}],["摄像头",{"2":{"444":2,"474":3,"1000":1}}],["摄像头传感器对光照条件敏感",{"2":{"444":1}}],["摄像头融合分解为两个可以独立输出感知结果的流",{"2":{"512":1}}],["摄像头融合特征细化",{"2":{"767":1}}],["摄像头融合特征细化3d高斯",{"2":{"415":1}}],["摄像头融合特征来更新高斯",{"2":{"444":1}}],["摄像头融合特征更新高斯",{"2":{"444":1}}],["摄像头融合的语义占据预测框架",{"2":{"444":1}}],["摄像头融合是最受欢迎且表现最佳的",{"2":{"444":1}}],["摄像头融合",{"2":{"444":1}}],["摄像头融合方法",{"2":{"415":1}}],["摄像头的运行频率为",{"2":{"211":1}}],["摄像头内参校准",{"2":{"191":1}}],["摄像头外参",{"2":{"191":1}}],["雷达可以穿透雨滴",{"2":{"1005":1}}],["雷达在内的融合策略",{"2":{"977":1}}],["雷达和激光雷达来预测",{"2":{"977":1}}],["雷达和摄像头的数据将提供对环境的全面理解",{"2":{"691":1}}],["雷达的贡献逐渐减少",{"2":{"944":1}}],["雷达擅长测量远处的物体",{"2":{"927":1}}],["雷达稀疏",{"0":{"809":1}}],["雷达传感器融合策略在",{"2":{"678":1}}],["雷达传感器融合",{"2":{"678":1}}],["雷达传感器读数在嘈杂条件下表现出鲁棒性",{"2":{"653":1}}],["雷达以及激光雷达",{"2":{"474":1}}],["雷达融合策略及其在环境感知中的性能",{"2":{"678":1}}],["雷达融合算法",{"2":{"653":1}}],["雷达融合的环境感知",{"0":{"653":1,"678":1}}],["雷达融合的3d语义占据预测",{"0":{"497":1}}],["雷达融合领域",{"2":{"482":1}}],["雷达融合",{"2":{"444":1,"653":1}}],["雷达融合以及激光雷达",{"2":{"444":1}}],["雷达",{"2":{"254":1,"277":1,"474":1,"809":1,"877":1,"977":1}}],["雷达外参",{"2":{"191":1}}],["停走专家",{"2":{"283":1}}],["停放",{"2":{"277":1}}],["停止",{"2":{"254":1,"277":1}}],["停在那辆红车后面",{"2":{"176":1}}],["父体素",{"2":{"253":1,"276":1}}],["活动窗口",{"2":{"253":1}}],["活动和姿态",{"2":{"126":1}}],["性能下降",{"2":{"971":1}}],["性能下降了大约",{"2":{"971":1}}],["性能一致提升",{"2":{"934":1}}],["性能优于视角分解方法",{"2":{"922":1}}],["性能都有所下降",{"2":{"827":1}}],["性能评估指标",{"0":{"807":1,"915":1}}],["性能提升受限",{"2":{"601":1}}],["性能的重要性显而易见",{"2":{"971":1}}],["性能的变化趋势如图",{"2":{"944":1}}],["性能的同时",{"2":{"862":1}}],["性能的",{"2":{"425":1}}],["性能",{"0":{"887":1,"999":1},"1":{"903":1,"917":1,"1000":1,"1001":1},"2":{"252":1,"588":1,"632":1,"794":1,"803":1}}],["性能会有下降",{"2":{"220":1}}],["潜在成功",{"2":{"806":1}}],["潜在的形状是端到端学习的",{"2":{"314":1}}],["潜在形状遵循先验分布",{"2":{"314":1}}],["潜在扩散模型",{"2":{"248":1}}],["潜在空间中的潜在向量是原始像素图像的压缩形式",{"2":{"270":1}}],["潜在空间简单的说是对压缩数据的表示",{"2":{"227":1}}],["潜在空间",{"0":{"227":1}}],["顶视图",{"2":{"605":1}}],["顶行",{"2":{"605":1}}],["顶点的sdf值和位置是继承自细分前的层次",{"2":{"372":1}}],["顶点位置",{"2":{"372":1}}],["顶点由",{"2":{"247":1}}],["顶部元素是top",{"2":{"774":1}}],["顶部是基于笛卡尔坐标系的方法",{"2":{"409":1}}],["顶部",{"2":{"197":1,"503":1}}],["住宅",{"2":{"240":1}}],["头部删除元素",{"2":{"904":1}}],["头部添加元素",{"2":{"904":1}}],["头部",{"2":{"877":1}}],["头设计源于组卷积",{"2":{"863":1}}],["头文件",{"0":{"239":1}}],["头发颜色",{"2":{"181":1}}],["头发的长度",{"2":{"149":1}}],["头发的细节需要用matting工具或者手工标注",{"2":{"117":1}}],["环绕视图",{"2":{"792":1}}],["环视相机对光照变化敏感",{"2":{"952":1}}],["环视图像特征提取",{"0":{"768":1}}],["环视图像首先通过2d主干网络处理",{"2":{"649":1}}],["环视图像首先通过2d主干网络处理以提取视觉特征",{"2":{"621":1}}],["环视雷达",{"2":{"724":1}}],["环视雷达和360度激光雷达的特征",{"2":{"503":1}}],["环视雷达和高密度激光雷达",{"2":{"438":1}}],["环视毫米波雷达成本低廉",{"2":{"503":1}}],["环路闭合消融研究",{"2":{"437":1}}],["环路闭合更为重要",{"2":{"437":1}}],["环路闭合策略不会显著影响性能",{"2":{"437":1}}],["环路闭合检测",{"2":{"352":1}}],["环路闭合检测的目标是找到一个过去的代理节点",{"2":{"352":1}}],["环路闭合检测和几何验证",{"0":{"352":1}}],["环路闭合检测和3d场景图优化",{"0":{"326":1},"1":{"352":1,"380":1}}],["环路闭合检测和优化",{"0":{"190":1},"2":{"380":1}}],["环路闭合检测后",{"2":{"190":1}}],["环边聚合成两对具有模糊性的边",{"2":{"325":1}}],["环邻居可以排序为",{"2":{"325":1}}],["环境动态变化和语义歧义",{"2":{"864":1}}],["环境探索比例",{"2":{"826":1}}],["环境的精细几何形状和语义信息",{"2":{"567":1}}],["环境尺寸变化时难以扩展",{"2":{"495":1}}],["环境感知模块分析车载传感器捕获的数据",{"2":{"665":1}}],["环境感知",{"2":{"475":1,"665":1}}],["环境中的物体",{"2":{"525":1}}],["环境中的小孔",{"2":{"301":1}}],["环境中移动",{"2":{"310":1}}],["环境及其核心贡献",{"2":{"238":1}}],["突出了激光雷达在理解复杂非道路地形几何结构方面的作用",{"2":{"700":1}}],["突出每阶段如何逐步闭合感知",{"2":{"538":1}}],["突出其输入模态",{"2":{"238":1}}],["突出不同表示方法之间的权衡",{"2":{"90":1}}],["扰动后",{"2":{"235":1}}],["变换对齐",{"2":{"634":1}}],["变换算子等",{"2":{"535":1}}],["变换后的公式不需要显式的概率密度pθ",{"2":{"235":1}}],["变形图方法",{"2":{"390":1}}],["变形图优化如下",{"2":{"390":1}}],["变形图",{"2":{"380":1}}],["变分自编码器",{"2":{"292":2}}],["变成了",{"2":{"659":2}}],["变成",{"2":{"133":1}}],["˙​∇x​logpdata​",{"2":{"235":1}}],["˙∇xlog⁡pdata",{"2":{"235":1}}],["∫∇x​",{"2":{"235":1}}],["∫∇x",{"2":{"235":1}}],["∇logp",{"2":{"338":1,"513":3}}],["∇log⁡p",{"2":{"338":1,"513":3}}],["∇θ​​epdata​​",{"2":{"235":1}}],["∇θepdata",{"2":{"235":1}}],["∇",{"2":{"235":1}}],["∇x​sθ​",{"2":{"235":1}}],["∇x​pdata​",{"2":{"235":1}}],["∇x​log⁡p",{"2":{"235":1}}],["∇x​logpdata​",{"2":{"235":2}}],["∇x​logp",{"2":{"208":1}}],["∇xsθ",{"2":{"235":1}}],["∇xlog⁡pdata",{"2":{"235":2}}],["∇xlog⁡p",{"2":{"208":1,"235":1}}],["∇xt+δt​​logp",{"2":{"208":2}}],["∇xt+δtlog⁡p",{"2":{"208":2}}],["∇xt​​logp",{"2":{"208":6,"316":2}}],["∇xtlog⁡p",{"2":{"208":6,"316":2}}],["保留的",{"2":{"557":1}}],["保留尽可能多的关于任务",{"2":{"153":1}}],["保存",{"2":{"504":1}}],["保存为潜层表示",{"2":{"406":1}}],["保持一致",{"2":{"886":1}}],["保持了与仅使用摄像头的方法大致相同的低内存使用量",{"2":{"700":1}}],["保持语言流畅度且无需大gpu成本",{"2":{"417":1}}],["保持连接两个网格顶点的边",{"2":{"390":1}}],["保持忠实语言接口",{"2":{"388":1}}],["保持llm推理在30hz控制循环内及形式化验证语言条件策略",{"2":{"334":1}}],["保持和为1",{"2":{"303":1}}],["保护第三方隐私是我们的首要任务",{"2":{"233":1}}],["隐藏测试集",{"2":{"903":1}}],["隐藏测试集上的",{"2":{"349":1}}],["隐式地学习上下文信息",{"2":{"928":1}}],["隐式地图",{"2":{"721":1}}],["隐式视图变换模块以实现互补的2d",{"2":{"875":1}}],["隐式视图变换生成紧凑的几何占用特征",{"2":{"875":1}}],["隐式编码则使用特征嵌入",{"2":{"675":1}}],["隐式编码高斯更新的空间和语义信息",{"2":{"563":1}}],["隐式编码",{"0":{"721":1},"1":{"743":1,"765":1},"2":{"406":1}}],["隐式特征",{"2":{"80":1,"209":1,"846":1}}],["隐私保护",{"0":{"233":1}}],["必须构建",{"2":{"897":1}}],["必须持续保存精细空间布局与物体级信息",{"2":{"864":1}}],["必须保证语义信息依旧准确",{"2":{"826":1}}],["必须将每一时刻的以自我为中心",{"2":{"495":1}}],["必须将",{"2":{"435":1}}],["必须满足0",{"2":{"351":1}}],["必须shape相等",{"2":{"351":1}}],["必须在0到len",{"2":{"351":1}}],["必须在",{"2":{"231":1}}],["必须高于同一行",{"2":{"184":1}}],["ϵ",{"2":{"225":1}}],["坏处是我们无法监督这一过程",{"2":{"224":1}}],["色度等变换",{"2":{"220":1}}],["缺省情况下",{"2":{"938":1}}],["缺少稠密的全局信息",{"2":{"525":1}}],["缺乏包含3d占用标注的公开大规模数据集",{"2":{"997":1}}],["缺乏上下文感知能力",{"2":{"570":1}}],["缺乏密集的周围占据监督",{"2":{"482":1}}],["缺乏高层次的评价方式",{"2":{"265":1}}],["缺乏统一的backbone",{"2":{"265":1}}],["缺乏与high",{"2":{"220":1}}],["缺点是受限于",{"2":{"743":1}}],["缺点",{"2":{"20":1,"203":2,"264":1,"765":1}}],["落地的问题",{"2":{"220":1}}],["客观指标与主观感受存在",{"2":{"220":1}}],["客观指标主要是psnr",{"2":{"220":1}}],["换成了",{"2":{"410":1}}],["换句话来说",{"2":{"338":1}}],["换句话说",{"2":{"131":1,"147":1,"271":1,"312":1,"362":1}}],["换个数据集",{"2":{"220":1}}],["泛化至未见城镇与天气",{"2":{"447":1}}],["泛化性差",{"2":{"220":1}}],["泛化能力弱",{"2":{"299":1}}],["泛化能力和安全验证仍是主要挑战",{"2":{"252":1}}],["泛化能力",{"0":{"995":1},"2":{"90":1}}],["常遇此问题",{"2":{"617":1}}],["常见为",{"2":{"619":1}}],["常见载体包括三角网格",{"2":{"556":1}}],["常见做法如下",{"2":{"525":1}}],["常见做法有三类",{"2":{"435":1}}],["常见形式包括",{"2":{"525":1}}],["常见聚合策略有",{"2":{"495":1}}],["常见的方法是采用鸟瞰图",{"2":{"908":1}}],["常见的解决方案包括基于",{"2":{"808":1}}],["常见的格式如图像和点云",{"2":{"780":1}}],["常见的做法是将现有3d点云分割任务的真实标签体素化",{"2":{"735":1}}],["常见的做法是将重建与目标检测结合起来",{"2":{"603":1}}],["常见的多模态语义占据传感器配置包括激光雷达",{"2":{"474":1}}],["常见的以物体为中心的流程",{"2":{"455":1}}],["常见的包括",{"2":{"220":1}}],["常用的评估指标是体素级交并比",{"2":{"998":1}}],["常用指标包括",{"2":{"826":1}}],["常用数据集",{"2":{"689":1}}],["常用于将多视角2d图像特征提升至3d空间",{"2":{"595":1}}],["常用函数",{"0":{"448":1},"1":{"479":1,"509":1,"540":1,"571":1,"604":1,"633":1,"661":1}}],["常用",{"2":{"63":2,"806":1}}],["走廊中观察到的自由空间在",{"2":{"796":1}}],["走廊与拐角用拓扑节点表示",{"2":{"648":1}}],["走廊",{"2":{"218":1,"967":1}}],["走廊和大厅的节点",{"2":{"218":1}}],["餐厅",{"2":{"218":1}}],["去宝宝正在睡觉的房间",{"2":{"864":1}}],["去除退化面和边",{"2":{"390":1}}],["去除退化点",{"2":{"310":1}}],["去集成",{"2":{"390":1}}],["去重容器",{"2":{"217":1}}],["去厨房拿起购物袋",{"2":{"116":1}}],["典型流水线现冻结clip与llama",{"2":{"417":1}}],["典型补救为dagger式噪声推出或显式极端案例增广",{"2":{"417":1}}],["典型例子emma",{"2":{"308":1}}],["典型vla4ad模型以多模态传感器数据与自然语言输入为语境",{"2":{"216":1}}],["典型的",{"2":{"189":1}}],["情境化地驾驶",{"2":{"216":1}}],["油门与制动",{"2":{"216":1}}],["油门与加速度",{"2":{"176":1}}],["低于0",{"2":{"1000":1}}],["低于检测到的天花板水平",{"2":{"480":1}}],["低",{"2":{"803":1}}],["低召回率对应于过分割",{"2":{"437":1}}],["低精度对应于欠分割",{"2":{"437":1}}],["低级感知",{"2":{"408":1}}],["低级路径规划模块负责从当前位姿到目标位姿规划可行路径",{"2":{"274":1}}],["低层控制",{"2":{"334":1}}],["低层动作",{"2":{"216":1}}],["低延迟的局部网格以及",{"2":{"285":1}}],["低分辨率的style",{"2":{"181":1}}],["归一化动态时间规整",{"2":{"806":1}}],["归一化的语义属性",{"2":{"681":1}}],["归一化",{"2":{"303":1,"470":1,"681":1}}],["归一化常数非常难求",{"2":{"213":1}}],["归一化常数",{"2":{"213":1}}],["归结为空间表示",{"2":{"116":1}}],["次运行的平均值",{"2":{"928":1}}],["次激光雷达扫描",{"2":{"744":1}}],["次激光雷达扫描之间",{"2":{"211":1}}],["次佳结果以",{"2":{"700":1}}],["次扫描的点云",{"2":{"677":1}}],["次",{"2":{"495":1}}],["次迭代中逐渐将高斯噪声添加到高分辨率图像",{"2":{"304":1}}],["次摄像头曝光尽可能均匀地分布在",{"2":{"211":1}}],["次合并操作导致的互信息减少量占原始互信息总量的比例",{"2":{"153":1}}],["鉴于3d占用比其他感知方式",{"2":{"1003":1}}],["鉴于3d占用感知的多源性质",{"2":{"714":1}}],["鉴于其在详细表示整个驾驶场景数据方面的熟练程度",{"2":{"963":1}}],["鉴于其在缓解3d物体检测中普遍存在的长尾缺陷和复杂形状缺失方面的能力",{"2":{"505":1}}],["鉴于基础模型的最新进展以及对通用性",{"2":{"958":1}}],["鉴于我们的插件适用性受限",{"2":{"811":1}}],["鉴于几何和语义预测",{"2":{"681":1}}],["鉴于这些挑战",{"2":{"1005":1}}],["鉴于这些限制",{"2":{"609":1}}],["鉴于这种条件概率的选择",{"2":{"153":1}}],["鉴于bev感知任务的进展",{"2":{"535":1}}],["鉴于高斯混合的通用近似能力",{"2":{"486":1}}],["鉴于点云的稀疏性",{"2":{"421":1}}],["鉴于从单目图像中估计深度是一个病态问题",{"2":{"421":1}}],["鉴于此",{"2":{"392":1}}],["鉴于上述结构各有所长",{"2":{"378":1}}],["鉴于摄像头的曝光时间几乎瞬间完成",{"2":{"211":1}}],["触发摄像头曝光",{"2":{"211":1}}],["读者可参考以下综述论文",{"2":{"209":1}}],["读音为",{"2":{"126":1}}],["物品移动",{"2":{"864":1}}],["物品增减",{"2":{"864":1}}],["物体声",{"2":{"864":1}}],["物体类别",{"2":{"826":1,"864":1}}],["物体类别上预训练的视觉模型提取特征",{"2":{"721":1}}],["物体级嵌入",{"2":{"765":1}}],["物体发现与场景解析",{"2":{"619":1}}],["物体搜索",{"2":{"588":1}}],["物体query预测的3d参考点通过相机参数投影回图像空间",{"2":{"341":1}}],["物体",{"2":{"209":1,"406":1,"648":1,"793":1,"992":2}}],["物理定律增强框架引入先验知识",{"2":{"114":1}}],["物理机器人或虚拟体",{"2":{"110":1}}],["逐体素级填充",{"2":{"209":1}}],["逐帧累积",{"2":{"743":1}}],["逐帧生成长描述引入延迟",{"2":{"260":1}}],["逐帧",{"2":{"123":1}}],["稠密结构必然带来内存与计算开销",{"2":{"913":1}}],["稠密而高效的地图",{"0":{"913":1}}],["稠密",{"2":{"881":1}}],["稠密表示",{"2":{"209":1}}],["稠密几何和混合表征",{"2":{"958":1}}],["稠密几何图又过于冗余",{"2":{"913":1}}],["稠密几何等",{"2":{"846":1}}],["稠密几何与拓扑三种结构",{"2":{"648":1}}],["稠密几何表征",{"2":{"556":1}}],["稠密几何地图最大",{"2":{"648":1}}],["稠密几何地图则可更细腻地表现场景中物体的",{"2":{"648":1}}],["稠密几何地图在每个",{"2":{"378":1}}],["稠密几何地图",{"0":{"556":1},"1":{"588":1,"619":1},"2":{"378":1,"465":1}}],["稠密几何地图以及它们的混合形式",{"2":{"378":1,"465":1}}],["稠密几何",{"2":{"80":1,"864":1}}],["却能显式表示物体",{"2":{"935":1}}],["却丢失了高度维度的关键语义",{"2":{"913":1}}],["却未针对建图或长期记忆训练",{"2":{"864":1}}],["却瞬态且难以持续空间化",{"2":{"864":1}}],["却缺乏精细几何",{"2":{"864":1}}],["却构建",{"2":{"743":1}}],["却忽视了对这些特征监督策略的探索",{"2":{"392":1}}],["却不足以应对更高阶的推理任务",{"2":{"350":1}}],["却需数百万训练步及精心设计的奖励函数",{"2":{"274":1}}],["却难以提供对环境语义内容的深入理解",{"2":{"209":1}}],["却留下",{"2":{"82":1}}],["≈0",{"2":{"362":1}}],["≈pdata​",{"2":{"235":1}}],["≈pdata",{"2":{"235":1}}],["≈∇x​logp",{"2":{"225":1}}],["≈∇xlog⁡p",{"2":{"225":1}}],["≈logp",{"2":{"208":1}}],["≈log⁡p",{"2":{"208":1}}],["≈exp",{"2":{"208":1}}],["郎之万动力学",{"2":{"208":1}}],["菲克第二定律",{"2":{"208":1}}],["确定哪些智能体最需要协调",{"2":{"969":1}}],["确定其语义类别",{"2":{"957":1}}],["确定每个",{"2":{"833":1}}],["确定fb",{"2":{"805":1}}],["确定一堆笔记本是一个对象还是多个",{"2":{"462":1}}],["确定性",{"2":{"208":1}}],["确保了合成数据的真实性",{"2":{"963":1}}],["确保这些高斯分布的更新更好地与局部结构对齐",{"2":{"600":1}}],["确保30hz内推理吞吐量",{"2":{"538":1}}],["确保生成行为在约束内安全",{"2":{"283":1}}],["确保ros软件源是使用的国内源",{"2":{"76":1}}],["离群值分布分散",{"2":{"622":1}}],["离散化为由密集体素组成的网格体积",{"2":{"780":1}}],["离散卷积",{"0":{"511":1}}],["离散过程",{"2":{"208":1}}],["离线",{"2":{"435":1}}],["离线建图",{"2":{"435":1}}],["离线将vlm能力迁移至传统系统",{"2":{"128":1}}],["离线运行需要几分钟来构建3d场景图",{"2":{"125":1}}],["迪菲赫尔曼的博客",{"2":{"207":1}}],["耗时的串行式cnn前向传播",{"2":{"207":1}}],["耗时的",{"2":{"207":1}}],["秒",{"2":{"652":1,"749":1}}],["秒内没有被关联",{"2":{"206":1}}],["秒的场景",{"2":{"157":1}}],["秒的场景是手动挑选的",{"2":{"126":1}}],["候选track需要与segment的余弦相似度高于阈值",{"2":{"206":1}}],["×0",{"2":{"998":2}}],["×h×w",{"2":{"863":3}}],["×z×w×h的占据逻辑",{"2":{"703":1}}],["×",{"2":{"205":2,"495":7,"616":3,"652":12,"694":2,"703":1,"741":2,"828":4,"971":6}}],["昂贵的细粒度注释",{"2":{"799":1}}],["昂贵",{"2":{"205":1}}],["间的数据",{"2":{"904":1}}],["间的元素",{"2":{"104":1}}],["间隔值来调整伪",{"2":{"882":1}}],["间接对数据分布进行拟合",{"2":{"203":1}}],["脉络梳理",{"2":{"201":1}}],["让网络能够自主学习哪些",{"2":{"928":1}}],["让网络能够感知到可能被遮挡的内容",{"2":{"814":1}}],["让网络输出与预训练",{"2":{"619":1}}],["让模型自己学习最优匹配",{"2":{"651":1}}],["让模型输出和随机生成的噪音",{"2":{"279":1}}],["让u",{"2":{"205":1}}],["让生成的人脸的细节部分更随机",{"2":{"199":1}}],["让服务器端继续运行任务",{"2":{"77":1}}],["挂在",{"2":{"197":1}}],["挂载",{"2":{"26":1}}],["东西",{"2":{"197":1}}],["柱子和交通标志",{"2":{"1000":1}}],["柱子",{"2":{"197":1}}],["柱子被认为是结构",{"2":{"178":1}}],["哈希函数",{"2":{"196":1}}],["获取充足的现实驾驶数据对于增强自动驾驶感知系统的整体能力至关重要",{"2":{"963":1}}],["获取的点云具有固有的稀疏性",{"2":{"910":1}}],["获取真值地图往往非常困难",{"2":{"826":1}}],["获取连续的原始lidar帧",{"2":{"735":1}}],["获取类别",{"2":{"698":1}}],["获取3d体素表示和优化的bev表示后",{"2":{"585":1}}],["获取密集几何信息",{"2":{"585":1}}],["获取",{"2":{"539":1}}],["获取单帧深度图",{"2":{"424":1}}],["获取查询向量特征",{"2":{"377":1}}],["获取指向指定键值对的前向迭代器",{"2":{"196":1}}],["获得每像素嵌入",{"2":{"765":1}}],["获得平均特征",{"2":{"677":1}}],["获得的点块根据它们的中心点被组织成一个连贯的序列",{"2":{"426":1}}],["获得投影后",{"2":{"419":1}}],["获得深度图",{"2":{"362":1}}],["获得最优占据图压缩",{"2":{"121":1}}],["获得文件权限",{"2":{"26":1}}],["存储与表示",{"2":{"926":1}}],["存储开销高",{"2":{"864":1}}],["存储每个类别的index",{"2":{"747":1}}],["存储需求方面",{"2":{"648":1}}],["存储占用信息",{"2":{"648":1}}],["存储带有语义标签的",{"2":{"556":1}}],["存储两类信息",{"2":{"406":1}}],["存储直到当前时间的整个场景图",{"2":{"380":1}}],["存储数分钟观测与动作",{"2":{"334":1}}],["存储的键值对包括",{"2":{"196":2}}],["存在严重的类别不平衡问题",{"2":{"928":1}}],["存在第五个维度",{"2":{"278":1}}],["存在一种简单申请哈希表的函数",{"2":{"196":1}}],["属性等",{"2":{"826":1}}],["属性会随着时间而改变",{"2":{"254":1,"654":1}}],["属性描述",{"2":{"254":1}}],["属性名",{"2":{"254":1}}],["属性是可以在类别保持不变的情况下更改的实例的属性",{"2":{"254":1}}],["属性",{"2":{"196":2,"277":1}}],["属于同一语义段的一组像素的相关性不会改变",{"2":{"498":1}}],["属于同一房间的地点也连接到第4层的同一房间节点",{"2":{"197":1}}],["属于batch中的哪个点云",{"2":{"357":1}}],["属于gvd的体素可以很容易地从用于更新esdf的刷火算法的波前中检测到",{"2":{"276":1}}],["属于模板的成员函数",{"2":{"177":1}}],["属于所有类别的概率分布",{"2":{"13":1}}],["功能相同",{"2":{"196":2}}],["功能",{"2":{"196":1}}],["迭代细化表面",{"2":{"372":1}}],["迭代器算法",{"0":{"918":1}}],["迭代器+待插入元素",{"2":{"571":1}}],["迭代器指向阻止插入的元素",{"2":{"571":1}}],["迭代器构造",{"2":{"261":1}}],["迭代器",{"2":{"196":1,"918":1}}],["迭代捆绑调整",{"2":{"168":1}}],["键和映射的类型可以不同",{"2":{"196":1}}],["键值通常用于唯一的标识元素",{"2":{"196":1}}],["键值对的关联式容器",{"2":{"196":1}}],["轻量化设计和准确性方面同时具备优势",{"2":{"1004":1}}],["轻量化设计",{"2":{"877":1}}],["轻量化的标注工具不希望用又慢又大的模型",{"2":{"117":1}}],["轻量",{"2":{"864":1}}],["轻量token缩减",{"2":{"417":1}}],["轻量级微调策略如lora",{"2":{"195":1}}],["假正例和假反例的数量",{"2":{"998":2}}],["假正例和假负例的数量",{"2":{"749":1,"802":1,"807":1,"848":1}}],["假阳性和假阴性的数量",{"2":{"915":1}}],["假阳性和假阴性",{"2":{"778":2}}],["假阳性和假阴性预测数",{"2":{"739":1,"742":1}}],["假如以pout",{"2":{"561":1}}],["假如有k个目标",{"2":{"358":1}}],["假设pip",{"2":{"794":1}}],["假设超体素vvv包含体素",{"2":{"730":1}}],["假设已知相机内参",{"2":{"660":2}}],["假设输入的是rgb三通道图片",{"2":{"659":1}}],["假设输入点云包含n个点",{"2":{"412":1}}],["假设占据网格的体素分辨率为",{"2":{"638":1}}],["假设点生成",{"0":{"524":1}}],["假设",{"2":{"435":1}}],["假设智能体在导航全程都能精确知道自己的位置和朝向",{"2":{"435":1}}],["假设深度为",{"2":{"411":1}}],["假设有",{"2":{"405":1}}],["假设我们处于一个全新的环境中",{"2":{"728":1}}],["假设我们在时间t",{"2":{"336":1}}],["假设我们通过某种方法",{"2":{"225":1}}],["假设所有形状都表示为流形网格",{"2":{"325":1}}],["假设所有原语的整个场景已经生成",{"2":{"271":1}}],["假设batch",{"2":{"124":1,"257":1}}],["假定我们有一个数据集",{"2":{"193":1}}],["优先队列",{"2":{"946":1}}],["优势超过了所有方法",{"2":{"903":1}}],["优于现有的仅使用单一",{"2":{"827":1}}],["优于3d体素级表示方法",{"2":{"811":1}}],["优化目标",{"2":{"773":1}}],["优化器",{"2":{"761":1,"822":1}}],["优化器进行优化",{"2":{"744":1,"867":1}}],["优化器进行训练",{"2":{"677":1,"853":1}}],["优化了类内和类间的场景级指标",{"2":{"632":1}}],["优化了全局语义",{"2":{"632":1}}],["优化了一个由surfels组成的地图",{"2":{"190":1}}],["优化",{"2":{"489":1}}],["优化后",{"2":{"390":1}}],["优化被表述为gtsam中的因子图",{"2":{"390":1}}],["优化完成后",{"2":{"380":1}}],["优化流程",{"2":{"209":1}}],["优点",{"2":{"20":1,"264":1}}],["面临准确性与带宽之间的矛盾",{"2":{"969":1}}],["面临两大瓶颈",{"2":{"846":1}}],["面级别精度高",{"2":{"864":1}}],["面对导航",{"2":{"806":1}}],["面向",{"2":{"360":1}}],["面向自动驾驶的视觉",{"2":{"92":2}}],["面向自动驾驶的vla",{"2":{"82":1}}],["面的顶点按逆时针顺序排序",{"2":{"325":1}}],["面",{"2":{"189":1,"351":1}}],["得益于",{"2":{"962":1}}],["得益于有效利用多模态输入",{"2":{"779":1}}],["得益于廉价相机的普及与计算机视觉的进步而广泛应用",{"2":{"189":1}}],["得到更新后的目标查询",{"2":{"623":1}}],["得到更加精细的深度图",{"2":{"618":1}}],["得到最终3d体素表示",{"2":{"585":1}}],["得到最终的柱坐标体素表示",{"2":{"676":1}}],["得到最终的",{"2":{"621":1}}],["得到最终的融合3d表示",{"2":{"527":1}}],["得到最终的分割结果",{"2":{"54":1}}],["得到伪三维点云",{"2":{"578":1}}],["得到对应的特征图是18×30",{"2":{"554":1}}],["得到对应的token",{"2":{"373":1}}],["得到潜在表示",{"2":{"549":1}}],["得到两个分别代表不同模态的3d特征体",{"2":{"527":1}}],["得到稀疏图",{"2":{"525":1}}],["得到当前层的输出",{"2":{"511":1}}],["得到干净地图",{"2":{"495":1}}],["得到修订边框后的proposal",{"2":{"493":1}}],["得到优化的深度图",{"2":{"470":1}}],["得到相机邻域的局部地图",{"2":{"495":1}}],["得到相机坐标系下的",{"2":{"435":1}}],["得到相同维度的特征",{"2":{"184":1}}],["得到4个特征",{"2":{"424":1}}],["得到一个较小的节点子集",{"2":{"380":1}}],["得到一个纯的高斯噪声",{"2":{"279":1}}],["得到照片2上的对应二维像素点p",{"2":{"355":1}}],["得到照片1上的对应二维像素点p",{"2":{"355":1}}],["得到这个anchor的attn",{"2":{"328":1}}],["得到我们最后的",{"2":{"279":1}}],["得到了",{"2":{"225":1}}],["得到物体的类别",{"2":{"169":1}}],["得到的二维语义标签结合起来获得的",{"2":{"870":1}}],["得到的特征图分辨率分别是输入图像分辨率的",{"2":{"768":1}}],["得到的对角尺度矩阵",{"2":{"656":1}}],["得到的双掩码m",{"2":{"518":1}}],["得到的中间隐藏码",{"2":{"221":1}}],["得到的结果都不准确",{"2":{"149":1}}],["得到的隐藏特征",{"2":{"149":1}}],["得到t时刻的随机噪声预测值",{"2":{"124":1,"257":1}}],["得到",{"2":{"111":1,"149":1,"236":1,"429":1,"595":1}}],["技术实现",{"2":{"942":1}}],["技术",{"0":{"189":1},"2":{"308":1,"362":1,"860":1,"950":1}}],["技巧",{"2":{"63":1}}],["轨迹rmse在循环闭合应用之前为15厘米",{"2":{"754":1}}],["轨迹大约20米长",{"2":{"605":1}}],["轨迹输出",{"2":{"334":1}}],["轨迹规划",{"2":{"216":1}}],["轨迹",{"2":{"188":1,"334":1,"360":1}}],["固定滞后平滑",{"2":{"686":1}}],["固定滞后平滑和带有循环闭合的pgo",{"2":{"686":1}}],["固定",{"2":{"188":2}}],["硬件感知量化及事件触发推理",{"2":{"478":1}}],["硬核解读stable",{"2":{"185":1}}],["硬盘名字",{"2":{"24":1}}],["才合理",{"2":{"184":1}}],["列概述了用于训练占用网络的监督学习类型",{"2":{"1000":1}}],["列简要概述了各种占用感知方法的网络训练情况",{"2":{"981":1}}],["列出了occ3d",{"2":{"791":1}}],["列出所有的",{"2":{"68":1}}],["列显示",{"2":{"709":1}}],["列",{"2":{"462":1,"709":2}}],["列中",{"2":{"770":1}}],["列中匹配图文的内积尽可能大",{"2":{"184":1}}],["列中其他图文对的相似度",{"2":{"184":1}}],["配备了丰富的",{"2":{"749":1}}],["配备",{"2":{"744":1,"867":1}}],["配准决定新观测落在哪些栅格单元",{"2":{"495":1}}],["配准",{"2":{"495":1}}],["配件",{"2":{"181":1}}],["配置",{"0":{"78":1}}],["脸型",{"2":{"181":1}}],["肤色随b",{"2":{"181":1}}],["姿态和位置",{"2":{"992":1}}],["姿态和地面真实深度图的kimera",{"2":{"732":1}}],["姿态估计",{"0":{"634":1},"1":{"662":1}}],["姿态估计和",{"2":{"285":1}}],["姿态顶点根据姿态图的原始连通性相互连接",{"2":{"390":1}}],["姿态",{"2":{"310":1}}],["姿态等都发生改变",{"2":{"181":1}}],["姿态图系统的优点是双重的",{"2":{"419":1}}],["姿态图",{"2":{"178":1,"419":1}}],["姿态图和网格优化",{"2":{"131":1,"390":1}}],["称为",{"2":{"181":1,"811":1}}],["称为聚合",{"2":{"121":1}}],["主席研究资助和",{"2":{"958":1}}],["主干图像特征下采样步长为16",{"2":{"764":1}}],["主干学习率小10倍",{"2":{"764":1}}],["主干网络的特征图从阶段",{"2":{"867":1}}],["主干网络输出最高分辨率的全局和局部特征",{"2":{"789":1}}],["主干网络中",{"2":{"789":1,"809":1}}],["主干网络中提取的图像特征监督像素对齐的占用分布",{"2":{"704":1}}],["主干网络从阶段",{"2":{"744":1}}],["主干网络",{"2":{"545":1,"744":1,"746":3,"768":1,"789":1,"865":1,"867":2}}],["主干网络以提取多尺度特征",{"2":{"545":1,"746":1}}],["主干",{"2":{"334":1}}],["主动",{"2":{"189":1}}],["主观质量越好",{"2":{"180":1}}],["主要原因有三点",{"2":{"942":1}}],["主要通过轻量级的2d",{"2":{"908":1}}],["主要区别为不同主干",{"2":{"825":1}}],["主要区别在于步骤3",{"2":{"735":1}}],["主要结果来自隐藏的测试集",{"2":{"853":1}}],["主要结果",{"0":{"792":1}}],["主要趋势集中在以视觉为中心的占用感知",{"2":{"759":1}}],["主要就是数组和链表的底层实现",{"2":{"685":1}}],["主要是由于数据集的稀缺",{"2":{"1005":1}}],["主要是因为",{"2":{"803":1}}],["主要是因为中间层仍然可以保持语义多样性",{"2":{"559":1}}],["主要是为人眼服务",{"2":{"220":1}}],["主要关注学习有效的鸟瞰图特征表示",{"2":{"512":1}}],["主要关注对象及其关系",{"2":{"125":1}}],["主要集中于基于视觉的方法",{"2":{"503":1}}],["主要集中在获取更有效的融合特征上",{"2":{"421":1}}],["主要贡献",{"0":{"356":1}}],["主要训练的是反向的去噪过程",{"2":{"304":1}}],["主要由交通密度低",{"2":{"302":1}}],["主要由前端和后端两大模块组成",{"2":{"189":1}}],["主要研究了2d中的分层表示",{"2":{"116":1}}],["主要依赖栅格化表示",{"2":{"114":1}}],["主要促进模块间特征级信息流",{"2":{"114":1}}],["主要参考",{"2":{"99":1}}],["主要用于三维重建",{"2":{"31":1}}],["取决于场景的规模",{"2":{"816":3}}],["取决于边的类型",{"2":{"390":1}}],["取得了显著的整体性能",{"2":{"996":1}}],["取得了类似的检测结果",{"2":{"847":1}}],["取得了53",{"2":{"779":1}}],["取得了sota",{"2":{"454":1}}],["取并集",{"2":{"765":1}}],["取最大",{"2":{"495":1}}],["取最新",{"2":{"495":1,"765":1}}],["取聚类中心",{"2":{"495":1}}],["取平衡",{"2":{"489":1}}],["取平均",{"2":{"180":1,"765":1}}],["取正反两个方向相加",{"2":{"328":1}}],["取代r",{"2":{"272":1}}],["取单前视相机图像",{"2":{"260":1}}],["取消安装",{"2":{"66":1}}],["附加结果",{"0":{"986":1},"1":{"989":1,"992":1,"995":1}}],["附加材料",{"0":{"840":1},"1":{"859":1,"876":1,"893":1,"909":1}}],["附录部分",{"0":{"895":1},"1":{"911":1,"924":1,"934":1}}],["附录",{"0":{"869":1,"966":1},"1":{"886":1,"902":1,"972":1,"978":1,"982":1,"986":1,"989":1,"992":1,"995":1},"2":{"903":1}}],["附录j中提供了更多支持clio区域聚类有意义性的可视化",{"2":{"522":1}}],["附近相似",{"2":{"234":1}}],["附实战代码",{"2":{"179":1}}],["附带一些新手错误",{"2":{"73":1}}],["形式展示了这些关系",{"2":{"707":1}}],["形式为预测动态物体的占用流",{"2":{"1003":1}}],["形式为点云",{"2":{"967":1}}],["形式为",{"2":{"693":1}}],["形式上",{"2":{"693":1}}],["形式计算的",{"2":{"582":2}}],["形式进行定义",{"2":{"582":1}}],["形式和",{"2":{"582":1}}],["形式化表示为",{"2":{"985":1}}],["形式化验证",{"2":{"507":1}}],["形式化安全分析",{"2":{"478":1}}],["形式化近期工作共享的架构基本模块",{"2":{"72":1}}],["形式",{"2":{"465":1}}],["形的空间填充曲线",{"2":{"426":1}}],["形成了一个完全稀疏的架构",{"2":{"922":1}}],["形成了有序的点块序列",{"2":{"340":1}}],["形成感知闭环",{"2":{"658":1}}],["形成稠密的语义地图",{"2":{"588":1}}],["形成最终的",{"2":{"564":1,"660":1}}],["形成一个唯一的",{"2":{"660":1}}],["形成一个有序序列",{"2":{"315":1}}],["形成一组三视图",{"2":{"438":1}}],["形成混合地图",{"2":{"378":1}}],["形成",{"2":{"355":1,"495":1}}],["形成机器人周围环境的体积模型",{"2":{"253":1}}],["形状或外观未定义的长尾物体",{"2":{"665":1}}],["形状不规则",{"2":{"630":1,"658":1}}],["形状估计",{"2":{"419":1}}],["形状分类的分类法",{"2":{"948":1}}],["形状分类结果比较",{"2":{"688":1}}],["形状分类",{"2":{"263":1}}],["形状",{"2":{"220":1}}],["形状的网格模型",{"2":{"178":1}}],["户外环境中的动物",{"2":{"178":1}}],["杯子在桌子上",{"2":{"178":1}}],["反映在iou中",{"2":{"1000":1}}],["反映在miou中",{"2":{"1000":1}}],["反映了更广趋势",{"2":{"176":1}}],["反投影到",{"2":{"978":1}}],["反卷积详解",{"2":{"496":1}}],["反卷积",{"2":{"496":1}}],["反池化",{"2":{"496":1}}],["反倒看上去有一定的反作用",{"2":{"313":1}}],["反之返回0",{"2":{"795":1}}],["反之亦然",{"2":{"686":1}}],["反之则随机选择",{"2":{"563":1}}],["反之",{"2":{"196":1}}],["反之客观质量越好",{"2":{"180":1}}],["反向投影使用每个像素的估计深度",{"2":{"950":1}}],["反向投影是投影的逆过程",{"2":{"950":1}}],["反向投影",{"2":{"942":1,"950":2}}],["反向投影或交叉注意力",{"2":{"942":1}}],["反向迭代器指针",{"2":{"918":2}}],["反向迭代器与正向迭代器声明时不同需要改为reverse",{"2":{"130":1}}],["反向迭代器",{"2":{"130":2}}],["反向传播修正机制",{"2":{"75":1}}],["查找输入哈希表找到对应的tensor向量",{"2":{"561":1}}],["查找2",{"2":{"509":1}}],["查找",{"2":{"509":1}}],["查找以",{"2":{"196":1}}],["查询等核心操作在仿真与真实机器人上都愈发昂贵",{"2":{"864":1}}],["查询的灵活地图",{"2":{"721":1}}],["查询形式显著提高了三个传感器之间的特征交互和聚合效率",{"2":{"678":1}}],["查询和匹配计算的相对姿态",{"2":{"437":1}}],["查询向量在训练前随机初始化",{"2":{"405":1}}],["查询解码器将",{"2":{"441":1}}],["查询解码器由实例分支和掩码分支组成",{"2":{"405":1}}],["查询解码器为分为两个分支",{"2":{"377":1}}],["查询",{"2":{"352":1}}],["查询与结构化描述",{"2":{"176":1}}],["查看所有的",{"2":{"99":1}}],["查看22端口是否处于监听状态",{"2":{"78":1}}],["查看ssh状态",{"2":{"78":1}}],["查看swap文件是否创建好了",{"2":{"26":1}}],["查看",{"2":{"47":1,"120":1}}],["查看安装版本",{"2":{"36":1}}],["查看当前系统是否设置了swap",{"2":{"26":1}}],["查看是否挂载成果",{"2":{"24":1}}],["查看自己的硬盘信息",{"2":{"24":1}}],["领域差距",{"2":{"995":1}}],["领域常用",{"2":{"826":1}}],["领域小几个数量级",{"2":{"643":1}}],["领域的成本效益和多功能性",{"2":{"564":1}}],["领域适应与评估",{"2":{"478":1}}],["领域",{"2":{"360":1}}],["领域不同",{"2":{"340":1}}],["领域亦日益关注本体感知数据",{"2":{"176":1}}],["领域大约于",{"2":{"139":1}}],["除此之外",{"2":{"886":1,"888":1}}],["除上述显式空间地图外",{"2":{"698":1}}],["除占用外",{"2":{"698":1}}],["除非另有说明",{"2":{"800":1,"811":1,"853":1}}],["除非进行消融实验",{"2":{"758":1}}],["除非特别说明",{"2":{"670":1}}],["除非节点",{"2":{"390":1}}],["除环视摄像头外",{"2":{"503":1}}],["除",{"2":{"495":1}}],["除视觉外",{"2":{"176":1}}],["除了这些损失外",{"2":{"985":1}}],["除了这些数据集",{"2":{"131":1}}],["除了以下几处不同",{"2":{"938":1}}],["除了以目标为中心且避免重叠的几何建模外",{"2":{"681":1}}],["除了整体结构外",{"2":{"924":1}}],["除了在规则欧几里得空间中进行体素化外",{"2":{"910":1}}],["除了第4",{"2":{"876":1}}],["除了将3d空间转换为投影视角",{"2":{"875":1}}],["除了bev特征外",{"2":{"858":1}}],["除了语义",{"2":{"842":1}}],["除了原始比例的occ",{"2":{"793":1}}],["除了任务层面的外在评估",{"2":{"786":1}}],["除了与局部预测相似的每个场景的初始更新外",{"2":{"728":1}}],["除了实现以目标为中心的特性外",{"2":{"681":1}}],["除了上述方法外",{"2":{"664":1}}],["除了stage1中先通过一个linear",{"2":{"659":1}}],["除了selective",{"2":{"272":1}}],["除了训练",{"2":{"552":1}}],["除了架构上的贡献",{"2":{"539":1}}],["除了模型结构设计的努力外",{"2":{"520":1}}],["除了靠近墙壁的地方",{"2":{"480":1}}],["除了运行conceptgraphs和clio",{"2":{"431":1}}],["除了骨盆位置外",{"2":{"419":1}}],["除了用于跟踪外",{"2":{"419":1}}],["除了采用l1重建损失外",{"2":{"345":1}}],["除了",{"2":{"277":1,"302":1,"534":1}}],["除了kimera中许多模块的新颖性",{"2":{"131":1}}],["多级监督机制",{"2":{"971":1}}],["多级监督",{"2":{"971":2}}],["多尺度粗到细细化结构",{"2":{"971":1}}],["多尺度粗到细的细化结构有助于将语义信息从深层传递到浅层",{"2":{"971":1}}],["多尺度结构",{"2":{"971":2}}],["多尺度机制对于提升最终模型的",{"2":{"971":1}}],["多尺度机制的消融研究",{"2":{"971":1}}],["多摄像头交叉注意力过程可以表示为",{"2":{"957":1}}],["多摄像头交叉注意力被用于自适应地融合来自多个视角的信息",{"2":{"957":1}}],["多摄像头观测的融合可以创建一个具有扩展视野的3d特征体积",{"2":{"957":1}}],["多摄像头感知覆盖了更广的视野",{"2":{"942":1}}],["多元高斯分布",{"2":{"916":1}}],["多相机信息融合",{"2":{"942":1}}],["多相机图像经过2d图像主干网络提取特征图",{"2":{"942":1}}],["多相机",{"2":{"877":1}}],["多相机设置",{"2":{"176":1}}],["多组",{"2":{"863":1}}],["多阶段占据蒸馏",{"0":{"694":1}}],["多阶段训练",{"2":{"417":1}}],["多帧",{"2":{"686":1,"877":1}}],["多帧网格将vio滞后范围内收集的每帧网格融合到单个网格中",{"2":{"336":1}}],["多帧网格",{"2":{"336":1}}],["多目标跟踪",{"2":{"1003":1}}],["多目标跟踪最常用的标准",{"2":{"263":1}}],["多目标检测任务上",{"2":{"678":1}}],["多目标检测的",{"2":{"678":1}}],["多传感器融合提高了最终模型对光照和天气条件的鲁棒性",{"2":{"944":1}}],["多传感器融合显著提升了三维语义占据预测的精度与鲁棒性",{"2":{"392":1}}],["多传感器",{"2":{"538":1}}],["多传感器模型",{"2":{"507":1}}],["多语言查询",{"2":{"447":1}}],["多智能体协同3d占用预测方法利用协同感知和学习的力量进行3d占用预测",{"2":{"969":1}}],["多智能体协同感知方法开辟了一个新的维度",{"2":{"969":1}}],["多智能体社会复杂性",{"2":{"478":1}}],["多智能体设置如langcoop",{"2":{"417":1}}],["多智能体场景下",{"2":{"283":1}}],["多数vla4ad模型通过四阶段课程训练",{"2":{"417":1}}],["多数多传感器融合方法主要关注改进融合特征",{"2":{"392":1}}],["多数工作采用预训练→微调流水线",{"2":{"388":1}}],["多数空间地图仅用",{"2":{"378":1}}],["多数先前工作采用启发式",{"2":{"274":1}}],["多轮问答",{"2":{"360":1}}],["多源信息融合和有效的网络训练",{"2":{"714":1}}],["多源",{"2":{"360":1}}],["多个元素赋值",{"2":{"904":1}}],["多个房间",{"2":{"605":1}}],["多个图像特征可能落在同一栅格",{"2":{"495":1}}],["多个3维的凑成一个4维的张量",{"2":{"351":1}}],["多个环境网格",{"2":{"285":1}}],["多视图网络来结合",{"2":{"968":1}}],["多视图分割方法的性能对视点选择和遮挡敏感",{"2":{"955":1}}],["多视图特征融合",{"2":{"443":1}}],["多视图表示",{"0":{"337":1},"2":{"955":1}}],["多视角图像和bev布局相比",{"2":{"963":1}}],["多视角3d目标检测问题",{"0":{"443":1}}],["多视角2d图像特征输入到一个1×1卷积层中以降低维度",{"2":{"427":1}}],["多视角的3d数据",{"2":{"394":1}}],["多视角",{"2":{"334":9}}],["多基准强化微调",{"2":{"334":1}}],["多任务学习是三维目标检测的一个发展方向",{"2":{"931":1}}],["多任务通用",{"2":{"881":1}}],["多任务感知模型的性能提升受到限制",{"2":{"601":1}}],["多任务感知模型需要同时处理多个任务",{"2":{"601":1}}],["多任务感知",{"0":{"601":1}}],["多任务输出",{"2":{"334":1}}],["多任务",{"2":{"334":1}}],["多种度量",{"2":{"285":1}}],["多头之间的差异远小于不同map之间kl散度的阈值",{"2":{"278":1}}],["多步推理的演进",{"2":{"176":1}}],["多模态模型",{"2":{"1005":1}}],["多模态传感器的3d占用数据集概览",{"2":{"997":1}}],["多模态占用感知仍有很大的改进空间",{"2":{"1000":1}}],["多模态占用感知中的信息融合",{"0":{"976":1}}],["多模态占用感知架构",{"2":{"970":1}}],["多模态占用感知可以结合多种模态的优势",{"2":{"970":1}}],["多模态占用感知",{"0":{"964":1},"1":{"970":1,"976":1}}],["多模态占据方法通常优于单模态方法",{"2":{"474":1}}],["多模态",{"2":{"864":1,"958":1,"1005":1}}],["多模态基础模型",{"2":{"864":1}}],["多模态数据",{"2":{"610":1}}],["多模态对齐",{"2":{"478":1}}],["多模态语义占据预测",{"2":{"474":1}}],["多模态融合方法在雨天和夜间场景下的性能进行了比较",{"2":{"827":1}}],["多模态融合的研究将通过结合不同模态数据的优势来促进鲁棒的占用感知",{"2":{"691":1}}],["多模态融合",{"2":{"423":1,"864":1}}],["多模态融合和查询的核心设计选择",{"2":{"90":1}}],["多模态流程",{"2":{"415":1}}],["多模态输入与语言指令",{"0":{"176":1}}],["多模态大语言模型",{"2":{"72":1}}],["随时间演化而非一次性构建",{"2":{"864":1}}],["随时间变化的语义准确率",{"2":{"826":1}}],["随时间推移",{"2":{"176":1}}],["随意设置点云的xy范围或体素分辨率可能会导致bev特征与占据真值之间出现对齐错误",{"2":{"638":1}}],["随机选择",{"2":{"789":1}}],["随机超分辨率",{"2":{"552":1}}],["随机变量",{"2":{"188":1}}],["随后应用这些权重对激光雷达分支表示和摄像头分支特征进行求和",{"2":{"976":1}}],["随后应用于各种驾驶任务",{"2":{"759":1}}],["随后使用交叉注意力细化特征体积",{"2":{"950":1}}],["随后使用特征金字塔网络",{"2":{"699":1}}],["随后进行2d到3d的转换",{"2":{"942":1}}],["随后进行bev池化",{"2":{"821":1}}],["随后将它们送入",{"2":{"704":1}}],["随后将这些语义信息存入结构化的语义地图中",{"2":{"350":1}}],["随后的研究进一步关注解决单目设置中的深度模糊问题",{"2":{"629":1}}],["随后的工作转向稀疏以目标为中心的表示",{"2":{"599":1}}],["随后输入到颈部模块进行融合",{"2":{"627":1}}],["随后通过简单的squeeze",{"2":{"976":1}}],["随后通过编码器",{"2":{"910":1}}],["随后通过可微映射模块投影到地图",{"2":{"743":1}}],["随后通过体素池化创建最终的",{"2":{"564":1}}],["随后通过占据头进行预测",{"2":{"474":1}}],["随后",{"2":{"436":1,"527":1,"544":1,"576":1,"578":1,"588":1,"621":4,"655":1,"664":1,"676":1,"691":1,"746":3,"757":1,"759":1,"765":1,"768":1,"789":1,"809":1,"829":1,"850":1,"853":1,"860":1,"875":2,"898":1,"991":1}}],["随后利用通道到高度",{"2":{"421":1}}],["随后在仿真中或用基于规则约束细化",{"2":{"388":1}}],["随系统成熟",{"2":{"176":1}}],["随着相机设置与训练集的偏离",{"2":{"995":1}}],["随着相机水平视场角",{"2":{"945":1}}],["随着领域迈向灵活",{"2":{"951":1}}],["随着感知范围的增加",{"2":{"944":1}}],["随着感知范围的扩大",{"2":{"944":1}}],["随着",{"2":{"928":1,"944":1}}],["随着分组数量",{"2":{"882":1}}],["随着开放词汇",{"2":{"864":1}}],["随着地图扩张",{"2":{"864":1}}],["随着地图纳入更细粒度的语义信息",{"2":{"864":1}}],["随着语义建图系统被部署到越来越庞大",{"2":{"864":1}}],["随着大规模室外基准数据集semantickitti",{"2":{"841":1}}],["随着大规模视觉",{"2":{"274":1}}],["随着高斯数量的增加",{"2":{"700":1}}],["随着具身智能和主动智能体的快速发展",{"2":{"600":1}}],["随着实时视觉",{"2":{"588":1}}],["随着探索的进行",{"2":{"568":1}}],["随着技术进步",{"2":{"503":1}}],["随着智能体移动逐步填充",{"2":{"495":1}}],["随着网格的增长",{"2":{"390":1}}],["随着vla研究进展",{"2":{"283":1}}],["随着压缩倍数的增加",{"2":{"264":1}}],["随着时间的推移",{"2":{"254":1,"654":1}}],["随着机器人系统日益复杂",{"2":{"209":1}}],["随着机器人探索环境",{"2":{"153":1}}],["随着机器人的操作",{"2":{"109":1}}],["随着传感器性能逐年提升",{"2":{"123":1}}],["随着深度学习和传感器技术的发展",{"2":{"665":1}}],["随着深度学习发展",{"2":{"209":1}}],["随着深度学习",{"2":{"90":1}}],["带时间融合的方法",{"2":{"942":1}}],["带来了大约",{"2":{"936":1}}],["带来协议",{"2":{"478":1}}],["带有语义标签的点云可以指导占用预测",{"2":{"988":1}}],["带有和不带有语义的体素级表示示意图",{"2":{"841":1}}],["带有回路闭合的姿态图和网格优化",{"0":{"390":1}}],["带有is",{"2":{"254":1,"534":1}}],["带动作级标签",{"2":{"360":1}}],["带宽和存储需求",{"2":{"211":1}}],["带",{"2":{"173":1}}],["带入",{"2":{"140":1,"280":1,"513":1}}],["毫秒",{"2":{"349":1}}],["毫秒以内",{"2":{"173":1}}],["毫米波",{"2":{"478":1}}],["毫米波雷达和gps数据",{"2":{"103":1}}],["毫米",{"2":{"173":1}}],["曝光时间限制在最大",{"2":{"173":1}}],["字幕生成",{"2":{"360":1}}],["字节",{"2":{"173":1}}],["字符串类型转换函数",{"0":{"63":1}}],["厘米",{"2":{"173":1}}],["±",{"2":{"437":3,"522":27}}],["±0",{"2":{"173":1}}],["±2",{"2":{"173":1}}],["±10",{"2":{"173":1}}],["范围图像的语义标签首先转移到",{"2":{"955":1}}],["范围内",{"2":{"863":1}}],["范围内的占据标注",{"2":{"742":1}}],["范围从",{"2":{"724":1}}],["范围从0到17",{"2":{"590":1}}],["范围",{"2":{"173":1}}],["范式铺平了道路",{"2":{"72":1}}],["垂直视场角",{"2":{"173":1}}],["束光",{"2":{"173":1}}],["采集图像的过程中会面临各种降质问题",{"2":{"220":1}}],["采集频率",{"2":{"173":3}}],["采样特征分别乘以通道混合矩阵",{"2":{"957":1}}],["采样偏移",{"2":{"844":2}}],["采样的深度值",{"2":{"705":1}}],["采样点的数量",{"2":{"623":1}}],["采样层",{"2":{"420":1}}],["采样",{"2":{"188":1,"208":1,"328":1,"334":1,"574":1}}],["采样步数越多",{"2":{"180":1}}],["采用粗略投影来实现鲁棒的bev表示",{"2":{"1005":1}}],["采用kl散度损失",{"2":{"985":1}}],["采用k最近邻搜索来选择邻近的摄像头特征",{"2":{"482":1}}],["采用三个不同级别的对齐来蒸馏3d占用模型",{"2":{"975":1}}],["采用三种额外的损失函数",{"2":{"803":1}}],["采用多级监督方法使得更深层能够捕获更一般的语义信息",{"2":{"971":1}}],["采用多任务学习",{"2":{"603":1}}],["采用从粗到细的策略来分层提高预测结果的分辨率",{"2":{"962":1}}],["采用的是从小到大的排序",{"2":{"929":1}}],["采用较重骨干网络和处理较大图像的模型可以实现更好的准确性",{"2":{"922":1}}],["采用级联占用网络",{"2":{"922":1}}],["采用两步法学习3d空间中的占用表示",{"2":{"922":1}}],["采用共享的2d编码器",{"2":{"898":1}}],["采用泊松重建",{"2":{"850":1}}],["采用像素级语义分割指标",{"2":{"826":1}}],["采用通道分组匹配机制导致相对较少的内存开销",{"2":{"811":1}}],["采用类似思路构建拓扑地图",{"2":{"765":1}}],["采用常用数据增强策略",{"2":{"764":1}}],["采用先入先出",{"2":{"718":1}}],["采用激光雷达",{"2":{"652":1}}],["采用l1损失",{"2":{"647":1}}],["采用一种改进的置换不变自组织映射",{"2":{"636":1}}],["采用自适应融合模块动态整合摄像头和激光雷达分支的占用表示",{"2":{"976":1}}],["采用自适应混合",{"2":{"957":1}}],["采用自适应的矩阵乘法分组",{"2":{"593":1}}],["采用自下而上的方法",{"2":{"636":1}}],["采用内核融合",{"2":{"593":1}}],["采用量化",{"2":{"593":1}}],["采用bevdepth",{"2":{"585":1}}],["采用max",{"2":{"574":1}}],["采用鸟瞰图",{"2":{"497":1}}],["采用此策略",{"2":{"495":1}}],["采用体素查询和从粗到细的方法来学习统一的占据表示",{"2":{"482":1}}],["采用方差的方法",{"2":{"411":1}}],["采用俯视的离散网格",{"2":{"378":1}}],["采用比较小的权重",{"2":{"345":1}}],["采用了可变形交叉注意力",{"2":{"950":1}}],["采用了显式深度监督",{"2":{"779":1}}],["采用了嵌入",{"2":{"456":1}}],["采用了两种正则化方法",{"2":{"345":1}}],["采用了由粗糙到精细的深度图生成策略",{"2":{"322":1}}],["采用基于提取器",{"2":{"315":1}}],["采用基于随机游走的对象描述符",{"2":{"190":1}}],["采用专家混合架构",{"2":{"283":1}}],["采用",{"2":{"173":1,"744":1,"867":1,"998":1}}],["采用全矢量化场景表示进行端到端规划",{"2":{"114":1}}],["产品中所使用的配置",{"2":{"173":1}}],["产生很大的不利影响",{"2":{"778":1}}],["产生的检测误差",{"2":{"775":1}}],["产生了一项重要的自监督学习任务",{"2":{"715":1}}],["产生了更多的判别特征",{"2":{"664":1}}],["产生两个新的特征向量",{"2":{"466":1}}],["产生文本描述或高层操作标签",{"2":{"260":1}}],["产生驾驶决策",{"2":{"216":1}}],["产生嵌入",{"2":{"153":1}}],["产生思维链",{"2":{"145":1}}],["近处点云密集",{"2":{"858":1}}],["近似无噪音输入",{"2":{"278":1}}],["近年来对实时度量",{"2":{"967":1}}],["近年来受到越来越多的关注",{"2":{"570":1,"688":1}}],["近年来",{"2":{"172":1,"455":1,"556":1,"564":1,"588":2,"596":1,"612":1,"637":1,"665":1,"841":1,"957":1}}],["近期构建的开放词汇",{"2":{"806":1}}],["近期的大语言模型",{"2":{"765":1}}],["近期的研究重点转向了传感器融合技术",{"2":{"625":1}}],["近期进展",{"2":{"619":1}}],["近期研究",{"2":{"619":1}}],["近期研究显示",{"2":{"252":1}}],["近期成为传统点云的强有力替代",{"2":{"588":1}}],["近期混合体添加规则层",{"2":{"507":1}}],["近期语义",{"2":{"209":1}}],["近期示例系统突出vla能力广度",{"2":{"145":1}}],["近期工作进一步探索输入分辨率与模型效率间权衡",{"2":{"176":1}}],["近期工作",{"2":{"128":1}}],["近期工作提出更集成的范式",{"2":{"82":1}}],["近期趋势包括不确定性感知规划",{"2":{"123":1}}],["²侯默ai",{"2":{"477":1}}],["²智能绿色车辆与运载国家重点实验室",{"2":{"395":1}}],["²",{"2":{"171":2,"395":9}}],["ẑ",{"2":{"171":2}}],["∈d",{"2":{"712":2}}],["∈",{"2":{"193":1,"278":2,"390":1,"429":2,"579":1,"844":2,"863":4,"947":4}}],["∈rc×c",{"2":{"957":2}}],["∈r是一个以θ",{"2":{"193":1}}],["∈rf",{"2":{"193":1}}],["∈rm+1",{"2":{"153":2}}],["∈ε",{"2":{"171":2}}],["ωc​",{"2":{"985":1}}],["ωc",{"2":{"985":1}}],["ωi=linear",{"2":{"976":1}}],["ωi​=linear",{"2":{"976":1}}],["ωi​",{"2":{"976":2}}],["ωi",{"2":{"976":2}}],["ωij",{"2":{"390":1}}],["ωgij",{"2":{"390":1}}],["ωzij",{"2":{"390":1}}],["ωt​",{"2":{"780":1}}],["ωt​=",{"2":{"780":1}}],["ωt−k​",{"2":{"780":1}}],["ωt−k",{"2":{"780":1}}],["ωt",{"2":{"390":1,"780":1}}],["ωri3",{"2":{"390":1}}],["ω",{"2":{"171":2,"390":3,"976":1}}],["ωₜ",{"2":{"171":3}}],["ωyω​",{"2":{"57":2}}],["ᵀ",{"2":{"171":3}}],["ₘ",{"2":{"171":1}}],["误差和环境变化保持低不确定性与高置信度",{"2":{"826":1}}],["误差增加高达24",{"2":{"686":1}}],["误差",{"2":{"171":1}}],["联合解决场景理解和重建的问题",{"2":{"967":1}}],["联合损失",{"2":{"877":1}}],["联合损失通常权衡轨迹项与描述或qa项",{"2":{"417":1}}],["联合数据增强策略和渐进损失权重调整策略以增强多任务框架训练的效率和稳定性",{"2":{"875":1}}],["联合熵",{"2":{"826":1}}],["联合",{"2":{"765":1}}],["联合体素",{"2":{"490":1}}],["联合举办的3d占据预测挑战赛中的获胜解决方案",{"2":{"490":1}}],["联合执行目标检测与运动规划",{"2":{"308":1}}],["联合训练",{"2":{"220":1}}],["联合训练图像编码器和文本编码器来预测一批",{"2":{"184":1}}],["联合估计机器人的轨迹和环境地图",{"2":{"171":1}}],["联合推理视觉",{"2":{"145":1}}],["激励示例",{"0":{"905":1}}],["激励模块通过将合并后的特征与挤压特征相乘来执行激励操作",{"2":{"829":1}}],["激光强度和颜色",{"2":{"574":1}}],["激光",{"2":{"189":1}}],["激光雷达以及相机",{"2":{"977":1}}],["激光雷达信息进一步增强了我们框架对",{"2":{"952":1}}],["激光雷达数据始终保持高质量",{"2":{"936":1}}],["激光雷达数据的稀疏性不同",{"2":{"853":1}}],["激光雷达姿态或地面真实深度的样本",{"2":{"828":1}}],["激光雷达收集",{"2":{"828":1}}],["激光雷达模型的",{"2":{"803":1}}],["激光雷达密集",{"0":{"789":1}}],["激光雷达坐标系",{"2":{"787":1}}],["激光雷达前视图",{"2":{"777":1}}],["激光雷达和",{"2":{"749":1}}],["激光雷达和雷达",{"2":{"736":2}}],["激光雷达和雷达的感知数据使车辆能够智能地感知其周围环境",{"2":{"691":1}}],["激光雷达和雷达数据对光照变化不敏感",{"2":{"691":1}}],["激光雷达和雷达数据",{"2":{"545":1,"965":1}}],["激光雷达和雷达信息集成到",{"2":{"503":1}}],["激光雷达和雷达信息作为输入",{"2":{"438":1}}],["激光雷达引导的",{"2":{"723":1}}],["激光雷达引导的3d可变形注意力",{"0":{"595":1}}],["激光雷达深度图在训练前生成并保存",{"2":{"677":1}}],["激光雷达分支上的",{"2":{"670":1}}],["激光雷达点和相应的图像像素在提升的",{"2":{"723":1}}],["激光雷达点云",{"2":{"652":1}}],["激光雷达点云和多视角图像通过融合网络生成基于融合的占据预测",{"2":{"642":1}}],["激光雷达点数",{"2":{"532":1}}],["激光雷达融合技术进行广泛研究",{"2":{"625":1}}],["激光雷达融合的环境感知",{"0":{"625":1}}],["激光雷达融合的3d语义占据预测",{"0":{"527":1}}],["激光雷达编码器",{"2":{"609":1}}],["激光雷达生成的密集",{"2":{"746":1}}],["激光雷达生成的3d点云",{"2":{"621":1}}],["激光雷达生成的3d点云在近距离区域是密集的",{"2":{"438":1}}],["激光雷达生成的",{"2":{"596":1}}],["激光雷达在捕捉物体的几何形状和",{"2":{"596":1}}],["激光雷达扫描使用",{"2":{"828":1}}],["激光雷达扫描",{"2":{"507":1}}],["激光雷达擅长捕捉物体的几何形状并精确测量深度",{"2":{"503":1}}],["激光雷达提供了更准确的深度信息",{"2":{"444":1}}],["激光雷达传感器已被广泛应用于自动驾驶中的感知任务",{"2":{"444":1}}],["激光雷达+毫米波及完整3d标签",{"2":{"360":1}}],["激光雷达等",{"2":{"252":1,"350":1}}],["激光雷达外参",{"2":{"191":1}}],["激光雷达",{"0":{"678":1},"2":{"171":1,"254":1,"277":1,"421":1,"435":1,"444":1,"455":1,"474":1,"478":1,"678":3,"877":1,"977":1,"997":1,"1000":1}}],["激活函数",{"2":{"549":1}}],["激活",{"2":{"26":1}}],["博客园",{"2":{"170":1,"207":1,"325":1,"382":1}}],["馒头and花卷",{"2":{"170":1,"382":1}}],["串联方式",{"2":{"169":1}}],["流来提取特征",{"2":{"968":1}}],["流和多个",{"2":{"968":1}}],["流形学习",{"2":{"325":2}}],["流形网络",{"2":{"325":1}}],["流程如下",{"2":{"525":1}}],["流程",{"0":{"169":1,"250":1}}],["流图和代价图",{"2":{"114":1}}],["成为关键挑战",{"2":{"864":1}}],["成为该任务的瓶颈",{"2":{"799":1}}],["成功预测了既逼真又整体的语义占用结果",{"2":{"911":1}}],["成功检测到了远处的摩托车",{"2":{"847":1}}],["成功与否的关键",{"2":{"826":1}}],["成功率与最短路径之比",{"2":{"806":1}}],["成功率",{"2":{"806":1}}],["成功率为71",{"2":{"522":1}}],["成功返回下一个pair的迭代器",{"2":{"633":1}}],["成功返回1",{"2":{"633":1}}],["成功地整合了所有环视相机的信息",{"2":{"564":1}}],["成功将产生通用",{"2":{"507":1}}],["成对一致测量集最大化",{"2":{"390":1}}],["成人",{"2":{"277":1,"534":1}}],["成员函数",{"2":{"217":1}}],["成员方法",{"2":{"196":1}}],["成果",{"0":{"167":1}}],["成连续的分布函数",{"2":{"149":1}}],["右下",{"2":{"947":1}}],["右上",{"2":{"947":1}}],["右侧的体素体积加入了语义丰富性",{"2":{"841":1}}],["右侧的深色体素",{"2":{"570":1}}],["右侧是我们的预测结果",{"2":{"833":1}}],["右图中蓝色部分表示包含了轿车主体的的信息的方格",{"2":{"554":1}}],["右图",{"2":{"352":1,"480":1,"686":1,"889":2,"947":2}}],["右",{"2":{"189":1}}],["右边是比较窄的椅子",{"2":{"165":1}}],["右键",{"2":{"24":1}}],["左下",{"2":{"947":1}}],["左上",{"2":{"947":1}}],["左上角缺失的部分代表头发越长",{"2":{"149":1}}],["左侧的体素体积描绘了整体占用分布",{"2":{"841":1}}],["左侧是输入图像",{"2":{"833":1}}],["左图",{"2":{"352":1,"480":1,"686":1,"889":2,"947":2}}],["左转",{"2":{"260":1,"283":1}}],["左",{"2":{"189":1,"408":1}}],["左边是比较宽的椅子",{"2":{"165":1}}],["侧视图",{"2":{"162":1}}],["侧重于对象或密集地图",{"2":{"967":1}}],["侧重于",{"2":{"116":1}}],["估计楼层平面图也得到了研究",{"2":{"967":1}}],["估计已知对象的3d姿态",{"2":{"967":1}}],["估计深度分布允许在深度不确定的情况下进行信息融合",{"2":{"950":1}}],["估计的深度被用作预测占用和选择相关查询的先验",{"2":{"875":1}}],["估计了两个realsense设备之间的变换",{"2":{"605":1}}],["估计问题",{"2":{"570":1}}],["估计",{"2":{"419":1}}],["估计对象的总数",{"2":{"402":1}}],["估计噪声就是估计score",{"2":{"398":1}}],["估计观察到的特征的3d位置",{"2":{"310":1}}],["估计器可以执行全平滑或固定滞后平滑",{"2":{"310":1}}],["估计给定cad模型的对象的3d姿态",{"2":{"162":1}}],["估计未知形状物体的质心和边界框",{"2":{"162":1}}],["抽象且计算复杂",{"2":{"826":1}}],["抽象为更高级别的空间概念",{"2":{"162":1}}],["抽取常识知识",{"2":{"274":1}}],["抽屉",{"2":{"162":1}}],["椅子",{"2":{"162":1,"178":1,"775":1,"793":1,"905":1}}],["部件分割",{"0":{"993":1}}],["部件级",{"2":{"940":1}}],["部分可观测环境中的鲁棒性",{"2":{"826":1}}],["部分工作还使用",{"2":{"806":1}}],["部分工作也构建了显式的拓扑地图",{"2":{"698":1}}],["部分工作表明",{"2":{"209":1}}],["部分",{"2":{"162":1,"449":2,"971":2}}],["部署效率",{"0":{"1004":1}}],["部署友好性和标签效率的统一框架",{"2":{"969":1}}],["部署友好性和标签效率三个方面对基于视觉的3d占用预测的进展进行了全面调查",{"2":{"637":1}}],["部署友好方法应牢记在确保最小性能下降的同时减少内存使用和延迟",{"2":{"969":1}}],["部署友好方法",{"0":{"892":1},"1":{"908":1,"922":1}}],["部署友好方法旨在通过设计简洁高效的网络架构",{"2":{"799":1}}],["部署友好方法和标签高效方法",{"2":{"665":1}}],["部署友好和标签高效",{"2":{"799":1}}],["部署文档",{"0":{"635":1}}],["部署自动驾驶车辆将每日遇新危险",{"2":{"507":1}}],["部署",{"0":{"7":1,"12":1},"1":{"11":1,"17":1,"19":1,"25":1,"27":1,"32":1,"34":1,"38":1,"43":1,"51":1}}],["描述整个点云",{"2":{"636":1}}],["描述查询在3d空间中的位置",{"2":{"623":1}}],["描述查询的特征",{"2":{"623":1}}],["描述符仅在新代理节点实例化时计算一次",{"2":{"352":1}}],["描述",{"2":{"188":1,"961":1}}],["描述扩散模型",{"0":{"188":1}}],["描述他们",{"2":{"178":1}}],["描述他们随时间的轨迹的3d姿态图",{"2":{"178":1}}],["描述网格中的面",{"2":{"162":1}}],["描述环境在多个抽象层次",{"2":{"105":1}}],["法线等",{"2":{"864":1}}],["法线估计和曲率预测",{"2":{"715":1}}],["法线",{"2":{"162":1}}],["网络训练",{"0":{"981":1},"1":{"985":1,"988":1}}],["网络训练和评估以及开源状态",{"2":{"877":1}}],["网络首先从图像中学习粗略表示",{"2":{"922":1}}],["网络设计和学习策略",{"2":{"1005":1}}],["网络设计",{"2":{"877":1}}],["网络设置",{"0":{"526":1}}],["网络的任务类型",{"2":{"877":1}}],["网络的输出头部设计",{"2":{"877":1}}],["网络的每一层对应一层八叉树",{"2":{"636":1}}],["网络细节",{"2":{"764":1}}],["网络通过从稀疏分布径向基函数",{"2":{"664":1}}],["网络自主发现哪些",{"2":{"660":1}}],["网络自行发现相关的",{"2":{"570":1}}],["网络提供了使用高级",{"2":{"660":1}}],["网络处理这种表示",{"2":{"660":1}}],["网络连接起来",{"2":{"570":1}}],["网络遵循多次mresconv+norm+meshpool的模式",{"2":{"526":1}}],["网络结构由mresconv层组成",{"2":{"526":1}}],["网络结构如下图所示",{"2":{"305":1}}],["网络对每个点块进行处理",{"2":{"456":1}}],["网络对其进行处理",{"2":{"456":1}}],["网络来进行几何信息的提取",{"2":{"456":1}}],["网络",{"2":{"440":1,"456":1,"539":1,"570":1,"632":1,"660":1,"937":1}}],["网络转换为3d位置嵌入",{"2":{"427":1}}],["网络摄入传感器流",{"2":{"417":1}}],["网络需要学习到几何变换下的不变性",{"2":{"339":1}}],["网络架构包含四个级别",{"2":{"867":1}}],["网络架构",{"0":{"198":1},"2":{"982":2}}],["网络无法及时响应用户点击",{"2":{"96":1}}],["网格虽介于两者之间",{"2":{"913":1}}],["网格仍然嘈杂和不完整",{"2":{"872":1}}],["网格的大小和简化网格的分辨率",{"2":{"816":1}}],["网格的顶点",{"2":{"162":1}}],["网格检查",{"2":{"775":1}}],["网格以得出",{"2":{"567":1}}],["网格上的测地距离",{"2":{"525":1}}],["网格池是通过边缘折叠过程完成的",{"2":{"436":1}}],["网格池化是广义池化的另一种特殊情况",{"2":{"466":1}}],["网格池化",{"2":{"275":1}}],["网格索引的正交投影矩阵",{"2":{"435":1}}],["网格模型的3d位置",{"2":{"419":1}}],["网格和地点层以及对象层",{"2":{"408":1}}],["网格和地点重建",{"2":{"408":1}}],["网格和对象",{"0":{"253":1}}],["网格顶点通过简化网格的边",{"2":{"390":1}}],["网格顶点对应于简化网格的顶点",{"2":{"390":1}}],["网格顶点和姿态顶点",{"2":{"390":1}}],["网格通过变形进行校正",{"2":{"390":1}}],["网格控制点和相应的边",{"2":{"380":1}}],["网格卷积保留了卷积的便利性质",{"2":{"275":1}}],["网格",{"0":{"232":1},"1":{"253":1,"276":1},"2":{"262":1,"378":2,"465":1,"495":1,"967":2}}],["网格或体素",{"2":{"190":1}}],["驾驶大脑",{"2":{"507":1}}],["驾驶骨干",{"2":{"507":1}}],["驾驶策略基本未探索",{"2":{"478":1}}],["驾驶输出",{"0":{"216":1}}],["驾驶路线经过精心选择",{"2":{"157":1}}],["驾驶系统可能无法生成合适轨迹",{"2":{"114":1}}],["旨在使用注意力机制从图像中查询特征到3d体积中",{"2":{"875":1}}],["旨在实现快速且内存高效的占用预测",{"2":{"908":1}}],["旨在实现快速且内存高效的占据预测",{"2":{"831":1}}],["旨在实现不同的全局",{"2":{"773":1}}],["旨在利用利于部署的图像骨干网络和实用的输入图像分辨率实现卓越性能",{"2":{"820":1}}],["旨在仅对物体占据的区域进行建模",{"2":{"808":1}}],["旨在从噪声和不确定的测量中生成栅格地图",{"2":{"759":1}}],["旨在从图像中提取视觉信息",{"2":{"716":1}}],["旨在从最小标签中学习高效且高性能的",{"2":{"455":1}}],["旨在整合历史信息以提高性能",{"2":{"598":1,"908":1}}],["旨在联合推断场景的几何和语义信息",{"2":{"570":1}}],["旨在将知识从大型复杂教师模型迁移到小型学生模型",{"2":{"548":1}}],["旨在将感知",{"2":{"283":1}}],["旨在以最小的网络复杂度和标注需求实现最先进的精度",{"2":{"425":1}}],["旨在提取掩模感知特征smasks",{"2":{"405":1}}],["旨在改进这些方面",{"2":{"302":1}}],["旨在支持低频功能",{"2":{"285":1}}],["旨在创建统一时空表示",{"2":{"176":1}}],["旨在寻找最优轨迹",{"2":{"171":1}}],["旨在捕捉具有挑战性的场景",{"2":{"157":1}}],["旨在构建全局一致",{"2":{"155":1}}],["旨在压缩给定信号",{"2":{"121":1}}],["源视图表示为",{"2":{"464":1}}],["源数据与目标数据之间的域差距",{"2":{"313":1}}],["源于机器人学的语义",{"2":{"155":1}}],["源文件的输入流名称",{"2":{"152":1}}],["文章中也称为object",{"2":{"333":1}}],["文中叫做anchor",{"2":{"321":1}}],["文生图模型往往参数量比较大",{"2":{"205":1}}],["文本标签或音频强度等可直接解释的量",{"2":{"698":1}}],["文本描述",{"2":{"667":1}}],["文本到图像和布局到图像模型",{"2":{"552":1}}],["文本落地是早期研究线索",{"2":{"478":1}}],["文本监督",{"2":{"439":1}}],["文本与控制联合梯度基本未探索",{"2":{"417":1}}],["文本对被视作最匹配",{"2":{"765":1}}],["文本对",{"2":{"360":1}}],["文本理由",{"2":{"334":1}}],["文本匹配之对比学习和simcse以及infonce",{"2":{"223":1}}],["文本相似度",{"2":{"223":1}}],["文本",{"2":{"184":1,"204":1,"334":1,"417":1,"877":1}}],["文本t1和图像i1是匹配的图文对",{"2":{"184":1}}],["文献主要依赖于交叉熵损失函数",{"2":{"570":1}}],["文献中仍少见",{"2":{"417":1}}],["文献集中于基于对象的地图",{"2":{"172":1}}],["文献",{"2":{"155":1,"481":1,"603":2,"664":1}}],["文件结构",{"2":{"476":1}}],["文件中用于提高效率的标签索引",{"2":{"254":1}}],["文件中删除有效",{"2":{"33":1}}],["文件夹中",{"2":{"38":1}}],["文件夹",{"2":{"32":1,"107":1}}],["文件",{"2":{"26":2,"33":1,"152":1}}],["尤其在自动驾驶与实时人机交互中",{"2":{"864":1}}],["尤其对边缘案例鲁棒性",{"2":{"417":1}}],["尤其是对于高分辨率输出",{"2":{"860":1}}],["尤其是在第",{"2":{"992":1}}],["尤其是在某些视角被遮挡或模糊的情况下",{"2":{"957":1}}],["尤其是在捕捉静态物体的几何形状和轮廓方面",{"2":{"952":1}}],["尤其是在分离语义相似的类别",{"2":{"945":1}}],["尤其是在与仅在图像级别",{"2":{"928":1}}],["尤其是在",{"2":{"928":1}}],["尤其是在远处物体的重建方面",{"2":{"843":1}}],["尤其是在未标注数据上",{"2":{"455":1}}],["尤其是自动驾驶场景",{"2":{"808":1}}],["尤其是",{"2":{"785":1}}],["尤其是大规模模型易过拟合",{"2":{"617":1}}],["尤其是点云数据",{"2":{"779":1}}],["尤其是点云",{"2":{"556":1}}],["尤其是由传感器特性引起的密度变化",{"2":{"527":1}}],["尤其是来自激光雷达和摄像头的数据",{"2":{"474":1}}],["尤其是激光雷达",{"2":{"415":1}}],["尤其是语义",{"2":{"155":1}}],["尤其引入",{"2":{"308":1}}],["尤其注意的是",{"2":{"296":1}}],["尤其用于行为预测与闭环控制",{"2":{"176":1}}],["尤其适用于自动驾驶",{"2":{"90":1}}],["ηi​",{"2":{"532":1}}],["ηi",{"2":{"532":1}}],["η",{"2":{"153":1}}],["η∑l=1k​γl​",{"2":{"153":1}}],["⊤",{"2":{"153":2,"316":2}}],["θmin​l",{"2":{"712":1}}],["θzθ​",{"2":{"213":1,"235":1}}],["θtrack​",{"2":{"206":1}}],["θtrackθ",{"2":{"206":1}}],["θ",{"2":{"153":7,"193":3,"213":2,"235":3,"354":1,"525":2,"728":1,"813":1}}],["ϕn",{"2":{"264":1,"266":1}}],["ϕ",{"2":{"153":3}}],["独立描述占用区域的有效高斯的比例可能极低",{"2":{"567":1}}],["独立地对每个点建模",{"2":{"420":1}}],["独立计算",{"2":{"153":1}}],["独立于不受新测量影响的连通分量进行计算",{"2":{"153":2}}],["那这时候代表同样一个语义的词",{"2":{"631":1}}],["那这个anchor就算前景",{"2":{"347":1}}],["那变换后该列该处的特征值应该是近似的",{"2":{"411":1}}],["那些未能通过基于外观的几何验证的假定匹配项",{"2":{"352":1}}],["那就处理这个函数的导数",{"2":{"235":1}}],["那就改写成下面这样",{"2":{"66":1}}],["那么deque的在内存中的数据分布是什么样的呢",{"2":{"938":1}}],["那么问题来了",{"2":{"685":1}}],["那么每个patch就有4x4=16个像素",{"2":{"659":1}}],["那么每个ddd都对应了一个单应变换矩阵hhh",{"2":{"355":1}}],["那么这个获得的方法就可以总结成rulebook",{"2":{"561":1}}],["那么这个anchor就算背景",{"2":{"347":1}}],["那么这次卷积操作只需要通过这个位置的卷积权重和输入值计算得到",{"2":{"561":1}}],["那么100个object",{"2":{"358":1}}],["那么很自然地",{"2":{"338":1}}],["那么我们是否可以直接省略这一步直接让前向过程不要加噪到纯噪声",{"2":{"287":1}}],["那么它不在乎图像是一张狗的照片",{"2":{"204":1}}],["那么只有与这些新出现的对象或场景部分相关的连通分量需要被考虑",{"2":{"153":1}}],["那么算法就不会对这些部分进行重新计算或聚类",{"2":{"153":1}}],["增益",{"2":{"803":2}}],["增强自监督的广义3d占用感知是一个重要的未来研究方向",{"2":{"1006":1}}],["增强的前视图像特征和增强的bev视觉特征通过交叉注意力融合",{"2":{"976":1}}],["增强的前视图像特征通过估计深度转换为bev视觉表示",{"2":{"976":1}}],["增强的上下文感知能力和新的损失函数",{"2":{"937":1}}],["增强了学生模型的鲁棒性",{"2":{"1005":1}}],["增强了模型基于输入环境观察理解整个场景并直接输出合适动态场景演变数据的能力",{"2":{"963":1}}],["增强了我们",{"2":{"886":1}}],["增强和净化",{"2":{"735":1}}],["增强空间语义感知能力",{"2":{"632":1}}],["增强模型语义感知能力",{"2":{"617":1}}],["增强",{"2":{"334":1,"761":1}}],["增强现实等",{"2":{"331":1}}],["增量更新一致测量集以实现在线操作",{"2":{"390":1}}],["增量地将gvd稀疏化为地点子图",{"2":{"276":1}}],["增量聚合ib",{"2":{"153":1}}],["增加模型规模通常是提升精度的便捷方法",{"2":{"617":1}}],["增加扰动",{"2":{"398":1}}],["增加可以准确估计score的区域",{"2":{"267":1,"398":1}}],["增加了对回路闭合的里程计一致性检查",{"2":{"390":1}}],["增加了",{"2":{"196":1}}],["增加了一个mask作为每次迭代的输入",{"2":{"84":1}}],["尽可能保留关于任务的有用信息",{"2":{"153":1}}],["尽管更准确的3d标签意味着更高的占用预测性能",{"2":{"1006":1}}],["尽管体素级iou和miou指标被广泛认可",{"2":{"998":1}}],["尽管一些方法",{"2":{"996":1}}],["尽管开放词汇3d占用预测任务和4d占用预测任务旨在从不同角度增强自动驾驶在开放动态环境中的感知能力",{"2":{"975":1}}],["尽管bev特征位于俯视的2d平面上",{"2":{"950":1}}],["尽管bev感知在3d目标检测中取得了巨大成功",{"2":{"612":1}}],["尽管数据是由真实生活",{"2":{"947":1}}],["尽管取得了良好的结果",{"2":{"937":1}}],["尽管取得进展",{"2":{"128":1}}],["尽管激光雷达在雨天场景中存在反射问题",{"2":{"936":1}}],["尽管雷达传感器提供的",{"2":{"936":1}}],["尽管flashocc",{"2":{"922":1}}],["尽管它不在视野范围内",{"2":{"903":1}}],["尽管它们能够实现相当的性能",{"2":{"444":1}}],["尽管相机的视野范围相对场景较窄",{"2":{"903":1}}],["尽管相关工作通过调整对象检测的阈值隐式选择了粒度级别",{"2":{"98":1}}],["尽管高斯是以固定分辨率的真实标注进行监督的",{"2":{"899":1}}],["尽管gaussianformer的内存消耗较低",{"2":{"878":1}}],["尽管由于intel",{"2":{"947":1}}],["尽管由于我们使用了相同的传感器",{"2":{"872":1}}],["尽管由于高斯分布的可变形性",{"2":{"656":1}}],["尽管3d网格嘈杂和不完整",{"2":{"872":1}}],["尽管3d场景图",{"2":{"125":1}}],["尽管3d场景图可以作为机器人的高级",{"2":{"112":1}}],["尽管intel",{"2":{"872":1}}],["尽管il易于扩展",{"2":{"417":1}}],["尽管贝叶斯滤波或概率表征可在机器人学中量化不确定",{"2":{"864":1}}],["尽管语义建图已取得显著进展",{"2":{"864":1}}],["尽管每个调制因子均在",{"2":{"863":1}}],["尽管原始的tpvformer",{"2":{"842":1}}],["尽管上述量在建图和规划中广泛应用",{"2":{"826":1}}],["尽管上一节描述了如何增量构建一个",{"2":{"326":1}}],["尽管大多数机器人与具身智能系统都依据下游任务的成功与否来判定好坏",{"2":{"826":1}}],["尽管大多数现有工作采用密集网格表示法",{"2":{"415":1}}],["尽管外部指标长期占据主导地位",{"2":{"806":1}}],["尽管近年来基于视觉的3d占用预测取得了显著进展",{"2":{"799":1}}],["尽管其中许多方法采用了多帧时间融合",{"2":{"779":1}}],["尽管公式",{"2":{"738":1}}],["尽管点云相对密集",{"2":{"735":1}}],["尽管许多机器人研究已经探索了结合空间和地标信息的混合地图",{"2":{"958":1}}],["尽管许多3d感知数据集",{"2":{"735":1}}],["尽管许多研究已经证明了3d占用预测相较于以物体为中心的感知任务的更大优势",{"2":{"637":1}}],["尽管许多研究人员会同意地图表示必须是任务依赖的",{"2":{"137":1}}],["尽管存在这些差异",{"2":{"686":1}}],["尽管存在漂移",{"2":{"437":1}}],["尽管计算复杂度有所降低",{"2":{"655":1}}],["尽管已经开发出各种算法以实现相机",{"2":{"653":1}}],["尽管已有大量文献",{"2":{"90":1}}],["尽管已有综述涵盖llm与vlm在自动驾驶中的应用",{"2":{"82":1}}],["尽管混合地图在机器人领域已有探索",{"2":{"648":1}}],["尽管pointgpt表现出了良好的性能",{"2":{"643":1}}],["尽管如此",{"2":{"629":1,"811":1,"827":2,"917":1,"930":1,"937":1}}],["尽管octreeocc",{"2":{"612":1}}],["尽管occfusion",{"2":{"482":1}}],["尽管人类的数量不同",{"2":{"605":1}}],["尽管人类能够自然地从单张图像中理解场景",{"2":{"570":1}}],["尽管有些方法使用了",{"2":{"603":1}}],["尽管早期的研究",{"2":{"603":1}}],["尽管目前没有基于bev级特征执行占据预测的方法",{"2":{"566":1}}],["尽管实验结果令人鼓舞",{"2":{"553":1}}],["尽管应用前景广阔",{"2":{"547":1,"567":1}}],["尽管这种设置对我们来说是不公平的",{"2":{"917":1}}],["尽管这为部分高斯分布的均值提供了直接提示",{"2":{"705":1}}],["尽管这些方法可以实现最符合实际应用期望的训练模式",{"2":{"949":1}}],["尽管这些方法准确",{"2":{"535":1}}],["尽管这些表征在传统意义上不一定被视作",{"2":{"556":1}}],["尽管这两种方法在基准数据集上均表现出色",{"2":{"527":1}}],["尽管clio使用相同的一组参数产生",{"2":{"522":1}}],["尽管co",{"2":{"421":1}}],["尽管基于bev的方法仅具有单一投影视角的特征表示",{"2":{"875":1}}],["尽管基于",{"2":{"808":1}}],["尽管基于平面的表示方法在资源利用上较为友好",{"2":{"693":1}}],["尽管基于激光雷达的方法在",{"2":{"599":1}}],["尽管基于摄像头的占据预测已经取得了有希望的结果",{"2":{"482":1}}],["尽管基于视觉的占据网络近年来取得了成功",{"2":{"455":1}}],["尽管进展迅速",{"2":{"478":1,"538":1}}],["尽管此处有任何版权声明",{"2":{"467":1}}],["尽管仍然在所有其他指标上提高了性能",{"2":{"462":1}}],["尽管仍然远低于批量处理",{"2":{"437":1}}],["尽管kimera",{"2":{"437":1}}],["尽管我们的层次方法的轨迹更长",{"2":{"947":1}}],["尽管我们的方法仅使用了",{"2":{"832":1}}],["尽管我们的双模态方法仅使用了摄像头和激光雷达",{"2":{"827":1}}],["尽管我们的局部空间占用预测模块在相机坐标系中初始化并更新高斯分布",{"2":{"728":1}}],["尽管我们的3d高斯表示也采用了3d高斯分布的物理形式",{"2":{"641":1}}],["尽管我们的flashocc专注于以通用和即插即用的方式增强现有模型",{"2":{"598":1}}],["尽管我们还在本节末尾报告了在嵌入式计算机",{"2":{"437":1}}],["尽管我们知道给定画面中的人数",{"2":{"419":1}}],["尽管我们在第",{"2":{"155":1}}],["尽管该方法已经取得了令人鼓舞的性能",{"2":{"363":1}}],["尽管掩码部分重新生成的结果与周围的材质和颜色接近",{"2":{"312":1}}],["尽管在空间推理方面很有前景",{"2":{"958":1}}],["尽管在表",{"2":{"928":1}}],["尽管在某些区域占据的真实标注是稀疏的并且存在缺失",{"2":{"899":1}}],["尽管在室外驾驶场景中基于视觉信息的三维空间占用预测已取得显著进展",{"2":{"600":1}}],["尽管在许多情况下很有用",{"2":{"302":1}}],["尽管在几何重建",{"2":{"116":1}}],["尽管学习式方法减少手工规则",{"2":{"274":1}}],["尽管",{"2":{"209":1,"536":1,"917":1,"945":1,"989":1}}],["综上",{"2":{"216":1,"698":1,"864":1,"926":1}}],["综上所述",{"2":{"153":2}}],["综述",{"0":{"70":1,"89":1,"577":1},"1":{"79":1,"89":1,"610":1,"639":1,"667":1,"691":1,"714":1,"737":1,"759":1,"780":1,"801":1,"821":1,"841":1,"860":1,"877":1,"894":1,"910":1,"923":1,"933":1,"942":1,"950":1,"957":1,"964":1,"970":1,"976":1,"981":1,"985":1,"988":1,"991":1,"994":1,"997":1,"998":1,"999":1,"1000":1,"1001":1,"1002":1,"1003":1,"1004":1,"1005":1,"1006":1,"1007":1,"1008":1}}],["扮演类似的角色",{"2":{"153":1}}],["调制因子的综合为1",{"2":{"863":1}}],["调制因子",{"2":{"863":1}}],["调整为depthwise",{"2":{"863":1}}],["调节",{"2":{"844":1}}],["调节能力",{"2":{"804":1}}],["调节压缩量",{"2":{"153":1}}],["调试工具",{"0":{"510":1}}],["调用应该使用",{"2":{"177":1}}],["调用",{"2":{"177":1}}],["调音销等",{"2":{"109":1}}],["δpgk​是第g组中网格采样位置",{"2":{"863":1}}],["δpgk​",{"2":{"863":1}}],["δpgk",{"2":{"863":2}}],["δpk",{"2":{"844":2}}],["δg",{"2":{"833":1}}],["δg=",{"2":{"705":2}}],["δc+c",{"2":{"705":2}}],["δc",{"2":{"705":2}}],["δo+o",{"2":{"705":2}}],["δo",{"2":{"705":2}}],["δr⊗r",{"2":{"705":2}}],["δr",{"2":{"705":2}}],["δq=nc​1​c=1∑nc​​i",{"2":{"595":1}}],["δq=1nc∑c=1nc∑i",{"2":{"595":1}}],["δq",{"2":{"595":2}}],["δuij​",{"2":{"595":1}}],["δuij",{"2":{"595":1}}],["δm+m",{"2":{"705":2}}],["δm~ij​=",{"2":{"595":1}}],["δm~ij=",{"2":{"595":1}}],["δm",{"2":{"595":2,"705":2,"716":1}}],["δs+s",{"2":{"705":2}}],["δs",{"2":{"372":4,"705":2}}],["δvij​",{"2":{"595":1}}],["δvij",{"2":{"595":1}}],["δvi​",{"2":{"372":1}}],["δvi",{"2":{"372":2}}],["δdij​",{"2":{"595":1}}],["δdij",{"2":{"595":1}}],["δd个平面",{"2":{"355":1}}],["δdd=",{"2":{"355":2}}],["δ中检测到的连通分量",{"2":{"301":1}}],["δ中的连通分量数量",{"2":{"301":1}}],["δ可能错过了原始图gp中的一些节点",{"2":{"301":1}}],["δi",{"2":{"268":3}}],["δt=t1​=1−β",{"2":{"273":1}}],["δt=1txt+δt=1−β",{"2":{"273":1}}],["δtxt+β",{"2":{"273":1}}],["δt​xt​+β",{"2":{"273":1}}],["δt​22​",{"2":{"208":1}}],["δt​22​−δt∂t∂​logp",{"2":{"208":1}}],["δt​+2g2",{"2":{"208":1}}],["δt​",{"2":{"208":1}}],["δt​ε​",{"2":{"273":1}}],["δt​ε​​",{"2":{"208":1}}],["δt​ε≈",{"2":{"273":2}}],["δt​ε∼n",{"2":{"208":1}}],["δt​ε",{"2":{"208":1,"273":1}}],["δt∇xt​​logp",{"2":{"208":1}}],["δt∇xtlog⁡p",{"2":{"208":1}}],["δt1​​",{"2":{"208":2}}],["δt1​",{"2":{"208":1}}],["δt∥xt+δt​−xt​−f",{"2":{"208":1}}],["δt∥22​​−",{"2":{"208":1}}],["δt∥22",{"2":{"208":1}}],["δt∥22−δt∂∂tlog⁡p",{"2":{"208":1}}],["δt∥222g2",{"2":{"208":1}}],["δt∥",{"2":{"208":2}}],["δt2g2",{"2":{"208":2}}],["δt−2g2",{"2":{"208":2}}],["δt−",{"2":{"208":1}}],["δt",{"2":{"208":5,"268":3,"273":6}}],["δtε≈",{"2":{"273":2}}],["δtεx",{"2":{"273":1}}],["δtεp",{"2":{"208":1}}],["δtε",{"2":{"208":2,"273":1}}],["δt+g",{"2":{"208":6,"273":2}}],["δt→0",{"2":{"208":3}}],["δt→0x",{"2":{"208":1}}],["δˉ",{"2":{"153":6}}],["δ",{"2":{"153":13,"301":2,"970":1}}],["正被机器人与具身智能社区广泛采纳",{"2":{"619":1}}],["正则化损失",{"2":{"460":1}}],["正确预测且在边界框内的体素使用流进行变换",{"2":{"941":1}}],["正确",{"2":{"437":1}}],["正交投影则可写为",{"2":{"435":1}}],["正是因为我们不仅记录空间形状",{"2":{"350":1}}],["正比于map分辨率",{"2":{"303":1}}],["正式地",{"2":{"153":1}}],["正如拓扑图中节点的密度所示",{"2":{"796":1}}],["正如图15",{"2":{"686":1}}],["正如在下一节中看到的那样",{"2":{"464":1}}],["正如预期的那样",{"2":{"437":1}}],["正如我们提到的",{"2":{"437":1}}],["正如我们将在实验部分看到的",{"2":{"390":1}}],["正如第3",{"2":{"930":1}}],["正如第",{"2":{"274":1,"943":1}}],["正如",{"2":{"153":1,"853":1,"905":1,"917":1}}],["正文内容",{"2":{"57":1}}],["香农散度",{"2":{"153":1}}],["名义",{"2":{"437":1}}],["名为",{"2":{"444":1}}],["名为gaussianformer3d",{"2":{"415":1}}],["名为clio",{"2":{"98":1,"109":1}}],["名称",{"2":{"360":1}}],["名称修改",{"2":{"152":1}}],["费时费力",{"2":{"151":1}}],["出来之后",{"2":{"631":1}}],["出于这个原因",{"2":{"605":1}}],["出于计算负担考虑",{"2":{"585":1}}],["出于可视化目的",{"2":{"557":1}}],["出发点",{"0":{"151":1}}],["出现误检和漏检",{"2":{"630":1}}],["出现次数",{"2":{"540":1}}],["出现两个问题",{"2":{"260":1}}],["出现环境查询",{"2":{"176":1}}],["出现原因",{"0":{"64":1}}],["出现一个可以拖动的方块",{"2":{"40":1}}],["均从",{"2":{"782":1}}],["均为线性",{"2":{"716":1}}],["均方根误差",{"2":{"686":1}}],["均方误差",{"2":{"5":1,"823":1}}],["均通过传感器",{"2":{"350":1}}],["均值和协方差属性使得3d高斯表示能够根据物体尺度和区域复杂性自适应地分配计算和存储资源",{"2":{"693":1}}],["均值",{"2":{"208":2,"716":1}}],["均匀覆盖",{"2":{"864":1}}],["均匀随机采样一个点",{"2":{"274":1}}],["均匀方位角",{"2":{"173":1}}],["均匀分布或者高斯分布对特征变量头发长度和男子气概进行采样",{"2":{"149":1}}],["男子气概越强",{"2":{"149":1}}],["男子气概",{"2":{"149":1}}],["风格的主干",{"2":{"579":1}}],["风格的组合",{"2":{"181":1}}],["风格迁移",{"2":{"149":1}}],["风格变换方法",{"2":{"149":1}}],["否则为空",{"2":{"988":1}}],["否则为false",{"2":{"254":1}}],["否则报错",{"2":{"774":1}}],["否则新增节点",{"2":{"765":1}}],["否则新建节点",{"2":{"525":1}}],["否则我们使用cbgs",{"2":{"758":1}}],["否则它将仅尝试估计质心和边界框",{"2":{"449":1}}],["否则",{"2":{"177":1,"479":1,"638":1}}],["否则返回false",{"2":{"146":1}}],["否则会报内存不够错误",{"2":{"11":1}}],["判别器然后预测指示输入是来自真实形状还是生成形状的概率",{"2":{"429":1}}],["判别生成的数据是不是",{"2":{"129":1}}],["判断队列是否为空",{"2":{"854":1}}],["判断其中一个是否为空闲",{"2":{"707":1}}],["判断是否为空",{"2":{"479":1}}],["判断当前观测是否对应曾经到访过的区域",{"2":{"189":1}}],["判断vector容器是否为空",{"2":{"146":1}}],["申请n个元素个数的内存空间",{"2":{"146":1}}],["示范了新的vla4ad范式",{"2":{"145":1}}],["示例",{"2":{"57":1,"753":1,"795":1}}],["连同",{"2":{"765":1}}],["连同高斯分布均值在相机坐标系中的z分量",{"2":{"705":1}}],["连同里程计",{"2":{"390":1}}],["连同kimera",{"2":{"285":1}}],["连续的函数",{"2":{"619":1}}],["连续的姿态通过一个因子",{"2":{"419":1}}],["连续卷积",{"0":{"481":1}}],["连续动作",{"2":{"334":1}}],["连续过程",{"2":{"208":1}}],["连续控制",{"2":{"145":1}}],["连通分量将对应于环境中的房间",{"2":{"301":1}}],["连通分量可能代表不同的物理区域或对象群组",{"2":{"153":1}}],["连通分量是指图中的一组顶点",{"2":{"153":1}}],["连通分量",{"2":{"153":1}}],["连接到所有房间",{"2":{"210":1}}],["连接是针对每个时间戳的姿态",{"2":{"197":1}}],["连接",{"0":{"50":1,"77":1},"1":{"60":1,"69":1,"78":1},"2":{"390":1,"419":1,"539":1,"632":2,"660":1,"928":1,"939":1}}],["及可供性问答",{"2":{"864":1}}],["及可选文本命令",{"2":{"308":1}}],["及基于轮廓的边界",{"2":{"826":1}}],["及更长周期任务",{"2":{"698":1}}],["及具身智能研究",{"2":{"525":1}}],["及内参",{"2":{"435":1}}],["及提供细粒度解释上仍可能困难",{"2":{"308":1}}],["及carllava",{"2":{"308":1}}],["及其对应的相机视锥在真实情况",{"2":{"903":1}}],["及其对应的深度bin坐标",{"2":{"621":1}}],["及其连通性",{"2":{"480":1}}],["及其边",{"2":{"301":1}}],["及其扩展",{"2":{"128":1}}],["及低层规划器等多个子模块",{"2":{"274":1}}],["及",{"2":{"216":1}}],["及语义",{"2":{"209":1}}],["及工具增强语言接口",{"2":{"176":1}}],["及混合离散",{"2":{"145":1}}],["超越了基于变换器的最先进方法panoocc",{"2":{"791":1}}],["超越直接控制token",{"2":{"145":1}}],["超体素↔",{"0":{"730":1}}],["超体素↔体素",{"2":{"707":1}}],["超参",{"2":{"623":1}}],["超出图像边界的点",{"2":{"623":1}}],["超出平滑范围的状态使用gtsam边缘化",{"2":{"310":1}}],["超点特征与这些内核进行卷积",{"2":{"441":1}}],["超车专家",{"2":{"283":1}}],["超详解",{"2":{"207":1}}],["超分辨率扩散",{"2":{"205":1}}],["超过了真实标注",{"2":{"745":1}}],["超过了最先进的方法",{"2":{"349":1}}],["超过一个预设的阈值",{"2":{"153":1}}],["超过阈值",{"2":{"153":1}}],["超过卡车",{"2":{"145":1}}],["受益于多模态输入的互补性",{"2":{"1005":1}}],["受益于稀疏采样",{"2":{"863":1}}],["受bevfusion",{"2":{"976":1}}],["受maskformer",{"2":{"957":1}}],["受特斯拉自动驾驶车辆感知系统技术的启发",{"2":{"942":1}}],["受启发于分离卷积",{"2":{"863":1}}],["受自训练的启发",{"2":{"735":1}}],["受形状上下文描述符结构的启发",{"2":{"664":1}}],["受petr",{"2":{"649":1}}],["受",{"2":{"632":1,"694":1}}],["受此启发",{"2":{"595":1,"705":1,"863":1}}],["受vit中class",{"2":{"591":1}}],["受图像渲染中3d高斯溅射方法",{"2":{"547":1}}],["受子像素卷积技术",{"2":{"535":1}}],["受到了学术界和工业界越来越多的关注",{"2":{"535":1}}],["受3d高斯绘制成功的启发",{"2":{"444":1}}],["受具身智能领域进展启发",{"2":{"145":1}}],["受的启发",{"2":{"96":1}}],["仅依赖环视相机的算法无法准确预测远处的行人",{"2":{"952":1}}],["仅依赖摄像头传感器的以视觉为中心的占用感知代表了当前的研究趋势",{"2":{"942":1}}],["仅依赖于单张",{"2":{"570":1}}],["仅从给定的",{"2":{"928":1}}],["仅从单张",{"2":{"632":1}}],["仅智能体运动",{"2":{"926":1}}],["仅对非空区域进行建模",{"2":{"922":1}}],["仅3d分支",{"2":{"910":1}}],["仅2d分支",{"2":{"910":1}}],["仅预测稀疏点的语义类别",{"2":{"910":1}}],["仅用一张地图即可在多样环境中完成导航",{"2":{"897":1}}],["仅用于可视化",{"2":{"419":1}}],["仅有少量研究关注任务过程中所构建地图的质量",{"2":{"826":1}}],["仅有几何地图可以帮助智能体避开障碍物",{"2":{"350":1}}],["仅影响bev编码器和占据头",{"2":{"811":1}}],["仅在",{"2":{"982":1}}],["仅在最后一个stage加入可变卷积",{"2":{"804":1}}],["仅在反射表面上有一层占用真实标签",{"2":{"778":1}}],["仅比",{"2":{"803":1}}],["仅包含激光雷达输入",{"2":{"997":1}}],["仅包含",{"2":{"739":1}}],["仅基于视觉模态的3d占用预测进行了综述",{"2":{"714":1}}],["仅占占据体素的",{"2":{"700":1}}],["仅靠占用与已探索不足以定位语义目标",{"2":{"698":1}}],["仅视觉学生网络在输入数据有标注时使用蒸馏损失和分类损失的总和进行训练",{"2":{"694":1}}],["仅覆盖长尾子集",{"2":{"478":1}}],["仅使用2d语义和深度标签提供直接的3d监督",{"2":{"941":1}}],["仅使用占用的查询通过可变形注意力",{"2":{"875":1}}],["仅使用不到",{"2":{"812":1}}],["仅使用",{"2":{"803":1,"989":1}}],["仅使用前置摄像头的图像作为输入",{"2":{"757":1}}],["仅使用激光雷达的环境感知算法",{"2":{"596":1}}],["仅使用少量标注数据和其他未标注数据",{"2":{"455":1}}],["仅使用clip代替llava+gpt",{"2":{"431":1}}],["仅使用简单的",{"2":{"425":1}}],["仅使用resnet50",{"2":{"421":1}}],["仅使用resnet50和256×704输入图像分辨率",{"2":{"392":1,"421":1}}],["仅提示编码器训练",{"2":{"417":1}}],["仅惩罚不安全动作",{"2":{"417":1}}],["仅通过轻适配器提示",{"2":{"417":1}}],["仅通过图像级标签预测像素级别的语义相似度",{"2":{"410":1}}],["仅通过使用score",{"2":{"256":1}}],["仅当使用旋转代替仿射变换时",{"2":{"390":1}}],["仅运行一次sd",{"2":{"278":1}}],["仅保留少量关键几何",{"2":{"209":1}}],["仅保留前",{"2":{"153":1}}],["仅需几毫秒",{"2":{"141":1}}],["仅仅使用单视图的三维深度扫描信息就足以使用自监督学习获得有效的特征表示了",{"2":{"394":1}}],["仅仅比不进行预训练的68",{"2":{"366":1}}],["仅仅识别障碍物并不足以保证安全有效的导航",{"2":{"116":1}}],["仅仅是换行符",{"2":{"41":1}}],["∝exp",{"2":{"140":4,"208":1,"280":4,"316":1}}],["∝exp⁡",{"2":{"140":5,"208":1,"280":5,"316":1}}],["⟶q",{"2":{"140":4,"280":4}}],["探索了nerf中空间占用与体积密度之间的关系",{"2":{"941":1}}],["探索通常",{"2":{"826":1}}],["探索视觉大模型",{"2":{"824":1}}],["探索",{"2":{"786":1}}],["探索里程碑如表1所示",{"2":{"785":1}}],["探索模块会依据建图器生成的障碍地图及当前位姿",{"2":{"274":1}}],["探索模块",{"2":{"274":1}}],["探索器",{"2":{"274":1}}],["探索任务",{"2":{"139":1,"698":1,"806":1}}],["探讨不同的地图结构",{"2":{"90":1}}],["前视图像特征通过bev点云特征使用交叉注意力进行增强",{"2":{"976":1}}],["前视图和侧视图特征将与更新后的bev特征进行交互",{"2":{"858":1}}],["前述段落已验证了flashocc在多样化配置中的性能",{"2":{"811":1}}],["前向投影通过lss",{"2":{"839":1}}],["前向投影",{"2":{"585":1}}],["前向马尔可夫扩散过程",{"2":{"304":1}}],["前一帧t",{"2":{"550":1,"583":1}}],["前vla解释器",{"2":{"538":1}}],["前往子目标",{"2":{"525":1}}],["前方障碍",{"2":{"507":1}}],["前两维对应环境平面尺寸",{"2":{"495":1}}],["前景可期",{"2":{"478":1}}],["前景",{"2":{"455":1}}],["前景提取",{"2":{"302":1}}],["前沿论文报告四大互补指标支柱",{"2":{"447":1}}],["前进",{"2":{"435":1}}],["前者从几何和语义角度优化精度",{"2":{"985":1}}],["前者将被小幅更新",{"2":{"728":1}}],["前者是计算代理节点周围对象标签的直方图",{"2":{"352":1}}],["前者64",{"2":{"198":1}}],["前者更侧重于利用视觉",{"2":{"139":1}}],["前端模块在非关键帧上平均需要10毫秒",{"2":{"836":1}}],["前端模块负责从传感器观测中提取特征",{"2":{"189":1}}],["前端计算一个简化版本的网格",{"2":{"380":1}}],["前端使用nanoflann",{"2":{"380":1}}],["前端将第iii节描述的模块的结果作为输入",{"2":{"380":1}}],["前端构建了一个未校正漂移的初始估计的3d场景图",{"2":{"380":1}}],["前端还发布imu速率的状态估计",{"2":{"285":1}}],["前端",{"2":{"168":1,"310":1}}],["前作的缺点",{"0":{"141":1}}],["前身为",{"2":{"126":1}}],["启用更复杂和时间感知的查询",{"2":{"905":1}}],["启动算法节点",{"2":{"152":1}}],["启动相机",{"2":{"152":1}}],["启动ssh服务",{"2":{"78":1}}],["启发的距离感知focal损失函数",{"2":{"585":1}}],["启发",{"2":{"138":1,"585":1,"632":1,"912":1,"957":1}}],["了解更多细节",{"2":{"336":1}}],["了",{"2":{"138":1}}],["信道对称聚集也被应用于每个点的邻域相关的边缘特征上",{"2":{"574":1}}],["信息密度差异和生成任务与下游任务之间的差距等挑战",{"2":{"643":1}}],["信息融合扩展了感知的空间范围",{"2":{"691":1}}],["信息融合研究的动机",{"0":{"691":1}}],["信息融合",{"2":{"610":1}}],["信息融合视角",{"2":{"577":1}}],["信息最为多样化",{"2":{"599":1}}],["信息是计算机视觉领域的经典问题之一",{"2":{"570":1}}],["信息",{"2":{"504":1,"698":1}}],["信息逐步累加到全局坐标系中",{"2":{"495":1}}],["信息类型",{"2":{"80":1}}],["信任与安全问题",{"2":{"478":1}}],["信号处理",{"2":{"137":1}}],["两项实验均采用了",{"2":{"914":1}}],["两条路径的输出被自适应融合以生成输出的3d特征体积",{"2":{"875":1}}],["两部分",{"2":{"863":1}}],["两阶段采样",{"2":{"595":1}}],["两阶段端到端的",{"2":{"349":1}}],["两帧的2d特征和3d坐标分别被拼接在一起",{"2":{"550":1}}],["两层",{"2":{"489":1}}],["两图通道拼接",{"2":{"470":1}}],["两两取出来使用info",{"2":{"424":1}}],["两种重建在质量上相似",{"2":{"889":1}}],["两种方法的流程对比",{"2":{"503":1}}],["两种方法的流程图",{"2":{"409":1}}],["两种设计方案各有利弊",{"2":{"299":1}}],["两个",{"2":{"928":1}}],["两个实验都使用地面真实2d语义",{"2":{"732":1}}],["两个体素都为空",{"2":{"707":1}}],["两个体素都被占用但语义类别不同",{"2":{"707":1}}],["两个体素都被占用且语义类别相同",{"2":{"707":1}}],["两个体素都被占用",{"2":{"707":1}}],["两个多尺度特征被集成以提高表示质量",{"2":{"680":1}}],["两个realsense设备都使用硬件同步",{"2":{"605":1}}],["两个realsense相机的内参和外参",{"2":{"605":1}}],["两个图中都叠加了估计的房间布局",{"2":{"480":1}}],["两个大规模数据集上的三个公开基准测试中验证了模型的有效性",{"2":{"455":1}}],["两个相邻面之间的角",{"2":{"379":1}}],["两个平面的变换矩阵",{"2":{"355":1}}],["两个主要参数是房间之间的最小和最大开口大小",{"2":{"301":1}}],["两个随机变量",{"2":{"137":1}}],["两者都由kimera重建",{"2":{"889":1}}],["两者都是通过距离函数来描述空间中物体的位置和形状",{"2":{"31":1}}],["两者均亟待进一步探索",{"2":{"826":1}}],["两者在同一框架内无缝切换",{"2":{"648":1}}],["两者分开训练",{"2":{"220":1}}],["互信息是衡量两个随机变量之间共享信息量的指标",{"2":{"153":1}}],["互信息是衡量两个随机变量之间相互依赖程度的量",{"2":{"137":1}}],["互信息是信息论中的一个基本概念",{"2":{"137":1}}],["互信息也可以用条件熵来表示",{"2":{"137":1}}],["互信息可以告诉我们在已知一个随机变量的情况下",{"2":{"137":1}}],["控制可靠性",{"2":{"447":1}}],["控制点云形状",{"2":{"314":1}}],["控制姿态",{"2":{"181":1}}],["控制这两个项之间的期望平衡",{"2":{"137":1}}],["控制等独立模块",{"2":{"103":1}}],["参见li等人",{"2":{"967":1}}],["参见公式8",{"2":{"957":1}}],["参见图",{"2":{"252":1,"435":1}}],["参照mvsnet",{"2":{"464":1}}],["参数超10亿",{"2":{"805":1}}],["参数减少了",{"2":{"803":1}}],["参数化",{"2":{"532":1}}],["参数θtrack",{"2":{"431":2}}],["参数在所有特征图间共享",{"2":{"305":1}}],["参数共享",{"2":{"305":1}}],["参数更少",{"2":{"275":1}}],["参数量前者",{"2":{"198":1}}],["参数",{"2":{"137":1,"351":1,"545":1,"965":1,"971":1}}],["参考文献内容省略",{"2":{"879":1}}],["参考文献",{"0":{"879":1}}],["参考视图表示为",{"2":{"464":1}}],["参考点的预测坐标可能不够准确",{"2":{"341":1}}],["参考",{"2":{"17":1}}],["⋅e",{"2":{"681":2}}],["⋅∇x​pdata​",{"2":{"235":2}}],["⋅∇xpdata",{"2":{"235":3}}],["⋅pdata​",{"2":{"235":2}}],["⋅pdata",{"2":{"235":1}}],["⋅djs​",{"2":{"153":1}}],["⋅djs",{"2":{"153":1}}],["⋅",{"2":{"137":4,"532":4,"595":4,"656":6,"660":6,"693":4,"716":4,"730":2}}],["类比航空icao用语",{"2":{"507":1}}],["类别的平均交并比",{"2":{"1000":1}}],["类别分布已在附录",{"2":{"899":1}}],["类别异常iou",{"2":{"785":1}}],["类别值为",{"2":{"724":1}}],["类别值为0表示空网格",{"2":{"590":1}}],["类别数量",{"2":{"997":1}}],["类别数",{"2":{"703":1}}],["类别三种目标的统一导航",{"2":{"698":1}}],["类别则取最新值",{"2":{"698":1}}],["类别可能包括未单独标注的自行车",{"2":{"277":1}}],["类别",{"0":{"702":1,"790":1},"2":{"277":1,"534":3,"698":1,"828":1,"998":1,"1000":1}}],["类别描述",{"2":{"254":1}}],["类别名称",{"2":{"254":1}}],["类似常规卷积",{"2":{"863":1}}],["类似simlingo",{"2":{"507":1}}],["类似可学习的",{"2":{"489":1}}],["类似的方法从未应用于",{"2":{"471":1}}],["类似文章",{"2":{"410":1}}],["类似工作",{"0":{"381":1},"1":{"410":1,"439":1,"469":1,"498":1,"528":1,"559":1,"591":1}}],["类似vae增加一个latent和标准正态分布的kl",{"2":{"345":1}}],["类似",{"2":{"328":1,"426":1,"660":1,"924":1,"948":1}}],["类似于其他方法",{"2":{"982":1}}],["类似于初始化时用数组进行赋值",{"2":{"904":1}}],["类似于2d像素级语义分割任务",{"2":{"778":1}}],["类似于occ3d",{"2":{"757":1}}],["类似于fpn",{"2":{"609":1}}],["类似于蓝色线条中的预测3d参考点",{"2":{"594":1}}],["类似于立体的左右视差检查",{"2":{"592":1}}],["类似于办公室",{"2":{"572":1}}],["类似于3d",{"2":{"440":1}}],["类似于",{"2":{"310":1,"354":1,"362":1,"609":1,"853":1,"982":1}}],["类似于著名的信息瓶颈",{"2":{"137":1}}],["类似地",{"2":{"137":1,"283":1,"347":1,"527":1,"847":1,"930":1,"955":1,"957":1,"967":1,"976":1}}],["类无关分割网络",{"2":{"121":1}}],["捡起玩具并放在架子上",{"2":{"137":1}}],["叠衣服",{"2":{"137":1}}],["洗碗",{"2":{"137":1}}],["棋盘格",{"2":{"136":1}}],["米到",{"2":{"900":4}}],["米",{"2":{"136":1,"173":4,"749":1,"787":3,"853":1,"900":5,"917":2}}],["创新点",{"0":{"258":1,"289":1,"473":1}}],["创新之处在于给每一层子网络都喂了",{"2":{"133":1}}],["创造出比上述所有模型更稳健和高效的生成模型",{"2":{"248":1}}],["创建了一个轻量级版本",{"2":{"928":1}}],["创建的伪影显著阻碍了网格精度",{"2":{"709":1}}],["创建地点后",{"2":{"480":1}}],["创建空的set",{"0":{"284":1}}],["创建空set",{"2":{"261":1}}],["创建工作目录",{"2":{"120":1}}],["创建一个size",{"2":{"93":2}}],["创建一个空的vector容器",{"2":{"93":1}}],["创建一个",{"0":{"68":1}}],["创建容器",{"0":{"60":1}}],["创建",{"2":{"26":1,"196":1}}],["创建挂载的目录",{"2":{"24":1}}],["呢",{"2":{"133":1}}],["发射光线",{"2":{"435":1}}],["发现",{"2":{"973":1}}],["发现基金的支持",{"2":{"958":1}}],["发现使用不同的输入表示",{"2":{"394":1}}],["发现没有权限操作硬盘",{"2":{"24":1}}],["发布预训练的潜在扩散和自动编码模型",{"2":{"552":1}}],["发布",{"2":{"302":1,"425":1}}],["发布之后",{"2":{"302":1}}],["发型等style",{"2":{"181":1}}],["发型等等",{"2":{"133":1}}],["发型",{"2":{"181":1}}],["∣1​i∈c",{"2":{"749":1,"802":1,"848":1}}],["∣∑i∈c",{"2":{"749":1,"802":1,"848":1}}],["∣sf∣|s",{"2":{"694":1}}],["∣dreproj−d1∣",{"2":{"592":1}}],["∣preproj−p1∣",{"2":{"592":1}}],["∣re∩rg∣",{"2":{"437":2}}],["∣re∣召回率=1",{"2":{"437":2}}],["∣re∣σ",{"2":{"437":2}}],["∣rg∣",{"2":{"437":2}}],["∣rg∣σ",{"2":{"437":2}}],["∣rg∩re∣",{"2":{"437":2}}],["∣b−d∣",{"2":{"351":2}}],["∣a−c∣",{"2":{"351":2}}],["∣x→−∞x→+∞​≡0=∇θ​edata​",{"2":{"235":1}}],["∣x→−∞x→+∞≡0=∇θedata",{"2":{"235":1}}],["∣xp​−xq​∣≤edge",{"2":{"132":1}}],["∣xp−xq∣≤edge",{"2":{"132":1}}],["∣∣a∣∣ω2​=tr",{"2":{"390":1}}],["∣∣a∣∣ω2=tr||a||^2",{"2":{"390":1}}],["∣∣rxig~il+txi−tml∣∣2ωil",{"2":{"390":1}}],["∣∣rmk",{"2":{"390":1}}],["∣∣sθ​",{"2":{"235":6}}],["∣∣sθ",{"2":{"235":6}}],["∣∣∇x​log",{"2":{"235":1}}],["∣∣∇xlog",{"2":{"235":1}}],["∣∣22−2tr",{"2":{"235":1}}],["∣∣22+",{"2":{"235":1}}],["∣∣22​−2tr",{"2":{"235":1}}],["∣∣22​+",{"2":{"235":1}}],["∣∣22​",{"2":{"235":5}}],["∣∣22",{"2":{"235":5}}],["∣∣p",{"2":{"13":2}}],["∣zp​−zq​∣≤edge0",{"2":{"132":1}}],["∣zp−zq∣≤edge0",{"2":{"132":1}}],["∣yp​−yq​∣≤edge",{"2":{"132":1}}],["∣yp−yq∣≤edge",{"2":{"132":1}}],["评价",{"2":{"826":1}}],["评价指标",{"0":{"1":1,"263":1},"1":{"3":1}}],["评分控制与解释质量仍待定义",{"2":{"478":1}}],["评估范围",{"2":{"989":1}}],["评估",{"0":{"903":1,"991":1},"1":{"994":1,"997":1,"998":1}}],["评估仅考虑可见的体素",{"2":{"900":1}}],["评估重心仍放在",{"2":{"881":1}}],["评估在语义",{"2":{"846":1}}],["评估了我们的方法",{"2":{"827":1}}],["评估了使用resnet",{"2":{"791":1}}],["评估旨在检验语义地图在不可预测或动态环境中的可靠性",{"2":{"826":1}}],["评估开放词汇语义地图的准确性尤为棘手",{"2":{"826":1}}],["评估方法",{"0":{"786":1},"1":{"806":1,"826":1,"846":1}}],["评估指标细节",{"0":{"916":1}}],["评估指标已在文献中得到广泛研究",{"2":{"806":1}}],["评估指标遵循常见做法",{"2":{"749":1}}],["评估指标",{"0":{"778":1,"802":1,"848":1,"998":1},"2":{"736":1,"793":1,"853":1}}],["评估指标和关键挑战",{"2":{"665":1,"689":1}}],["评估和挑战的深入讨论",{"2":{"714":1}}],["评估vla4ad智能体是双重目标任务",{"2":{"447":1}}],["评估协议",{"0":{"447":1}}],["评估集为celeba",{"2":{"382":1}}],["评估数据来源",{"2":{"334":1}}],["评估预训练效果的方法",{"2":{"265":1}}],["评估所用数据",{"2":{"238":1}}],["评估表明",{"2":{"131":1}}],["天花板高度",{"2":{"301":1}}],["天花板灯安装在天花板上",{"2":{"197":1}}],["天花板",{"2":{"131":1,"162":1,"178":1,"197":1,"285":1,"793":1,"967":1}}],["天气条件及驾驶规范上表现更强",{"2":{"128":1}}],["天气条件",{"2":{"126":1}}],["墙壁以灰色显示",{"2":{"276":1}}],["墙壁和地板的爆炸视图",{"2":{"197":1}}],["墙壁",{"2":{"131":1,"162":2,"178":1,"197":2,"285":1,"793":1,"903":1,"967":1}}],["后的整个场景的空间占用预测",{"2":{"833":1}}],["后对",{"2":{"762":1}}],["后向投影bev表示",{"2":{"839":1}}],["后向投影",{"2":{"839":1}}],["后向投影定义了3d空间中的体素位置",{"2":{"839":1}}],["后向投影模块使用1层",{"2":{"764":1}}],["后向投影在投影阶段利用深度分布",{"2":{"585":1}}],["后向投影方法受bevformer",{"2":{"585":1}}],["后面还会接上一个layer",{"2":{"659":1}}],["后面会细讲",{"2":{"659":1}}],["后面会详细讲到",{"2":{"133":1}}],["后面是每个池化层之后的中间简化网格",{"2":{"557":1}}],["后",{"2":{"463":1,"824":1,"963":1}}],["后处理步骤来缓解离散化错误和模糊推理输出的问题",{"2":{"955":1}}],["后处理",{"0":{"529":1,"646":1,"825":1},"1":{"560":1,"592":1,"622":1,"650":1,"673":1,"697":1}}],["后处理复杂",{"2":{"443":1}}],["后处理结果以移除对应于机器人多次访问同一位置的冗余子图",{"2":{"380":1}}],["后三步常被合称为",{"2":{"435":1}}],["后端在不到60毫秒内解决因子图优化",{"2":{"816":1}}],["后端优化由前端场景图构建的嵌入式变形图",{"2":{"380":1}}],["后端模块则依据前端提供的数据进行位姿优化与地图估计",{"2":{"189":1}}],["后续探索涉及到从高斯记忆中更新高斯分布",{"2":{"728":1}}],["后续通常会剪枝冗余节点与边",{"2":{"525":1}}],["后续",{"2":{"328":1}}],["后续研究转向轨迹或航点级预测",{"2":{"216":1}}],["后续研究通过若干关键方向解决限制",{"2":{"128":1}}],["后续研究通过自监督或弱监督框架减少3d感知任务标注负担",{"2":{"114":1}}],["后结合毫米波雷达以估计速度",{"2":{"176":1}}],["后送入unet",{"2":{"175":1}}],["后者通常与掩码解码器头部",{"2":{"985":1}}],["后者在性质上与",{"2":{"928":1}}],["后者在每个体素处获取的特征由场景的固定空间分区确定",{"2":{"464":1}}],["后者是一种三传感器融合方法",{"2":{"827":1}}],["后者是计算与代理节点周围每个地点相关联的距离的直方图",{"2":{"352":1}}],["后者展现出更优的全局感受野",{"2":{"703":1}}],["后者本质上是没有信息瓶颈任务驱动聚类的clio",{"2":{"462":1}}],["后者更易于迁移到真实场景",{"2":{"435":1}}],["后者只优化姿态图",{"2":{"285":1}}],["后者只优化描述机器人轨迹的姿态图",{"2":{"131":1}}],["后者7m",{"2":{"198":1}}],["后者32",{"2":{"198":1}}],["后者假设给定了注释的网格模型",{"2":{"131":1}}],["鲁棒3d占用感知的方法可以包括但不限于鲁棒的场景表示",{"2":{"1005":1}}],["鲁棒的3d占用感知",{"0":{"1005":1}}],["鲁棒的环境表示是必要的",{"2":{"270":1}}],["鲁棒感知",{"2":{"478":1}}],["鲁棒姿态图和网格优化器",{"2":{"285":1}}],["鲁棒姿态图优化",{"2":{"131":1}}],["鲁棒性与可靠性",{"2":{"478":1}}],["鲁棒性与压力测试",{"2":{"447":1}}],["鲁棒性",{"2":{"72":1,"826":1,"943":1}}],["负责预测每个体素的分割标签的占用预测模块",{"2":{"908":1}}],["负责将2d感知视图图像特征映射到bev表示的视图变换模块",{"2":{"908":1}}],["负责避障与低级路径规划",{"2":{"648":1}}],["负责处理bev特征信息的bev编码器",{"2":{"908":1}}],["负责处理bev特征信息",{"2":{"598":1}}],["负责处理原始传感器数据",{"2":{"310":1}}],["负责从多相机图像中提取图像特征的2d图像编码器",{"2":{"908":1}}],["负责从多相机图像中提取图像特征",{"2":{"598":1}}],["负责构建任务不可知的对象和地点原语",{"2":{"168":1}}],["负责场景的实时度量",{"2":{"131":1}}],["负责连接到xserver进行输入和输出",{"2":{"74":1}}],["指针统一",{"2":{"888":1}}],["指地图中语义标注与其物理位置的持续对齐",{"2":{"826":1}}],["指地图在空间结构",{"2":{"826":1}}],["指可行驶表面",{"2":{"782":1}}],["指工程车辆",{"2":{"782":1}}],["指示该物理位置是否被物体占据",{"2":{"698":1}}],["指当前整个场景的空间占用预测",{"2":{"682":1}}],["指定插入位置",{"2":{"571":1}}],["指定roi的位置",{"2":{"296":1}}],["指数移动平均",{"2":{"528":2,"758":1}}],["指出",{"2":{"495":1}}],["指出当前面临的挑战",{"2":{"80":1}}],["指标来评估结果",{"2":{"893":1}}],["指标已得到充分研究",{"2":{"846":1}}],["指标上下降了",{"2":{"827":2}}],["指标稳步提高",{"2":{"700":1}}],["指标下提高约",{"2":{"653":1}}],["指标",{"0":{"402":1},"2":{"742":1,"806":1,"998":1}}],["指标隔离特定技能",{"2":{"360":1}}],["指标刷很高",{"2":{"220":1}}],["指导模糊或长尾场景决策",{"2":{"283":1}}],["指令跟随等领域不断出现的新挑战",{"2":{"806":1}}],["指令跟随任务采用",{"2":{"806":1}}],["指令遵循",{"2":{"447":1}}],["指令遵循的多模态智能体关键转变",{"2":{"145":1}}],["指令条件目标到达率",{"2":{"447":1}}],["指令调优变体",{"2":{"195":1}}],["指向常量的末尾迭代器指针",{"2":{"918":1}}],["指向常量的开始迭代器指针",{"2":{"918":1}}],["指向场景中的最后一个样本",{"2":{"254":1}}],["指向场景中的第一个样本",{"2":{"254":1}}],["指向scene的外键",{"2":{"254":1}}],["指向此实例的最后一个注释",{"2":{"254":1}}],["指向此实例的第一个注释",{"2":{"254":1}}],["指向物体类别的外键",{"2":{"254":1}}],["指向传感器类型的外键",{"2":{"254":1}}],["指向最后一个元素",{"2":{"130":1,"918":1}}],["指向最后一个元素的下一个位置",{"2":{"130":1,"918":1}}],["指向第一个元素的前一个元素",{"2":{"918":1}}],["指向第一个元素之前的位置",{"2":{"130":1}}],["指向第一个元素",{"2":{"130":1}}],["返回队列的大小",{"2":{"854":1}}],["返回队首元素",{"2":{"835":1}}],["返回队尾元素",{"2":{"835":1}}],["返回容器中的篮子总数",{"2":{"661":1}}],["返回的迭代器会指向新元素",{"2":{"571":1}}],["返回的是被查找元素的位置",{"2":{"177":1}}],["返回的是被查找元素的个数",{"2":{"177":1}}],["返回pair",{"2":{"571":1}}],["返回pos位置处元素的引用",{"2":{"130":1}}],["返回指向end的迭代器",{"2":{"633":1}}],["返回指向插入元素的迭代器",{"2":{"571":1}}],["返回指向容器中最后一个键值对之后位置的正向迭代器",{"2":{"196":1}}],["返回指向容器中第一个键值对的正向迭代器",{"2":{"196":1}}],["返回指2出现的次数",{"2":{"540":1}}],["返回",{"2":{"285":1}}],["返回一个",{"2":{"196":1}}],["返回0",{"2":{"177":1}}],["返回1",{"2":{"177":1}}],["返回原始原语集合",{"2":{"153":1}}],["返回vector容器容量",{"2":{"146":1}}],["返回vector容器元素个数",{"2":{"146":1}}],["返回向量vector容器的尾指针",{"2":{"130":1}}],["返回向量vector容器的头指针",{"2":{"130":1}}],["返回尾元素的应用",{"2":{"130":1}}],["返回首元素的引用",{"2":{"130":1}}],["返回esam的根目录",{"2":{"32":1,"38":1}}],["代替二进制占用表示",{"2":{"962":1}}],["代价体",{"2":{"440":1}}],["代价体正则化",{"0":{"440":1}}],["代理层",{"2":{"380":1,"408":1}}],["代理代表环境中的动态实体",{"2":{"178":1}}],["代理a在时间t在房间b",{"2":{"147":1,"162":1}}],["代理及其关系",{"2":{"147":1}}],["代理",{"2":{"131":1,"147":1,"162":2,"218":1}}],["代表了假设深度为",{"2":{"411":1}}],["代表性工作",{"2":{"619":1}}],["代表性",{"2":{"334":1}}],["代表的是3d场景中的对象原语",{"2":{"271":1}}],["代表所有形状类别的平均准确度",{"2":{"263":1}}],["代表所有测试实例的平均准确度",{"2":{"263":1}}],["代表梯度预测网络",{"2":{"235":1}}],["代表作有polarmask和adaptis",{"2":{"138":1}}],["代表作有yolact和solo",{"2":{"138":1}}],["代表任务相关概念",{"2":{"137":1}}],["代表",{"2":{"129":1}}],["代码链接失效",{"2":{"578":1}}],["代码地址",{"2":{"536":1}}],["代码和模型将在以下地址发布",{"2":{"490":1}}],["代码将公开提供",{"2":{"505":1}}],["代码将在",{"2":{"425":1}}],["代码将发布于https",{"2":{"392":1}}],["代码可在以下链接获取",{"2":{"409":1,"568":1}}],["代码暂未开源",{"2":{"387":1,"514":1}}],["代码中叫作query",{"2":{"333":1}}],["代码还提供使用imu旋转执行单目和立体验证的选项",{"2":{"310":1}}],["代码分组",{"2":{"57":1}}],["代码",{"2":{"57":1,"584":1}}],["犯错",{"2":{"129":1}}],["解析地点和房间",{"0":{"796":1}}],["解析人类和对象",{"0":{"775":1}}],["解析高层目标或理解自然语言表达地图约束",{"2":{"176":1}}],["解耦视角信息使模型能够更好地泛化",{"2":{"908":1}}],["解耦",{"2":{"632":1}}],["解耦了融合特征在分类和回归中的使用",{"2":{"512":1}}],["解缠结匹配策略采用端到端的方式训练实例内核",{"2":{"384":1}}],["解码器包含两个反卷积层",{"2":{"982":1}}],["解码器中所有可能的尺度",{"2":{"928":1}}],["解码器中与物体查询进行交互",{"2":{"369":1}}],["解码器特征调整到所需的",{"2":{"928":1}}],["解码器特征图f1",{"2":{"660":1}}],["解码器特征图",{"2":{"660":1}}],["解码器模块进行表示增强",{"2":{"910":1}}],["解码器模块",{"2":{"898":1}}],["解码器的输出为四尺度的细化tpv",{"2":{"699":1}}],["解码器的检测头",{"2":{"512":1}}],["解码器进行细化",{"2":{"621":1}}],["解码器进一步细化特征",{"2":{"438":1}}],["解码器架构和基于分数的先验的先前工作",{"2":{"552":1}}],["解码器块组成",{"2":{"549":1}}],["解码器",{"0":{"699":1},"2":{"526":1,"632":1,"928":1}}],["解码器来自回归地预测点块",{"2":{"488":1}}],["解码器结构进一步细化tpv",{"2":{"578":1,"621":1}}],["解码器结构",{"2":{"440":1,"875":1}}],["解码器层交换了自注意力层和交叉注意力层的顺序",{"2":{"405":1}}],["解码器层的详细架构如下图所示",{"2":{"405":1}}],["解码器层的查询向量的特征预定义为",{"2":{"405":1}}],["解码器层组成",{"2":{"405":1}}],["解码器通过交叉注意机制捕获超点信息",{"2":{"384":1}}],["解码器将采样的特征和query作为输入",{"2":{"341":1}}],["解码器从潜在空间恢复图像",{"2":{"270":1}}],["解释",{"2":{"835":1,"854":1}}],["解释性语言模型",{"2":{"238":1}}],["解释自发",{"2":{"145":1}}],["解释输出无形式化安全保证",{"2":{"128":1}}],["解决方案通常需要在有限的时间内完成计算",{"2":{"1004":1}}],["解决方法",{"0":{"74":1},"2":{"267":1,"291":1}}],["解决这一挑战性任务的关键在于学习一种信息丰富且紧凑的场景表示",{"2":{"808":1}}],["解决了这一问题",{"2":{"860":1}}],["解决了点云的无序性",{"2":{"643":1}}],["解决了上述挑战",{"2":{"535":1}}],["解决了任意输入n个输入的问题",{"2":{"411":1}}],["解决的问题",{"0":{"331":1}}],["解决的是一个寻找最小值的问题",{"2":{"129":1}}],["解决qt",{"0":{"53":1},"1":{"64":1,"74":1},"2":{"74":1}}],["解决办法",{"2":{"48":1}}],["解决过程",{"2":{"41":1}}],["幻觉缓解",{"2":{"128":1}}],["知识蒸馏广泛应用于视觉",{"2":{"548":1}}],["知识蒸馏是一种学习技术",{"2":{"548":1}}],["知识蒸馏方法",{"2":{"128":1}}],["知乎",{"2":{"73":1,"133":1,"179":1,"201":1,"223":1,"243":1,"258":1,"264":1,"266":1,"292":2,"325":1,"328":1,"382":2,"469":1,"500":1,"513":1,"528":1,"589":1,"715":1,"763":1,"804":1,"824":1}}],["表9显示了我们的语义层次路径规划实现的计时性能",{"2":{"947":1}}],["表9",{"2":{"893":1,"947":1}}],["表8",{"2":{"876":1}}],["表8展示了有助于最终性能的消融实验结果",{"2":{"876":1}}],["表8显示了uhumans数据集中每个人类的平均定位误差",{"2":{"775":1}}],["表7",{"2":{"840":1}}],["表7显示了kimera",{"2":{"754":1}}],["表7显示kimera",{"2":{"754":1}}],["表6",{"2":{"800":1,"1001":1}}],["表6总结了我们的发现",{"2":{"732":1}}],["表4显示",{"2":{"1000":1}}],["表4显示了现有方法在公开基准上取得的结果",{"2":{"996":1}}],["表4的",{"2":{"1000":1}}],["表4采用miou和miou来评估3d语义占用感知",{"2":{"1000":1}}],["表4展示了部署友好方法在occ3d",{"2":{"922":1}}],["表4中的结果还表明",{"2":{"833":1}}],["表4中kimera",{"2":{"754":1}}],["表4",{"2":{"779":1,"1000":1}}],["表4报告了使用5点ransac",{"2":{"662":1}}],["表5展示了标签高效方法在occ3d",{"2":{"949":1}}],["表5展示了关于3d高斯分布数量的消融研究",{"2":{"842":1}}],["表5展示了不同数量的冻结优化层和不同的置信度值",{"2":{"833":1}}],["表5",{"2":{"709":1,"800":1,"1000":1}}],["表5中的3d网格误差与表1中的定位误差相比要小",{"2":{"709":1}}],["表5报告了有和没有动态掩蔽的kimera",{"2":{"709":1}}],["表中的",{"2":{"709":1}}],["表１显示了不同基于点的网络所取得的结果",{"2":{"688":1}}],["表3和表5报告了不同模态下占用感知的性能",{"2":{"1000":1}}],["表3和表5显示",{"2":{"1000":1}}],["表3和表5使用iou和miou指标来评估3d几何和3d语义占用感知能力",{"2":{"1000":1}}],["表3展示了特征增强方法在occ3d",{"2":{"875":1}}],["表3展示了在surroundocc验证集上的定量比较",{"2":{"779":1}}],["表3",{"2":{"686":1,"736":1,"1000":1}}],["表3提供了kimera",{"2":{"686":1}}],["表2提供了数据集的详细总结",{"2":{"997":1}}],["表2和表3分别显示了不同检测器在kitti测试3d和bev基准上取得的结果",{"2":{"931":1}}],["表2比较了在sscbench",{"2":{"842":1}}],["表2展示了我们的embodiedocc与基线之间的性能比较",{"2":{"833":1}}],["表2中展示了相应插件替换的详细架构",{"2":{"770":1}}],["表2",{"2":{"686":1,"736":1,"997":1}}],["表2显示",{"2":{"634":1}}],["表2显示了不同循环闭合阈值α下kimera",{"2":{"634":1}}],["表1中的",{"2":{"981":1}}],["表1中的结果使用α",{"2":{"634":1}}],["表1详细列出了近年来用于自动驾驶的占用感知方法及其特点",{"2":{"877":1}}],["表1",{"2":{"700":1,"736":1,"842":1,"877":1}}],["表1列出了与最新开源vio管道相比",{"2":{"686":1}}],["表1比较了kimera",{"2":{"634":1}}],["表1总结了2023",{"2":{"238":1}}],["表征",{"2":{"588":1}}],["表iii中的结果在5次试验中平均",{"2":{"522":1}}],["表iii",{"2":{"522":1}}],["表ii显示clio在macc上实现了与领先方法相当的性能",{"2":{"492":1}}],["表i中蓝色阴影行",{"2":{"462":1}}],["表i报告了在单个试验中每个层的增量创建的计时分解",{"2":{"437":1}}],["表面对齐损失",{"2":{"460":1}}],["表",{"2":{"274":2,"334":1,"360":1,"382":1,"495":1,"525":1,"545":1,"556":1,"700":1,"765":1,"782":3,"803":3,"823":1,"846":1,"903":3,"917":4,"928":2,"931":1,"965":2,"971":2,"989":1}}],["表述为以下优化问题的解",{"2":{"137":1}}],["表明这些特征与相机属性在我们的框架中得到了有效的整合",{"2":{"936":1}}],["表明高斯表示存在冗余",{"2":{"916":1}}],["表明模型容量的利用效率越低",{"2":{"916":1}}],["表明可以使用smpl身体参数估计进行有效的数据关联",{"2":{"775":1}}],["表明捆绑射线投射在几何上",{"2":{"732":1}}],["表明了关于这个场景的记忆的形成",{"2":{"728":1}}],["表明智能体已返回到之前探索过的位置",{"2":{"682":1}}],["表明我们的模拟是现实的",{"2":{"889":1}}],["表明我们的pointgpt在模型容量相似的单模态方法中表现优异",{"2":{"643":1}}],["表明我们的任务感知聚类不会降低封闭集任务的性能",{"2":{"492":1}}],["表明",{"2":{"128":1,"252":1,"603":1,"800":2}}],["表示occfiner从monoscene的结果中进一步细化预测的占用情况",{"2":{"1000":1}}],["表示监督学习类型",{"2":{"1000":1}}],["表示几何感知",{"2":{"1000":1}}],["表示数据集中包含的传感器类型",{"2":{"997":1}}],["表示标注",{"2":{"997":1}}],["表示来自fastocc",{"2":{"1001":1}}],["表示来自sparseocc",{"2":{"1001":1}}],["表示来自",{"2":{"976":1}}],["表示逐元素乘积",{"2":{"970":1}}],["表示3d坐标",{"2":{"957":1}}],["表示3d特征体积中查询位置的特征",{"2":{"957":1}}],["表示3d空间中的坐标",{"2":{"950":1}}],["表示可学习的位置偏移",{"2":{"950":1}}],["表示注意力",{"2":{"950":1}}],["表示外积",{"2":{"950":1}}],["表示反向投影函数",{"2":{"950":1}}],["表示在bev或tpv平面中可能不存在的特定维度",{"2":{"950":1}}],["表示在坐标aaa处对bbb进行采样",{"2":{"660":1}}],["表示输入图像",{"2":{"942":1}}],["表示输入数据的特征表示形式",{"2":{"877":1}}],["表示柱体或立方体素化",{"2":{"910":1}}],["表示体素的特征维度",{"2":{"910":1}}],["表示框架内的第",{"2":{"884":1}}],["表示切片的输入特征图",{"2":{"863":1}}],["表示组维度",{"2":{"863":1}}],["表示该组的位置无关投影权重",{"2":{"863":1}}],["表示聚合组的数量",{"2":{"863":1}}],["表示非空类别集合",{"2":{"848":1}}],["表示空类别",{"2":{"848":1}}],["表示空网格",{"2":{"724":1}}],["表示预定义网格采样的第",{"2":{"844":1}}],["表示预定义类别的数量",{"2":{"712":1}}],["表示采样点总数",{"2":{"844":1}}],["表示总类别数",{"2":{"807":1,"915":1}}],["表示已观测环境的比例",{"2":{"806":1}}],["表示原始论文提供的结果",{"2":{"782":1}}],["表示通过官方代码复现的性能",{"2":{"782":2}}],["表示语义类别的总数",{"2":{"998":1}}],["表示语义",{"2":{"780":1}}],["表示占用",{"2":{"997":1}}],["表示占用状态",{"2":{"780":1}}],["表示占用体素的数量",{"2":{"712":1}}],["表示它们将是本次更新的重点",{"2":{"728":1}}],["表示它们将是当前更新的重点",{"2":{"728":1}}],["表示初始化这个场景的高斯分布的数量",{"2":{"728":1}}],["表示用于",{"2":{"724":1}}],["表示用于自动驾驶中的3d感知",{"2":{"612":1}}],["表示相机视角的数量",{"2":{"712":1}}],["表示定义一个类型为int名字为s的栈",{"2":{"708":1}}],["表示四元数的特殊组合",{"2":{"705":1}}],["表示参考特征的位置",{"2":{"950":1}}],["表示参考点是否被占用",{"2":{"704":1}}],["表示参考相机的法线方向",{"2":{"524":1}}],["表示每个尺度3d特征体积的体素网格笛卡尔坐标",{"2":{"699":1}}],["表示没有结果",{"2":{"688":1,"931":1,"979":1}}],["表示没有设置",{"2":{"26":1}}],["表示表中所有形状类别的平均准确度",{"2":{"688":1}}],["表示所有命中的视角",{"2":{"957":1}}],["表示所有测试实例的平均准确度",{"2":{"688":1}}],["表示所有深度bin的3d柱坐标",{"2":{"649":1}}],["表示模型的参数数量",{"2":{"688":1}}],["表示整个场景的维度",{"2":{"682":1}}],["表示点的数量",{"2":{"910":1}}],["表示点的",{"2":{"789":1}}],["表示点",{"2":{"681":1,"738":1}}],["表示点云的坐标",{"2":{"357":1}}],["表示由高斯",{"2":{"681":1}}],["表示由latent",{"2":{"221":1}}],["表示融合这些特征以执行",{"2":{"678":1}}],["表示融合框架",{"2":{"590":1}}],["表示沿",{"2":{"809":2}}],["表示沿特定轴对第",{"2":{"676":1}}],["表示沿批量轴",{"2":{"550":1}}],["表示本质上提供了3d空间的俯视投影",{"2":{"665":1}}],["表示范式",{"2":{"665":1}}],["表示特征采样",{"2":{"957":1}}],["表示特征图的下采样比例",{"2":{"660":1}}],["表示特征维度",{"2":{"609":1}}],["表示解耦",{"2":{"660":1}}],["表示迭代的轮次",{"2":{"647":1}}],["表示有限",{"2":{"630":1,"665":1}}],["表示投影和采样操作",{"2":{"621":1}}],["表示图像的输入分辨率",{"2":{"609":1}}],["表示经过x倍下采样后提取的特征",{"2":{"609":1}}],["表示使用x帧进行时间融合",{"2":{"736":2,"840":1}}],["表示使用",{"2":{"582":2}}],["表示从笛卡尔坐标到柱坐标的转换",{"2":{"699":1}}],["表示从帧t",{"2":{"550":1}}],["表示从下标为index的地方开始算",{"2":{"52":1}}],["表示单位距离",{"2":{"524":1}}],["表示构建",{"2":{"474":1}}],["表示不同的尺度",{"2":{"647":1}}],["表示不同视图",{"2":{"464":2}}],["表示不同尺度",{"2":{"464":2}}],["表示以点",{"2":{"450":1}}],["表示展平操作",{"2":{"427":1}}],["表示加权的frobenius范数",{"2":{"390":1}}],["表示顶点",{"2":{"390":1}}],["表示变形图中网格或姿态顶点",{"2":{"390":1}}],["表示变形图中顶点",{"2":{"390":1}}],["表示1个batch中所有点的数量",{"2":{"357":1}}],["表示与利用",{"2":{"231":1}}],["表示下一个时间点",{"2":{"221":1}}],["表示某一个时间点",{"2":{"221":1}}],["表示mapping",{"2":{"221":1}}],["表示判别器",{"2":{"221":1}}],["表示生成器",{"2":{"221":1}}],["表示为",{"2":{"998":1}}],["表示为p和q",{"2":{"466":1}}],["表示为点云或网格",{"2":{"190":1}}],["表示为一个1000维数向量",{"2":{"13":1}}],["表示中这个过程很简单",{"2":{"190":1}}],["表示第$",{"2":{"844":1}}],["表示第",{"2":{"153":1,"357":1,"656":1,"699":1,"738":1,"766":1,"844":1,"863":1}}],["表示两个随机变量之间的互信息",{"2":{"137":1}}],["表示任务列表",{"2":{"137":1}}],["表示",{"2":{"116":1,"123":2,"137":1,"235":1,"357":1,"603":1,"660":1,"694":1,"712":1,"724":1,"752":1,"782":1,"808":1,"908":1,"916":1,"967":1}}],["表示创建",{"2":{"26":1}}],["赋予模型常识关联",{"2":{"128":1}}],["学生模型接收多视角图像输入",{"2":{"642":1}}],["学校",{"0":{"872":1},"2":{"605":6,"796":2,"855":1,"872":3,"947":1}}],["学术界的",{"2":{"302":1}}],["学习每点特征",{"2":{"974":1}}],["学习率通过多步调度器进行衰减",{"2":{"867":1}}],["学习率通过多步调度器衰减",{"2":{"744":1}}],["学习率设置为",{"2":{"853":1}}],["学习率在前500次迭代中逐渐升温至最大值2e",{"2":{"822":1}}],["学习率在前1000次迭代中逐渐升温至最大值2e",{"2":{"813":1}}],["学习率",{"2":{"764":1}}],["学习率为1e",{"2":{"770":1}}],["学习率为",{"2":{"761":1}}],["学习率分别设置为",{"2":{"677":1}}],["学习大小为n2",{"2":{"730":1}}],["学习二元",{"2":{"684":1}}],["学习如何有效地探索场景并仅使用",{"2":{"668":1}}],["学习到的特征被进一步输入到一个有效的2dcnn中",{"2":{"664":1}}],["学习到数据的分布",{"2":{"129":1}}],["学习具有代表性的强潜在胶囊",{"2":{"664":1}}],["学习y^=f",{"2":{"632":1}}],["学习场景的连续隐式表达",{"2":{"619":1}}],["学习有效的表示方法是完成这一挑战性任务的基础步骤",{"2":{"612":1}}],["学习一个以自我为中心的投影",{"2":{"495":1}}],["学习的",{"2":{"481":1}}],["学习的文本编码器通过嵌入目标数据集类的名称或描述来合成零样本线性分类器",{"2":{"184":1}}],["学习式聚合",{"2":{"435":1}}],["学习通用视觉与语言先验",{"2":{"417":1}}],["学习安全",{"2":{"388":1}}],["学习潜在世界模型",{"2":{"308":1}}],["学习方法必须去除高频细节将数据封装到抽象表示中",{"2":{"270":1}}],["学习记录",{"2":{"99":1}}],["学院",{"2":{"126":1,"302":1}}],["大语言模型",{"2":{"1006":1}}],["大尺度的",{"2":{"996":1}}],["大大减少了手动注释的负担",{"2":{"941":1}}],["大大减少了参数的数目",{"2":{"511":1}}],["大模型局限",{"2":{"864":1}}],["大量实验证明了该方法在精度",{"2":{"831":1}}],["大量工作集中在解析2d地图",{"2":{"172":1}}],["大核密集卷积由于没有空间聚合能力",{"2":{"824":1}}],["大训练数据",{"2":{"824":1}}],["大家虽然看到了transformer在视觉领域的强大潜力",{"2":{"631":1}}],["大家指标都刷的很高",{"2":{"220":1}}],["大型五层建筑数据集的定性结果包括在视频附件中",{"2":{"462":1}}],["大llm常冻结",{"2":{"417":1}}],["大规模环境中保持计算效率与一致性",{"2":{"881":1}}],["大规模环境扩展",{"2":{"588":1}}],["大规模真实环境中难以获取精确",{"2":{"846":1}}],["大规模真实环境真值地图的采集耗时或不现实",{"2":{"826":1}}],["大规模模型中",{"2":{"764":1}}],["大规模模型和预训练技术的使用是我们成功的关键因素",{"2":{"520":1}}],["大规模日志行为克隆",{"2":{"388":1}}],["大规模的数据集",{"2":{"265":1}}],["大多数数据集仅包含2d语义分割标注",{"2":{"997":1}}],["大多数占用感知方法采用这种训练方式",{"2":{"985":1}}],["大多数多模态方法",{"2":{"970":1}}],["大多数当前的建图方法都假设环境是静态的",{"2":{"958":1}}],["大多数无注释方法使用2d渲染监督作为显式3d占用监督的补充",{"2":{"949":1}}],["大多数网格误差都很小",{"2":{"709":1}}],["大多数网络需要将点云采样降为固定的小尺寸",{"2":{"688":1}}],["大多数",{"2":{"670":1}}],["大多数高斯被归类为空",{"2":{"656":1}}],["大多数对象处于相同的水平水平面上",{"2":{"630":1}}],["大多数三维场景感知工作都是离线进行的",{"2":{"629":1}}],["大多数这些努力都局限于局部和离线预测",{"2":{"629":1}}],["大多数计算高效的设计针对仅视觉",{"2":{"517":1}}],["大多数方法采用",{"2":{"495":1}}],["大多数现有文献在机器人学中将动态目标建模为一个3d点",{"2":{"967":1}}],["大多数现有的激光雷达",{"2":{"444":1}}],["大多数现有方法依赖于复杂的损失函数组合",{"2":{"690":1}}],["大多数现有方法依赖于高分辨率图像和复杂网络来实现最优性能",{"2":{"392":1}}],["大多数现有方法采用单目深度估计",{"2":{"609":1}}],["大多数现有方法采用基于密集网格的场景表示",{"2":{"536":1}}],["大多数现有方法通过整合从视觉输入中提取的语义和深度信息来推导局部离线三维局部空间占用预测",{"2":{"600":1}}],["大多数现有方法通过扩展用于",{"2":{"349":1}}],["大多数现有方法都专注于从一个或几个视角进行离线感知",{"2":{"568":1}}],["大多数现有方法使用密集的网格",{"2":{"516":1}}],["大多数提案会被视为背景",{"2":{"434":1}}],["大多数关于多模态occ的研究工作",{"2":{"421":1}}],["大多数之前发布的数据集都专注于基于摄像头的目标检测",{"2":{"126":1}}],["大约需要10分钟",{"2":{"816":1}}],["大约10毫秒",{"2":{"816":1}}],["大约",{"2":{"254":1}}],["大奥特曼打小怪兽",{"2":{"207":1}}],["大小",{"2":{"146":1}}],["大小的单位为",{"2":{"136":1}}],["大体上",{"2":{"139":1}}],["大学等场所",{"2":{"126":1,"302":1}}],["大概率会提示你",{"2":{"66":1}}],["万",{"2":{"360":1}}],["万段视频",{"2":{"360":1}}],["万个关键帧的每个激光雷达点的标注",{"2":{"302":1}}],["万个关键帧中的",{"2":{"126":1}}],["万个点",{"2":{"173":1}}],["万个点云和",{"2":{"126":1}}],["万个目标边界框",{"2":{"126":1}}],["万次雷达扫描以及",{"2":{"126":1}}],["万次激光雷达扫描",{"2":{"126":1}}],["万张摄像头图像",{"2":{"126":1}}],["包含大规模的3d占用和3d占用流标注",{"2":{"997":1}}],["包含更多带有3d占用标签的标注帧",{"2":{"997":1}}],["包含来自环视雷达的稀疏",{"2":{"927":1}}],["包含来自kitti",{"2":{"757":1}}],["包含室外激光雷达扫描",{"2":{"853":1}}],["包含一个初始特征向量",{"2":{"789":1}}],["包含一类背景",{"2":{"463":1}}],["包含在波士顿和新加坡收集的1000个各种驾驶场景序列",{"2":{"781":1}}],["包含预热阶段",{"2":{"758":1}}],["包含超过",{"2":{"749":1}}],["包含700个场景用于训练和150个场景用于验证",{"2":{"736":1}}],["包含",{"2":{"652":1,"739":2,"853":1}}],["包含两层",{"2":{"632":1}}],["包含两个全连接",{"2":{"549":1}}],["包含两个阶段",{"2":{"377":1}}],["包含均值",{"2":{"547":1}}],["包含点的3d位置和强度",{"2":{"532":1}}],["包含三大模块",{"2":{"525":1}}],["包含相机1",{"2":{"355":1}}],["包含nuscenes",{"2":{"254":1,"534":1}}],["包含表面的体素",{"2":{"253":1}}],["包含了更丰富的场景信息",{"2":{"1000":1}}],["包含了",{"2":{"126":2}}],["包含所有",{"2":{"126":1}}],["包括语义",{"2":{"979":1}}],["包括语义和层次路径规划",{"2":{"973":1}}],["包括对象的材料类型和可供性",{"2":{"973":1}}],["包括里程计和循环闭合约束",{"2":{"967":1}}],["包括单目相机",{"2":{"967":1}}],["包括slam++",{"2":{"967":1}}],["包括s3dis",{"2":{"356":1,"996":1}}],["包括一个2d地图",{"2":{"961":1}}],["包括一个几何感知的占用编码器和一个语义感知的组解码器",{"2":{"875":1}}],["包括多视图和球形图像",{"2":{"955":1}}],["包括多个传感器",{"2":{"667":1}}],["包括视图转换",{"2":{"942":1}}],["包括均匀分布",{"2":{"934":1}}],["包括草地",{"2":{"899":1}}],["包括汽车",{"2":{"893":1}}],["包括几何损失",{"2":{"877":1}}],["包括类无关提议和类特定分割",{"2":{"875":1}}],["包括雨天和夜间条件",{"2":{"847":1}}],["包括前景和背景重新加权的",{"2":{"823":1}}],["包括从鸟瞰图",{"2":{"819":1}}],["包括11种有效语义",{"2":{"793":1}}],["包括16个常见类别和一个标记为",{"2":{"736":1}}],["包括pcm异常值拒绝和位姿图修剪",{"2":{"775":1}}],["包括通用物体类别",{"2":{"739":2}}],["包括网络流程",{"2":{"714":1}}],["包括理解被遮挡的区域",{"2":{"691":1}}],["包括骨干和颈部",{"2":{"680":1}}],["包括自编码",{"2":{"669":1}}],["包括两个intel",{"2":{"605":1}}],["包括真实生活",{"2":{"605":1}}],["包括任务相关对象和区域",{"2":{"586":1}}],["包括光度",{"2":{"579":1}}],["包括端到端自动驾驶",{"2":{"567":1}}],["包括需要对对象部分有大量理解的任务",{"2":{"553":1}}],["包括3d",{"2":{"535":1}}],["包括位置",{"2":{"516":1}}],["包括联合深度",{"2":{"490":1,"839":1}}],["包括具有挑战性的夜间和雨天场景",{"2":{"475":1}}],["包括具有挑战性的雨天和夜间场景",{"2":{"409":1,"438":1}}],["包括检测",{"2":{"455":1}}],["包括三个场景",{"2":{"437":1}}],["包括形状分类",{"2":{"420":1}}],["包括姿态顶点和网格顶点以及边",{"2":{"390":1}}],["包括代理姿态",{"2":{"380":1}}],["包括环路闭合",{"2":{"380":1}}],["包括机器车间",{"2":{"374":1}}],["包括五个楼层",{"2":{"374":1}}],["包括点块划分",{"2":{"340":1}}],["包括快速局部网格和全局语义注释网格",{"2":{"285":1}}],["包括四个主要模块",{"2":{"285":1}}],["包括描述环境中结构元素的节点",{"2":{"197":1}}],["包括人类",{"2":{"178":1}}],["包括材料和可供性",{"2":{"178":1}}],["包括基于规则的",{"2":{"172":1}}],["包括基于扩散头",{"2":{"145":1}}],["包括体积模型",{"2":{"172":1}}],["包括了脸型上面的表情",{"2":{"133":1}}],["包括我们自己的真实数据集和新的模拟数据集",{"2":{"131":1}}],["包括我们新发布的uhumans2数据集",{"2":{"105":1}}],["包括层次语义路径规划的示例",{"2":{"131":1}}],["包括公寓大楼",{"2":{"141":1}}],["包括公寓",{"2":{"131":1}}],["包括euroc数据集",{"2":{"131":1}}],["包括以下模块",{"2":{"131":1}}],["包括地点子图",{"2":{"125":1}}],["包括",{"2":{"109":1,"285":1,"749":1,"870":1,"979":1}}],["包括静态和动态实体及其关系",{"2":{"105":1}}],["包括instance",{"2":{"38":1}}],["月作为",{"2":{"302":1}}],["月",{"2":{"126":2}}],["年份",{"2":{"334":1,"360":1}}],["年开始显著兴起",{"2":{"139":1}}],["年",{"2":{"126":2,"302":1}}],["个小时",{"2":{"982":2}}],["个项目",{"2":{"982":2}}],["个非空特征",{"2":{"976":1}}],["个非空体素初始化高斯",{"2":{"563":1}}],["个最近邻",{"2":{"976":1}}],["个最近邻上定义的泰勒展开式的乘积",{"2":{"481":1}}],["个训练周期才能达到最佳性能",{"2":{"959":1}}],["个训练场景",{"2":{"739":1}}],["个特征",{"2":{"957":1}}],["个特征体viv",{"2":{"355":1}}],["个体重叠比率定义为",{"2":{"916":1}}],["个体素用于障碍物和碎石",{"2":{"828":1}}],["个自由度的卡方临界值",{"2":{"916":1}}],["个自由空间类别和",{"2":{"853":2}}],["个带姿态的图像",{"2":{"886":1}}],["个组",{"2":{"863":1}}],["个未知类别",{"2":{"853":2}}],["个使用",{"2":{"853":1}}],["个网格采样位置的偏移量",{"2":{"844":1}}],["个网格顶点",{"2":{"390":1}}],["个位置",{"2":{"844":1}}],["个采样点的调制标量",{"2":{"844":1,"863":1}}],["个采样点的投影权重",{"2":{"844":1}}],["个损失函数和标准交叉熵损失",{"2":{"834":1}}],["个样本",{"2":{"828":1}}],["个关键帧",{"2":{"749":1}}],["个序列",{"2":{"749":1}}],["个序列用于验证集",{"2":{"739":1}}],["个序列用于训练集",{"2":{"739":1}}],["个序列用于训练验证集",{"2":{"739":1}}],["个激光扫描仪",{"2":{"749":1}}],["个激光雷达扫描和",{"2":{"867":1}}],["个激光雷达扫描",{"2":{"828":1}}],["个激光雷达和",{"2":{"749":1}}],["个激光雷达",{"2":{"126":1,"652":1,"739":1}}],["个鱼眼相机",{"2":{"749":1}}],["个透视相机",{"2":{"749":1}}],["个噪声类别",{"2":{"749":1}}],["个噪声类别和",{"2":{"652":1}}],["个可能类别中的一个",{"2":{"749":1}}],["个可学习的查询向量",{"2":{"405":1}}],["个尺度的特征",{"2":{"746":1}}],["个环视雷达扫描作为每个数据样本",{"2":{"867":1}}],["个环视摄像头",{"2":{"739":2}}],["个环绕摄像头",{"2":{"652":1}}],["个测试场景",{"2":{"739":1}}],["个验证场景和",{"2":{"739":1}}],["个相同元素",{"2":{"904":1}}],["个相机的",{"2":{"853":1}}],["个相机",{"2":{"749":1}}],["个相机中的第",{"2":{"623":1}}],["个相邻体素组成的非重叠组",{"2":{"730":1}}],["个块",{"2":{"738":1}}],["个块中的连贯性",{"2":{"716":1}}],["个块中迭代细化高斯属性",{"2":{"716":1}}],["个块之后的特征图",{"2":{"143":1}}],["个不重叠的关系",{"2":{"707":1}}],["个查询和",{"2":{"700":1}}],["个通道来实现类似的性能",{"2":{"700":1}}],["个通道",{"2":{"700":1}}],["个高斯",{"2":{"914":1}}],["个高斯和",{"2":{"700":1}}],["个高斯进行初始化",{"2":{"563":1}}],["个连续图像的",{"2":{"700":1}}],["个3d高斯分布",{"2":{"693":1}}],["个周期的蒸馏",{"2":{"823":1}}],["个周期的训练",{"2":{"803":2}}],["个周期",{"2":{"677":2,"782":4,"803":1,"823":1}}],["个其他类别和",{"2":{"652":1}}],["个空类别和",{"2":{"749":1}}],["个空类别",{"2":{"652":2,"749":1}}],["个语义类别的室外激光雷达扫描注释",{"2":{"900":1}}],["个语义类别和",{"2":{"749":1}}],["个语义类别",{"2":{"652":2,"739":3,"749":1,"853":2}}],["个惯性测量单元",{"2":{"652":1,"749":1}}],["个级别第",{"2":{"623":1}}],["个稀疏卷积",{"2":{"595":1}}],["个假设点",{"2":{"524":1}}],["个姿态顶点和",{"2":{"390":1}}],["个深度",{"2":{"355":1}}],["个类别的真阳性",{"2":{"915":1}}],["个类别之一",{"2":{"652":1}}],["个类别",{"2":{"302":1,"652":1,"828":1,"853":2,"985":1}}],["个类别中的一个",{"2":{"302":1,"749":1}}],["个维度",{"2":{"278":1}}],["个多头输出",{"2":{"278":1}}],["个人移动工具",{"2":{"277":1,"534":1}}],["个背景类别",{"2":{"277":1,"302":1,"534":1}}],["个前景类别",{"2":{"277":1,"302":1,"534":1}}],["个目标类别提供了真值标签",{"2":{"277":1}}],["个目标类别标注了准确的",{"2":{"126":1}}],["个迭代器",{"2":{"196":1}}],["个",{"2":{"173":1,"489":1,"562":1,"739":1,"749":1,"766":1,"771":2,"789":1,"853":1,"959":2,"982":4}}],["个长距离雷达传感器",{"2":{"173":1}}],["个点patch对应的真实点patch",{"2":{"582":1}}],["个点的特征",{"2":{"357":1}}],["个点",{"2":{"173":1,"328":1,"623":1,"789":2}}],["个旋转激光雷达",{"2":{"173":1}}],["个时长为",{"2":{"157":1}}],["个值",{"2":{"153":1}}],["个任务分配了",{"2":{"153":1}}],["个任务",{"2":{"153":1}}],["个任务乘以",{"2":{"153":1}}],["个雷达和",{"2":{"652":1}}],["个雷达",{"2":{"126":1,"749":1}}],["个摄像头",{"2":{"126":1,"173":1}}],["个场景作为评估集",{"2":{"886":1}}],["个场景作为",{"2":{"886":1}}],["个场景用于测试",{"2":{"126":1}}],["个场景用于训练和验证",{"2":{"126":1,"652":1}}],["个场景中的",{"2":{"126":1}}],["个场景",{"2":{"126":1,"749":2}}],["个驾驶场景序列",{"2":{"652":1}}],["个驾驶场景",{"2":{"126":1}}],["道路标记以及左侧行驶与右侧行驶情况下的泛化能力",{"2":{"126":1}}],["植被",{"2":{"126":1,"277":1,"534":1,"700":1,"723":1,"975":1}}],["车道查询",{"2":{"644":1}}],["车道线检测等",{"2":{"601":1}}],["车道等语义元素的推理",{"2":{"123":1}}],["车",{"2":{"463":1}}],["车队规模学习以桥接研究原型与生产系统",{"2":{"538":1}}],["车队规模持续学习",{"2":{"507":1}}],["车队",{"2":{"360":1}}],["车队数据",{"2":{"334":1}}],["车协同",{"2":{"334":1}}],["车辆等移动目标时则显然不切实际",{"2":{"926":1}}],["车辆需即时识别红绿灯",{"2":{"864":1}}],["车辆和行人所在区域的密度更高",{"2":{"842":1}}],["车辆可上传简洁语言片段",{"2":{"507":1}}],["车辆状态",{"2":{"334":5,"360":1}}],["车辆",{"2":{"277":14,"534":11,"926":1}}],["车辆名称",{"2":{"254":1}}],["车辆或自行车",{"2":{"178":1}}],["车辆配置",{"0":{"173":1}}],["车辆类型",{"2":{"126":1}}],["交换两个同类型容器的元素",{"2":{"904":1}}],["交换两个同类型向量的数据",{"2":{"161":1}}],["交换的两个队列中包含元素的类型必须相同",{"2":{"854":1}}],["交并比",{"2":{"778":1}}],["交叉熵",{"2":{"985":1}}],["交叉熵损失和",{"2":{"823":1}}],["交叉熵损失",{"2":{"670":1,"782":1}}],["交叉注意力和自适应混合",{"2":{"957":1}}],["交叉注意力",{"2":{"942":1,"950":1,"976":1}}],["交叉注意机制捕获上下文信息",{"2":{"405":1}}],["交叉注意机制捕获实例信息并生成实例的",{"2":{"349":1}}],["交叉口",{"2":{"525":1}}],["交叉点之后的部分使用",{"2":{"181":1}}],["交叉点之前的部分使用",{"2":{"181":1}}],["交通灯",{"2":{"893":1}}],["交通语言",{"2":{"478":1}}],["交通俚语及法律约束力措辞覆盖仍薄",{"2":{"478":1}}],["交通情况不太复杂的郊区街道组成",{"2":{"302":1}}],["交通情况和意外行为",{"2":{"126":1}}],["交通锥和障碍物",{"2":{"893":1}}],["交通锥",{"2":{"277":1,"534":1,"723":1,"893":1}}],["交互问答任务里",{"2":{"698":1}}],["交互",{"2":{"417":1}}],["交互图像和边缘掩模特征是异构的",{"2":{"96":1}}],["交互特征比图像特征稀疏得多",{"2":{"96":1}}],["交互式分割",{"0":{"45":1},"1":{"54":1,"65":1,"75":1,"84":1,"96":1,"106":1,"117":1,"132":1}}],["团队开发的用于自动驾驶的公开大规模数据集",{"2":{"126":1}}],["甚至在所有方法中分别取得了第3和第4的优异排名",{"2":{"949":1}}],["甚至在某些使用",{"2":{"570":1}}],["甚至估计其语义类别",{"2":{"910":1}}],["甚至更优的cnn方案",{"2":{"824":1}}],["甚至表现出更好的性能",{"2":{"682":1}}],["甚至能够在相机视野之外合理地生成场景",{"2":{"539":1}}],["甚至是空文本",{"2":{"373":1}}],["甚至添加中间层",{"2":{"262":2}}],["甚至连完成该任务所需的基本技能也必须从零开始学习",{"2":{"252":1}}],["甚至假设事先已经构建了正确且完整的环境度量语义网格",{"2":{"125":1}}],["甚至方法一都没有安装过",{"2":{"66":1}}],["允许车辆与其他交通元素共享互补信息",{"2":{"969":1}}],["允许可视化人类轨迹和密集姿态",{"2":{"905":1}}],["允许我们确定每个模块对性能的影响",{"2":{"732":1}}],["允许更多的利用",{"2":{"599":1}}],["允许构建环境的持久表示",{"2":{"467":1}}],["允许网络选择网格的哪些部分与解决任务相关",{"2":{"466":1}}],["允许网络通过将5条边折叠成2条边并同时分解两个面来学习特定任务的池化",{"2":{"275":1}}],["允许通过",{"2":{"196":1}}],["允许语言规划器向独立低层pid或mpc栈分派子目标草图",{"2":{"195":1}}],["允许用户或代理提出",{"2":{"176":1}}],["允许实时操作",{"2":{"125":1}}],["允许进行属性类型检查",{"2":{"57":1}}],["捕捉更全面的场景理解",{"2":{"875":1}}],["捕捉了2d",{"2":{"658":1}}],["捕捉复杂形状并解决物体检测中的长尾缺陷问题",{"2":{"535":1}}],["捕捉点云的局部和全局上下文信息",{"2":{"331":1}}],["捕捉实体",{"2":{"116":1}}],["捕获的室内场景",{"2":{"853":1}}],["捕获的特征不足进一步复杂化了预测过程",{"2":{"828":1}}],["捕获长距离语义上下文",{"2":{"632":1}}],["捕获场景图中各层的统计数据",{"2":{"141":1}}],["捕获环境中的移动实体",{"2":{"125":1}}],["把大量空白空间一并保存",{"2":{"913":1}}],["把手机从笔记本旁边的桌面拿给我",{"2":{"913":1}}],["把物体检测置信度存入空间图",{"2":{"698":1}}],["把遮挡",{"2":{"650":1}}],["把实体作为层次图中的节点",{"2":{"648":1}}],["把下游任务比如说检测和分割留给以后的人去探索",{"2":{"631":1}}],["把神经场集成进",{"2":{"619":1}}],["把按当前位姿旋转后的观测与上一时刻的",{"2":{"495":1}}],["把特征直接映射到",{"2":{"495":1}}],["把深度的取值集中起来",{"2":{"440":1}}],["把当前观测的特征或预测融合进已有地图",{"2":{"435":1}}],["把cnn的feature",{"2":{"410":1}}],["把多个2维的张量凑成一个3维的张量",{"2":{"351":1}}],["把我留在餐厅桌子上的茶杯拿给我",{"2":{"125":1}}],["把杯子放到桌上",{"2":{"123":1}}],["构成了以视觉为中心的占用流程的基础",{"2":{"942":1}}],["构成了一个自包含模块",{"2":{"811":1}}],["构造模型的输入",{"2":{"124":1,"257":1}}],["构建模型",{"0":{"880":1},"1":{"896":1,"912":1}}],["构建同时衡量结构与语义保真度的统一基准",{"2":{"864":1}}],["构建鲁棒语义地图仍是机器人与具身智能的共同开放问题",{"2":{"864":1}}],["构建dsg可能需要大约30分钟",{"2":{"816":1}}],["构建拓扑图",{"2":{"816":1}}],["构建类似的层次化场景图",{"2":{"648":1}}],["构建的是",{"2":{"765":1}}],["构建的开放词汇地图与",{"2":{"765":1}}],["构建的3d占用预测数据集",{"2":{"757":1}}],["构建的混合地图包含",{"2":{"648":1}}],["构建的",{"2":{"636":1,"997":1}}],["构建统一的3d特征空间",{"2":{"595":1}}],["构建fpn",{"2":{"562":1}}],["构建hash表的最重要原因是我们在前面提到的在完成稀疏卷积后为了防止稀疏特征的塌缩失去几何特征的表示能力",{"2":{"530":1}}],["构建与维护都更简洁",{"2":{"525":1}}],["构建空间网格地图时",{"2":{"435":1}}],["构建精确且详尽的语义地图需要将来自相机",{"2":{"435":1}}],["构建姿态图的关键问题之一是将哪些节点归属于同一个人类随时间关联",{"2":{"419":1}}],["构建vla4ad策略涉及双重目标",{"2":{"388":1}}],["构建",{"2":{"378":1,"736":1,"742":1}}],["构建覆盖整个轨迹的准确全局3d网格",{"2":{"362":1}}],["构建一个稀疏卷积需要满足哪些要求",{"2":{"332":1}}],["构建特征体",{"0":{"330":1},"1":{"355":1,"383":1}}],["构建了密度和语义体积",{"2":{"988":1}}],["构建了更简洁且有用的地图表示",{"2":{"320":1}}],["构建了一个整体esdf环境",{"2":{"276":1}}],["构建了一个分层神经地图",{"2":{"121":1}}],["构建环境的语义地图",{"2":{"274":1}}],["构建3d场景图的层",{"2":{"210":1}}],["构建全局3d网格",{"2":{"131":1}}],["构建全局",{"2":{"125":1}}],["构建全稀疏架构",{"2":{"114":1}}],["构建和维护环境的语义地图对长期任务至关重要",{"2":{"80":1}}],["能复用已学到的通用表征",{"2":{"743":1}}],["能复用其他任务的预训练模型",{"2":{"274":1}}],["能见度描述",{"2":{"254":1}}],["能见度水平",{"2":{"254":1}}],["能见度也可能随着时间的推移而改变",{"2":{"254":1,"654":1}}],["能在动态现实环境中自主运行的系统的转变",{"2":{"123":1}}],["能够处理具有数百万个点的大规模点云",{"2":{"955":1}}],["能够带来更高的性能指标",{"2":{"928":1}}],["能够恢复薄元素",{"2":{"903":1}}],["能够预测出",{"2":{"901":1}}],["能够与短程或长程特征交互",{"2":{"844":1}}],["能够获得最佳的具身空间占用预测性能",{"2":{"833":1}}],["能够在bev空间中检测物体和车道线",{"2":{"821":1}}],["能够在真实机器人上支持任务执行",{"2":{"320":1}}],["能够全面感知车辆周围环境",{"2":{"770":1}}],["能够更全面地感知整个场景",{"2":{"703":1}}],["能够更好地保留传感器的细节几何信息",{"2":{"409":1}}],["能够直观地考察",{"2":{"698":1}}],["能够识别基于颜色的环境元素",{"2":{"691":1}}],["能够让相邻的两个窗口之间有了交互",{"2":{"631":1}}],["能够从图像中估计",{"2":{"570":1}}],["能够从单张",{"2":{"539":1}}],["能够生成既整体又逼真的场景感知",{"2":{"567":1}}],["能够生成空间一致",{"2":{"123":1}}],["能够以灵活的尺度和形状对物体进行建模",{"2":{"700":1}}],["能够以极少的额外计算成本将低分辨率数据超分辨到高分辨率空间",{"2":{"566":1}}],["能够以传感器速率运行",{"2":{"467":1}}],["能够执行",{"2":{"564":1}}],["能够有效地从图像输入中获得3d语义高斯分布",{"2":{"547":1}}],["能够有效的提升模型效果",{"2":{"258":1}}],["能够高效地将2d图像转换为3d高斯表示",{"2":{"486":1}}],["能够对点云数据进行特征提取和学习",{"2":{"456":1}}],["能够产生更准确",{"2":{"415":1}}],["能够将环境聚类成有意义的语义区域",{"2":{"320":1}}],["能够将环境中的3d原语聚类成与任务相关的对象和区域",{"2":{"98":1}}],["能够保留关于任务的足够信息",{"2":{"153":1}}],["能够正确地将室内建筑划分为房间",{"2":{"131":1}}],["能够正确地变形密集网格以执行回路闭合",{"2":{"131":1}}],["能够准确定位和跟踪对象和人类",{"2":{"131":1}}],["能够实时在嵌入式cpu上重建度量",{"2":{"131":1}}],["能够实时估计准确的3d度量",{"2":{"105":1}}],["训练其网络",{"2":{"1006":1}}],["训练了",{"2":{"982":2}}],["训练设置",{"2":{"853":1}}],["训练样本",{"2":{"803":1}}],["训练大规模模型需巨大计算资源",{"2":{"785":1}}],["训练大规模模型时",{"2":{"764":1}}],["训练细节",{"2":{"770":1}}],["训练阶段忽略相机不可见体素",{"2":{"764":1}}],["训练策略",{"0":{"834":1},"1":{"870":1,"887":1,"903":1,"917":1,"928":1,"945":1,"953":1,"960":1},"2":{"764":1}}],["训练和推理",{"2":{"761":1}}],["训练6个epoch的daocc",{"2":{"758":1}}],["训练基于视觉的3d占用预测模型可以描述为",{"2":{"712":1}}],["训练均在",{"2":{"677":1}}],["训练目标基于高斯热图的焦点损失",{"2":{"666":1}}],["训练速度",{"2":{"619":1}}],["训练神经场主要有两条思路",{"2":{"619":1}}],["训练模型时",{"2":{"585":1}}],["训练模型克隆数百万仿真演示",{"2":{"417":1}}],["训练时长为两天",{"2":{"867":1}}],["训练时长分别从64减少到32和从144减少到84",{"2":{"811":1}}],["训练时使用在线时序序列以提升效率",{"2":{"764":1}}],["训练时间为两天",{"2":{"744":1}}],["训练时",{"2":{"532":1}}],["训练数据达400m并取得与vit相当",{"2":{"824":1}}],["训练数据仅为随机采样图像",{"2":{"525":1}}],["训练数据等细节上进行了很多探究",{"2":{"106":1}}],["训练范式",{"0":{"417":1}}],["训练与评估策略",{"0":{"388":1},"1":{"417":1,"447":1}}],["训练起来非常慢",{"2":{"386":1}}],["训练集与评估集为imagenet",{"2":{"382":1}}],["训练集为ffhq",{"2":{"382":1}}],["训练集为图像对",{"2":{"329":1}}],["训练一个",{"2":{"525":1}}],["训练一个transformer来学习第一步里的离散编码向量序列间的关系",{"2":{"371":1}}],["训练一个这样的模型需要数百个v100卡满载天数",{"2":{"205":1,"428":1}}],["训练于80k极端案例片段",{"2":{"334":1}}],["训练过程",{"0":{"329":1}}],["训练程序会在合适的anchors中随机选取128个postive",{"2":{"321":1}}],["训练",{"0":{"281":1},"1":{"305":1,"330":1,"355":1,"383":1,"411":1,"440":1,"470":1,"499":1},"2":{"334":1,"632":1,"782":1,"853":1,"981":1}}],["训练任务专用的端到端模型已取得显著进展",{"2":{"252":1}}],["训练示例的正确配对",{"2":{"184":1}}],["训练的学习式",{"2":{"274":1}}],["训练的目标可以看作是在进行对比",{"2":{"184":1}}],["训练的时候用小patch",{"2":{"180":1}}],["训练gan需要达到纳什均衡",{"2":{"129":1}}],["训练端到端系统",{"2":{"123":1}}],["支持自动驾驶的进一步发展",{"2":{"1007":1}}],["支持自然语言描述的新颖物体",{"2":{"897":1}}],["支持自然语言开放查询且高度可解释",{"2":{"765":1}}],["支持3d占用标注",{"2":{"997":1}}],["支持更可靠的决策",{"2":{"826":1}}],["支持更丰富推理形式及与人类决策过程的对齐",{"2":{"176":1}}],["支持高层地标间推理",{"2":{"648":1}}],["支持开放词汇语义推理与文本驱动查询",{"2":{"619":1}}],["支持",{"2":{"619":1}}],["支持视觉定位",{"2":{"588":1}}],["支持了一系列新兴应用",{"2":{"567":1}}],["支持多模态训练",{"2":{"552":1}}],["支持多相机vqa与3d推理",{"2":{"360":1}}],["支持细粒度推理与人类对齐动作",{"2":{"360":1}}],["支持从高级规范",{"2":{"262":1}}],["支持括号内的类别",{"2":{"254":1}}],["支持检测",{"2":{"123":1}}],["支持分层决策制定和规划要求机器人感知能够构建一系列一致的抽象层次",{"2":{"116":1}}],["障碍物和碎石类别在测试集中的出现频率极低",{"2":{"828":1}}],["障碍物",{"2":{"123":1,"277":1,"534":1,"828":1,"893":1}}],["拿起杯子",{"2":{"123":1}}],["要完成",{"2":{"913":1}}],["要忘记图1中的一个房间",{"2":{"905":1}}],["要在机器人与具身智能中真正落地",{"2":{"897":1}}],["要解决的问题",{"0":{"695":1}}],["要简单得多",{"2":{"693":1}}],["要通过正则化来得到一个概率体",{"2":{"440":1}}],["要加少强度的噪声",{"0":{"291":1}}],["要么错误地估计了他们的数量",{"2":{"952":1}}],["要么无法识别他们",{"2":{"952":1}}],["要么排名第二",{"2":{"903":1}}],["要么表现最佳",{"2":{"903":1}}],["要么就是把图片画成一个一个的小窗口",{"2":{"631":1}}],["要么就是把图片打成",{"2":{"631":1}}],["要么kimera",{"2":{"390":2}}],["要么使用teaser++",{"2":{"285":1}}],["要么为未知形状的对象估计一个边界框",{"2":{"285":1}}],["要么计算成本太高",{"2":{"137":1}}],["要想访问",{"2":{"217":1}}],["要做的事就是对隐藏空间",{"2":{"149":1}}],["要求按特定顺序依次导航至多个物体",{"2":{"139":1}}],["要求导航至某一物体类别的任意实例",{"2":{"139":1}}],["要求智能体执行交互动作以改变环境中其他对象的状态",{"2":{"139":1}}],["要求智能体采取行动在环境中移动",{"2":{"139":1}}],["要求智能体高效地遍历环境",{"2":{"139":1}}],["要求智能体完成一系列相互关联的任务而非孤立动作",{"2":{"123":1}}],["要自己实现",{"2":{"52":1}}],["已建图区域占整个环境的百分比",{"2":{"826":1}}],["已有研究分别从以下角度开展评估",{"2":{"826":1}}],["已有多种鸟瞰图",{"2":{"520":1}}],["已更新高斯分布的置信度值",{"2":{"813":1}}],["已在基于视觉的",{"2":{"808":1}}],["已在具身智能领域催生出一系列新工作",{"2":{"765":1}}],["已展现出复杂任务规划能力",{"2":{"765":1}}],["已探索用逐元素",{"2":{"698":1}}],["已探索",{"2":{"698":2}}],["已探索区域或检测目标的语义标签",{"2":{"274":1}}],["已针对相机和雷达的融合进行了各种研究",{"2":{"653":1}}],["已被广泛综述",{"2":{"714":1}}],["已被广泛运用于各类机器人任务和",{"2":{"588":1}}],["已被现代强化学习系统如",{"2":{"123":1}}],["已成为推动该领域前进的关键",{"2":{"864":1}}],["已成为三维感知领域的一个重要任务",{"2":{"568":1}}],["已成为最先进的方法",{"2":{"123":1}}],["已访问位置",{"2":{"525":1}}],["已访问区域追踪",{"2":{"435":1}}],["已知形状的对象",{"2":{"449":2}}],["已知相机姿态",{"2":{"435":1}}],["已经开始从动态点云中学习时空信息",{"2":{"996":1}}],["已经探索的",{"2":{"905":1}}],["已经证明",{"2":{"866":1}}],["已经证明了使用密集占用作为真实标签的重要性",{"2":{"735":1}}],["已经引起了研究人员的广泛关注",{"2":{"665":1}}],["已经涉及了从单目图像中估计三维信息的问题",{"2":{"603":1}}],["已经扩展为一个自下而上的聚类方法",{"2":{"121":1}}],["已经与基础模型结合",{"2":{"121":1}}],["放入getoffset",{"2":{"561":1}}],["放大视图",{"2":{"162":1}}],["放置等成功百分比",{"2":{"806":1}}],["放置",{"2":{"123":1}}],["放我们下载的驱动文件",{"2":{"66":1}}],["框架的有效性",{"2":{"977":1}}],["框架的总体架构",{"2":{"502":1}}],["框架中动态融合",{"2":{"971":1}}],["框架中多尺度机制的消融研究结果",{"2":{"971":1}}],["框架消融研究",{"0":{"971":1}}],["框架效率研究",{"0":{"965":1}}],["框架训练收敛速度研究",{"0":{"959":1}}],["框架定性分析",{"0":{"952":1}}],["框架进行了消融研究",{"2":{"928":1}}],["框架内统一研究",{"2":{"435":1}}],["框架基于",{"2":{"384":1}}],["框架",{"0":{"598":1},"1":{"627":1,"655":1,"680":1,"703":1,"726":1},"2":{"123":1,"197":1,"539":1,"632":1}}],["蒙特卡洛定位",{"2":{"123":1}}],["建模目标分解为几何和语义预测",{"2":{"681":1}}],["建立了一个新的4d占用预测基准",{"2":{"975":1}}],["建立统一",{"2":{"943":1}}],["建立rulebook",{"0":{"561":1}}],["建立输入哈希表",{"0":{"530":1}}],["建立映射关系",{"2":{"482":1}}],["建立一个置换不变",{"2":{"420":1}}],["建好完整地图",{"2":{"435":1}}],["建筑车辆",{"2":{"893":2}}],["建筑",{"2":{"522":1,"617":1,"648":1,"903":1}}],["建筑工人",{"2":{"277":1,"534":1}}],["建筑物z的房间",{"2":{"947":1}}],["建筑物不同楼层上的两个相同房间",{"2":{"390":1}}],["建筑物节点有边指向建筑物中的所有房间",{"2":{"240":1}}],["建筑物等",{"2":{"125":1}}],["建筑物等高层次的语义",{"2":{"112":1}}],["建筑物",{"0":{"240":1},"2":{"105":1,"147":1,"262":1,"301":1,"796":1}}],["建图过程中还需考虑其他关键维度",{"2":{"435":1}}],["建图过程要求智能体在空间中移动",{"2":{"435":1}}],["建图",{"2":{"435":1}}],["建图器通常将当前地图与上一时刻地图进行聚合",{"2":{"274":1}}],["建图器负责利用编码后的图像特征与智能体位姿",{"2":{"274":1}}],["建图器",{"2":{"274":2}}],["建图准确性以及长期鲁棒性",{"2":{"155":1}}],["建图与操作的复杂现实能力",{"2":{"123":1}}],["围绕构建物理场景的基础模型理论",{"2":{"121":1}}],["执行器噪声",{"2":{"826":1}}],["执行器等",{"2":{"100":1}}],["执行的评估方法",{"2":{"492":1}}],["执行场景图后端优化",{"2":{"408":1}}],["执行诸如特征检测和跟踪",{"2":{"408":1}}],["执行左右立体匹配",{"2":{"310":1}}],["执行任务驱动的对象和区域聚类",{"2":{"168":1}}],["执行视觉回路闭合",{"2":{"131":1}}],["执行开放词汇映射",{"2":{"121":1}}],["几种有代表性的方法如图10所示",{"2":{"948":1}}],["几个连续的relu+batchnorm+meshconv层和一个残差连接和另一个relu组成",{"2":{"526":1}}],["几个特性",{"2":{"217":1}}],["几何感知",{"2":{"998":1}}],["几何感知的占用编码器通过显式",{"2":{"875":1}}],["几何损失",{"2":{"985":1}}],["几何特征",{"2":{"968":1}}],["几何结构和语义信息",{"2":{"953":1}}],["几何与语义覆盖是否充分",{"2":{"943":1}}],["几何一致性",{"2":{"826":1}}],["几何覆盖",{"2":{"826":1}}],["几何完整度",{"2":{"826":1}}],["几何和语义信息",{"2":{"971":1}}],["几何和语义亲和力损失",{"2":{"782":1}}],["几何和物理",{"2":{"116":1}}],["几何重建",{"0":{"686":1},"1":{"709":1}}],["几何预测",{"2":{"681":1}}],["几何匹配",{"2":{"648":1}}],["几何约束测量多个视图之间的深度一致性",{"2":{"592":1}}],["几何约束",{"0":{"592":1}}],["几何之上",{"2":{"556":1}}],["几何房间分割准确性比较",{"2":{"522":1}}],["几何验证来拒绝异常回路闭合",{"2":{"390":1}}],["几何节点属性",{"2":{"262":1}}],["几何",{"2":{"189":1,"935":1}}],["几项工作将开放集检测纳入场景的3d地图中",{"2":{"121":1}}],["聚类所有对象片段",{"2":{"271":1}}],["聚类和划分对象",{"2":{"121":1}}],["聚合",{"2":{"698":1}}],["聚合过程忽略了重叠问题",{"2":{"567":1}}],["聚合为课程更新",{"2":{"507":1}}],["聚合语义信息并忽略其具体值",{"2":{"378":1}}],["聚合权重",{"2":{"303":1}}],["聚合成",{"2":{"303":1}}],["聚合ib计算聚类",{"2":{"153":1}}],["聚合ib算法要求定义条件概率p",{"2":{"153":1}}],["聚合ib方法是一种自下而上的合并方法",{"2":{"153":1}}],["聚合信息瓶颈",{"2":{"153":1}}],["聚焦于语义地图构建方法",{"2":{"90":1}}],["聚焦于语义地图构建方法本身",{"2":{"90":1}}],["兼容的ade20k",{"2":{"437":1}}],["兼容属性设置为",{"2":{"120":1}}],["兼容性错误",{"2":{"107":1}}],["兼容性问题",{"2":{"40":1,"67":1}}],["接收位置",{"2":{"619":1}}],["接着",{"2":{"271":1,"285":1,"369":1,"576":1,"746":1}}],["接着输出了",{"2":{"48":1}}],["接下来大家都上",{"2":{"631":1}}],["接下来的两个线程以较慢的速率运行",{"2":{"285":1}}],["接下来",{"2":{"210":1,"274":1,"421":1,"544":1,"609":2,"786":1,"799":1,"826":1,"876":1,"886":1,"916":1,"985":1}}],["接口兼容问题",{"2":{"120":1}}],["库",{"2":{"120":1}}],["首次使用广泛使用的nuscenes数据集",{"2":{"975":1}}],["首次实现了从单目",{"2":{"937":1}}],["首次提出了语义场景补全问题",{"2":{"841":1}}],["首次到达该节点的时间步",{"2":{"698":1}}],["首次定义了",{"2":{"603":1}}],["首次探索了高效融合网络",{"2":{"517":1}}],["首次评估了3d点云的高级表达在不同场景中的转移性",{"2":{"265":1}}],["首个仅使用单张",{"2":{"570":1}}],["首个将",{"2":{"414":1}}],["首个高性能交互式自动标注工具",{"2":{"117":1}}],["首先优化姿态图",{"2":{"967":1}}],["首先从点云中分层抽象出不同级别的几何关系",{"2":{"962":1}}],["首先从单位球随机采样均匀分布的基点集",{"2":{"664":1}}],["首先在不同级别构建图像特征",{"2":{"922":1}}],["首先估计前视图像的深度",{"2":{"821":1}}],["首先第一个问题是为什么需要roi",{"2":{"741":1}}],["首先对点云应用mlp来去提取点独立性特征",{"2":{"664":1}}],["首先基于局部线索",{"2":{"636":1}}],["首先介绍fb",{"2":{"585":1}}],["首先来看如何构建getoffset",{"2":{"561":1}}],["首先集成的是深度分支",{"2":{"544":1}}],["首先通过处理激光雷达点云生成占用标签",{"2":{"988":1}}],["首先通过逐像素深度估计和反向投影计算粗略的3d特征体积",{"2":{"950":1}}],["首先通过视图变换从图像特征生成场景的显式3d体素特征",{"2":{"941":1}}],["首先通过圆柱坐标系中的体素化和空间池化操作将其转换为三视角特征",{"2":{"858":1}}],["首先通过一个多层感知机",{"2":{"621":1}}],["首先通过",{"2":{"561":1}}],["首先通过rpn生成约20000个anchor",{"2":{"493":1}}],["首先通过目标检测的方法找出实例所在的区域",{"2":{"138":1}}],["首先投影一个点云以获得旋转不变的表示",{"2":{"420":1}}],["首先建立一个邻域图",{"2":{"410":1}}],["首先根据当前的s",{"2":{"372":1}}],["首先将点云划分为一组占用体素",{"2":{"962":1}}],["首先将点云划分为平行的波束",{"2":{"664":1}}],["首先将",{"2":{"955":1}}],["首先将当前bev特征与之前的bev特征进行交互",{"2":{"858":1}}],["首先将3d坐标投影到每个视图上",{"2":{"858":1}}],["首先将图片输入到patch",{"2":{"659":1}}],["首先将由不同视角共享的相机视锥空间离散化为网格坐标",{"2":{"369":1}}],["首先将待分割的图像和用户标注作为输入传入分割框架中进行前向传播得到初始分割结果",{"2":{"75":1}}],["首先使用多个相机位置生成点云的多个",{"2":{"955":1}}],["首先使用2d骨干网络提取图像特征",{"2":{"875":1}}],["首先使用2d骨干网络从视觉输入中提取图像特征",{"2":{"839":1,"858":1}}],["首先使用混合网格八叉树结构分层地划分点云",{"2":{"363":1}}],["首先使用共享的卷积层为全图提取特征",{"2":{"296":1}}],["首先利用一组视图上的相互关系",{"2":{"337":1}}],["首先我们在每一步去噪的时候",{"2":{"312":1}}],["首先需要构建一个图",{"2":{"271":1}}],["首先还是采用selective",{"2":{"250":1}}],["首先校正机器人轨迹",{"2":{"190":1}}],["首先模型输入为一张图片",{"2":{"169":1}}],["首先进行像素级别的语义分割",{"2":{"138":1}}],["首先",{"2":{"82":1,"131":1,"137":1,"184":1,"276":1,"301":1,"325":1,"419":1,"421":1,"449":1,"462":1,"467":1,"505":1,"520":1,"530":1,"535":1,"553":1,"567":1,"578":1,"632":1,"656":1,"665":1,"694":1,"732":1,"746":2,"833":1,"876":1,"931":1,"973":1,"991":1}}],["首先输入以下命令停用",{"2":{"33":1}}],["小型交通锥也在我们的预测占据结果中观察到",{"2":{"791":1}}],["小型和大型",{"2":{"541":1,"605":1}}],["小结",{"0":{"688":1,"931":1,"951":1,"979":1,"996":1},"2":{"495":1,"525":1,"864":1}}],["小时",{"2":{"173":1}}],["小时的驾驶数据",{"2":{"157":1}}],["小目标",{"2":{"117":1}}],["小厨房",{"2":{"109":1}}],["问答等多样化下游任务",{"2":{"881":1}}],["问答对",{"2":{"360":1}}],["问答",{"2":{"360":3}}],["问题陈述",{"0":{"724":1}}],["问题可以表述为",{"2":{"590":1}}],["问题描述",{"0":{"590":1}}],["问题2",{"2":{"554":1}}],["问题1",{"2":{"554":1}}],["问题从建图流程中剥离出来单独处理",{"2":{"435":1}}],["问题",{"0":{"207":1,"245":1,"343":1,"554":1},"1":{"267":1,"291":1,"316":1},"2":{"137":1,"341":1,"525":1,"603":1,"632":1,"668":1}}],["问题表述",{"0":{"137":1}}],["问题就出在",{"2":{"117":1}}],["问你",{"2":{"66":2}}],["问你装32",{"2":{"66":2}}],["错过了",{"2":{"961":1}}],["错过了多个抽象层次",{"2":{"116":1}}],["错误累积会造成语义漂移",{"2":{"864":1}}],["错误对象",{"2":{"522":1}}],["错误原因",{"2":{"48":1}}],["先在固定类别上做语义分割",{"2":{"826":1}}],["先将特征地面投影",{"2":{"743":1}}],["先前的",{"2":{"704":1}}],["先前的工作集中在2d场景图上",{"2":{"116":1}}],["先使用一个w",{"2":{"659":1}}],["先离线构建混合地图",{"2":{"648":1}}],["先用类无关的",{"2":{"765":1}}],["先用类无关的区域提议网络",{"2":{"765":1}}],["先用粗粒度拓扑地图校正全局里程计误差",{"2":{"648":1}}],["先用内参把像素反投影到相机坐标系",{"2":{"495":1}}],["先学习观测的无监督表示",{"2":{"525":1}}],["先计算两张图像对应位置在",{"2":{"525":1}}],["先尝试将当前帧定位到上一时刻的图中节点",{"2":{"525":1}}],["先编码图像→投影到地面→在",{"2":{"495":1}}],["先把图像特征投影成",{"2":{"495":1}}],["先探索环境",{"2":{"435":1}}],["先补全低频信息再到高频信息",{"2":{"264":1,"266":1}}],["先丢失高频信息再丢失低频信息",{"2":{"264":1,"266":1}}],["先经过low",{"2":{"220":1}}],["先设置容器root用户密码",{"2":{"78":1}}],["关注其准确性",{"2":{"786":1}}],["关于鲁棒3d占用的研究有限",{"2":{"1005":1}}],["关于行人的体素描述",{"2":{"791":1}}],["关于这一主题的全面综述可以参考文献",{"2":{"603":1}}],["关于大规模模型和预训练对占据预测任务影响的研究仍有限",{"2":{"520":1}}],["关于监督预训练",{"2":{"366":1}}],["关于度量",{"2":{"116":1}}],["关键思想是首先从bev和tpv视角学习",{"2":{"908":1}}],["关键思想是生成器的中间特征非常有辨别力",{"2":{"143":1}}],["关键挑战",{"0":{"799":1}}],["关键能力之一是理解周围环境",{"2":{"667":1}}],["关键的洞察是",{"2":{"480":1}}],["关键词",{"2":{"475":1,"610":1,"637":1}}],["关键开放问题是如何融合驾驶奖励与语言保真",{"2":{"417":1}}],["关键帧以2hz的频率标注",{"2":{"781":1}}],["关键帧",{"2":{"285":1}}],["关联起来",{"2":{"770":1}}],["关联容器如",{"2":{"177":1}}],["关联vla与传统端到端驾驶",{"2":{"82":1}}],["关系能力",{"2":{"935":1}}],["关系矩阵ama",{"2":{"752":1}}],["关系矩阵与重塑后的超体素特征相乘",{"2":{"752":1}}],["关系如",{"2":{"684":1}}],["关系",{"2":{"197":1,"707":1}}],["关系紧密",{"2":{"155":1}}],["关系层面上的推理对于解析高级指令",{"2":{"116":1}}],["之所以这么说",{"2":{"631":1}}],["之外",{"2":{"552":1,"806":1}}],["之后",{"2":{"372":1,"746":1,"748":1,"898":1,"941":1,"975":1,"976":1}}],["之后每一步都更新未掩码区域为前向的记录部分",{"2":{"312":1}}],["之后就是fast",{"2":{"296":1}}],["之前",{"2":{"753":1}}],["之前更新过的高斯分布可以为当前帧的更新提供高置信度的信息",{"2":{"600":1}}],["之前标好的头发区域也会被完全重新预测",{"2":{"117":1}}],["之前的方法也不能在已有的略带瑕疵的掩膜上进行修改",{"2":{"117":1}}],["之前的方法根本不能和其他工具配合",{"2":{"117":1}}],["之前的方法没有兼容性",{"2":{"117":1}}],["之前的方法太重了",{"2":{"117":1}}],["之前提出的",{"2":{"116":1}}],["之间取得平衡",{"2":{"897":1}}],["之间存在强烈的相互作用",{"2":{"853":1}}],["之间存在很强的相互作用",{"2":{"778":1}}],["之间显著变窄",{"2":{"796":1,"872":1}}],["之间添加边",{"2":{"480":2}}],["之间添加循环闭合时发生变形",{"2":{"390":1}}],["之间振荡",{"2":{"437":1}}],["之间有一个假定的环路闭合之后",{"2":{"352":1}}],["之间",{"2":{"31":1,"351":1,"796":1,"872":1}}],["之间的重建误差",{"2":{"988":1}}],["之间的关系",{"2":{"967":1}}],["之间的性能差异逐渐扩大",{"2":{"944":1}}],["之间的语义关系",{"2":{"935":1}}],["之间的定性比较",{"2":{"924":1}}],["之间的大差距部分是由于深度精度较低",{"2":{"917":1}}],["之间的元素",{"2":{"904":1}}],["之间的信息流动",{"2":{"660":1}}],["之间的",{"2":{"582":1,"694":1}}],["之间的相对位姿测量",{"2":{"171":1}}],["之间的互信息",{"2":{"137":1,"153":3}}],["之间的互信息来奖励压缩表示的任务相关性",{"2":{"137":1}}],["之间的互信息来压缩",{"2":{"137":1}}],["之间的时空关系",{"2":{"116":1}}],["之间的近似程度",{"2":{"13":1}}],["之间的三个比较衡量",{"2":{"8":1}}],["深度传感器获取的点云通常是巨大的",{"2":{"996":1}}],["深度传感器等多种来源的数据进行整合",{"2":{"435":1}}],["深度学习技术的快速发展使得从2d视觉实现3d占用感知成为可能",{"2":{"942":1}}],["深度学习革命",{"2":{"116":1}}],["深度一致性损失对齐渲染光线的终止分布",{"2":{"941":1}}],["深度可以作为选择占用查询的有价值先验",{"2":{"875":1}}],["深度",{"2":{"864":2}}],["深度监督策略也通过确保每个中间细化步骤都有助于3d感知",{"2":{"842":1}}],["深度信息尤其关键",{"2":{"934":1}}],["深度信息将显著有助于局部和具身空间占用预测",{"2":{"833":1}}],["深度信息不仅影响高斯分布的均值",{"2":{"705":1}}],["深度网络预测80个离散深度类别",{"2":{"764":1}}],["深度感知层是一个3层mlp",{"2":{"813":1}}],["深度感知层是一个多层感知机",{"2":{"705":1}}],["深度感知分支中使用的深度预测网络是一个微调的depthanythingv2模型",{"2":{"813":1}}],["深度感知分支的动机",{"2":{"705":1}}],["深度感知分支",{"2":{"705":1}}],["深度模糊一直是限制单目设置下室内空间占用预测模型性能的核心挑战之一",{"2":{"705":1}}],["深度损失",{"2":{"690":1}}],["深度特征通过激光雷达生成的3d点云进行监督",{"2":{"649":1}}],["深度bin之间的间隔",{"2":{"649":1}}],["深度bin的间隔",{"2":{"621":1}}],["深度bin的设置是为了将深度信息从连续值转换为可处理的离散形式",{"2":{"621":1}}],["深度bin是将连续的深度值划分为一系列离散的区间",{"2":{"621":1}}],["深度bin",{"2":{"621":1}}],["深度分布特征以及每个深度bin坐标",{"2":{"621":1}}],["深度分布特征通过激光雷达点云进行深度监督",{"2":{"621":1}}],["深度估计模块的消融研究",{"2":{"882":1}}],["深度估计模块",{"0":{"649":1}}],["深度估计",{"2":{"566":1}}],["深度图还用于合成环绕图像以进行自监督",{"2":{"941":1}}],["深度图融合",{"0":{"650":1}}],["深度图等",{"2":{"570":1,"632":1}}],["深度图滤波",{"0":{"560":1},"1":{"592":1,"622":1}}],["深度图优化",{"2":{"470":1}}],["深度图初始估计",{"0":{"470":1}}],["深度d计算得到",{"2":{"355":1}}],["深度3d条件生成模型",{"2":{"247":1}}],["深入地了解",{"2":{"209":1}}],["深入探讨其设计选择",{"2":{"90":1}}],["深井蛙i的博客",{"2":{"149":1}}],["运动预测",{"2":{"1003":1}}],["运动规划和反应性控制所需的信息",{"2":{"116":1}}],["运用于三维点云的体素表示上",{"2":{"363":1}}],["运算符进行重载",{"2":{"217":1}}],["运行速度为毫秒级",{"2":{"816":1}}],["运行时效率和内存成本方面优于先前的最先进方法",{"2":{"505":1}}],["运行时间比较",{"0":{"859":1}}],["运行时间线性增加",{"2":{"437":1}}],["运行时间评估",{"2":{"437":1}}],["运行的过程",{"2":{"408":3}}],["运行捆绑射线投射",{"2":{"362":1}}],["运行bash脚本文件出现",{"2":{"48":1}}],["运行",{"0":{"34":1,"152":1}}],["运行以下命令行",{"2":{"32":1}}],["方面存在困难",{"2":{"989":1}}],["方面也显著提升",{"2":{"952":1}}],["方面仍不理想",{"2":{"700":1}}],["方面表现出色",{"2":{"700":1,"827":1}}],["方面取得了改进结果",{"2":{"678":1}}],["方面取得了前所未有的进展",{"2":{"116":1}}],["方向上为",{"2":{"900":4}}],["方向分类损失",{"2":{"651":1}}],["方向取最大的概率和",{"2":{"622":1}}],["方向计算四个邻域的概率和",{"2":{"622":1}}],["方形节点",{"2":{"480":1}}],["方差越小",{"2":{"411":1}}],["方差",{"2":{"208":3}}],["方法层面",{"0":{"969":1}}],["方法结合",{"2":{"963":1}}],["方法访问",{"2":{"904":1}}],["方法论",{"0":{"877":1},"1":{"894":1,"910":1,"923":1,"933":1,"942":1,"950":1,"957":1,"964":1,"970":1,"976":1}}],["方法更强的适应性",{"2":{"827":1}}],["方法更强的鲁棒性",{"2":{"827":1}}],["方法和任务的角度提出了几个可能显著推动基于视觉的3d占用预测领域的重要研究方向",{"2":{"956":1}}],["方法和任务的角度为3d占用预测提供了一些启发性的未来展望",{"2":{"665":1}}],["方法和基于",{"2":{"564":1}}],["方法使用对抗性训练来指导真实感",{"2":{"603":1}}],["方法不同",{"2":{"539":1}}],["方法涵盖从点云bev投影到3d",{"2":{"478":1}}],["方法类似",{"2":{"456":1}}],["方法来过滤由感知别名引起的错误回路闭合",{"2":{"390":1}}],["方法返回的迭代器",{"2":{"196":1}}],["方法",{"0":{"192":1,"225":1,"288":1,"348":1,"371":1,"424":1,"502":1,"551":1,"581":1,"632":1,"830":1,"857":1},"1":{"212":1,"234":1,"245":1,"255":1,"267":1,"278":1,"291":1,"303":1,"313":1,"316":1,"328":1,"339":1,"342":1,"370":1,"376":1,"404":1,"433":1,"464":1,"494":1,"524":1,"532":1,"555":1,"563":1,"585":1,"587":1,"595":1,"613":1,"617":1,"618":1,"642":1,"646":1,"660":1,"670":1,"673":1,"684":1,"694":1,"697":1,"707":1,"730":1,"752":1,"773":1,"794":1,"814":1,"834":1,"874":1,"891":1},"2":{"256":1,"516":1,"522":1,"545":1,"570":1,"770":1,"827":1,"840":1,"965":1,"1000":1}}],["方程",{"2":{"153":1,"681":3}}],["方便卷积计算好数值之后将其放回原本tensor的位置",{"2":{"530":1}}],["方便",{"2":{"116":1}}],["厨房和客厅",{"2":{"605":1}}],["厨房",{"2":{"116":1,"218":1,"467":1}}],["购物袋",{"2":{"116":1}}],["幸存者",{"2":{"116":1}}],["计时性能快几个数量级",{"2":{"947":1}}],["计时",{"0":{"816":1},"2":{"947":1}}],["计划从波士顿到罗马的旅行",{"2":{"116":1}}],["计算渲染的rgb图像和目标rgb图像之间的光度差异",{"2":{"988":1}}],["计算预测深度和真实深度之间的对数差异作为尺度不变对数损失",{"2":{"985":1}}],["计算效率低下",{"2":{"958":1}}],["计算如下",{"2":{"916":1}}],["计算复杂性显著降低",{"2":{"908":1}}],["计算复杂度也没有增加",{"2":{"751":1}}],["计算复杂度不随环境大小增加",{"2":{"109":1}}],["计算交集",{"2":{"826":1}}],["计算得出",{"2":{"793":1}}],["计算得到p",{"2":{"13":1}}],["计算其邻域的半径",{"2":{"738":1}}],["计算友好性",{"2":{"665":1}}],["计算友好和标签高效三个角度结构性地总结了基于视觉的3d占用预测方法",{"2":{"665":1}}],["计算匹配后的损失",{"2":{"651":1}}],["计算负担重",{"2":{"601":1}}],["计算开销高",{"2":{"588":1}}],["计算能力与",{"2":{"588":1}}],["计算两个视图",{"2":{"579":1}}],["计算两张图像的语义相似度",{"2":{"525":1}}],["计算每个非空体素的特征",{"2":{"563":1}}],["计算图像特征的余弦相似度",{"2":{"525":1}}],["计算高效的占据网络",{"0":{"517":1}}],["计算量很大",{"2":{"386":1}}],["计算量和整个图像像素点个数呈平方关系",{"2":{"386":1}}],["计算量太大了",{"2":{"386":1}}],["计算量大",{"2":{"386":1}}],["计算量巨大",{"2":{"235":1}}],["计算低延迟",{"2":{"285":1}}],["计算",{"2":{"285":1,"447":1}}],["计算出从摄像头到激光雷达的变换矩阵",{"2":{"191":1}}],["计算缩放的余弦相似度",{"2":{"184":1}}],["计算上",{"2":{"116":1}}],["计算密集",{"2":{"114":1,"926":1}}],["计算机视觉和多模态感知的进步",{"2":{"90":1}}],["像素级",{"2":{"826":1,"961":1}}],["像素级嵌入",{"2":{"765":1}}],["像素的大而一致的图像",{"2":{"552":1}}],["像素坐标转换为",{"2":{"435":1}}],["像kimera",{"2":{"131":1,"253":1}}],["像人类一样",{"2":{"116":3}}],["像一堆衣服应该被表示为一个单独的堆还是作为单独的衣服",{"2":{"109":1}}],["遍历元素",{"2":{"929":1}}],["遍历所有帧",{"2":{"850":1}}],["遍历所有的生成样本",{"2":{"13":1}}],["遍历输出",{"2":{"196":1}}],["遍历+删除指定元素正确用法",{"2":{"115":1}}],["脆弱语义",{"2":{"114":1}}],["总而言之",{"2":{"863":1}}],["总批量大小为64",{"2":{"770":1}}],["总批次为",{"2":{"761":1}}],["总损失",{"2":{"670":1}}],["总是智能体前方",{"2":{"435":1}}],["总之",{"2":{"421":1,"455":1,"552":1,"811":1}}],["总共平均需要51毫秒",{"2":{"816":1}}],["总共使用",{"2":{"803":1}}],["总共12865个关键帧",{"2":{"781":1}}],["总共16个注意力层",{"2":{"278":1}}],["总共进行了21次独特的抓取尝试",{"2":{"522":1}}],["总共为5个输入特征",{"2":{"379":1}}],["总计",{"2":{"277":3,"534":2,"947":1}}],["总的来说",{"2":{"265":1,"437":1,"554":1,"974":1,"983":1}}],["总体准确率",{"2":{"979":1}}],["总体重叠是通过计算所有高斯在",{"2":{"812":1}}],["总体架构",{"0":{"746":1}}],["总体目标函数",{"0":{"690":1}}],["总体目标是从模型中心角度追求网络最小化和训练成本最低化",{"2":{"642":1}}],["总体框架",{"0":{"576":1}}],["总体上",{"2":{"283":1,"334":1,"522":1}}],["总体精度",{"2":{"263":1}}],["总体而言",{"2":{"114":1,"123":1,"435":1,"447":1,"704":1,"899":1,"955":1,"962":1,"992":1}}],["总结一下",{"2":{"793":1}}],["总结于表2",{"2":{"360":1}}],["总结了各类方法在地图中存储的信息类型",{"2":{"274":1}}],["总结来说",{"2":{"31":1,"444":1}}],["总结",{"0":{"398":1,"459":1,"485":1,"552":1,"589":1,"846":1,"938":1},"2":{"13":1,"208":1,"588":1,"619":1,"648":1,"698":1,"743":1,"765":1,"806":1,"946":1}}],["遇到罕见事件",{"2":{"114":1}}],["遇到警告也不怕",{"2":{"66":1}}],["场景数量",{"2":{"997":1}}],["场景数量约为",{"2":{"495":1}}],["场景分割",{"0":{"948":1},"1":{"955":1,"962":1,"968":1,"974":1,"979":1}}],["场景被视为一个建筑物",{"2":{"947":1}}],["场景被建模为一组3d高斯分布",{"2":{"532":1}}],["场景级",{"2":{"940":1}}],["场景开辟了新的可能性",{"2":{"937":1}}],["场景补全实验是使用",{"2":{"900":1}}],["场景类型激增",{"2":{"864":1}}],["场景类别亲和力损失",{"0":{"794":1},"2":{"632":1,"690":1,"750":1}}],["场景提供对象标签",{"2":{"826":1}}],["场景大约需要2分钟",{"2":{"816":1}}],["场景表示方法",{"2":{"681":1}}],["场景的复杂几何形状和语义信息",{"2":{"901":1}}],["场景的dsg",{"2":{"889":2,"947":1}}],["场景的约3000平方米的12分钟",{"2":{"816":1}}],["场景的约100平方米的3分钟到最大的",{"2":{"816":1}}],["场景的地点分割的精度和召回率分别为71",{"2":{"796":1}}],["场景的地点分割的精度和召回率分别为68",{"2":{"796":1}}],["场景的精细几何形状和语义信息",{"2":{"656":1}}],["场景的数据收集装置",{"2":{"605":1}}],["场景编码为紧凑",{"2":{"619":1}}],["场景包括一个大约15米长的轨迹",{"2":{"605":1}}],["场景包括一个大约40米的循环",{"2":{"605":1}}],["场景由三个通过走廊连接的房间组成",{"2":{"605":1}}],["场景在uhumans2中与uhumans中的相同",{"2":{"605":1}}],["场景将为许多新应用铺平道路",{"2":{"570":1}}],["场景进行既高效又有效的表示",{"2":{"567":1}}],["场景多为总面积",{"2":{"495":1}}],["场景中的物体可能被遮挡或处于运动状态",{"2":{"957":1}}],["场景中的物体及其关系在我们的脑海中不断更新",{"2":{"728":1}}],["场景中的所有房间都被正确检测到",{"2":{"796":1}}],["场景中的位置为",{"2":{"378":1}}],["场景中每一个",{"2":{"465":1}}],["场景",{"2":{"360":3,"599":1,"605":2,"709":1,"754":1,"796":5,"947":2}}],["场景是从日志中提取的20秒长的连续帧序列",{"2":{"254":1}}],["场景规划",{"0":{"157":1}}],["场景理解中不可避免的错误可能会带来严重的后果",{"2":{"953":1}}],["场景理解等多种任务",{"2":{"897":1}}],["场景理解方面",{"2":{"619":1}}],["场景理解领域",{"2":{"588":1}}],["场景理解任务",{"2":{"588":1}}],["场景理解任务中被广泛采用",{"2":{"556":1}}],["场景理解",{"0":{"137":1},"2":{"567":1}}],["场景图是计算机图形中流行的模型",{"2":{"961":1}}],["场景图是计算机图形和游戏应用中常用的数据结构",{"2":{"116":1}}],["场景图可以支持用户导向的任务",{"2":{"905":1}}],["场景图环路闭合方法在10厘米误差和1度误差内的环路闭合数量大约是宽容的视觉方法的两倍",{"2":{"437":1}}],["场景图优化",{"2":{"408":2}}],["场景图后端",{"2":{"380":1}}],["场景图前端",{"2":{"380":2}}],["场景图结构qa",{"2":{"360":1}}],["场景图",{"0":{"961":1},"2":{"360":1,"648":2}}],["场景图的全局优化",{"2":{"112":1,"141":1}}],["场景下仍不足",{"2":{"114":1}}],["相近",{"2":{"928":1}}],["相较于从零训练",{"2":{"743":1}}],["相较于2d领域",{"2":{"265":1}}],["相同",{"2":{"651":1,"738":1,"867":1}}],["相同的高斯表示仍然可以生成多分辨率预测",{"2":{"899":1}}],["相同的图像主干网络检查点",{"2":{"771":1}}],["相同的特征通道维度",{"2":{"649":1}}],["相同的场景部分",{"2":{"352":1}}],["相同的时间戳作为单个lidar扫描的一部分",{"2":{"254":1}}],["相应的损失函数可以分为",{"2":{"985":1}}],["相应的层次结构分类如图4所示",{"2":{"665":1}}],["相应的节点和边被增量地添加到3d场景图数据结构中",{"2":{"380":1}}],["相应地",{"2":{"535":1,"682":1}}],["相似度",{"2":{"525":1}}],["相似度越高",{"2":{"184":1}}],["相似",{"2":{"437":1}}],["相互连接",{"2":{"390":1}}],["相对位置",{"2":{"826":1}}],["相对改进率",{"2":{"686":1}}],["相对不受房间内杂物的影响",{"2":{"480":1}}],["相对于其所在点块的中心点进行归一化",{"2":{"456":1}}],["相对角的角",{"2":{"379":1}}],["相对大小",{"2":{"178":1}}],["相关作品包括occnet",{"2":{"1003":1}}],["相关联",{"2":{"985":1}}],["相关联的相机可见的",{"2":{"390":1}}],["相关",{"2":{"325":1}}],["相关工作还尝试通过对动态场景使用imu",{"2":{"967":1}}],["相关工作",{"0":{"121":1,"156":1,"174":1,"451":1,"468":1,"474":1,"487":1,"533":1,"566":1,"580":1,"599":1,"603":1,"629":1,"801":1,"808":1,"954":1},"1":{"172":1,"190":1,"482":1,"497":1,"512":1,"517":1,"527":1,"548":1,"564":1,"596":1,"612":1,"625":1,"641":1,"653":1,"678":1,"821":1,"841":1,"860":1,"961":1,"967":1}}],["相加",{"2":{"303":1,"716":1}}],["相机的语义信息也显著降低",{"2":{"952":1}}],["相机的视野是有限的",{"2":{"800":1}}],["相机等多传感器数据",{"2":{"926":1}}],["相机和激光雷达的数据",{"2":{"900":1}}],["相机视角的占用可视化与输入",{"2":{"885":1}}],["相机以",{"2":{"828":1}}],["相机可见掩码的主要作用是标记出哪些区域是相机能够看到的",{"2":{"800":1}}],["相机可见掩码",{"2":{"800":1,"893":1}}],["相机坐标系中的局部预测",{"2":{"705":1}}],["相机内参",{"2":{"597":1}}],["相机被广泛应用于智能手机",{"2":{"570":1}}],["相机融合",{"2":{"803":1}}],["相机融合的最新方法相当",{"2":{"700":1}}],["相机融合的",{"2":{"455":1}}],["相机融合占据网络能更好地适应少量标注数据",{"2":{"455":1}}],["相机不稳定而产生的自然噪声让模型变得更加鲁棒",{"2":{"366":1}}],["相机1",{"2":{"355":1}}],["相机1到点x的距离d",{"2":{"355":1}}],["相机后面的点或没有足够的视差进行三角测量的点",{"2":{"310":1}}],["相机",{"2":{"171":1,"189":1,"350":1,"360":1,"864":1,"877":1,"977":1}}],["相机标定",{"0":{"136":1}}],["相机驱动安装",{"0":{"120":1}}],["相结合",{"2":{"123":1,"765":1}}],["相当于白标",{"2":{"117":1}}],["相反",{"2":{"114":1,"607":1,"716":1,"754":1,"768":1,"800":1,"821":1,"949":2,"975":1}}],["相比显示出显著差异",{"2":{"944":1}}],["相比mhsa与重参数大核",{"2":{"863":1}}],["相比mhsa与形变注意力",{"2":{"863":1}}],["相比版本h",{"2":{"805":1}}],["相比于仅使用",{"2":{"928":1}}],["相比于使用3d代价体的重建方法而言",{"2":{"618":1}}],["相比于argmax",{"2":{"470":1}}],["相比的新颖性",{"2":{"131":1}}],["相比",{"2":{"126":1,"129":1,"369":1,"485":1,"552":2,"641":2,"660":1,"681":1,"700":2,"779":2,"792":1,"798":1,"803":2,"914":1}}],["相比与前面的文章",{"2":{"106":1}}],["相比之下",{"2":{"105":1,"421":1,"464":1,"497":1,"503":1,"527":1,"570":2,"603":2,"619":1,"690":1,"779":1,"821":1,"860":1,"910":1,"923":1,"939":1,"948":1,"950":1,"959":1,"963":1,"967":1,"970":1,"988":1}}],["绕过手工模块化流水线",{"2":{"114":1}}],["研究鲁棒的3d占用感知具有重要意义",{"2":{"1005":1}}],["研究也聚焦于",{"2":{"881":1}}],["研究也可依据语义地图的",{"2":{"209":1}}],["研究正在向",{"2":{"881":1}}],["研究室外场景的占用感知对于自动驾驶至关重要",{"2":{"759":1}}],["研究来自多个传感器",{"2":{"691":1}}],["研究人员将激光雷达的",{"2":{"596":1}}],["研究由美国空军研究实验室和美国空军人工智能加速器赞助",{"2":{"467":1}}],["研究者需解决",{"2":{"951":1}}],["研究者提出",{"2":{"935":1}}],["研究者提出在端到端框架中引入中间地图表示",{"2":{"252":1}}],["研究者基于",{"2":{"824":1}}],["研究者们提出先在图像中定位物体",{"2":{"765":1}}],["研究者也在构建能够按不同抽象层级捕捉场景语义层次结构的地图",{"2":{"648":1}}],["研究者发现使用更强大的2d主干易导致过拟合",{"2":{"617":1}}],["研究者开始将这些表征引入具身智能",{"2":{"556":1}}],["研究者转向全统一网络",{"2":{"308":1}}],["研究者还训练了学习式策略",{"2":{"274":1}}],["研究者通过ts",{"2":{"260":1}}],["研究",{"2":{"209":1}}],["研究层次化地图在度量和拓扑表示之间的明显分歧",{"2":{"172":1}}],["研究转向更集成的端到端方法",{"2":{"114":1}}],["研究重点已转向富含语义信息的地图",{"2":{"90":1}}],["定量性能",{"2":{"989":1}}],["定量和可视化结果都表明",{"2":{"852":1}}],["定量结果",{"0":{"700":1,"914":1}}],["定性性能",{"2":{"989":1}}],["定性分析",{"2":{"903":1}}],["定性研究比较了我们的方法与其他",{"2":{"847":1}}],["定性结果",{"0":{"745":1,"843":1,"899":1}}],["定性的可视化结果表明",{"2":{"567":1}}],["定制模块",{"2":{"334":1}}],["定位本身颇具挑战",{"2":{"435":1}}],["定位在x",{"2":{"254":1}}],["定位结合了",{"2":{"173":1}}],["定位精度",{"2":{"173":1}}],["定位于计算机视觉",{"2":{"139":1}}],["定位",{"2":{"131":1,"254":1,"435":2,"556":1}}],["定位和映射",{"2":{"112":1}}],["定义并用双端队列a初始化双端队列b",{"2":{"888":1}}],["定义一个int类型的双端队列a",{"2":{"888":3}}],["定义的实现代码",{"2":{"888":1}}],["定义和相关研究领域",{"2":{"714":1}}],["定义在整个3d空间中",{"2":{"644":1}}],["定义在特定车辆上校准的特定传感器",{"2":{"254":1}}],["定义给定邻接的池化区域",{"2":{"466":1}}],["定义了一个球面卷积核",{"2":{"511":1}}],["定义了一组用于不同下游任务的评估办法",{"2":{"265":1}}],["定义了它们之间的语义和几何相似性",{"2":{"121":1}}],["定义样本中物体位置的边界框",{"2":{"254":1,"654":1}}],["定义",{"0":{"708":1},"2":{"57":1}}],["定义为块中各个像素视锥的并集",{"2":{"814":1}}],["定义为",{"2":{"5":1,"137":1}}],["心智模型",{"2":{"112":1,"125":1}}],["αlog",{"2":{"666":1}}],["αlog⁡",{"2":{"666":1}}],["αiα",{"2":{"400":2}}],["α为超参",{"2":{"329":1}}],["α=0",{"2":{"271":1}}],["αη∑l=1kγl",{"2":{"153":1}}],["α",{"2":{"153":4,"256":1,"279":1,"431":1,"666":1,"681":14,"686":1,"988":1}}],["αt​ˉ​​x0​",{"2":{"316":1}}],["αt​​xt−1​",{"2":{"140":2,"280":2}}],["αtˉx0",{"2":{"316":1}}],["αt−αˉt+βt1−αˉt",{"2":{"140":1,"280":1}}],["αt−1​​xt−2​+1−αt−1​​zt−1​",{"2":{"111":1,"236":1}}],["αt−1xt−2+1−αt−1zt−1",{"2":{"111":1,"236":1}}],["αtxtβt+αˉt−1x01−αˉt−1",{"2":{"140":3,"280":3}}],["αtxt−1",{"2":{"140":2,"280":2}}],["αtβt+11−αˉt−1",{"2":{"140":1,"280":1}}],["αˉ​x0​",{"2":{"188":1}}],["αˉx0",{"2":{"188":1}}],["αˉt→0",{"2":{"273":1}}],["αˉt​",{"2":{"175":2}}],["αˉt​​x0​",{"2":{"140":2,"280":2}}],["αˉt",{"2":{"175":3}}],["αˉt−1​",{"2":{"175":1}}],["αˉt−1​​x0​",{"2":{"140":1,"280":1}}],["αˉt−1",{"2":{"175":1}}],["αˉt−1x0",{"2":{"140":1,"280":1}}],["αˉtx0",{"2":{"140":2,"280":2}}],["αˉt=∏i=1tαi",{"2":{"111":1,"236":1}}],["αˉ→0",{"2":{"111":2,"236":2}}],["α⋅c",{"2":{"8":2}}],["令人惊讶的是",{"2":{"952":1}}],["令人惊叹的是",{"2":{"302":1}}],["令",{"2":{"111":2,"236":2,"273":3}}],["βpijα​log",{"2":{"666":1}}],["βpijαlog⁡",{"2":{"666":1}}],["βˉ​i​=tβi​",{"2":{"273":1}}],["βˉi=tβi",{"2":{"273":1}}],["βi​",{"2":{"273":2}}],["βi",{"2":{"273":2}}],["βt​α​t​xt​​+1−αˉt−1​αˉt−1​​x0​​",{"2":{"140":3,"280":3}}],["βt​αt​​+1−αˉt−1​1​",{"2":{"140":1,"280":1}}],["β",{"2":{"111":3,"137":1,"153":1,"236":3,"273":2,"312":1,"666":1}}],["β⋅s",{"2":{"8":2}}],["展现出了对整个场景的优越预测性能",{"2":{"833":1}}],["展示kimera的3d网格几何精度",{"2":{"541":1}}],["展示车辆可通过简洁自然语言消息在路口协调",{"2":{"283":1}}],["展示了其在自动驾驶领域的潜力",{"2":{"1002":1}}],["展示了其部署潜力",{"2":{"505":1}}],["展示了在不同相机设置的数据集上进行测试时",{"2":{"995":1}}],["展示了在雨天场景中性能的变化趋势",{"2":{"944":1}}],["展示了在两个数据集上",{"2":{"928":1}}],["展示了在",{"2":{"902":1,"944":1}}],["展示了在渲染质量和速度方面的卓越性能",{"2":{"641":1}}],["展示了基于视觉的占用网络的结果",{"2":{"823":1}}],["展示了",{"2":{"782":1,"803":3}}],["展示了euroc",{"2":{"754":1}}],["展示了我们在",{"2":{"885":1}}],["展示了我们的daocc与其他方法的性能",{"2":{"779":1}}],["展示了我们这一层的架构",{"2":{"752":1}}],["展示了我们所提出的框架的总体架构",{"2":{"746":1}}],["展示了转换的主要思想",{"2":{"738":1}}],["展示了随着探索的进行",{"2":{"568":1}}],["展示了两种方法的流程",{"2":{"503":1}}],["展示了多样的",{"2":{"126":1}}],["展示了大规模开放集语义使用分层3d场景图",{"2":{"121":1}}],["展示了clio的性能",{"2":{"109":1}}],["展望未来研究方向",{"2":{"90":1}}],["时空卷积神经网络",{"2":{"962":1}}],["时空对齐利用自车的姿态信息将历史特征",{"2":{"957":1}}],["时空对齐和特征融合",{"2":{"957":1}}],["时空对齐模块和特征融合模块",{"2":{"726":1}}],["时存在困难",{"2":{"796":1}}],["时的性能",{"2":{"989":1}}],["时的误差",{"2":{"775":1}}],["时的网格几何误差",{"2":{"709":1}}],["时序推理",{"2":{"864":1}}],["时序准确率",{"2":{"826":1}}],["时序窗口根据gpu内存确定",{"2":{"764":1}}],["时序一致的多模态融合",{"2":{"478":1}}],["时kimera的绝对轨迹误差",{"2":{"662":1}}],["时域对齐",{"0":{"583":1}}],["时间信息融合的过程包括两个部分",{"2":{"957":1}}],["时间信息融合",{"2":{"942":1,"957":1}}],["时间演化",{"2":{"864":1}}],["时间消耗",{"2":{"831":1}}],["时间预算耗尽",{"2":{"826":1}}],["时间模块的持续改进",{"2":{"811":1}}],["时间融合模块旨在通过整合历史信息增强对动态物体或属性的感知",{"2":{"726":1}}],["时间融合模块",{"0":{"726":1}}],["时间戳应该非常接近它所指向的样本",{"2":{"254":1}}],["时间和天气条件",{"2":{"157":1}}],["时终止算法",{"2":{"153":1}}],["时",{"2":{"114":1,"126":1,"137":2,"355":1,"390":1,"411":1,"765":2,"853":1,"928":1,"945":1}}],["时仅限于离线操作",{"2":{"109":1}}],["时报错",{"2":{"64":1}}],["贡献",{"0":{"131":1,"187":1,"272":1,"714":1},"2":{"109":1,"656":1}}],["贡献在于搭建了点击式交互式分割的基本pipeline",{"2":{"54":1}}],["决策延迟需控制在毫秒级",{"2":{"864":1}}],["决策过程联系起来",{"2":{"90":1}}],["决定几何结构的坐标和表示纹理特征的颜色",{"2":{"640":1}}],["决定具体前沿点时",{"2":{"274":1}}],["决定哪些对象要表示以及如何表示时考虑任务",{"2":{"109":1}}],["阅读棕色教科书",{"2":{"109":1}}],["树木和水坑",{"2":{"700":1}}],["树木",{"2":{"630":1,"828":1,"899":1}}],["树干等",{"2":{"109":1}}],["树叶",{"2":{"109":1}}],["同步生成稠密的",{"2":{"648":1}}],["同步定位与建图",{"2":{"171":1,"435":1}}],["同一张地图",{"2":{"881":1}}],["同一综述还强调了",{"2":{"603":1}}],["同一个日志可以产生多个场景",{"2":{"254":1}}],["同一个",{"2":{"234":1,"255":1}}],["同种任务变现就很差",{"2":{"220":1}}],["同理",{"2":{"117":1,"184":1}}],["同样用",{"2":{"743":1}}],["同样基于",{"2":{"739":1}}],["同样地",{"2":{"666":1}}],["同样构建分层场景图",{"2":{"648":1}}],["同样利用",{"2":{"588":1}}],["同样的",{"2":{"824":1}}],["同样的思想也被应用于bev分割",{"2":{"566":1}}],["同样的趋势可以在后向去噪时施加影响的终止步数上看到",{"2":{"264":1}}],["同样也是smoothl1",{"2":{"463":1}}],["同样是在ddpm生成的时候做额外的梯度引导",{"2":{"452":1}}],["同样通过最小化两个顶点之间的相对平移来执行",{"2":{"390":1}}],["同样",{"2":{"109":1,"116":2,"429":1,"438":1,"796":1,"816":1,"950":1}}],["同时评估了感知场景中物体运动",{"2":{"998":1}}],["同时推断占用状态和体素语义分类的占用预测可以被视为语义",{"2":{"998":1}}],["同时推断出几何和语义信息",{"2":{"570":1}}],["同时提供准确的预测",{"2":{"922":1}}],["同时提升建图与物体识别效果",{"2":{"209":1}}],["同时仍能捕捉到占用预测的关键信息",{"2":{"908":1}}],["同时利用前向和后向视图变换模块",{"2":{"875":1}}],["同时利用标注和未标注数据",{"2":{"455":1}}],["同时对噪声与不确定性保持鲁棒",{"2":{"864":1}}],["同时显著降低了超过75",{"2":{"861":1}}],["同时显着降低了计算成本",{"2":{"552":1}}],["同时证明了视觉基础模型和大规模预训练在3d占据预测中的有效性",{"2":{"845":1}}],["同时仅消耗其17",{"2":{"842":1}}],["同时将剩余标签归入",{"2":{"828":1}}],["同时包含几何完整度与语义完整度",{"2":{"826":1}}],["同时参数量少27",{"2":{"824":1}}],["同时还对模块定制化",{"2":{"824":1}}],["同时还对每个体素的语义标签进行贝叶斯推断",{"2":{"253":1}}],["同时在uniocc上保持了可比的性能",{"2":{"811":1}}],["同时在预测小物体",{"2":{"700":1}}],["同时确保在同一场景内的一致性",{"2":{"750":1}}],["同时由于高斯混合的强近似能力",{"2":{"693":1}}],["同时抵御不利的环境变化",{"2":{"691":1}}],["同时使用相同的一组参数",{"2":{"889":1}}],["同时使用",{"2":{"632":1}}],["同时因为自注意力是在小窗口之内算的",{"2":{"631":1}}],["同时通过",{"2":{"631":1}}],["同时通过压缩信号",{"2":{"137":1}}],["同时让",{"2":{"570":1}}],["同时也提供了对局部细节特征的更精细刻画",{"2":{"703":1}}],["同时也避免了3d卷积的需求",{"2":{"566":1}}],["同时也将不相关的原语分配给空任务",{"2":{"153":1}}],["同时采用多尺度监督机制",{"2":{"545":1,"746":1}}],["同时联合推断其语义信息",{"2":{"539":1}}],["同时探索场景",{"2":{"522":1}}],["同时允许使用开源数据集和模型",{"2":{"520":1}}],["同时预测非空体素的占据率并删除预测的空体素以保持稀疏性",{"2":{"517":1}}],["同时增强系统在多变光照和天气条件下的鲁棒性",{"2":{"503":1}}],["同时共同提高整体准确性",{"2":{"471":1}}],["同时具有降低的内存消耗和提高的效率",{"2":{"444":1}}],["同时减少了内存使用",{"2":{"444":1}}],["同时减少了内存消耗并提高了效率",{"2":{"415":1}}],["同时运用利于部署的图像编码器和实用的输入图像分辨率",{"2":{"421":2}}],["同时运用利于部署的图像特征提取网络和实用的输入图像分辨率",{"2":{"392":1}}],["同时该算法可以用于预训练高容量的3d框架",{"2":{"394":1}}],["同时该文章还在loss",{"2":{"106":1}}],["同时避免了复杂的",{"2":{"369":1}}],["同时为了防止得到的latent的标准差过大",{"2":{"345":1}}],["同时最大化不匹配的点之间的距离",{"2":{"339":1}}],["同时引入一个动态的点云采样模块",{"2":{"331":1}}],["同时图像还保留了数据的语义结构",{"2":{"248":1}}],["同时保持表达能力",{"2":{"693":1}}],["同时保持高精度",{"2":{"505":1}}],["同时保持对齐vla能力",{"2":{"417":1}}],["同时保持对象原语的高细节",{"2":{"206":1}}],["同时保持了快速的推理速度",{"2":{"349":1}}],["同时保留了每种传感器的独特优势",{"2":{"977":1}}],["同时保留了空间信息",{"2":{"922":1}}],["同时保留足够的几何信息",{"2":{"875":1}}],["同时保留图像中的语义结构",{"2":{"294":1}}],["同时保留压缩表示与另一个感兴趣信号之间的互信息",{"2":{"121":1}}],["同时定位与建图",{"0":{"155":1},"1":{"171":1,"189":1,"209":1}}],["同时处理大量的传感器数据",{"2":{"153":1}}],["同时支持实时流的新原语",{"2":{"153":1}}],["同时产生人类可读的推理",{"2":{"128":1}}],["同时忽视了图1中的顶层",{"2":{"125":1}}],["同时校正场景图的所有层",{"2":{"112":1,"141":1}}],["同时",{"2":{"90":1,"121":1,"129":1,"171":1,"189":1,"206":1,"289":1,"301":1,"545":1,"566":1,"621":2,"666":1,"746":2,"811":2,"962":1}}],["考虑一个",{"2":{"916":1}}],["考虑一个被指派在房间里移动钢琴的机器人",{"2":{"109":1}}],["考虑包括草地",{"2":{"828":1}}],["考虑每个像素深度估计的不确定性",{"2":{"585":1}}],["考虑了各种传感器组合和具有挑战性的场景",{"2":{"503":1}}],["考虑了所有相关的sample",{"2":{"254":1,"654":1}}],["考虑到固有的稀疏性和类别不平衡",{"2":{"875":1}}],["考虑到lidar点云在空间中的非均匀分布",{"2":{"858":1}}],["考虑到tpvformer仅关注空间线索而忽略了时间线索",{"2":{"858":1}}],["考虑到高分辨率",{"2":{"766":1,"884":1}}],["考虑到3d高斯分布的动态邻域大小",{"2":{"738":1}}],["考虑到3d空间的稀疏性",{"2":{"547":1}}],["考虑到自运动",{"2":{"583":1}}],["考虑到点块是用归一化坐标表示的",{"2":{"549":1}}],["考虑到点云的固有稀疏性和无序性",{"2":{"396":1}}],["考虑到",{"2":{"405":1}}],["考虑的拼合图像里包含了原图前向扩散的静态输出",{"2":{"312":1}}],["考虑极端情况完全替换后向过程的噪声图像的话则一定可以轻易地回到原图",{"2":{"264":1,"266":1}}],["考虑琴弦",{"2":{"109":1}}],["即直接使用3d占用标签",{"2":{"1000":1}}],["即直接对地图本身进行评价",{"2":{"826":1}}],["即以激光雷达为中心或以视觉为中心",{"2":{"1000":1}}],["即忽略语义",{"2":{"1000":1}}],["即占用流",{"2":{"998":1}}],["即确定3d空间中的每个体素是否被占用或为空",{"2":{"998":1}}],["即同一类别中的物体可能具有完全不同的外观",{"2":{"992":1}}],["即同步定位与地图构建",{"2":{"90":1}}],["即隐藏测试集",{"2":{"989":1}}],["即时间信息融合",{"2":{"942":1}}],["即空间信息融合",{"2":{"942":1}}],["即二维到三维转换",{"2":{"942":1}}],["即提供了更细粒度的局部监督",{"2":{"928":1}}],["即降低",{"2":{"853":1}}],["即nvidia",{"2":{"836":1}}],["即n=2n=2n=2",{"2":{"684":1}}],["即停止",{"2":{"826":1}}],["即视锥kkk中存在的真实类别",{"2":{"814":1}}],["即学习偏移的同时还会加入每一个采样点的权重",{"2":{"804":1}}],["即学习到的边折叠",{"2":{"275":1}}],["即特征增强",{"2":{"799":1}}],["即非类别ccc",{"2":{"794":1}}],["即monoscene",{"2":{"791":1}}],["即m0",{"2":{"770":1}}],["即bevdetocc",{"2":{"770":1}}],["即认为二者空间相关并建立边",{"2":{"765":1}}],["即智能体所见每张图像与目标物体语言指令之间的相似度分数",{"2":{"765":1}}],["即表现为注意力矩阵",{"2":{"752":1}}],["即平均交并比",{"2":{"749":1}}],["即对3d高斯分布的贡献进行求和",{"2":{"738":1}}],["即对所有视角的输入图像",{"2":{"305":1}}],["即射线交并比",{"2":{"736":1}}],["即质心预测",{"2":{"715":1}}],["即接受单目rgb图像作为输入",{"2":{"682":1}}],["即感知观察到的世界",{"2":{"667":1}}],["即图像编码器和视图变换",{"2":{"811":1}}],["即图像shape再由",{"2":{"659":1}}],["即图像的整体理解",{"2":{"343":1}}],["即每个高斯与其最近占用体素中心之间的平均距离",{"2":{"916":1}}],["即每个卷积层都能根据输入的a来调整",{"2":{"133":1}}],["即每4x4相邻的像素为一个patch",{"2":{"659":1}}],["即所谓的",{"2":{"648":1}}],["即所谓的高斯泼溅",{"2":{"588":1}}],["即均值和协方差",{"2":{"641":1}}],["即均匀分布",{"2":{"568":1}}],["即联合推断几何和语义信息",{"2":{"603":1}}],["即3",{"2":{"563":1}}],["即3d网格",{"2":{"141":1}}],["即3d场景图",{"2":{"109":1,"116":1}}],["即判断两张",{"2":{"525":1}}],["即我们可以用贝叶斯将显式分类器的梯度引导再拆解为两项其中一个是无条件生成的梯度预估模型",{"2":{"513":1}}],["即flashocc",{"2":{"505":1}}],["即可在地图上检索最高相似度的对象",{"2":{"765":1}}],["即可充分描述这类环境",{"2":{"495":1}}],["即可理解为上图中各层蓝色由深变浅的图层",{"2":{"355":1}}],["即办公室数据集中的iou和严格开放集召回率",{"2":{"462":1}}],["即度量",{"2":{"462":1}}],["即度量语义网格",{"2":{"172":1}}],["即0",{"2":{"449":1}}],["即将vit模块中的mhsa替换为了dcnv3",{"2":{"880":1}}],["即将概率体变成了一张概率图",{"2":{"470":1}}],["即将一摞书变成了一本书",{"2":{"440":1}}],["即将ground",{"2":{"358":1}}],["即这个代价体由于非朗伯面",{"2":{"440":1}}],["即更高的",{"2":{"853":1}}],["即更多且更小的房间估计",{"2":{"437":1}}],["即更少且更大的房间估计",{"2":{"437":1}}],["即姿态",{"2":{"380":1}}],["即沿着它们的光学射线进行聚合",{"2":{"660":1}}],["即沿",{"2":{"378":1}}],["即最后一个transformer",{"2":{"373":1}}],["即观察到与",{"2":{"352":1}}],["即lpips",{"2":{"345":1}}],["即latent",{"2":{"149":1}}],["即如何将三维点云中的每个点分配到不同的语义或实例类别",{"2":{"331":1}}],["即不条件于文本图像或类别等信息的生成",{"2":{"312":1}}],["即房间",{"2":{"301":2}}],["即门",{"2":{"301":1}}],["即顶点和面信息",{"2":{"275":1}}],["即它们的物理空间有交集",{"2":{"271":1}}],["即在融合教师模型和仅视觉学生模型生成的",{"2":{"694":1}}],["即在现实场景中出现的未标记类别超出了现有的预定义类别",{"2":{"535":1}}],["即在执行任务的同时逐步扩建图",{"2":{"525":1}}],["即在二分图中最多能找到多少条没有公共端点的边",{"2":{"358":1}}],["即在已经提前获取相机的内外参数前提下",{"2":{"355":1}}],["即在",{"2":{"221":1}}],["即使是来自环视雷达的稀疏",{"2":{"977":1}}],["即使是在小场景中也是如此",{"2":{"930":1}}],["即使在加入激光雷达数据后",{"2":{"952":1}}],["即使在完美的定位下",{"2":{"709":1}}],["即使仅使用单一尺度",{"2":{"928":1}}],["即使用真实的",{"2":{"917":1}}],["即使经过完整训练",{"2":{"916":1}}],["即使训练数据有限",{"2":{"899":1}}],["即使训练阶段未见该具体物体",{"2":{"765":1}}],["即使查询数量更多",{"2":{"842":1}}],["即使它们可能对任务有类似的相关性",{"2":{"553":1}}],["即使我们在后向去噪时不断地试图生成语义一致的内容",{"2":{"312":1}}],["即使不平均在后面也会被合并",{"2":{"278":1}}],["即使网络已经经过大量的数据增强",{"2":{"220":1}}],["即使被前面的车遮挡",{"2":{"116":1}}],["即该方法返回的迭代器不能用于修改容器内存储的键值对",{"2":{"196":2}}],["即后车轴中点",{"2":{"191":1}}],["即当前batch内",{"2":{"184":1}}],["即越可信的测量权重越大",{"2":{"171":1}}],["即新的传感器数据或图像帧",{"2":{"153":1}}],["即保留的任务相关信息越多",{"2":{"153":1}}],["即聚类",{"2":{"153":1}}],["即任务列表",{"2":{"137":1}}],["即任务不可知原语的集合",{"2":{"137":1}}],["即风格",{"2":{"133":1}}],["即无障碍位置",{"2":{"131":1}}],["即节点被分组成对应于场景的不同抽象层次的层",{"2":{"131":1,"147":1}}],["即激光雷达语义分割",{"2":{"126":1}}],["即",{"2":{"116":1,"131":3,"137":1,"153":1,"162":1,"178":2,"217":1,"218":1,"253":1,"276":1,"285":1,"301":1,"310":3,"390":1,"419":1,"437":4,"522":1,"623":1,"652":1,"686":1,"712":1,"771":1,"853":2,"928":3,"950":1}}],["即琴键",{"2":{"109":1}}],["即地图中的语义概念选择不仅仅是由语义相似性驱动的",{"2":{"109":1}}],["即调整合适的阈值来控制从场景中提取的片段数量以及用于决定两个片段是否应该聚类在一起的阈值",{"2":{"109":1}}],["改变局部视锥数量",{"2":{"928":1}}],["改用",{"2":{"765":1}}],["改进空间充足",{"2":{"360":1}}],["改成你安装的opencv的版本",{"2":{"107":1}}],["改为先投影编码特征再分割",{"2":{"698":1}}],["改为",{"2":{"67":1}}],["论文速览",{"2":{"616":1}}],["论文",{"2":{"584":1}}],["论文提出了双重掩码策略和提取器",{"2":{"488":1}}],["论文提出了一种双重掩码策略",{"2":{"488":1}}],["论文还引入了提取器",{"2":{"488":1}}],["论文中采用正弦位置编码",{"2":{"549":1}}],["论文中采用了一个三阶段的过程",{"2":{"340":1}}],["论文中提到",{"2":{"488":1}}],["论文的另一个核心贡献是探索了使用cross",{"2":{"459":1,"552":1}}],["论文进一步将不同fff的autoencoder在扩散模型上进行实验",{"2":{"345":1}}],["论文笔记",{"2":{"106":1,"410":1}}],["论文阅读",{"2":{"106":2,"258":1,"804":1}}],["论文阅读笔记之",{"2":{"164":1}}],["论文阅读笔记",{"2":{"96":1}}],["络小绎的博客",{"2":{"106":1}}],["人造物",{"2":{"975":1}}],["人造物体",{"2":{"277":1,"534":1}}],["人们提出了多种方法来从",{"2":{"968":1}}],["人机交互",{"2":{"905":1}}],["人机交互与策略联合进展",{"2":{"478":1}}],["人等",{"2":{"903":1}}],["人工评估场景图准确性",{"2":{"826":1}}],["人数",{"2":{"709":1}}],["人体模型通常使用skinned",{"2":{"967":1}}],["人体跟踪和监控",{"2":{"419":1}}],["人体姿态估计和跟踪",{"2":{"967":1}}],["人体姿态估计和鲁棒跟踪",{"0":{"419":1}}],["人体姿态和形状估计以及场景解析",{"2":{"105":1}}],["人行道和建筑物等类别的",{"2":{"792":1}}],["人行道",{"2":{"277":1,"534":1,"723":1}}],["人",{"2":{"254":1,"463":1}}],["人眼观感不佳",{"2":{"220":1}}],["人脸超分辨率的",{"2":{"382":1}}],["人脸图像",{"2":{"382":1}}],["人脸光照等方方面面",{"2":{"133":1}}],["人脸朝向",{"2":{"133":1}}],["人类擅长估计3d环境和被遮挡区域的几何和语义信息",{"2":{"841":1}}],["人类智能的本质是能够根据对周围环境的实时感知进行分析和响应",{"2":{"682":1}}],["人类非常敏感",{"2":{"419":1}}],["人类模型的不同特征的宽度和高度",{"2":{"419":1}}],["人类的平均步行速度约为1",{"2":{"419":1}}],["人类的位姿图可以定期优化",{"2":{"419":1}}],["人类节点",{"2":{"419":2,"775":1}}],["人类之所以能够高效地在环境中感知与导航",{"2":{"350":1}}],["人类和机器人节点都有三个属性",{"2":{"178":1}}],["人类和机器人",{"2":{"178":1}}],["人类高度依赖视觉输入以驾驶复杂环境",{"2":{"176":1}}],["人类",{"2":{"116":1,"178":1,"277":7,"534":7}}],["人类不仅在",{"2":{"109":1}}],["人类能够形成他们所处环境的复杂心理模型",{"2":{"105":1}}],["惯性传感",{"2":{"967":1}}],["惯性手持设备收集的真实数据集",{"2":{"437":1}}],["惯性估计器",{"2":{"310":1}}],["惯性",{"2":{"189":1}}],["惯性测量单元等",{"2":{"171":1}}],["惯性数据中全自动构建dsg的空间感知引擎",{"2":{"973":1}}],["惯性数据中实时重建语义注释的3d网格",{"2":{"285":1}}],["惯性数据以及地面真实深度和2d语义分割",{"2":{"437":1}}],["惯性数据重建dsg的空间感知引擎",{"2":{"162":1}}],["惯性数据构建dsg的空间感知引擎",{"2":{"131":1}}],["惯性数据构建dsg",{"2":{"105":1}}],["惯性里程计和目标姿态估计",{"2":{"967":1}}],["惯性里程计后端",{"2":{"408":1}}],["惯性里程计的前端",{"2":{"408":1}}],["惯性里程计模块",{"2":{"285":1}}],["惯性里程计",{"0":{"310":1},"2":{"131":1,"210":1,"437":2}}],["惯性slam中取得了竞争性能",{"2":{"105":1,"131":1}}],["惯性slam",{"2":{"105":1,"967":1}}],["边还存储由",{"2":{"765":1}}],["边为关系",{"2":{"648":1}}],["边形式压缩环境",{"2":{"525":1}}],["边",{"2":{"525":1,"935":1,"947":1}}],["边代表区域间的可通行路径",{"2":{"525":1}}],["边代表节点之间的成对时空关系",{"2":{"131":1}}],["边代表节点之间的空间或逻辑关系",{"2":{"116":1}}],["边代表节点之间的时空关系",{"2":{"105":1}}],["边在每个i通道中的特征p由以下公式给出",{"2":{"466":1}}],["边表示节点间的可达关系",{"2":{"525":1}}],["边表示相邻地标之间的关系",{"2":{"465":1}}],["边表示它们之间的关系",{"2":{"378":1}}],["边表示空间约束",{"2":{"171":1}}],["边是在两个节点之间添加的",{"2":{"271":1}}],["边框修正主要由4个值完成",{"2":{"375":1}}],["边框方向为四元数",{"2":{"254":1,"654":1}}],["边框大小以米为单位",{"2":{"254":1,"654":1}}],["边连接每个层内的节点",{"2":{"210":1}}],["边连接相邻的房间",{"2":{"210":1}}],["边连接三个点",{"2":{"162":1}}],["边界框相比",{"2":{"277":1}}],["边界框和属性",{"2":{"277":1}}],["边界框可以用作快速碰撞检查",{"2":{"262":1}}],["边界框的位置",{"2":{"254":1,"654":1}}],["边界框",{"2":{"126":1,"178":1,"197":1,"218":1,"240":1,"262":1,"369":1,"473":1,"931":1}}],["边缘计算与高效表征虽有进展",{"2":{"864":1}}],["边缘卷积",{"0":{"555":1}}],["边缘特征沿基的每个方向由可学习矩阵根据相邻点的基独立加权",{"2":{"511":1}}],["边缘特征确定优先级",{"2":{"436":1}}],["边缘",{"2":{"436":1}}],["边缘代表概念之间的关系",{"2":{"112":1}}],["边缘估计比输入的全掩码更稀疏且波动更小",{"2":{"96":1}}],["边缘掩码方案",{"2":{"96":1}}],["边缘概率",{"2":{"13":1}}],["来聚合来自2d多视图图像的外观特征和规范点云空间中的空间几何特征",{"2":{"968":1}}],["来强制这些推断的每点标签的空间一致性",{"2":{"962":1}}],["来扩展",{"2":{"905":1}}],["来不恰当地提高",{"2":{"903":1}}],["来处理体素特征",{"2":{"875":1}}],["来推断深度图",{"2":{"870":1}}],["来增加点云的密度",{"2":{"850":1}}],["来访问队列的第一个和最后一个元素",{"2":{"835":1}}],["来衡量",{"2":{"826":1}}],["来评估场景补全任务",{"2":{"915":1}}],["来评估每个语义类别",{"2":{"807":1,"915":1}}],["来评估模型的性能",{"2":{"802":1}}],["来计算从2d到3d的精确一对一映射",{"2":{"950":1}}],["来计算miou和iou",{"2":{"793":1}}],["来计算损失",{"2":{"750":1}}],["来优化深度分布特征",{"2":{"766":1}}],["来训练我们的局部空间占用预测模块",{"2":{"750":1}}],["来从图像中提取总共",{"2":{"746":1}}],["来获得鲁棒性",{"2":{"967":1}}],["来获得连续表示并捕获每个体素中点的分布",{"2":{"962":1}}],["来获得更密集的体素注释",{"2":{"735":1}}],["来获取局部领域的上下文信息来改进点特征",{"2":{"420":1}}],["来获取描述每个分割的开放集语义的嵌入向量",{"2":{"109":1}}],["来进行",{"2":{"866":1}}],["来进行更新",{"2":{"728":1}}],["来进行传感器融合",{"2":{"678":1}}],["来校正高斯属性",{"2":{"716":1}}],["来加权语义预测",{"2":{"681":1}}],["来模拟点云的空间分布",{"2":{"636":1}}],["来减少体素查询的数量",{"2":{"612":1}}],["来减轻由此扩展带来的计算开销",{"2":{"421":1}}],["来收集长距离信息",{"2":{"603":1}}],["来促进局部非显著区域与全局对象之间表示的一致性",{"2":{"591":1}}],["来证明clio与机器人的相关性",{"2":{"586":1}}],["来源于",{"2":{"574":1}}],["来表示3d高斯分布",{"2":{"716":1}}],["来表示每个场景",{"2":{"693":1}}],["来表示输入数据是稀疏的",{"2":{"500":1}}],["来表示原来由rgb三原色构成的图片",{"2":{"227":1}}],["来融合相应的特征",{"2":{"482":1}}],["来学习三维形状的旋转不变表示",{"2":{"481":1}}],["来细化并获得更准确的3d高斯表示",{"2":{"444":1}}],["来预测合成图像上的像素分数",{"2":{"955":1}}],["来预测每个查询向量的分类",{"2":{"434":1}}],["来预测初始可变形四面体网格中每个顶点的sdf值",{"2":{"344":1}}],["来提高效率",{"2":{"547":1}}],["来提取",{"2":{"743":1}}],["来提取3d关键点",{"2":{"449":1}}],["来提取图像和点云的特征",{"2":{"421":1}}],["来提出一个关系网络",{"2":{"337":1}}],["来降低这些方法的计算和存储开销",{"2":{"363":1}}],["来降低正则化对重建效果的影响",{"2":{"345":1}}],["来修剪地点子图",{"2":{"301":1}}],["来膨胀地图",{"2":{"301":1}}],["来指导ddpm在给定reference",{"2":{"289":1}}],["来估计密度体积",{"2":{"957":1}}],["来估计全局一致的轨迹",{"2":{"285":1}}],["来估计参数",{"2":{"235":1}}],["来实现鲁棒的特征学习",{"2":{"962":1}}],["来实现",{"2":{"273":1,"705":1,"950":1,"962":1}}],["来自激光雷达的密集",{"2":{"977":1}}],["来自激光雷达或雷达的点云对天气变化具有鲁棒性",{"2":{"970":1}}],["来自多个相机的特征通过平均",{"2":{"942":1}}],["来自摄像头",{"2":{"691":1}}],["来自不同视角",{"2":{"630":1,"667":1}}],["来自不确定区域",{"2":{"591":1}}],["来自背景区域",{"2":{"591":1}}],["来自相应网格的顶点",{"2":{"449":1}}],["来自当前检测",{"2":{"419":1}}],["来自位姿图",{"2":{"419":1}}],["来自unity的输入相机图像",{"2":{"419":1}}],["来自上一层的查询向量",{"2":{"405":1}}],["来自语义查询",{"2":{"384":1}}],["来自实例查询",{"2":{"384":1}}],["来自8个公开集",{"2":{"360":1}}],["来自同一传感器的样本数据在时间上跟随这个",{"2":{"254":1}}],["来自时间上位于此之前的同一对象实例的示例注释",{"2":{"254":1,"654":1}}],["来自后面同一对象实例的示例注释",{"2":{"254":1,"654":1}}],["来自视觉",{"2":{"210":1}}],["来根据用户指定的任务列表对对象和区域进行聚类",{"2":{"168":1}}],["来寻找假定的环路闭合和",{"2":{"141":1}}],["来构建3d场景图",{"2":{"141":1}}],["来结束本文",{"2":{"131":1}}],["来捕捉对象之间的关系",{"2":{"116":1}}],["来支持在多个抽象层次上的决策制定",{"2":{"116":1}}],["来生成图像的细粒度分割",{"2":{"109":1}}],["来缩小机器人和人类感知之间的差距",{"2":{"105":1}}],["来老铁干了这碗代码的博客",{"2":{"63":1}}],["线性投影头部和带阈值的线性投影头部",{"2":{"957":1}}],["线激光雷达强大得多",{"2":{"803":1}}],["线激光雷达",{"2":{"739":1}}],["线程",{"2":{"408":1}}],["线",{"2":{"105":1,"189":1}}],["房间y中的建筑物z的对象",{"2":{"947":1}}],["房间的边界框包含该房间中的对象",{"2":{"905":1}}],["房间的误分类是不重要的",{"2":{"796":1}}],["房间的背面或前面",{"2":{"197":1}}],["房间等先验知识进行推理",{"2":{"765":1}}],["房间用局部网格表示",{"2":{"648":1}}],["房间为55",{"2":{"437":1}}],["房间层的运行时间由地点的数量决定",{"2":{"437":1}}],["房间检测方法在kimera",{"2":{"301":1}}],["房间检测",{"0":{"301":1},"2":{"276":1}}],["房间节点有边连接到它包含的地点",{"2":{"218":1}}],["房间节点",{"2":{"218":1}}],["房间和地方层面",{"2":{"947":1}}],["房间和结构",{"0":{"480":1}}],["房间和相机位置的图",{"2":{"172":1}}],["房间和建筑物",{"2":{"125":1}}],["房间和楼层比绘制一条精确的度量路径更为方便",{"2":{"116":1}}],["房间",{"0":{"218":1},"2":{"105":1,"109":1,"112":1,"125":1,"131":1,"137":1,"147":2,"162":1,"172":1,"209":2,"262":1,"285":1,"437":1,"480":1,"648":1,"796":1,"947":1,"967":1}}],["注入新机制",{"2":{"824":1}}],["注入安全关键极端案例",{"2":{"360":1}}],["注入领域知识",{"2":{"195":1}}],["注册对象",{"2":{"352":1}}],["注释",{"2":{"997":1}}],["注释的第一个非道路",{"2":{"828":1}}],["注释3",{"2":{"390":1}}],["注释1",{"2":{"262":1}}],["注释2",{"2":{"262":2}}],["注",{"2":{"104":1,"115":1,"130":1,"146":1,"351":2,"387":1,"409":1,"444":1,"455":1,"486":1,"502":1,"503":1,"576":1,"621":1,"638":1,"642":1,"670":1,"681":2,"693":1,"700":2,"716":1,"736":3,"738":1,"746":1,"779":1,"800":2,"829":1,"842":2,"900":1}}],["注意g~il≠gl−gi",{"2":{"390":1}}],["注意力模块初始化比较稀疏",{"2":{"386":1}}],["注意z总是0",{"2":{"254":1}}],["注意是左开右闭",{"2":{"93":1}}],["注意",{"2":{"45":1,"73":1,"177":3,"254":3,"277":1,"405":1,"429":1,"509":1,"597":1,"607":1,"654":1,"688":1,"747":1,"796":1,"814":1,"835":1,"854":1,"947":1,"961":1}}],["往往需要借助3d",{"2":{"658":1}}],["往往需要对抗学习",{"2":{"203":1}}],["往vector容器后插入一个元素",{"2":{"104":1}}],["往vector容器最后一个元素位置后添加元素t",{"2":{"104":1}}],["往position迭代器指定位置前插入一个元素",{"2":{"104":1}}],["往iter迭代器指向元素前插入另一个相同类型vector容器的",{"2":{"104":1}}],["往iter迭代器指向元素前添加n个值为t的元素",{"2":{"104":1}}],["往iter迭代器指向元素前添加元素t",{"2":{"104":1}}],["上出现误预测",{"2":{"992":1}}],["上使用",{"2":{"982":2}}],["上预测深度图",{"2":{"978":1}}],["上预训练的resnet",{"2":{"758":1}}],["上预训练的",{"2":{"677":1,"771":1}}],["上预训练的模型权重的mask",{"2":{"605":1}}],["上部所示",{"2":{"952":1}}],["上部图表展示了动态融合",{"2":{"829":1}}],["上对",{"2":{"928":1}}],["上都超过了我们",{"2":{"917":1}}],["上超过了最近的",{"2":{"917":1}}],["上超过了使用",{"2":{"700":1}}],["上被超越",{"2":{"903":1}}],["上表现出色",{"2":{"842":1}}],["上表现相当",{"2":{"700":1}}],["上与真实环境的吻合程度",{"2":{"826":1}}],["上获得令人信服的结果",{"2":{"811":1}}],["上取得了显著提升",{"2":{"792":1}}],["上评估了我们的插件flashocc",{"2":{"791":1}}],["上展示了泛化性和效率",{"2":{"770":1}}],["上训练",{"2":{"744":1}}],["上训练了",{"2":{"677":2,"771":2}}],["上基本相同",{"2":{"735":1}}],["上提高了相同的指标",{"2":{"928":1}}],["上提高了",{"2":{"700":2,"903":2,"928":4}}],["上提供了首个非道路占据标注",{"2":{"652":1}}],["上报告了",{"2":{"700":1}}],["上注册估计和地面真实点云",{"2":{"686":1}}],["上采样与迭代优化",{"0":{"618":1}}],["上采样过程可能无法充分补偿粗阶段的信息损失",{"2":{"612":1}}],["上采样是邻域3个点",{"2":{"589":1}}],["上海ai",{"2":{"584":1}}],["上海交通大学",{"2":{"517":1}}],["上图显示了构建rulebook的整体流程",{"2":{"561":1}}],["上进行具身三维空间占用预测的视频演示的一个采样图像",{"2":{"902":1}}],["上进行训练",{"2":{"867":1}}],["上进行预训练",{"2":{"617":1}}],["上进行",{"2":{"545":1,"677":1,"712":1,"761":1,"885":1,"965":1}}],["上进行了实验",{"2":{"503":1}}],["上进行了广泛的评估",{"2":{"444":1}}],["上下文组件",{"2":{"603":1}}],["上下文特征对于语义",{"2":{"603":1}}],["上下文感知",{"2":{"603":1}}],["上下文层",{"2":{"570":1}}],["上下文关系先验层",{"0":{"752":1}}],["上下文关系先验组件",{"2":{"632":1}}],["上下文关系先验",{"0":{"684":1},"1":{"707":1,"730":1,"752":1},"2":{"539":1,"570":1,"632":1,"684":1,"752":1}}],["上下载驱动项目",{"2":{"120":1}}],["上的性能",{"2":{"903":1}}],["上的高斯和占用的可视化结果",{"2":{"901":1}}],["上的可视化",{"0":{"901":1}}],["上的结果",{"2":{"803":3}}],["上的单目",{"2":{"792":1}}],["上的计时结果",{"2":{"437":1}}],["上的表现优于",{"2":{"382":1}}],["上楼梯",{"2":{"437":1}}],["上将精度提升至最先进水平",{"2":{"425":1}}],["上存储信息",{"2":{"378":1}}],["上升",{"2":{"352":1}}],["上执行2d",{"2":{"336":1}}],["上实现了最先进的性能",{"2":{"290":1}}],["上式给出了一种从随机采样噪声出发一步步逼近目标数据的方法",{"2":{"225":1}}],["上百g",{"2":{"220":1}}],["上",{"2":{"117":1,"197":1,"417":1,"503":1,"622":1,"700":2,"903":1,"917":1,"947":1}}],["上游错误未经修正传播",{"2":{"103":1}}],["上述测量方法提供了一种硬性评估",{"2":{"916":1}}],["上述两项任务使网络能够更精确地感知目标边界",{"2":{"666":1}}],["上述方法距离实际部署到自动驾驶系统中仍有一定距离",{"2":{"1004":1}}],["上述方法消除了对显式3d占用注释的需求",{"2":{"941":1}}],["上述方法均在全图上操作",{"2":{"607":1}}],["上述方法通过向量描述每个体素对3d空间进行体素化",{"2":{"566":1}}],["上述方法在很大程度上依赖于graphcmr的准确性",{"2":{"419":1}}],["上述方法采用监督学习",{"2":{"252":1}}],["上述优化对应于因子图的优化",{"2":{"171":1}}],["上述步骤1和步骤2交替进行",{"2":{"75":1}}],["上述代码输出的结果为",{"2":{"52":1}}],["传入初始化列表",{"2":{"571":1}}],["传入两个参数",{"2":{"571":1}}],["传统数据集",{"2":{"997":1}}],["传统室内场景的空间占用预测工作接受rgb",{"2":{"682":1}}],["传统方法采用体素化技术",{"2":{"535":1}}],["传统上",{"2":{"525":1}}],["传统视觉检测器识别目标",{"2":{"103":1}}],["传统的基于体素的表示方法",{"2":{"693":1}}],["传统的基于深度学习的交互式分割框架利用前向传播得到的结果",{"2":{"75":1}}],["传统的3d检测在这类场景上很容易失效",{"2":{"630":1}}],["传统的图像分类模型无法对类别进行拓展",{"2":{"151":1}}],["传统的gan网络输入是一个随机变量或者隐藏变量",{"2":{"133":1}}],["传统的地图构建技术侧重于几何精度",{"2":{"90":1}}],["传感器故障",{"2":{"1005":1}}],["传感器生成的",{"2":{"889":1,"947":1}}],["传感器被保持得太靠近墙壁",{"2":{"872":1}}],["传感器重建",{"2":{"668":1}}],["传感器和时间序列的信息",{"2":{"630":1,"667":1}}],["传感器信息来自环视摄像头和",{"2":{"613":1}}],["传感器外参",{"2":{"597":1}}],["传感器的稠密点云生成变得可行",{"2":{"588":1}}],["传感器扫描构建大规模环境的几何一致表示",{"2":{"588":1}}],["传感器噪声",{"2":{"435":1,"864":1}}],["传感器形态",{"2":{"254":1}}],["传感器通道名称",{"2":{"254":1}}],["传感器数据",{"2":{"254":1}}],["传感器同步",{"0":{"211":1}}],["传感器校准和地图绘制等新问题",{"2":{"302":1}}],["传感器校准",{"0":{"191":1}}],["传感器",{"2":{"100":1,"173":1,"189":1}}],["具有高准确性",{"2":{"1000":1}}],["具有最佳的miou",{"2":{"1000":1}}],["具有最高余弦相似度的标签",{"2":{"492":1}}],["具有",{"2":{"985":1}}],["具有与voxformer和sgn类似的混合转换",{"2":{"950":1}}],["具有显著优势",{"2":{"950":1}}],["具有挑战性的场景性能分析",{"0":{"936":1}}],["具有灵活的位置和协方差属性",{"2":{"842":1}}],["具有区域权重",{"2":{"694":1}}],["具有对开放集对象",{"2":{"667":1}}],["具有较小的重叠",{"2":{"630":1}}],["具有代表性的",{"2":{"625":1}}],["具有很强的将概率正则化为单一模态分布的能力",{"2":{"622":1}}],["具有很强的语义性",{"2":{"143":1}}],["具有24个核心",{"2":{"522":1}}],["具有重要影响",{"2":{"520":1}}],["具有更强的三维理解和密度优势",{"2":{"691":1}}],["具有更宽容参数的基于视觉的环路闭合检测",{"2":{"437":1}}],["具有更好的扩展性",{"2":{"301":1}}],["具有名义参数的传统基于视觉的环路闭合检测",{"2":{"437":1}}],["具有固定的计算成本",{"2":{"437":1}}],["具有无序性的特点",{"2":{"340":1}}],["具有大重投影误差的点",{"2":{"310":1}}],["具有相似的有利特性",{"2":{"824":1,"844":1}}],["具有相似",{"2":{"255":1}}],["具有映射掩码的文件的相对路径",{"2":{"254":1}}],["具有以下属性",{"2":{"218":1,"240":1}}],["具备姿态信息的地图",{"2":{"155":1}}],["具身空间占用预测的性能急剧下降",{"2":{"833":1}}],["具身空间占用预测",{"2":{"833":1}}],["具身空间占用预测接受连续的实时视觉输入",{"2":{"793":1}}],["具身三维空间占用预测",{"0":{"682":1}}],["具身场景下",{"2":{"435":1}}],["具身智能领域对语义地图本身的评估远少于对下游任务表现的评估",{"2":{"943":1}}],["具身智能方法通常在仿真中假设无噪传感器",{"2":{"864":1}}],["具身智能中已有工作将不确定性纳入任务规划",{"2":{"826":1}}],["具身智能社区通常采用两种假设",{"2":{"435":1}}],["具身智能任务",{"0":{"139":1}}],["具身的输入模态",{"2":{"176":1}}],["具身式",{"2":{"139":3}}],["具身式问答",{"2":{"139":1}}],["具身式人工智能",{"2":{"139":1}}],["具身任务涉及一个智能体",{"2":{"110":1}}],["具身任务",{"0":{"110":1},"1":{"123":1,"139":1},"2":{"100":1}}],["具体步骤",{"2":{"563":1}}],["具体步骤如下",{"2":{"435":1}}],["具体采用了一个类似unet",{"2":{"440":1}}],["具体的是采用目前openai所开源的最大clip模型",{"2":{"373":1}}],["具体见论文the",{"2":{"345":1}}],["具体取决于哪个面定义第一个邻居",{"2":{"325":1}}],["具体取决于指定的时间范围",{"2":{"310":1}}],["具体做法是",{"2":{"181":1}}],["具体来说",{"2":{"143":1,"153":3,"253":1,"264":1,"266":1,"271":1,"301":1,"312":1,"352":2,"400":1,"421":1,"422":2,"429":1,"437":2,"471":1,"482":1,"512":1,"532":1,"567":1,"574":2,"600":1,"609":1,"610":1,"621":1,"623":1,"636":1,"656":1,"681":2,"693":1,"704":1,"716":3,"738":1,"780":1,"792":2,"794":1,"800":1,"821":1,"828":1,"833":1,"842":1,"851":1,"858":1,"860":1,"875":3,"910":1,"922":2,"928":1,"941":1,"942":2,"950":1,"957":3,"976":1,"988":1}}],["具体而言",{"2":{"114":1,"145":1,"306":1,"421":1,"426":1,"435":1,"456":1,"505":1,"535":1,"582":1,"627":1,"699":1,"718":1,"811":1}}],["具体原因后续学习相关知识再来补充",{"2":{"41":1}}],["具体实现为对所有的验证图片x",{"2":{"13":1}}],["具体公式如下",{"2":{"13":1}}],["背景区域掩码",{"2":{"694":1}}],["背景和空环境",{"2":{"694":1}}],["背景和空区域分解",{"2":{"694":1}}],["背景和空区域",{"2":{"455":1}}],["背景",{"0":{"689":1,"737":1},"1":{"712":1,"735":1,"757":1,"759":1,"778":1,"780":1,"799":1,"801":1,"821":1,"841":1,"860":1},"2":{"277":1,"302":1,"534":1}}],["背景色等style",{"2":{"181":1}}],["背景知识",{"0":{"100":1},"1":{"110":1,"123":1,"139":1,"155":1,"171":1,"189":1,"209":1,"231":1,"252":1,"274":1,"299":1}}],["背景label的",{"2":{"84":1}}],["现在我们展示kimera的准确姿态估计和对动态场景的鲁棒性如何提高重建的几何精度",{"2":{"686":1}}],["现在我们可以借助clip模型里文本和图像之间对齐的表征来做一些损失计算了",{"2":{"422":1}}],["现在自注意力是在窗口内算的",{"2":{"631":1}}],["现在设置一个深度区间",{"2":{"355":1}}],["现在基本上用end",{"2":{"220":1}}],["现在变道安全吗",{"2":{"176":1}}],["现在想要删除名叫",{"2":{"99":1}}],["现代vla模型可",{"2":{"145":1}}],["现代的基础模型为任务不可知分割提供了一种方式",{"2":{"137":1}}],["现代机器人时代始于",{"2":{"123":1}}],["现代工具",{"2":{"98":1}}],["现有网络在有限的3d标注数据集上训练的泛化能力尚未得到广泛研究",{"2":{"1006":1}}],["现有建图方法能否有效捕捉动态物体",{"2":{"926":1}}],["现有系统尚缺乏稳健的连续语义学习机制",{"2":{"864":1}}],["现有系统很少显式建模并传播不确定性",{"2":{"864":1}}],["现有做法",{"2":{"826":1}}],["现有方法的长距离检测能力相对较差",{"2":{"931":1}}],["现有方法是为室内或室外场景设计的",{"2":{"603":1}}],["现有方法主要基于两种视图变换策略",{"2":{"585":1}}],["现有方法需要耗时的聚合中间步骤",{"2":{"349":1}}],["现有研究根据监督类型可分为稀疏感知和密集感知",{"2":{"566":1}}],["现有的大多数方法",{"2":{"996":1}}],["现有的基于占用的应用主要集中在感知层面",{"2":{"1003":1}}],["现有的基于占用的应用包括分割",{"2":{"1003":1}}],["现有的基于点的方法大多采用昂贵的邻域搜索机制",{"2":{"996":1}}],["现有的基于时序的bev方法分为两类",{"2":{"695":1}}],["现有的单智能体自动驾驶感知系统本质上无法解决关键问题",{"2":{"969":1}}],["现有的工作主要使用空间地图来捕捉几何布局",{"2":{"958":1}}],["现有的三维物体检测器有两个局限性",{"2":{"931":1}}],["现有的3d占用预测方法都是基于网格表示的",{"2":{"612":1}}],["现有的3d占据预测方法高度依赖环视摄像头图像",{"2":{"475":1}}],["现有的方法可以分为两类",{"2":{"983":1}}],["现有的方法都使用了几何输入",{"2":{"603":1}}],["现有的方法仍然依赖于深度数据",{"2":{"570":1}}],["现有的方法主要集中在不同传感器模态之间的信息交互和融合上",{"2":{"438":1}}],["现有的激光雷达",{"2":{"474":1}}],["现有的",{"2":{"425":1,"570":1}}],["现有的多传感器融合方法主要集中在笛卡尔坐标系下对传感器信息进行交互和融合",{"2":{"409":1}}],["现有综述多将语义地图置于其下游应用背景下进行回顾",{"2":{"90":1}}],["现有文献仍显分散且迅速扩张",{"2":{"72":1}}],["光度一致性损失",{"2":{"988":1}}],["光度监督",{"2":{"934":1}}],["光度约束",{"0":{"622":1},"2":{"622":1}}],["光线追踪跳跃连接",{"2":{"928":1}}],["光照或环境动态变化时",{"2":{"826":1}}],["光照变化和噪声等因素普遍存在",{"2":{"665":1}}],["光照等影响降到了最低",{"2":{"650":1}}],["光程平差法",{"2":{"179":1}}],["光流方法最初用于对齐视频中两个相邻帧的特征",{"2":{"96":1}}],["光标会被移到行首",{"2":{"48":1}}],["全卷积bev编码器对这些融合后的特征进行编码",{"2":{"576":1}}],["全球可部署vla4ad系统",{"2":{"478":1}}],["全部替换",{"2":{"842":1}}],["全部窗口化到当前机器人姿态周围的半径内",{"2":{"380":1}}],["全部anchors拿去训练太多了",{"2":{"321":1}}],["全连接网络另外输出一个特征向量f",{"2":{"344":1}}],["全局特征提取和融合模块以实现高效和自适应的体素和bev特征交互",{"2":{"875":1}}],["全局一致的地图需要大量计算与内存",{"2":{"864":1}}],["全局一致的轨迹估计",{"2":{"285":1}}],["全局地图",{"2":{"743":1}}],["全局",{"2":{"686":1}}],["全局池化层以及全连接层得到最终输出",{"2":{"659":1}}],["全局池和多分辨率池用于捕获点云的全局和局部特征",{"2":{"607":1}}],["全局策略",{"2":{"525":1}}],["全局中心",{"2":{"435":1}}],["全局网格",{"2":{"362":1}}],["全局把握",{"2":{"343":1}}],["全局表示的",{"2":{"313":1}}],["全景图像",{"2":{"967":1}}],["全景",{"0":{"302":1},"2":{"302":4}}],["全景分割数据",{"2":{"850":1}}],["全景分割任务",{"2":{"384":1}}],["全景分割",{"2":{"162":1}}],["全景分割语义标签",{"2":{"162":1}}],["全掩码可能会使模型陷入局部最优",{"2":{"96":1}}],["全面回顾了具身智能中的语义地图构建方法",{"2":{"80":1}}],["全面综述",{"2":{"72":1}}],["作品",{"2":{"125":2}}],["作者声明他们没有利益冲突或财务冲突需要披露",{"2":{"984":1}}],["作者得到了加拿大",{"2":{"958":1}}],["作者对dcnv2进行了如下扩展改进",{"2":{"863":1}}],["作者成功的对cnn进行了大尺度扩展",{"2":{"824":1}}],["作者将元素级的sigmoid归一化调整为沿采样点的softmax归一化",{"2":{"863":1}}],["作者将空域聚合过程拆分为",{"2":{"863":1}}],["作者将原始的卷积权值",{"2":{"863":1}}],["作者将所有三种传感器的数据处理成",{"2":{"678":1}}],["作者将网格池化定义为一系列的边折叠操作",{"2":{"466":1}}],["作者通过这种巧妙的循环位移的方式和巧妙设计的掩码模板",{"2":{"751":1}}],["作者通过边折叠的方式来进行池化",{"2":{"589":1}}],["作者通过利用三角网格特有的对称性",{"2":{"589":1}}],["作者通过提出的高度关联变换器模块",{"2":{"497":1}}],["作者利用文献",{"2":{"527":1}}],["作者采用了vit的基本模块",{"2":{"880":1}}],["作者采用贝叶斯神经网络进行相机",{"2":{"678":1}}],["作者采用voxnet作为3d主干网络",{"2":{"527":1}}],["作者采用流模块来对齐图像和交互特征",{"2":{"96":1}}],["作者",{"2":{"477":1}}],["作者遵循qi",{"2":{"407":1}}],["作者简单地为每个面定义了二面角",{"2":{"379":1}}],["作者提出了以下洞见",{"2":{"343":1}}],["作者提出了一种早晚融合策略来整合交互和图像特征",{"2":{"96":1}}],["作者的目标是将多视角的2d特征转换为3d感知特征",{"2":{"341":1}}],["作者的研究主要涵盖了以下几个重要因素",{"2":{"265":1}}],["作者认为只有在房间内才需高精度",{"2":{"648":1}}],["作者认为",{"2":{"366":1}}],["作者认为这篇工作的贡献可以被总结为以下几点",{"2":{"265":1}}],["作者认为原因可能是以下几点",{"2":{"265":1}}],["作者设计了多阶段特征融合",{"2":{"96":1}}],["作为基本构建块",{"2":{"982":1}}],["作为基线",{"2":{"833":1}}],["作为双端队列a的初值",{"2":{"888":1}}],["作为双",{"2":{"888":1}}],["作为框架的",{"2":{"867":1}}],["作为底层容器",{"2":{"835":1}}],["作为体素级对比方法",{"2":{"811":1}}],["作为综合评估指标",{"2":{"807":1,"915":1}}],["作为我们的图像骨干网络",{"2":{"758":1}}],["作为真实标签",{"2":{"735":1}}],["作为解码器以生成多尺度tpv",{"2":{"699":1}}],["作为编码器以细化特征",{"2":{"699":1}}],["作为空类别的概率",{"2":{"681":1}}],["作为评估模型语义分割性能的指标",{"2":{"778":1}}],["作为评估指标",{"2":{"677":1,"736":1}}],["作为评估的基线",{"2":{"437":1}}],["作为颈部结构",{"2":{"768":1}}],["作为颈部网络",{"2":{"677":1}}],["作为颈部来聚合这些多尺度特征",{"2":{"609":1}}],["作为主干网络",{"2":{"677":1}}],["作为主干和",{"2":{"96":1}}],["作为视图投影器以加速从透视视图到",{"2":{"670":1}}],["作为激光雷达编码器",{"2":{"670":1}}],["作为行为决策和运动控制的前提",{"2":{"665":1}}],["作为教师模型",{"2":{"642":1}}],["作为颜色重建损失",{"2":{"640":1}}],["作为骨干网络来提取多尺度特征",{"2":{"609":1}}],["作为位置嵌入",{"2":{"578":1,"621":2}}],["作为edgeconv的核心层",{"2":{"574":1}}],["作为以目标为中心的稀疏场景表示的先驱",{"2":{"567":1}}],["作为注意力机制的查询",{"2":{"563":1}}],["作为提示而不暴露被掩码的点块的位置和整体点云对象的形状",{"2":{"549":1}}],["作为输入",{"2":{"549":1,"621":1}}],["作为一个类别",{"2":{"878":1}}],["作为一个开创新的工作",{"2":{"574":1}}],["作为一个开创性的工作",{"2":{"420":1}}],["作为一种高效的以目标为中心的表示方法",{"2":{"851":1}}],["作为一种更具",{"2":{"599":1}}],["作为一种解决方案",{"2":{"567":1}}],["作为一种以目标为中心的稀疏替代方案",{"2":{"536":1}}],["作为场景表示",{"2":{"516":1,"547":1}}],["作为transformer解码器的关键输入部分",{"2":{"427":1}}],["作为图像主干网络",{"2":{"822":1}}],["作为图像背景",{"2":{"803":1,"823":1}}],["作为图像backbone训练",{"2":{"803":1}}],["作为图像backbone",{"2":{"803":1}}],["作为图像骨干的融合模型参数为",{"2":{"425":1}}],["作为图1",{"2":{"285":1}}],["作为pointnet++层次结构的核心",{"2":{"420":1}}],["作为子模块",{"2":{"285":1}}],["作为第二阶段",{"2":{"276":1}}],["作为ib的输入",{"2":{"271":1}}],["作为参数访问",{"2":{"196":1}}],["作为条件",{"2":{"175":1}}],["作为合并操作对应的信息损失的分数度量",{"2":{"153":1}}],["作为",{"2":{"125":1,"481":1,"599":1,"660":1,"670":1,"744":1,"768":1,"789":1,"863":1,"865":1,"867":1,"870":3}}],["作为分割头",{"2":{"96":1}}],["早已在机器人学的建图",{"2":{"556":1}}],["早晚融合",{"2":{"96":1}}],["早期感知过程的结果是传递给中级感知过程",{"2":{"408":1}}],["早期的方法通常将点云体素化为密集网格",{"2":{"962":1}}],["早期的方法通常将三维卷积神经网络",{"2":{"363":1}}],["早期的方法利用形状从阴影",{"2":{"860":1}}],["早期的3d",{"2":{"841":1}}],["早期的室外占用感知方法主要使用激光雷达输入来推断3d占用",{"2":{"759":1}}],["早期的",{"2":{"588":1,"599":1}}],["早期的研究工作",{"2":{"482":1}}],["早期的融合方法普遍存在交互信息提取不正确的问题",{"2":{"96":1}}],["早期工作大多使用在封闭词汇",{"2":{"721":1}}],["早期工作",{"2":{"588":1,"967":1}}],["早期工作通常采用预训练骨干网络",{"2":{"274":1}}],["早期工作集中在2d地图上",{"2":{"172":1}}],["早期vla4ad系统通常直接预测原始控制信号如转向角",{"2":{"216":1}}],["早期做法主要通过两种方式引入语义",{"2":{"209":1}}],["早期研究聚焦于直接导航指令",{"2":{"176":1}}],["早期研究聚焦于碰撞避免",{"2":{"123":1}}],["早期系统集成激光雷达以获取精确3d结构",{"2":{"176":1}}],["早期方法采用单目前视相机作为标准视觉模态",{"2":{"176":1}}],["早期努力如gpt",{"2":{"128":1}}],["早期关于机器人地图表示的工作",{"2":{"116":1}}],["早期端到端方法通过集成感知与预测任务引入中间监督",{"2":{"114":1}}],["早期原型已在仿真和闭环测试中展现提升的安全性与指令保真度",{"2":{"82":1}}],["早期改进已提升对罕见目标的泛化能力",{"2":{"82":1}}],["理想情况下",{"2":{"435":1}}],["理由",{"2":{"145":1}}],["理解和建模周围场景对于自动驾驶车辆",{"2":{"438":1}}],["理解这一区别对于把语义建图置于更宏大的系统设计框架中至关重要",{"2":{"231":1}}],["理解场景的几何",{"2":{"116":1}}],["理解交通语境并在实时条件下安全行动",{"2":{"82":1}}],["理论上可以识别",{"2":{"406":1}}],["理论依据",{"0":{"212":1},"1":{"234":1,"255":1}}],["理论来表述",{"2":{"109":1}}],["理论篇",{"2":{"96":1}}],["图来自tpvformer",{"2":{"693":1}}],["图更新",{"2":{"525":2}}],["图9报告了hydra与",{"2":{"437":1}}],["图9",{"2":{"419":3}}],["图式",{"2":{"391":1}}],["图8显示",{"2":{"437":1}}],["图8评估了房间检测性能",{"2":{"437":1}}],["图8展示了变形图的组成部分和创建过程",{"2":{"390":1}}],["图8中的黄色边",{"2":{"390":1}}],["图8中的红色和蓝色边",{"2":{"390":1}}],["图8中的红色边",{"2":{"390":1}}],["图8中的绿色边",{"2":{"390":2}}],["图8",{"2":{"390":1}}],["图7展示了多模态占用感知的通用流程",{"2":{"970":1}}],["图7提供了在kitti",{"2":{"924":1}}],["图7中一些重要的趋势是",{"2":{"437":1}}],["图7中的l1",{"2":{"390":1}}],["图7评估了对象和地点层",{"2":{"437":1}}],["图7",{"2":{"390":2,"756":1,"970":1}}],["图问答",{"2":{"360":1}}],["图结构",{"2":{"360":1}}],["图5和图7中3d高斯分布的密度和尺度的差异是因为我们分别为nuscenes和kitti",{"2":{"924":1}}],["图5定性展示了clio在办公室场景中产生任务相关区域的能力",{"2":{"522":1}}],["图5",{"2":{"285":2,"336":3,"408":3,"833":1,"842":1,"924":1,"942":1}}],["图5显示了kimera",{"2":{"285":1}}],["图4展示了以激光雷达为中心的占用感知的通用流程",{"2":{"910":1}}],["图4展示了在occ3d",{"2":{"909":1}}],["图4显示了clio针对两组不同任务的检测对象的子集",{"2":{"462":1}}],["图4",{"2":{"285":2,"380":2,"728":1,"738":1,"909":1,"910":1}}],["图6展示了在nuscenes",{"2":{"911":1}}],["图6",{"2":{"210":1,"942":1}}],["图像数量",{"2":{"997":1}}],["图像非常吻合",{"2":{"885":1}}],["图像归一化和图像填充",{"2":{"866":1}}],["图像进行三维语义场景补全",{"2":{"853":1}}],["图像分类",{"2":{"824":1}}],["图像分支导致精度下降的异常现象可能是由于激光雷达特征网络的充分训练",{"2":{"803":1}}],["图像分辨率",{"2":{"693":1}}],["图像大小和计算平台存在差异",{"2":{"922":1}}],["图像大小和2d骨干网络分别表示输入图像分辨率和图像特征提取器",{"2":{"736":1}}],["图像大小为",{"2":{"803":2}}],["图像主干为resnet",{"2":{"785":1}}],["图像和3d空间旋转",{"2":{"764":1}}],["图像交叉注意力模块",{"2":{"716":2}}],["图像交叉注意力和细化模块",{"2":{"704":1}}],["图像交叉注意力和属性细化模块进行更新",{"2":{"716":1}}],["图像交叉注意力和属性细化",{"2":{"669":1}}],["图像匹配",{"2":{"698":2}}],["图像xrgbx",{"2":{"632":1}}],["图像推断三维语义场景补全",{"2":{"632":1}}],["图像推断出密集的语义场景",{"2":{"570":1}}],["图像编码器从输入图像中提取感知视图中的高级特征",{"2":{"627":1}}],["图像编码器",{"0":{"627":1}}],["图像来解决",{"2":{"603":1}}],["图像来推断密集的",{"2":{"570":1}}],["图像作为输入",{"2":{"603":1}}],["图像处理室内和室外场景的",{"2":{"570":1}}],["图像中进行语义场景补全",{"2":{"937":1}}],["图像中推断场景的密集几何结构和语义信息",{"2":{"539":1}}],["图像中相邻坐标像素对的语义相似度",{"2":{"410":1}}],["图像是否足够相似",{"2":{"525":1}}],["图像+控制+语言",{"2":{"478":1}}],["图像或者多模态的引导",{"2":{"422":1}}],["图像特征和3d",{"2":{"988":1}}],["图像特征与高斯分布之间的交互以及高斯分布之间的交互都将在相机坐标系中进行",{"2":{"705":1}}],["图像特征投影到",{"2":{"495":1}}],["图像特征",{"2":{"369":1}}],["图像的尺寸为",{"2":{"853":1}}],["图像的序列长度远比自然语言高",{"2":{"343":1}}],["图像的时间戳是曝光触发时间",{"2":{"211":1}}],["图像生成方法必须能够捕获数据中存在的语义结构",{"2":{"294":1}}],["图像相关性得分",{"2":{"274":1}}],["图像",{"2":{"184":1,"252":1,"277":1,"652":1,"698":1,"743":1,"808":1,"853":1,"955":1,"989":1}}],["图像解包为",{"2":{"173":1}}],["图中红色矩形突出了每种场景下每种预测结果的主要差异",{"2":{"952":1}}],["图中省略了特征维度",{"2":{"752":1}}],["图中没有画",{"2":{"659":1}}],["图中示例选取了验证集中点数最多的点云",{"2":{"638":1}}],["图中还展示了不同时间点",{"2":{"568":1}}],["图中的每个块表示与前面章节讨论相匹配的算法模块",{"2":{"408":1}}],["图中",{"2":{"184":1}}],["图中显示了示例输入数据和hydra在大型真实环境中创建的3d场景图",{"2":{"112":1}}],["图3",{"2":{"168":1,"197":2,"352":1,"480":1,"638":1,"670":1,"705":1,"716":1,"841":1}}],["图3展示了高层次的架构",{"2":{"168":1}}],["图20显示了这些设置对tx2上kimera",{"2":{"836":1}}],["图25",{"2":{"796":1}}],["图23显示了kimera重建的",{"2":{"872":1}}],["图23",{"2":{"796":2}}],["图21",{"2":{"947":1}}],["图21显示了使用microsoft的azure",{"2":{"889":1}}],["图21右侧dsg",{"2":{"796":1}}],["图21左侧dsg",{"2":{"796":1}}],["图22底部",{"2":{"947":1}}],["图22顶部",{"2":{"947":1}}],["图22还显示",{"2":{"872":1}}],["图22中的绿色节点应该是冰箱",{"2":{"872":1}}],["图22显示了kimera重建的",{"2":{"872":1}}],["图22",{"2":{"796":1,"947":1}}],["图24",{"2":{"796":1}}],["图2中的时间线概述表明",{"2":{"759":1}}],["图2橙色虚线框",{"2":{"595":1}}],["图2蓝色虚线框",{"2":{"563":1}}],["图2b给出了这个想法的可视化",{"2":{"301":1}}],["图2",{"2":{"162":1,"197":2,"218":1,"276":1,"480":2,"522":1,"568":1,"576":1,"642":1,"693":1,"759":1}}],["图",{"2":{"133":1,"149":1,"274":1,"285":4,"390":1,"444":1,"502":1,"503":1,"570":1,"621":1,"632":1,"660":1,"675":1,"681":2,"707":2,"746":2,"752":2,"765":1,"829":1,"839":1,"847":3,"885":1,"900":1,"902":1,"903":2,"944":2,"949":1,"982":2,"995":1}}],["图19报告了kimera",{"2":{"816":1}}],["图18",{"2":{"754":1}}],["图17",{"2":{"732":3}}],["图17显示了使用具有kimera",{"2":{"732":1}}],["图16",{"2":{"709":2}}],["图16可视化了动态掩蔽对kimera度量",{"2":{"709":1}}],["图1直观地展示了图像或点云无法提供3d全景或密集的环境扫描",{"2":{"691":1}}],["图14显示了来自intel",{"2":{"686":1}}],["图15",{"2":{"686":3}}],["图13",{"2":{"605":1,"855":1}}],["图12",{"2":{"605":1}}],["图12提供了用于评估的数据集的概览",{"2":{"572":1}}],["图1下",{"2":{"503":1}}],["图1上",{"2":{"503":1}}],["图11",{"2":{"480":2}}],["图10显示了检测到的环路闭合数量与估计环路闭合姿态的误差",{"2":{"437":1}}],["图10显示了办公室环境中一个人类的位姿图",{"2":{"419":1}}],["图1底部",{"2":{"162":1}}],["图1和图6",{"2":{"125":1}}],["图1",{"2":{"92":1,"112":1,"147":1,"162":1,"409":1,"449":1,"455":1,"486":1,"503":1,"568":1,"691":1,"796":1}}],["图标",{"2":{"57":1}}],["端队列b的初始值",{"2":{"888":1}}],["端到端地生成图像特征并构建全局空间地图",{"2":{"743":1}}],["端到端vla4ad及推理增强vla4ad",{"2":{"538":1}}],["端到端vla4ad及以推理为核心的vla4ad",{"2":{"238":1}}],["端到端vla栈",{"2":{"417":1}}],["端到端vla模型在传感器",{"2":{"308":1}}],["端到端系统训练与部署简单",{"2":{"299":1}}],["端到端训练",{"2":{"252":1}}],["端到端方法尝试将原始传感器输入",{"2":{"252":1}}],["端到端方法",{"0":{"252":1}}],["端到端方法用单一神经网络将原始感知输入直接映射为动作",{"2":{"231":1}}],["端到端策略将原始传感器流直接映射为控制指令",{"2":{"114":1}}],["端到端自动驾驶研讨会",{"2":{"490":1}}],["端到端自动驾驶和视觉预训练利用",{"2":{"474":1}}],["端到端自动驾驶",{"0":{"114":1}}],["端到端驾驶本质上是视觉",{"2":{"114":1}}],["端到端驾驶",{"2":{"92":1}}],["端到端学习显著缩小了原始传感器输入与控制决策间差距",{"2":{"114":1}}],["端到端学习",{"2":{"92":1,"231":1}}],["端口",{"2":{"60":1}}],["端口就相当于在访问容器的",{"2":{"60":1}}],["提升动态",{"2":{"826":1}}],["提升通用指令跟随能力",{"2":{"765":1}}],["提升任务表现",{"2":{"698":1}}],["提升",{"2":{"670":1}}],["提升到",{"2":{"660":1}}],["提升透明度",{"2":{"260":1}}],["提将非均匀三维点云转化为均匀网格",{"2":{"511":1}}],["提高占用估计的准确性",{"2":{"922":1}}],["提高到",{"2":{"917":1}}],["提高模型的准确性和效率",{"2":{"800":1}}],["提高模型的表示能力",{"2":{"488":1}}],["提高了12",{"2":{"1000":1}}],["提高了tpv特征表示整个场景的能力",{"2":{"858":1}}],["提高了",{"2":{"700":1,"792":1,"803":1,"928":2}}],["提高了开放集精确度",{"2":{"462":1}}],["提高交通效率并提升人们的出行体验",{"2":{"665":1}}],["提高计算的规则性",{"2":{"593":1}}],["提高伪标签质量",{"2":{"591":1}}],["提高语义的表达能力",{"2":{"488":1}}],["提案的排名深刻地影响实例分割结果",{"2":{"434":1}}],["提前规划或考虑复杂偶然性",{"2":{"308":1}}],["提取嵌入",{"2":{"765":1}}],["提取的特征来缓解",{"2":{"765":1}}],["提取特征",{"2":{"743":1}}],["提取特征向量",{"2":{"406":1}}],["提取出一个全局潜在的表示",{"2":{"664":1}}],["提取自车位置和传感器外参",{"2":{"654":1}}],["提取全局网格和esdf",{"2":{"480":1}}],["提取地点",{"0":{"480":1}}],["提取地点子图",{"2":{"276":1}}],["提取其中的几何信息",{"2":{"456":1}}],["提取人类骨骼",{"2":{"419":1}}],["提取",{"2":{"362":1}}],["提取网格",{"2":{"362":1}}],["提取点云的特征",{"2":{"331":1}}],["提取器完全由",{"2":{"549":1}}],["提取器利用学习到的表示进行下游任务",{"2":{"368":1}}],["提取器学习点块的潜在表示",{"2":{"368":1}}],["提取器的目标是从前面的点块中预测下一个点块",{"2":{"315":1}}],["提取器",{"2":{"315":1}}],["提取每幅输入图像的特征",{"2":{"305":1}}],["提取视觉特征",{"2":{"274":1,"578":1}}],["提取数据的位置记录日志的点",{"2":{"254":1}}],["提取数据的日志的信息",{"2":{"254":1}}],["提取系数",{"2":{"140":1,"280":1}}],["提出采用稀疏潜在表示和稀疏插值操作",{"2":{"1004":1}}],["提出从点云中学习一个3d语义场景图",{"2":{"967":1}}],["提出从标注和未标注样本中蒸馏教师模型特征",{"2":{"548":1}}],["提出voronoi随机场来通过地点标记获得2d网格地图的抽象模型",{"2":{"967":1}}],["提出在圆柱坐标系中建立点云的三视角表示",{"2":{"858":1}}],["提出一种新的大尺度cnn基础模型internimage",{"2":{"824":1}}],["提出一种统一统计建图算法",{"2":{"648":1}}],["提出一个混合框架",{"2":{"349":1}}],["提出基于在线点云构建算法的",{"2":{"588":1}}],["提出用于识别角体素的模板匹配",{"2":{"276":1}}],["提出的保留池化在掩码区域上计算注意力以更好地保留稀有类别",{"2":{"875":1}}],["提出的融合式占用网络的结果",{"0":{"803":1}}],["提出的体素到高斯初始化和激光雷达引导的",{"2":{"723":1}}],["提出的区域分解蒸馏通过不同比例的标注数据提升了仅视觉",{"2":{"642":1}}],["提出的方法",{"0":{"543":1,"628":1,"657":1,"669":1},"1":{"576":1,"609":1,"638":1,"656":1,"666":1,"681":1,"682":1,"690":1,"693":1,"704":1,"716":1,"738":1}}],["提出的方法在定量和定性上都比两个基线更好",{"2":{"437":1}}],["提出的方法涉及",{"2":{"141":1}}],["提出的场景图环路闭合检测",{"2":{"437":1}}],["提出的",{"2":{"369":1}}],["提出的层次化描述符提高了检测到的环路闭合的数量和质量",{"2":{"352":1}}],["提出的关键帧基础最大后验视觉",{"2":{"310":1}}],["提出的dsg是针对任务和运动规划查询而设计的",{"2":{"262":1}}],["提出的算法重建机器人周围的局部esdf",{"2":{"141":1}}],["提出空间关系图建模自车与交通参与者交互",{"2":{"128":1}}],["提出了sparseocc",{"2":{"1004":1}}],["提出了segcloud来实现细粒度和全局一致的语义分割",{"2":{"962":1}}],["提出了更大的挑战",{"2":{"1000":1}}],["提出了射线级miou",{"2":{"998":1}}],["提出了在前视",{"2":{"976":1}}],["提出了开创性的工作",{"2":{"974":1}}],["提出了多视图pointnet",{"2":{"968":1}}],["提出了多种方法",{"2":{"517":1}}],["提出了体积感知扩散",{"2":{"963":1}}],["提出了latticenet来实现大型点云的高效处理",{"2":{"962":1}}],["提出了lerf",{"2":{"121":1}}],["提出了广义稀疏卷积来有效处理高维数据",{"2":{"962":1}}],["提出了基于双边卷积层",{"2":{"962":1}}],["提出了基于索引结构的子流形稀疏卷积网络",{"2":{"962":1}}],["提出了基于多模态融合的算法",{"2":{"444":1}}],["提出了",{"2":{"955":1,"962":1}}],["提出了首个用于室外3d语义场景补全的单目方法",{"2":{"841":1}}],["提出了前向",{"2":{"839":1}}],["提出了app",{"2":{"735":1}}],["提出了以",{"2":{"695":1}}],["提出了占用网络",{"2":{"665":1}}],["提出了3dti",{"2":{"607":1}}],["提出了三视角表示",{"2":{"599":1}}],["提出了边缘条件卷积",{"2":{"574":1}}],["提出了完全稀疏模型以利用几何稀疏性和稀疏实例查询",{"2":{"517":1}}],["提出了高效的通道到高度方法",{"2":{"517":1}}],["提出了几种解决方法",{"2":{"481":1}}],["提出了使用一组可学习核点的",{"2":{"481":1}}],["提出了edgeconv",{"2":{"258":1}}],["提出了一个掩码视图重建模块",{"2":{"1005":1}}],["提出了一个支持开放词汇3d占用预测的框架",{"2":{"975":1}}],["提出了一个统一的基于点的框架来从点云中学习2d纹理外观",{"2":{"968":1}}],["提出了一个联合",{"2":{"968":1}}],["提出了一个混合度量",{"2":{"967":1}}],["提出了一个单一的层次表示",{"2":{"961":1}}],["提出了一个对象星座的层次表示",{"2":{"961":1}}],["提出了一个用于机器人学的3d场景图模型",{"2":{"961":1}}],["提出了一个3d场景图模型来描述3d静态场景",{"2":{"961":1}}],["提出了一个稀疏核生成器",{"2":{"593":1}}],["提出了一个具身三维空间占用预测任务",{"2":{"568":1}}],["提出了一个高效通用的多任务多传感器融合框架",{"2":{"512":1}}],["提出了一个高效轻量级的多模态三维占据网络",{"2":{"482":1}}],["提出了一个基于两阶段变换器",{"2":{"512":1}}],["提出了一个结构关系网络structural",{"2":{"420":1}}],["提出了一个两步优化",{"2":{"190":1}}],["提出了一个房间级别的环路闭合检测器",{"2":{"190":1}}],["提出了一种解决方案fastocc",{"2":{"1004":1}}],["提出了一种称为",{"2":{"962":1}}],["提出了一种称为点网格的混合网络",{"2":{"363":1}}],["提出了一种独特的后期融合策略",{"2":{"923":1}}],["提出了一种在截头体空间中预测占用标签的方法",{"2":{"922":1}}],["提出了一种无缝集成物体检测和语义分割的联合学习框架",{"2":{"922":1}}],["提出了一种无监督的多任务自动编码器来学习点和形状特征",{"2":{"574":1}}],["提出了一种增量标记选择策略",{"2":{"922":1}}],["提出了一种增量构建神经语义地图的方法",{"2":{"121":1}}],["提出了一种新颖的范式",{"2":{"875":1}}],["提出了一种新的shapecontextnet体系结构",{"2":{"664":1}}],["提出了一种新的3d场景图模型",{"2":{"125":1}}],["提出了一种自监督的点云重构方法",{"2":{"664":1}}],["提出了一种端到端无监督域自适应的三维点云表示网络pointdan",{"2":{"664":1}}],["提出了一种端到端的谱卷积网络localspecgcn",{"2":{"607":1}}],["提出了一种用于三维点云通用学习表示的无监督自动编码器3dpointcapsnet",{"2":{"664":1}}],["提出了一种使用球形卷积核的八叉树导向cnn",{"2":{"636":1}}],["提出了一种超图神经网络",{"2":{"607":1}}],["提出了一种利用截断切比雪夫多项式逼近谱滤波",{"2":{"607":1}}],["提出了一种利用riconv算子实现旋转不变性的方法",{"2":{"511":1}}],["提出了一种单目",{"2":{"539":1}}],["提出了一种稀疏潜在扩散器以扩散与占据体素相邻的空体素",{"2":{"517":1}}],["提出了一种插值卷积算子interpconv来度量输入点云与核权坐标之间的几何关系",{"2":{"511":1}}],["提出了一种多传感器融合框架",{"2":{"503":1}}],["提出了一种多阶段占据导向的蒸馏方法",{"2":{"455":1}}],["提出了一种以多值球面函数为输入的三维球面卷积神经网络",{"2":{"481":1}}],["提出了一种从粗到细的流程",{"2":{"474":1}}],["提出了一种标注高效的占据学习框架",{"2":{"455":1}}],["提出了一种层次网络pointnet++来从每个点的领域捕获精细的几何结构",{"2":{"420":1}}],["提出了一种层次化",{"2":{"363":1}}],["提出了一种cnn+gan+transformer的结构来生成高精度图像",{"2":{"371":1}}],["提出了一种基于squeezenet",{"2":{"955":1}}],["提出了一种基于核相关的特征学习方法",{"2":{"574":1}}],["提出了一种基于图卷积的动态点聚模块",{"2":{"574":1}}],["提出了一种基于三维短时傅里叶变换",{"2":{"511":1}}],["提出了一种基于高斯的多模态位置识别算法",{"2":{"474":1}}],["提出了一种基于卷积深度信念的三维形状网络",{"2":{"363":1}}],["提出了一种基于子图相似性匹配的基于对象的方法",{"2":{"190":1}}],["提出了为什么语义分割",{"2":{"54":1}}],["提示词是a",{"2":{"204":1}}],["提示词",{"2":{"204":1}}],["提示",{"2":{"117":2,"328":1,"396":1,"423":1,"424":1,"426":1,"534":2,"567":1,"582":1,"654":1,"716":1}}],["提供摄像头输入",{"2":{"997":1}}],["提供摄像头和激光雷达输入",{"2":{"997":1}}],["提供给我们的层次路径规划模块的查询是",{"2":{"947":1}}],["提供",{"2":{"787":1}}],["提供的数据",{"2":{"1001":1}}],["提供的高性能计算资源",{"2":{"960":1}}],["提供的密集标注进行监督",{"2":{"842":1}}],["提供的密集语义占用标注进行监督和评估",{"2":{"781":2}}],["提供的结果",{"2":{"782":1}}],["提供的注释",{"2":{"749":1}}],["提供的",{"2":{"749":1}}],["提供的预训练权重来提取图像特征",{"2":{"744":1,"867":1}}],["提供的真实标签进行验证",{"2":{"503":1}}],["提供迭代器iterator来遍历所有元素",{"2":{"685":1}}],["提供更多比以前的工作",{"2":{"552":1}}],["提供更稳定且可解释的中间表示",{"2":{"216":1}}],["提供结构化语言",{"2":{"360":1}}],["提供大规模传感器丰富真实数据",{"2":{"360":1}}],["提供评估协议",{"2":{"360":1}}],["提供开放评估服务器",{"2":{"360":1}}],["提供nuscenes",{"2":{"360":1}}],["提供了不完美场景",{"2":{"1005":1}}],["提供了约40k标注帧",{"2":{"997":1}}],["提供了约20k标注帧和约43k",{"2":{"997":1}}],["提供了有关框架效率的详细信息",{"2":{"965":1}}],["提供了有前景的解决方案",{"2":{"128":1}}],["提供了对场景中高斯之间重叠程度的细粒度分析",{"2":{"916":1}}],["提供了视野内外性能的详细信息",{"2":{"903":1}}],["提供了被分类为",{"2":{"900":1}}],["提供了",{"2":{"749":1}}],["提供了lidar点云分割标签",{"2":{"735":1}}],["提供了统一的表示空间",{"2":{"630":1,"667":1}}],["提供了更大的可靠性和鲁棒性",{"2":{"482":1}}],["提供了更多的上下文信息",{"2":{"421":2}}],["提供了精确的三维空间信息",{"2":{"421":1}}],["提供了数据对数密度梯度的估计",{"2":{"354":1}}],["提供了额外的鲁棒性层",{"2":{"310":1}}],["提供了两全其美的方法",{"2":{"294":1}}],["提供了一种自监督信号",{"2":{"988":1}}],["提供了一种富有表现力且紧凑的场景表示",{"2":{"808":1}}],["提供了一些信息",{"2":{"137":1}}],["提供了一个简单而优雅的框架",{"2":{"963":1}}],["提供了一个更大的bev视野范围",{"2":{"421":1}}],["提供了一个轻量级和可扩展的基于cpu的解决方案",{"2":{"131":1}}],["提供了一个对可视化和知识组织有用的层次模型",{"2":{"116":1}}],["提供了第一步",{"2":{"131":1}}],["提供了理想的抽象层次",{"2":{"116":1}}],["提供背景知识",{"2":{"90":1}}],["节指出的未来研究方向",{"2":{"951":1}}],["节消融实验的支持",{"2":{"928":1}}],["节进行的消融研究",{"2":{"853":1}}],["节详细说明了我们的性能表现",{"2":{"853":1}}],["节详细介绍了对最近",{"2":{"853":1}}],["节详细讨论每种结构",{"2":{"378":1}}],["节的消融实验表明",{"2":{"660":1}}],["节使用融合",{"2":{"642":1}}],["节介绍了仅使用",{"2":{"642":1}}],["节对我们的工作进行了总结",{"2":{"503":1}}],["节展示了我们的实验结果",{"2":{"503":1}}],["节概述了",{"2":{"503":1}}],["节提供了相关研究的概述",{"2":{"503":1}}],["节省任务阶段计算",{"2":{"435":1}}],["节深入讨论此主题",{"2":{"435":1}}],["节已简要介绍",{"2":{"435":1}}],["节所述",{"2":{"274":1,"943":1}}],["节讨论二者之间的权衡",{"2":{"231":1}}],["节与第",{"2":{"231":1}}],["节中简要提及了机器人学的应用",{"2":{"155":1}}],["节点间的边依据空间关系构建",{"2":{"765":1}}],["节点还可附加更多信息",{"2":{"765":1}}],["节点为地标",{"2":{"648":1}}],["节点一般编码可供智能体决策的位置语义信息",{"2":{"525":1}}],["节点代表关键区域",{"2":{"525":1}}],["节点对应关键地标",{"2":{"465":1}}],["节点误差监控和缓解",{"2":{"419":1}}],["节点表示场景中的物体或关键地标",{"2":{"378":1}}],["节点与所有过去代理节点描述符的层次化描述符",{"2":{"352":1}}],["节点属性包括",{"2":{"178":1}}],["节点",{"0":{"107":1},"2":{"276":1,"525":2,"935":1,"947":1}}],["节",{"2":{"90":8,"231":1,"274":3,"324":4,"384":3,"495":1,"570":4,"628":3,"632":8,"773":2,"864":1,"928":7,"945":1,"948":1}}],["第7",{"2":{"954":2}}],["第7节",{"2":{"131":1}}],["第6",{"2":{"796":1,"930":1}}],["第五列报告了启用beta参数数据关联技术时",{"2":{"775":1}}],["第四行",{"2":{"842":1}}],["第四列报告了当启用网格可行性检查进行数据关联时",{"2":{"775":1}}],["第四列为卷积结果对应的输出序号",{"2":{"561":1}}],["第四个线程包括kimera",{"2":{"285":1}}],["第十个encoder",{"2":{"559":1}}],["第1",{"0":{"232":1},"1":{"253":1,"276":1}}],["第1层是一个度量语义3d网格",{"2":{"210":1}}],["第1层",{"0":{"162":1}}],["第5层",{"0":{"240":1},"2":{"218":1}}],["第5层是一个建筑物节点",{"2":{"210":1}}],["第5节和第6节分别讨论了未来的研究方向和总结",{"2":{"714":1}}],["第5节",{"2":{"131":1,"665":1}}],["第4",{"2":{"541":9,"686":2,"748":1}}],["第4层",{"0":{"218":1,"301":1},"2":{"480":2}}],["第4层是一个房间的子图",{"2":{"210":1}}],["第4节进行了性能比较和分析",{"2":{"714":1}}],["第4节",{"0":{"541":1},"1":{"572":1,"605":1,"634":1,"662":1,"686":1,"709":1,"732":1,"754":1,"775":1,"796":1,"816":1,"836":1,"855":1,"872":1,"889":1},"2":{"131":1,"665":1}}],["第2行",{"2":{"942":1}}],["第2",{"2":{"551":3}}],["第2层是对象和代理的子图",{"2":{"210":1}}],["第2层中的每个对象和代理都与最近的地点连接",{"2":{"197":1}}],["第2层",{"0":{"178":1},"1":{"197":1,"218":1,"240":1,"262":1}}],["第2节简要介绍了历史背景",{"2":{"714":1}}],["第2节",{"2":{"131":1}}],["第8节",{"2":{"131":1}}],["第3行",{"2":{"942":1}}],["第3步中得到了代价体",{"2":{"440":1}}],["第3层的节点",{"2":{"480":1}}],["第3层是一个地点的子图",{"2":{"210":1}}],["第3层",{"0":{"197":1},"2":{"218":1,"480":1}}],["第3",{"0":{"310":1,"336":1,"362":1,"390":1,"419":1,"449":1,"480":1,"510":1},"2":{"131":7,"285":7,"669":3,"709":1,"796":1}}],["第3节详细介绍了方法学见解",{"2":{"714":1}}],["第3节",{"2":{"131":1,"665":1}}],["第一步是收集与多视图图像对应的lidar点云并进行语义分割注释",{"2":{"932":1}}],["第一步是提取图像特征",{"2":{"305":1}}],["第一行",{"2":{"899":1}}],["第一行是",{"2":{"181":1}}],["第一阶段生成类无关的查询提议",{"2":{"875":1}}],["第一列报告了由kolotouros等人",{"2":{"775":1}}],["第一列是source",{"2":{"181":1}}],["第一",{"2":{"561":1}}],["第一种类似于封闭集代理评估中提供的房间标签",{"2":{"522":1}}],["第一种配置",{"2":{"437":1}}],["第一种是kl",{"2":{"345":1}}],["第一件是为每个roi选取对应的特征",{"2":{"432":1,"741":1}}],["第一项在优化中强制执行姿态图中的里程计和回路闭合测量",{"2":{"390":1}}],["第一项贡献",{"2":{"131":1}}],["第一个数据集展示了mit一个学术建筑内的学生隔间集合",{"2":{"605":1}}],["第一个步骤先训练一个vqvae模型",{"2":{"371":1}}],["第一个是",{"2":{"301":1}}],["第一个线程包括kimera",{"2":{"285":1}}],["第一个",{"2":{"271":1}}],["第一次记录涵盖了两层楼",{"2":{"437":1}}],["第一次迭代",{"2":{"328":1}}],["第一次",{"2":{"244":1}}],["第一部分是",{"2":{"181":1}}],["第一台移动机器人",{"2":{"123":1}}],["第一台工业机械臂",{"2":{"123":1}}],["第一代ad系统",{"2":{"103":1}}],["第二步是通过复杂的算法借助动态对象的跟踪信息融合多帧点云",{"2":{"932":1}}],["第二列报告了我们过滤掉在相机图像中只有部分可见的人类或人类边界框太小",{"2":{"775":1}}],["第二类是基于感知的方法",{"2":{"695":1}}],["第二",{"2":{"561":1}}],["第二和第三种配置",{"2":{"437":1}}],["第二和第三项中仅优化平移",{"2":{"390":1}}],["第二次记录也涵盖了两层楼",{"2":{"437":1}}],["第二件事是为了满足全连接层的输入需求",{"2":{"432":1,"741":1}}],["第二项改编自",{"2":{"390":1}}],["第二项贡献",{"2":{"131":1}}],["第二种是vq",{"2":{"345":1}}],["第二个数据集在学校",{"2":{"605":1}}],["第二个见解是",{"2":{"301":1}}],["第二个线程运行kimera",{"2":{"285":1}}],["第二个",{"2":{"271":1}}],["第二个要素是提供对场景的可操作理解的能力",{"2":{"116":1}}],["第二部分是",{"2":{"181":1}}],["第二条研究线专注于构建层次化地图模型",{"2":{"172":1}}],["第二贡献是基于聚合ib方法的任务驱动3d场景理解算法",{"2":{"98":1}}],["第vi",{"2":{"320":4}}],["第vi节实际上表明",{"2":{"352":1}}],["第vi节",{"2":{"109":1}}],["第v节总结了我们的工作",{"2":{"438":1}}],["第v节",{"2":{"109":1}}],["第ii节概述了相关研究",{"2":{"438":1}}],["第iii",{"2":{"210":2,"301":1}}],["第iii节概述了occcylindrical的整体框架",{"2":{"438":1}}],["第iii节描述的模块的输出到一个单一的3d场景图中",{"2":{"380":1}}],["第iii节",{"2":{"109":1}}],["第iv",{"2":{"326":2}}],["第iv节展示了我们的实验结果",{"2":{"438":1}}],["第iv节讨论了如何响应环路闭合来校正图",{"2":{"210":1}}],["第iv节",{"2":{"109":1,"253":1}}],["第",{"2":{"90":8,"143":1,"231":1,"274":2,"324":4,"384":3,"435":1,"503":4,"562":2,"570":4,"623":1,"628":3,"632":8,"642":2,"660":1,"773":2,"903":4,"928":7,"945":1,"948":1,"989":4,"992":6}}],["第三列报告了我们在第3",{"2":{"775":1}}],["第三列的人数",{"2":{"662":1}}],["第三列为输入像素值的输入序号",{"2":{"561":1}}],["第三个数据集在公寓",{"2":{"605":1}}],["第三个线程运行kimera",{"2":{"285":1}}],["第三项强制执行姿态顶点i和网格顶点l之间的局部刚性",{"2":{"390":1}}],["第三十三节",{"2":{"207":1}}],["第三部分",{"2":{"181":1}}],["第三贡献是将我们的任务驱动聚类算法集成到一个实时流水线中",{"2":{"98":1}}],["第三",{"2":{"82":1,"131":1,"449":1,"462":1,"467":1,"553":1}}],["第三步的作用",{"2":{"66":1}}],["以视觉为中心和多模态感知解决方案",{"2":{"1007":1}}],["以视觉为中心的cgformer",{"2":{"1000":1}}],["以视觉为中心的占用感知近年来发展迅速",{"2":{"1000":1}}],["以视觉为中心的占用感知中的信息融合",{"0":{"957":1}}],["以视觉为中心的占用感知可以分为单目解决方案",{"2":{"942":1}}],["以视觉为中心的占用感知在工业界和学术界引起了广泛关注",{"2":{"942":1}}],["以视觉为中心的占用感知",{"0":{"933":1},"1":{"942":1,"950":1,"957":1}}],["以视觉为中心的占用感知和多模态占用感知",{"2":{"877":1}}],["以视觉为中心的",{"2":{"656":1}}],["以视觉为中心的系统相比基于激光雷达",{"2":{"567":1}}],["以视觉为中心的自动驾驶研讨会",{"2":{"490":1}}],["以雷达为中心的radarocc",{"2":{"1005":1}}],["以灰色突出显示的数据集为元数据集",{"2":{"997":1}}],["以这种方式生成的占用标签并不涵盖整个空间",{"2":{"988":1}}],["以说明4d占用预测框架的构建",{"2":{"975":1}}],["以满足实际自动驾驶应用的期望",{"2":{"969":1}}],["以网格状模式复制",{"2":{"947":1}}],["以层次方式进行",{"2":{"947":1}}],["以推断前视所缺乏的深度维度",{"2":{"942":1}}],["以推断每个体素的占用状态",{"2":{"910":1}}],["以与时间帧中的目标位置对齐",{"2":{"941":1}}],["以深入了解传感器融合的特性和有效性",{"2":{"936":1}}],["以考虑空间和语义元素之间的不确定接地",{"2":{"961":1}}],["以考虑训练的变异性",{"2":{"928":1}}],["以考虑效率因素",{"2":{"716":1}}],["以激光雷达为中心的占用方法具有更精确的感知能力",{"2":{"1000":1}}],["以激光雷达为中心的占用感知架构",{"2":{"910":1}}],["以激光雷达为中心的占用感知提供了对环境的密集3d理解",{"2":{"910":1}}],["以激光雷达为中心的占用感知",{"0":{"894":1},"1":{"910":1,"923":1},"2":{"877":1}}],["以激光雷达为中心的语义分割",{"2":{"910":1}}],["以构建体积特征为例",{"2":{"950":1}}],["以构建多尺度3d体积特征和bev平面",{"2":{"875":1}}],["以构建出既紧凑又能够保留完成任务所需信息的3d场景图",{"2":{"271":1}}],["以采样3d特征空间中的特征",{"2":{"875":1}}],["以同时保持理论等价性和提高效率",{"2":{"866":1}}],["以城市自动驾驶为例",{"2":{"864":1}}],["以寻找",{"2":{"862":1}}],["以融合时间信息",{"2":{"858":1}}],["以展示我们的embodiedocc的性能",{"2":{"833":1}}],["以展示我们的局部空间占用预测模块的性能",{"2":{"833":1}}],["以分批的方式进行",{"2":{"812":1}}],["以分别生成多尺度的全局",{"2":{"746":1}}],["以分别生成多尺度的局部",{"2":{"545":1,"746":1}}],["以进一步提高性能和速度",{"2":{"878":1}}],["以进一步细化特征",{"2":{"789":1}}],["以进行分析",{"2":{"811":1}}],["以60",{"2":{"811":1}}],["以210",{"2":{"811":1}}],["以2hz的频率提供注释",{"2":{"736":1}}],["以上开放问题为多维度研究提供了广阔前景",{"2":{"951":1}}],["以上两者的区别就是",{"2":{"904":1}}],["以上",{"2":{"803":1}}],["以讨论提升融合式",{"2":{"803":1}}],["以至于客厅被过度分割为三个独立的房间",{"2":{"796":1}}],["以比较不同方法的效率",{"2":{"778":1}}],["以比使用体积方法的规划器少得多的时间计算路径规划查询",{"2":{"131":1}}],["以改进这一评估指标",{"2":{"778":1}}],["以计算图像可见区域上的miou",{"2":{"778":1}}],["以计算对象的简洁描述",{"2":{"121":1}}],["以零样本方式验证",{"2":{"765":1}}],["以收集全局上下文信息",{"2":{"752":1}}],["以收集较大的感受野",{"2":{"752":1}}],["以收集上下文信息",{"2":{"752":1}}],["以研究我们提出的flashocc中每个组件的有效性",{"2":{"748":1}}],["以通过粗到细的方式细化特征",{"2":{"746":1}}],["以定性地验证",{"2":{"745":1}}],["以得出每个体素应关注的3d高斯分布的索引",{"2":{"738":1}}],["以得出初始的三维体素特征",{"2":{"544":1}}],["以确定3d占用",{"2":{"957":1}}],["以确定每个特征通道的重要性",{"2":{"829":1}}],["以确定每个体素应聚合的邻近3d高斯分布的索引",{"2":{"738":1}}],["以确保训练集中的场景与评估集中的场景不同",{"2":{"886":1}}],["以确保与现有方法的公平比较",{"2":{"736":1}}],["以确保预测语义的有界性",{"2":{"681":1}}],["以确保地图完整",{"2":{"274":1}}],["以确保其在更广泛应用中的可靠性与有效性",{"2":{"881":1}}],["以确保其在",{"2":{"125":1}}],["以对齐多帧点云",{"2":{"735":1}}],["以根据单目输入进行离线空间占用预测",{"2":{"728":1}}],["以根本性的方式解决这些问题",{"2":{"656":1}}],["以验证它们的有效性",{"2":{"842":1}}],["以验证我们的设计选择",{"2":{"723":1}}],["以验证其下游导航泛化能力",{"2":{"698":1}}],["以保持与不使用cbgs的24个epoch相当的总训练时间",{"2":{"876":1}}],["以保持其在整个gaussianformer的",{"2":{"716":1}}],["以保留低级和高级特征信息",{"2":{"875":1}}],["以保留每种模态的细粒度几何信息",{"2":{"438":1}}],["以反映其分布的形状",{"2":{"716":1}}],["以唤醒这种潜力",{"2":{"705":1}}],["以为我们局部预测模块中三维语义高斯分布的优化提供更准确",{"2":{"705":1}}],["以编码节点间的时间关系",{"2":{"698":1}}],["以编码可达性",{"2":{"525":1}}],["以物体为中心的3d场景表示",{"0":{"693":1}}],["以摄像头作为激光雷达的廉价替代品",{"2":{"667":1}}],["以捕捉现实世界的密集3d结构",{"2":{"667":1}}],["以捕捉更细致的细节",{"2":{"547":1}}],["以感知和理解周围环境",{"2":{"665":1}}],["以聚集局部区域特征",{"2":{"664":1}}],["以粗体显示",{"2":{"662":1}}],["以跟踪动态变化的室内环境中的物体",{"2":{"648":1}}],["以其在辐射场渲染领域的快速速度和高质量而闻名",{"2":{"629":1}}],["以有效地在占用区域周围初始化高斯",{"2":{"851":1}}],["以有效地在占用区域周围初始化概率高斯",{"2":{"628":1}}],["以有效地在非空区域周围初始化高斯",{"2":{"567":1}}],["以用于运动规划等更多下游任务",{"2":{"735":1}}],["以用于",{"2":{"625":1}}],["以克服这些限制并增强模型的整体环境感知能力",{"2":{"625":1}}],["以支撑开放世界的语义推理",{"2":{"619":1}}],["以支持下游的推理与决策",{"2":{"556":1}}],["以支持更精细的推理",{"2":{"525":1}}],["以支持长期自主性",{"2":{"125":1}}],["以环绕图像作为输入",{"2":{"609":1}}],["以了解潜在替代方案的综述",{"2":{"605":1}}],["以评估感知模型逐步探索未知场景的能力",{"2":{"600":1}}],["以评估在具有挑战性的光照和天气条件",{"2":{"503":1}}],["以目标为中心的场景表示",{"2":{"599":1}}],["以包含高度信息",{"2":{"599":1}}],["以scannet数据集为例",{"2":{"589":1}}],["以bevformer",{"2":{"585":1}}],["以lift",{"2":{"585":1}}],["以指导生成器的训练",{"2":{"582":1}}],["以补偿因降低图像分辨率而丢失的信息",{"2":{"638":1}}],["以补偿因降低图像分辨率而产生的信息损失",{"2":{"576":1}}],["以补偿未对准misalignment",{"2":{"434":1}}],["以往的工作一直专注于如何更好地从输入图像中提取和利用深度信息",{"2":{"705":1}}],["以往的研究已广泛研究了三种传感器融合方法在环境感知中的特性",{"2":{"678":1}}],["以往的多模态方法未能充分挖掘这些信息",{"2":{"576":1}}],["以往工作",{"2":{"563":1}}],["以优化区域高斯分布",{"2":{"568":1}}],["以高效处理大量空体素",{"2":{"922":1}}],["以高效率实现了最先进的性能",{"2":{"567":1}}],["以高效地将知识迁移到仅视觉的",{"2":{"425":1}}],["以解决密集表示固有的冗余问题",{"2":{"599":1}}],["以解决",{"2":{"567":1}}],["以解决复杂的",{"2":{"252":1}}],["以执行",{"2":{"564":1}}],["以rulebook第一行红色方框为例",{"2":{"561":1}}],["以预测3d边界框",{"2":{"550":1}}],["以预测3d语义占据",{"2":{"438":1}}],["以禁用分配给空任务",{"2":{"522":1}}],["以证明多传感器融合的优势",{"2":{"503":1}}],["以检验不同传感器融合策略在这些场景下的表现",{"2":{"503":1}}],["以表明我们的任务感知映射表述不会降低封闭集映射任务的性能",{"2":{"492":1}}],["以促进这些特征向量与图像特征之间的有效交互",{"2":{"705":1}}],["以促进对具身三维空间占用预测任务的评估",{"2":{"568":1}}],["以促进对点云的全面理解",{"2":{"488":1}}],["以促进训练的收敛性",{"2":{"456":1}}],["以pcnn为基础",{"2":{"481":1}}],["以ppo或dqn式更新优化路线进度",{"2":{"417":1}}],["以充分利用上下文信息",{"2":{"481":1}}],["以模拟接近关系",{"2":{"480":1}}],["以学习更好的",{"2":{"474":1}}],["以在每个级别启用跳跃连接",{"2":{"875":1}}],["以在保持高精度的同时实现快速且内存高效的占据预测",{"2":{"505":1}}],["以在训练期间进行额外的增强",{"2":{"471":1}}],["以在存在极端异常值的情况下找到点云之间最佳对齐",{"2":{"449":1}}],["以兼顾各自优势",{"2":{"465":1}}],["以提取和更新占用状态信息",{"2":{"1004":1}}],["以提取多尺度特征图",{"2":{"768":1}}],["以提取其中的几何信息",{"2":{"456":1}}],["以提升其性能",{"2":{"694":1}}],["以提升语言引导导航中的空间推理能力",{"2":{"648":1}}],["以提高模型的泛化能力",{"2":{"839":1}}],["以提高整体感知准确性和可靠性",{"2":{"726":1}}],["以提高效率",{"2":{"681":1}}],["以提高其性能并减小模型大小",{"2":{"574":1}}],["以提供驾驶场景的详细描述",{"2":{"975":1}}],["以提供位置信息和整合全局结构信息",{"2":{"549":1}}],["以提供更好的感知能力",{"2":{"438":1}}],["以提供任务规划",{"2":{"116":1}}],["以利用不同传感器的优势",{"2":{"444":1}}],["以相对较低的内存和计算成本",{"2":{"440":1}}],["以匹配激光雷达点云的3d点分布",{"2":{"438":1}}],["以回合起始点为基准",{"2":{"435":1}}],["以平滑轨迹并移除不良检测",{"2":{"419":1}}],["以强制安全约束并提升罕见事件性能",{"2":{"417":1}}],["以强调它们的方法论重叠",{"2":{"90":1}}],["以关键帧速率",{"2":{"408":1}}],["以帧速率",{"2":{"408":1}}],["以使慢但少有的计算",{"2":{"408":1}}],["以使所有测量得到最佳解释",{"2":{"171":1}}],["以亚秒速率",{"2":{"408":1}}],["以减轻降低图像分辨率带来的不利影响",{"2":{"392":1}}],["以减少对占用标签的依赖",{"2":{"1000":1}}],["以减少对构成对象的主观推理",{"2":{"374":1}}],["以减少漂移并定性地匹配建筑平面图",{"2":{"437":1}}],["以减少处理和传输带宽",{"2":{"173":1}}],["以更好地利用占用的稀疏性和物体尺度的多样性",{"2":{"861":1}}],["以更好地捕捉场景的空间信息",{"2":{"839":1}}],["以更好地近似真实人类外观的分布",{"2":{"775":1}}],["以更好地保留细粒度几何细节",{"2":{"676":1}}],["以更好地保留细粒度几何信息",{"2":{"409":1,"898":1}}],["以更新当前场景的三维空间占用预测",{"2":{"682":1}}],["以更多受益于检测预训练",{"2":{"670":1}}],["以更少的参数实现了最先进的占据预测性能",{"2":{"455":1}}],["以更大的计算成本解决更大的姿态图",{"2":{"390":1}}],["以更高效率取得良好性能",{"2":{"114":1}}],["以最小化与每个边相关联的变形",{"2":{"380":1}}],["以调整局部框架",{"2":{"380":1}}],["以取长补短",{"2":{"378":1}}],["以图结构呈现",{"2":{"378":1}}],["以生成最终的3d占用预测",{"2":{"970":1}}],["以生成体素网格及其相关坐标",{"2":{"789":1}}],["以生成每个体素对应的图像特征",{"2":{"609":1}}],["以生成每个尺度的最终",{"2":{"545":1,"746":1}}],["以生成归一化的语义预测",{"2":{"567":1}}],["以生成用于transformer解码器的键",{"2":{"550":1}}],["以生成密集的",{"2":{"502":1}}],["以生成",{"2":{"369":1}}],["以节省计算量",{"2":{"362":1}}],["以人类偏好驾驶决策为vla模型评分",{"2":{"360":1}}],["以此类推p2也会拥有一系列p2",{"2":{"530":1}}],["以此类推",{"2":{"351":1}}],["以此来推断摄像头的内参和畸变参数",{"2":{"191":1}}],["以此来校准偏航角",{"2":{"191":1}}],["以供高效查询与推理",{"2":{"350":1}}],["以自回归的方式逐步生成点块序列",{"2":{"315":1}}],["以自然语言解释驾驶场景或推荐动作",{"2":{"260":1}}],["以从原始imu数据中获得两个连续关键帧之间相对状态的紧凑预积分测量",{"2":{"310":1}}],["以文本场景描述为条件生成轨迹",{"2":{"308":1}}],["以",{"2":{"285":1,"362":1,"425":1,"588":1,"707":1,"806":1}}],["以避免信息丢失并降低计算复杂度",{"2":{"1004":1}}],["以避免高斯之间的不必要重叠",{"2":{"536":1}}],["以避免梯度干扰",{"2":{"417":1}}],["以避免使目标检测器偏向这些不太有趣的目标",{"2":{"277":1}}],["以避免需要校正结构化表示",{"2":{"190":1}}],["以智能体为中心的系统网格四角采样",{"2":{"274":1}}],["以像素为单位",{"2":{"254":2}}],["以米为单位",{"2":{"254":1,"654":1,"749":1,"916":1}}],["以米为单位的坐标系原点",{"2":{"254":1}}],["以缓解单靠相机带来的图像模糊与光照不足问题",{"2":{"189":1}}],["以一个batch",{"2":{"184":1}}],["以获取前视所缺失的深度维度",{"2":{"950":1}}],["以获取最佳精度",{"2":{"825":1}}],["以获取训练过程中点的空间分布",{"2":{"664":1}}],["以获取用于初始化",{"2":{"502":1}}],["以获取中心点和点块",{"2":{"396":1}}],["以获取商业许可选项",{"2":{"126":1,"302":1}}],["以获得真实深度和语义",{"2":{"988":1}}],["以获得对周围环境的整体感知",{"2":{"969":1}}],["以获得多视角深度图和语义图",{"2":{"941":1}}],["以获得",{"2":{"886":1}}],["以获得局部",{"2":{"809":1}}],["以获得全局",{"2":{"789":1}}],["以获得三维旋转框",{"2":{"777":1}}],["以获得合并后的局部",{"2":{"746":1}}],["以获得合并后的全局",{"2":{"746":1}}],["以获得密集的三维占用",{"2":{"850":1}}],["以获得密集的3d占用标签",{"2":{"735":1}}],["以获得密集注释",{"2":{"735":1}}],["以获得二进制标签",{"2":{"704":1}}],["以获得时间和空间信息",{"2":{"695":1}}],["以获得周围环境的初始三维感知",{"2":{"682":1}}],["以获得单尺度视觉特征",{"2":{"621":1}}],["以获得每个体素的最终特征",{"2":{"609":1}}],["以获得最终的bev表示",{"2":{"576":1}}],["以获得描述3d场景细粒度结构的密集表示",{"2":{"547":1}}],["以获得该层级的全局",{"2":{"545":1,"746":1}}],["以获得平滑且对误检测鲁棒的轨迹估计",{"2":{"419":1}}],["以获得一个标准的姿态图优化问题",{"2":{"380":1}}],["以获得强大的模型表现力",{"2":{"314":1}}],["以获得更全面的属性列表",{"2":{"178":1}}],["以实现较大的感受野和较低的内存成本",{"2":{"982":1}}],["以实现有效的占用预测",{"2":{"875":1}}],["以实现对近处区域的更细粒度建模",{"2":{"858":1}}],["以实现根据像素对齐的占用分布进行以目标为中心的建模",{"2":{"851":1}}],["以实现三个区域的平等平均",{"2":{"694":1}}],["以实现预期性能",{"2":{"690":1}}],["以实现变换的不变性的构思很巧妙",{"2":{"589":1}}],["以实现高效的芯片部署",{"2":{"831":1}}],["以实现高效的3d语义占用预测",{"2":{"547":1}}],["以实现高效的点云处理",{"2":{"363":1}}],["以实现更密集和更精细的注释",{"2":{"735":1}}],["以实现更好的加速",{"2":{"738":1}}],["以实现更好的效率",{"2":{"693":1}}],["以实现更好的表示",{"2":{"621":2}}],["以实现更好的表示并保留更多细粒度几何信息",{"2":{"527":1}}],["以实现更平滑的优化",{"2":{"547":1}}],["以实现更高效",{"2":{"444":1}}],["以实现分割",{"2":{"469":1}}],["以实现稳健的三维物体识别",{"2":{"363":1}}],["以实现模度的最大增加",{"2":{"301":1}}],["以实现基本指令跟随",{"2":{"176":1}}],["以实现开放集图像分割",{"2":{"121":1}}],["以换取更强的适应性",{"2":{"155":1}}],["以增加其规模",{"2":{"947":1}}],["以增强在各种摄像头丢失情况下的鲁棒性",{"2":{"1005":1}}],["以增强表示",{"2":{"957":1}}],["以增强类内特征分离并加速语义扩散的收敛",{"2":{"875":1}}],["以增强模型对场景的理解并减少补全的模糊性",{"2":{"841":1}}],["以增强不同方法的评估和比较",{"2":{"757":1}}],["以增强",{"2":{"596":1}}],["以增强空间语义一致性",{"2":{"539":1}}],["以增强相应的激光雷达特征",{"2":{"482":1}}],["以增强自动驾驶感知系统的鲁棒性",{"2":{"444":1}}],["以增强对δ选择的鲁棒性",{"2":{"301":1}}],["以增强可解释性",{"2":{"145":1}}],["以增量方式重建机器人探索环境时的场景图层",{"2":{"141":1}}],["以增量方式构建场景图的层",{"2":{"112":1}}],["以导航为例",{"2":{"139":1}}],["以下问题需要进一步研究",{"2":{"996":1}}],["以下总结六大前沿研究问题",{"2":{"478":1}}],["以下回顾两大主导范式",{"2":{"388":1}}],["以下两个点将是预训练过程中需要着重考虑的",{"2":{"313":1}}],["以下是最重要的步骤",{"2":{"191":1}}],["以下几类设定尤为常见",{"2":{"139":1}}],["以下",{"2":{"137":3,"390":1,"881":1,"1000":1}}],["以朝向目标迈进以进行导航",{"2":{"121":1}}],["以任务相关的方式压缩视觉观察",{"2":{"121":1}}],["以适应给定的一组任务",{"2":{"121":1}}],["以便框架能够捕获相关的语义信息并将其传递到更高层",{"2":{"971":1}}],["以便进行公平比较",{"2":{"876":1}}],["以便进行求和",{"2":{"660":1}}],["以便在线模型从不同场景中学习先验",{"2":{"934":1}}],["以便在合并来自不同模态的有价值特征的同时过滤掉噪声特征",{"2":{"829":1}}],["以便在不同粒度捕获信息",{"2":{"648":1}}],["以便移除房间之间的小开口",{"2":{"480":1}}],["以便更深入地理解场景",{"2":{"421":1}}],["以便更好地进行处理",{"2":{"340":1}}],["以便不在3d网格中重建动态元素",{"2":{"419":1}}],["以便任意的采样都能生成符合这个分布的新数据",{"2":{"193":1}}],["以便每个聚类保留包含在聚类中的图像的上下文信息",{"2":{"121":1}}],["以便推理不一致性",{"2":{"116":1}}],["以便可以精确表示空间信息",{"2":{"96":1}}],["以响应环路闭合来优化3d场景图",{"2":{"112":1,"141":1}}],["以大量的3d对象片段和3d无障碍地点的形式存在",{"2":{"109":1}}],["以darpa城市挑战赛车辆为代表",{"2":{"103":1}}],["以足以完成任务",{"2":{"98":1}}],["以及车辆运动导致的输入图像模糊",{"2":{"1005":1}}],["以及实现广义3d占用感知的路径",{"2":{"1002":1}}],["以及位置感知损失",{"2":{"985":1}}],["以及蒸馏损失",{"2":{"985":1}}],["以及与winter",{"2":{"973":1}}],["以及与图中的每个位姿相关的检测",{"2":{"419":1}}],["以及尝试从数据中学习属性和关系",{"2":{"973":1}}],["以及确定最有价值的协同区域以实现准确性和速度之间的最佳平衡",{"2":{"969":1}}],["以及基于学习的方法",{"2":{"967":1}}],["以及基于patch的对抗训练",{"2":{"345":1}}],["以及lin等人",{"2":{"967":1}}],["以及匿名审稿人对我们的论文提供的宝贵反馈",{"2":{"958":1}}],["以及室内环境中大部分",{"2":{"958":1}}],["以及语义编码方式",{"2":{"958":1}}],["以及语义场景补全",{"2":{"853":1}}],["以及构建这些表示所涉及的算法",{"2":{"954":1}}],["以及构建过程",{"2":{"324":1}}],["以及超越任务表现直接衡量地图质量的评估体系",{"2":{"951":1}}],["以及估计轨迹的长度进行比较",{"2":{"947":1}}],["以及历史信息融合",{"2":{"942":1}}],["以及切换算法优化仍是未来研究重点",{"2":{"935":1}}],["以及是否标注了3d占用流信息",{"2":{"997":1}}],["以及是否使用监督",{"2":{"928":1}}],["以及是否能够获得可用于后续建图模块的实例级边界框或分割掩码",{"2":{"274":1}}],["以及0",{"2":{"924":1}}],["以及同时集成2d和3d分支",{"2":{"910":1}}],["以及模拟的uhumans2",{"2":{"889":1}}],["以及模型结构",{"2":{"106":1}}],["以及pk",{"2":{"814":1}}],["以及大量不完整的场景",{"2":{"796":1}}],["以及94",{"2":{"796":1}}],["以及99",{"2":{"796":1}}],["以及顶级基于图像的方法fb",{"2":{"779":1}}],["以及由",{"2":{"765":1}}],["以及来自3个城市的407",{"2":{"757":1}}],["以及正确语义匹配的百分比",{"2":{"754":1}}],["以及正确标记点的整体部分",{"2":{"732":1}}],["以及flashocc的训练细节",{"2":{"748":1}}],["以及z轴的",{"2":{"736":1}}],["以及沿z轴的",{"2":{"736":1}}],["以及它们的语义类别是否相似或不同",{"2":{"707":1}}],["以及不同复杂度的背景区域",{"2":{"693":1}}],["以及对应的内参",{"2":{"693":1}}],["以及植被",{"2":{"665":1}}],["以及多模态方法",{"2":{"665":1}}],["以及多变量高斯分布",{"2":{"641":1}}],["以及从函数",{"2":{"656":1}}],["以及生成式3d",{"2":{"641":1}}],["以及石子等",{"2":{"630":1}}],["以及数量不等的人类",{"2":{"605":1}}],["以及场景的几何和语义的地面真实",{"2":{"605":1}}],["以及最近的高斯泼溅",{"2":{"588":1}}],["以及kimera",{"2":{"572":1,"872":1}}],["以及各种环境",{"2":{"541":1}}],["以及nvidia",{"2":{"522":1}}],["以及hydra",{"2":{"522":1}}],["以及自动评估3d重建的质量",{"2":{"510":1}}],["以及图像深度估计的需求",{"2":{"482":1}}],["以及图5",{"2":{"285":1}}],["以及走廊中的特征贫乏区域",{"2":{"437":1}}],["以及clio",{"2":{"431":2}}],["以及相机参数",{"2":{"419":1}}],["以及以更慢速率",{"2":{"408":1}}],["以及用于loop",{"2":{"400":1}}],["以及描述三角形面的顶点id三元组列表",{"2":{"336":1}}],["以及描述环境中动态实体的层",{"2":{"172":1}}],["以及如何在环路闭合后校正场景图",{"2":{"326":1}}],["以及如何将地点分割成房间",{"2":{"210":1}}],["以及一个可选的反卷积层",{"2":{"982":1}}],["以及一个体素ν",{"2":{"730":1}}],["以及一个体素为空而另一个体素被占用",{"2":{"707":1}}],["以及一个细化模块",{"2":{"716":1}}],["以及一个附加的布尔值用来说明插入是否成功",{"2":{"571":1}}],["以及一个非道路数据集",{"2":{"444":1}}],["以及一个全局一致且对异常值鲁棒的轨迹估计",{"2":{"285":1}}],["以及一辆自行车是否有人骑",{"2":{"254":1}}],["以及惯性测量单元",{"2":{"285":1}}],["以及每个出现帧的",{"2":{"277":1}}],["以及在第",{"2":{"853":1}}],["以及在检测到循环闭合时发生的变形",{"2":{"390":1}}],["以及在地图中编码何种信息",{"2":{"274":1}}],["以及在大规模条件下研究认知",{"2":{"139":1}}],["以及温度系数的作用",{"2":{"223":1}}],["以及whelan等人",{"2":{"190":1}}],["以及深度学习为语义理解提供的新机会的触发",{"2":{"172":1}}],["以及后端的65",{"2":{"836":1}}],["以及后端",{"2":{"168":1,"310":1}}],["以及评估信息检索系统的性能等",{"2":{"137":1}}],["以及我们与",{"2":{"131":1}}],["以及某些研究用途",{"2":{"126":1,"302":1}}],["以及",{"2":{"125":1,"131":2,"139":1,"141":1,"147":1,"157":1,"162":1,"178":2,"197":1,"209":1,"218":1,"240":1,"325":1,"336":1,"362":1,"380":2,"390":1,"408":1,"419":1,"437":1,"605":1,"796":1,"836":1,"853":1,"870":1,"872":1,"886":1,"900":1,"903":1,"905":1,"961":1,"982":1}}],["以及动态环境中的任务规划",{"2":{"123":1}}],["以及使机器人能在未知环境中同步定位与建图的",{"2":{"123":1}}],["以及更一般地",{"2":{"98":1}}],["以及train",{"2":{"54":1}}],["实习期间完成此工作",{"2":{"395":1}}],["实际应用和注释成本方面的限制",{"2":{"799":1}}],["实际地面摩擦差异会导致漂移",{"2":{"435":1}}],["实际上起到了语义地图的作用",{"2":{"556":1}}],["实际上我们完全可以把分类引导的定义拓展为文字",{"2":{"422":1}}],["实际上",{"2":{"419":1,"627":1,"660":1,"796":1,"930":1}}],["实际上就是一组由rpn",{"2":{"321":1}}],["实际车辆控制仍由传统模块",{"2":{"260":1}}],["实验在",{"2":{"761":1}}],["实验在单个",{"2":{"545":1,"965":1}}],["实验评估",{"0":{"541":1},"1":{"572":1,"605":1,"634":1,"662":1,"686":1,"709":1,"732":1,"754":1,"775":1,"796":1,"816":1,"836":1,"855":1,"872":1,"889":1}}],["实验表明该图能显著提升长程目标搜索效率",{"2":{"698":1}}],["实验表明",{"2":{"539":1,"568":1,"600":1,"765":1}}],["实验结果如表",{"2":{"882":1}}],["实验结果",{"0":{"382":1,"674":1,"722":1,"849":1},"1":{"744":1,"766":1,"787":1,"807":1,"827":1,"847":1,"865":1,"867":1,"882":1,"884":1,"900":1,"915":1,"927":1,"936":1,"944":1,"952":1,"959":1,"965":1,"971":1}}],["实验结果表明",{"2":{"265":1,"392":1,"481":1,"516":1}}],["实验设置",{"0":{"374":1,"770":1},"2":{"437":1}}],["实验",{"0":{"320":1,"437":1,"519":1,"624":1,"713":1,"717":1,"720":1,"727":1,"748":1,"760":1,"772":1,"783":1,"853":1},"1":{"346":1,"374":1,"402":1,"431":1,"462":1,"492":1,"522":1,"652":1,"677":1,"700":1,"723":1,"736":1,"739":1,"742":1,"745":1,"749":1,"758":1,"761":1,"764":1,"770":1,"771":1,"779":1,"781":1,"782":1,"785":1,"791":1,"792":1,"793":1,"800":1,"803":1,"805":1,"811":1,"812":1,"813":1,"823":1,"825":1,"832":1,"833":1,"843":1,"870":1,"887":1,"903":1,"917":1,"928":1}}],["实验中使用的真值标签来自",{"2":{"900":1}}],["实验中",{"2":{"278":1}}],["实验使用clip进行",{"2":{"121":1}}],["实例和",{"2":{"441":1}}],["实例和全景分割问题",{"2":{"384":1}}],["实例",{"2":{"384":1,"698":1}}],["实例分支由一系列",{"2":{"405":1}}],["实例分支通过",{"2":{"377":1}}],["实例分割更具挑战性",{"2":{"983":1}}],["实例分割模型mask",{"2":{"741":1}}],["实例分割方法相同",{"2":{"441":1}}],["实例分割方法",{"2":{"349":1,"471":1}}],["实例分割框架的性能",{"2":{"349":1}}],["实例分割和全景分割方面的最先进结果",{"2":{"306":1}}],["实例分割和全景分割已经分别使用了特定设计的任务模型进行了研究",{"2":{"306":1}}],["实例分割",{"0":{"122":1,"138":1,"983":1},"1":{"154":1,"169":1,"187":1,"207":1,"229":1,"250":1,"272":1,"296":1,"321":1,"347":1,"375":1,"403":1,"432":1,"463":1,"493":1,"523":1,"554":1,"987":1,"990":1},"2":{"119":1,"349":1,"940":1}}],["实例标签和跟踪标签",{"2":{"302":1}}],["实例的可见性是在所有6个图像中可见的注释的百分比",{"2":{"254":1}}],["实例token",{"2":{"254":1}}],["实例不是跨场景跟踪的",{"2":{"254":1}}],["实时持续追踪与更新",{"2":{"926":1}}],["实时处理",{"2":{"864":1}}],["实时单目视觉输入用于场景感知可以进一步推动具身智能体的研究",{"2":{"629":1}}],["实时性差",{"2":{"588":1}}],["实时性能",{"2":{"478":1}}],["实时性能以及动态环境建模方面均有显著提升",{"2":{"209":1}}],["实时",{"2":{"437":1}}],["实时接收图像流并使用我们的增量ib算法构建地图",{"2":{"271":1}}],["实时增量3d场景图层构建",{"0":{"210":1},"1":{"232":1,"253":1,"276":1,"301":1}}],["实时确定自身在地图中的位置",{"2":{"171":1}}],["实时任务驱动开放集3d场景图",{"0":{"168":1},"1":{"186":1,"206":1,"228":1,"249":1,"271":1,"295":1}}],["实时任务驱动的开放集3d场景图",{"2":{"98":1}}],["实时跟踪人类代理的密集网格模型",{"2":{"162":1}}],["实时系统的应用",{"2":{"153":1}}],["实时场景理解",{"2":{"112":1}}],["实时效率和形式化验证",{"2":{"72":1}}],["实现对3d道路环境的更深入理解",{"2":{"969":1}}],["实现大场景实时更新与持续维护",{"2":{"897":1}}],["实现高效训练",{"2":{"824":1}}],["实现高效适配",{"2":{"195":1}}],["实现细节",{"0":{"744":1,"758":1,"761":1,"764":1,"771":1,"813":1,"822":1,"866":1,"867":1},"1":{"842":1}}],["实现细粒度推断",{"2":{"588":1}}],["实现语言",{"2":{"698":1}}],["实现和评估细节",{"0":{"677":1}}],["实现实时建图",{"2":{"619":1}}],["实现开放词汇抓取",{"2":{"588":1}}],["实现可微渲染",{"2":{"588":1}}],["实现可解释且鲁棒的闭环控制",{"2":{"92":1}}],["实现更稠密的语义",{"2":{"648":1}}],["实现更精确的投影关系建模",{"2":{"585":1}}],["实现更高效率和更优规划性能",{"2":{"114":1}}],["实现由集成视觉",{"2":{"538":1}}],["实现该愿景需掩码多模态目标与架构",{"2":{"507":1}}],["实现",{"2":{"481":1}}],["实现真正的端到端检测",{"2":{"473":1}}],["实现卓越性能通常需要使用极高分辨率的图像和复杂的图像特征提取网络",{"2":{"421":1}}],["实现这一目标需要",{"2":{"897":1}}],["实现这一目标需要整合来自多个传感器的数据",{"2":{"421":1}}],["实现这些目标需大规模多模态学习",{"2":{"507":1}}],["实现这种",{"2":{"199":1}}],["实现nuplan与carla闭环成功率领先",{"2":{"334":1}}],["实现车辆间零样本协商最佳性能",{"2":{"334":1}}],["实现比独立组件更好闭环性能",{"2":{"308":1}}],["实现了最佳性能",{"2":{"859":1}}],["实现了更快",{"2":{"860":1}}],["实现了更好的性能与效率权衡",{"2":{"812":1}}],["实现了更高层次的粒度",{"2":{"302":1}}],["实现了显著的",{"2":{"803":1}}],["实现了类似的",{"2":{"803":1}}],["实现了3d目标检测",{"2":{"1003":1}}],["实现了3",{"2":{"779":1}}],["实现了相当的整体性能",{"2":{"700":1}}],["实现了单视点融合和多视点融合",{"2":{"664":1}}],["实现了竞争性能",{"2":{"634":1}}],["实现了激光雷达和环视相机的融合",{"2":{"625":1}}],["实现了准确的深度预测",{"2":{"544":1}}],["实现了旋转不变性",{"2":{"481":1}}],["实现了",{"2":{"425":1}}],["实现了48",{"2":{"421":1}}],["实现了对多维数据的排序",{"2":{"340":1}}],["实现了直接访问操作符",{"2":{"196":1}}],["实现imu预积分和固定滞后平滑",{"2":{"285":1}}],["实现交互式情境感知",{"2":{"176":1}}],["实现工具增强思维链提示以增强推理",{"2":{"128":1}}],["实现从感知到控制的直接映射",{"2":{"92":1}}],["实践相关且技术丰富的环境",{"2":{"90":1}}],["见表4",{"2":{"1006":1}}],["见表1和表3",{"2":{"421":1}}],["见表1对所综述论文的总结",{"2":{"90":1}}],["见特征融合模块中的第1行",{"2":{"942":1}}],["见视频附件中的可视化",{"2":{"905":1}}],["见上图的基本模块示意图",{"2":{"880":1}}],["见3",{"2":{"576":3}}],["见结论",{"2":{"437":1}}],["见注释3",{"2":{"390":1}}],["见注释1和第5节的更广泛讨论",{"2":{"262":1}}],["见第4",{"2":{"362":1,"634":1,"686":1}}],["见第2",{"2":{"178":1}}],["见",{"2":{"162":1,"467":1,"495":1}}],["见图例中的颜色含义",{"2":{"707":1}}],["见图5",{"2":{"437":1}}],["见图3的可视化总结",{"2":{"352":1}}],["见图",{"2":{"189":2,"378":1,"436":1,"495":1,"525":1,"552":1,"570":1,"622":1}}],["见图2",{"2":{"109":1,"480":1}}],["见图1a和图11中的楼层平面图",{"2":{"947":1}}],["见图14",{"2":{"872":1}}],["见图14进行比较",{"2":{"605":1}}],["见图1顶部",{"2":{"438":1}}],["见图1底部",{"2":{"438":1}}],["见图16中的结果",{"2":{"419":1}}],["见图1",{"2":{"90":1,"109":1,"449":1}}],["显着降低了内存和计算成本",{"2":{"962":1}}],["显著高于miou分数",{"2":{"1000":1}}],["显著优于单车辆系统的性能",{"2":{"969":1}}],["显著提高了内存效率",{"2":{"922":1}}],["显著提高了性能",{"2":{"875":1}}],["显著提高了模型的推理速度",{"2":{"625":1}}],["显著增加了计算和内存开销",{"2":{"799":1}}],["显著降噪",{"2":{"698":1}}],["显著更好的性能",{"2":{"421":1}}],["显著性检测被用来识别人类可能首先注意到的图像部分",{"2":{"121":1}}],["显然能够更好地捕捉场景布局",{"2":{"903":1}}],["显然",{"2":{"262":1,"449":1}}],["显示所有组件都对最佳结果做出了贡献",{"2":{"928":1}}],["显示",{"2":{"917":1}}],["显示输入图像",{"2":{"903":1}}],["显示出在保留细粒度几何和语义信息方面的卓越能力",{"2":{"847":1}}],["显示出比其他",{"2":{"827":2}}],["显示屏",{"2":{"507":1}}],["显示了多头自注意力",{"2":{"824":1}}],["显示了动态掩蔽避免了这个问题",{"2":{"709":1}}],["显示了没有动态掩蔽时",{"2":{"709":1}}],["显示了地面真实云",{"2":{"686":1}}],["显示了由kimera",{"2":{"686":1}}],["显示了截断的",{"2":{"480":1}}],["显示了3d",{"2":{"480":1}}],["显示了优化后的网格和姿态图",{"2":{"390":1}}],["显示了当在姿态图节点",{"2":{"390":1}}],["显示了创建变形图时",{"2":{"390":1}}],["显示了在检测到循环闭合之前收到的网格和姿态图",{"2":{"390":1}}],["显示了",{"2":{"382":1}}],["显示了按房间颜色编码的地点的可视化",{"2":{"197":1}}],["显示在左侧",{"2":{"285":1}}],["显示为黑色置信条",{"2":{"437":1}}],["显示为",{"2":{"41":1}}],["显式或隐式",{"2":{"958":1}}],["显式建模并管理不确定性",{"2":{"864":1}}],["显式建模感知",{"2":{"114":1}}],["显式",{"2":{"846":1}}],["显式地图编码的优点在于可解释性强",{"2":{"698":1}}],["显式的上下文学习是有益的",{"2":{"603":1}}],["显式编码通过存储占用",{"2":{"698":1}}],["显式编码中",{"2":{"675":1}}],["显式编码",{"0":{"698":1},"2":{"406":1}}],["显式编码与隐式编码",{"2":{"406":1,"675":1}}],["显式概念",{"2":{"209":1}}],["显式注释与学习到的隐式特征",{"2":{"90":1}}],["密度分布函数",{"2":{"316":1}}],["密集方法构建更密集的语义注释模型",{"2":{"967":1}}],["密集离散化表示",{"2":{"962":1}}],["密集设计",{"2":{"875":1}}],["密集立体视觉的kimera",{"2":{"732":1}}],["密集立体视觉",{"2":{"732":1}}],["密集感知与语义场景补全",{"2":{"566":1}}],["密集人群",{"2":{"360":1}}],["密集网格使用loper等人",{"2":{"131":1}}],["密集几何形状以及混合表示",{"2":{"90":1}}],["密钥",{"2":{"76":1}}],["地标",{"2":{"765":1}}],["地铁",{"2":{"605":1,"709":1,"754":1,"796":2,"816":5}}],["地铁站和住宅区",{"2":{"131":1}}],["地形",{"2":{"277":1,"534":1,"723":1}}],["地板和天花板的不同标签",{"2":{"480":1}}],["地板油",{"2":{"478":1}}],["地板",{"2":{"178":1,"197":2,"793":1,"967":1}}],["地面真实标签是通过手动分割地点获得的",{"2":{"796":1}}],["地面真实立体深度或",{"2":{"732":1}}],["地面真实点云",{"2":{"686":1}}],["地面真实",{"2":{"437":1}}],["地面真实场景图中具有正确语义标签的估计对象的百分比",{"2":{"437":1}}],["地面",{"2":{"162":1}}],["地图必须实时更新",{"2":{"864":1}}],["地图级",{"2":{"846":1}}],["地图级评估",{"2":{"826":1}}],["地图准确率",{"2":{"826":1}}],["地图准确性衡量地图与真值在几何或语义上的吻合程度",{"2":{"826":1}}],["地图作为输入",{"2":{"752":1}}],["地图中语义信息",{"2":{"826":1}}],["地图中保存的是",{"2":{"765":1}}],["地图中的每个单元格保存二进制值",{"2":{"698":1}}],["地图中存储什么样的编码",{"0":{"406":1}}],["地图编码无需显式监督",{"2":{"743":1}}],["地图编码",{"0":{"675":1},"1":{"698":1,"721":1,"743":1,"765":1}}],["地图上",{"2":{"660":1}}],["地图做分割",{"2":{"495":1}}],["地图聚合",{"2":{"495":1}}],["地图的稠密匹配",{"2":{"495":1}}],["地图的结构是什么",{"0":{"378":1}}],["地图是如何构建的",{"0":{"435":1}}],["地图建成后",{"2":{"274":1}}],["地图类别",{"2":{"254":1}}],["地图以辅助空间推理",{"2":{"176":1}}],["地图图层",{"2":{"126":1}}],["地图通常是短时",{"2":{"123":1}}],["地图",{"2":{"123":1,"378":1,"495":1,"556":1,"619":1,"648":1,"765":2}}],["地图结构",{"0":{"465":1},"1":{"495":1,"525":1,"556":1,"588":1,"619":1,"648":1},"2":{"90":1}}],["地点被精确标记",{"2":{"796":1}}],["地点为33",{"2":{"437":1}}],["地点提取和房间检测",{"2":{"437":1}}],["地点位置误差对于vio+sg",{"2":{"437":1}}],["地点节点会更新到新的位置",{"2":{"380":1}}],["地点层的最小生成树",{"2":{"380":1}}],["地点子图",{"2":{"380":1}}],["地点可以用作路径规划的拓扑图",{"2":{"262":1}}],["地点属性只包括3d位置",{"2":{"197":1}}],["地点及其连通性形成一个拓扑图",{"2":{"197":1}}],["地点及其连通性显示为图",{"2":{"162":1}}],["地点之间的边表示直线可达性",{"2":{"210":1}}],["地点之间的边代表可通行性",{"2":{"197":1}}],["地点之间是否存在直线路径",{"2":{"197":1}}],["地点是自由空间的模型",{"2":{"197":1}}],["地点的图以及背景的度量",{"2":{"168":1}}],["地点和房间层的dsg保持准确",{"2":{"889":1}}],["地点和网格顶点的一个子集",{"2":{"380":1}}],["地点和拓扑",{"2":{"162":1}}],["地点和结构",{"0":{"197":1},"2":{"131":1,"147":1,"197":1}}],["地点",{"0":{"276":1},"2":{"112":1,"125":1,"141":1,"147":1,"162":1,"197":1,"285":1,"480":3,"905":1}}],["地址",{"2":{"78":1}}],["地址是",{"2":{"78":1}}],["与bevformer的miou相当",{"2":{"1001":1}}],["与miou不同",{"2":{"1000":1}}],["与monoscene同时",{"2":{"759":1}}],["与整个场景相比",{"2":{"989":1}}],["与所有基线方法相比",{"2":{"989":1}}],["与主文中表",{"2":{"989":1}}],["与点云",{"2":{"963":1}}],["与注意力机制",{"2":{"950":1}}],["与投影不同",{"2":{"950":1}}],["与以激光雷达为中心的方法相比",{"2":{"942":1}}],["与以离散形式存储信息的点云不同",{"2":{"619":1}}],["与纯视觉中心方法相比",{"2":{"927":1}}],["与纯粹基于transformer的方法",{"2":{"552":1}}],["与一些原始基线进行了比较",{"2":{"917":1}}],["与基线相比",{"2":{"903":1}}],["与基于体素的方法相比",{"2":{"566":1}}],["与基于像素的扩散方法相比",{"2":{"552":1}}],["与基于密集输入网络的网络相比",{"2":{"363":1}}],["与随机初始化相比",{"2":{"899":1}}],["与世界共同成长",{"2":{"864":1}}],["与具身智能中仍严重不足",{"2":{"846":1}}],["与具身式",{"2":{"209":1}}],["与常规卷积中一样",{"2":{"844":1}}],["与常见的匹配任务类似",{"2":{"305":1}}],["与蒸馏前的基于视觉的模型相比",{"2":{"843":1}}],["与道路表面相比",{"2":{"842":1}}],["与默认设置相比",{"2":{"836":1}}],["与其它类别相比",{"2":{"828":1}}],["与其他自监督占用方法进行比较",{"2":{"1000":1}}],["与其他激光雷达",{"2":{"803":1}}],["与其他方法相比",{"2":{"248":1}}],["与其他顶点则不连通",{"2":{"153":1}}],["与单视图投影相比",{"2":{"955":1}}],["与单目图像配对",{"2":{"828":1}}],["与单模态流程类似",{"2":{"474":1}}],["与探索",{"2":{"826":1}}],["与真值几何的均方根误差",{"2":{"826":1}}],["与真实点块",{"2":{"582":1}}],["与真实噪声一起计算误差",{"2":{"124":1,"257":1}}],["与上一节",{"2":{"826":1}}],["与非时间方法相比",{"2":{"811":1}}],["与处理激光雷达点云类似",{"2":{"809":1}}],["与激光雷达",{"2":{"809":1}}],["与仅使用单目或双目图像的semantickitti和sscbench",{"2":{"1000":1}}],["与仅使用摄像头的基线",{"2":{"914":1}}],["与仅使用摄像头的感知系统相比",{"2":{"415":1}}],["与仅使用交叉熵损失训练的模型相比",{"2":{"803":1}}],["与iso评估相同",{"2":{"793":1}}],["与impromptu",{"2":{"360":1}}],["与多视图方法",{"2":{"798":1}}],["与多视角输入或带有三维信息的输入相比",{"2":{"793":1}}],["与多传感器融合方法",{"2":{"503":1}}],["与两种顶级多模态方法radocc",{"2":{"779":1}}],["与地图逐像素计算相似度",{"2":{"765":1}}],["与只能存储预定义对象类别的早期编码相比",{"2":{"765":1}}],["与zhao等人的方法一致",{"2":{"758":1}}],["与在图像上可能具有误导性的刚性网格投影相比",{"2":{"842":1}}],["与在固定分辨率上进行训练和预测的基于体素的离散化方法相比",{"2":{"745":1}}],["与在体素化空间中进行特征整合的传统工作不同",{"2":{"705":1}}],["与使用",{"2":{"803":1}}],["与使用dvio姿态估计的未优化3d网格相比",{"2":{"754":1}}],["与使用密集立体视觉的混淆矩阵",{"2":{"732":1}}],["与使用vio姿态",{"2":{"709":1}}],["与偏移量",{"2":{"716":1}}],["与最先进方法的比较",{"0":{"791":1}}],["与最先进的激光雷达",{"2":{"700":1}}],["与最新的多模态方法effocc",{"2":{"779":1}}],["与最新方法的比较",{"0":{"779":1}}],["与最近直接采用掩模自动编码器",{"2":{"715":1}}],["与他们的工作不同",{"2":{"714":1}}],["与先前的初始化方案不同",{"2":{"704":1}}],["与体素表示相比",{"2":{"693":1}}],["与透视视图和鸟瞰图等2d视图相比",{"2":{"667":1}}],["与全连接层相比",{"2":{"664":1}}],["与隐式神经辐射场",{"2":{"641":1}}],["与octnet",{"2":{"636":1}}],["与tpvformer",{"2":{"738":1}}],["与task的关系不大",{"2":{"589":1}}],["与ts",{"2":{"417":1}}],["与操作等任务",{"2":{"588":1}}],["与深度特征一起重新融合到视觉特征中",{"2":{"578":1,"621":1}}],["与pointnet++相比",{"2":{"636":1}}],["与pointnet++的层次化策略相比",{"2":{"574":1}}],["与pcm一样",{"2":{"390":1}}],["与同时学习编码器",{"2":{"552":1}}],["与依赖于",{"2":{"539":1}}],["与传统方法相比",{"2":{"875":1}}],["与传统的基于体素的方法相比",{"2":{"629":1}}],["与传统的鸟瞰图",{"2":{"610":1}}],["与传统密集网格表示不同",{"2":{"532":1}}],["与传统三维重建方法类似",{"2":{"305":1}}],["与高精度网格地图相比",{"2":{"525":1}}],["与二维卷积",{"2":{"511":1}}],["与二维网格结构",{"2":{"450":1}}],["与模型更大",{"2":{"505":1}}],["与旧信息融合",{"2":{"495":1}}],["与固定采样的方式相比",{"2":{"489":1}}],["与初始深度图逐元素相加",{"2":{"470":1}}],["与clioprim中的对象数量相比",{"2":{"462":1}}],["与carla",{"2":{"360":1}}],["与论文中引用的",{"2":{"456":1}}],["与drivelm",{"2":{"447":1}}],["与driveaction",{"2":{"360":1}}],["与摄像头相比",{"2":{"444":1}}],["与现有技术相比",{"2":{"548":1}}],["与现有的",{"2":{"441":1}}],["与现有方法的效率比较",{"2":{"842":1}}],["与现有方法相比",{"2":{"486":1,"820":1}}],["与现有方法",{"2":{"438":1}}],["与图7相同",{"2":{"437":1}}],["与图像相比",{"2":{"421":1}}],["与平移",{"2":{"435":1}}],["与相机多尺度特征",{"2":{"595":1}}],["与相关工作不同",{"2":{"419":1}}],["与相同的图像匹配产生的概率是不同的",{"2":{"204":1}}],["与语义分割相比",{"2":{"983":1}}],["与语义分割整合为联合框架",{"2":{"209":1}}],["与语义占用感知",{"2":{"841":1}}],["与语言噪声下保持稳定",{"2":{"478":1}}],["与语言模型",{"2":{"417":1}}],["与simlingo语料",{"2":{"417":1}}],["与safeauto",{"2":{"360":1}}],["与当前特征进行空间对齐",{"2":{"957":1}}],["与当前多传感器融合框架在笛卡尔坐标系下处理3d特征体积不同",{"2":{"409":1}}],["与当前移动机器人所面临的功率限制兼容",{"2":{"408":1}}],["与当前的开放集3d场景图构建方法",{"2":{"109":1}}],["与标准解码器层相比",{"2":{"405":1}}],["与网格顶点",{"2":{"390":1}}],["与变形图中的每个节点关联起来",{"2":{"380":1}}],["与规则体素网格不同",{"2":{"378":1}}],["与nuscenes",{"2":{"360":1,"924":1}}],["与200万帧训练集",{"2":{"360":1}}],["与自然语言处理",{"2":{"340":1}}],["与第一次迭代类似",{"2":{"328":1}}],["与密集体素的数量相比",{"2":{"656":1}}],["与密集",{"2":{"308":1}}],["与直接在体积esdf层面上规划相比",{"2":{"947":1}}],["与直接对原始图像稠密匹配相比",{"2":{"305":1}}],["与直接生成网格等显式表示的深度",{"2":{"247":1}}],["与llm解码器",{"2":{"260":1}}],["与此sample",{"2":{"254":1}}],["与此同时",{"2":{"123":1,"578":1,"746":1,"881":1,"913":1}}],["与kimera",{"2":{"253":1,"390":1,"754":1}}],["与训练有符号距离值回归的当前隐式方法相比",{"2":{"247":1}}],["与检索增强提示",{"2":{"195":1}}],["与噪声图",{"2":{"175":1}}],["与任务",{"2":{"153":3}}],["与方程",{"2":{"153":1,"681":1}}],["与实时操作不兼容",{"2":{"141":1}}],["与机器人学分道扬镳",{"2":{"139":1}}],["与之前的显式场景表示",{"2":{"641":1}}],["与之前工作的联系",{"0":{"230":1},"1":{"251":1,"273":1}}],["与之前工作",{"2":{"131":1}}],["与之不同的是",{"2":{"612":1,"693":1}}],["与之不同",{"2":{"90":1}}],["与armeni等人",{"2":{"131":1}}],["与知识库",{"2":{"131":1,"147":1}}],["与wkad",{"2":{"128":1}}],["与vlm",{"2":{"128":1}}],["与我们不同的是",{"2":{"870":1}}],["与我们的工作更接近的是",{"2":{"603":1}}],["与我们的提议更相关的是利用语义信息进行环路闭合检测的一系列论文",{"2":{"190":1}}],["与我们联系",{"2":{"126":1,"302":1}}],["与我们最相似的是conceptgraphs",{"2":{"121":1}}],["与本文讨论的语义地图不同",{"2":{"123":1}}],["与低层连续运动规划",{"2":{"123":1}}],["与更慢的高级感知",{"2":{"112":1,"141":1}}],["与",{"0":{"917":1},"2":{"111":1,"126":1,"171":1,"209":1,"231":1,"236":1,"252":1,"277":1,"302":1,"369":2,"485":1,"489":1,"525":1,"588":1,"660":2,"700":1,"792":1,"803":1,"826":1,"832":1,"844":1,"863":1,"864":1,"872":1,"897":1,"901":1,"928":2,"948":1,"961":1,"967":1}}],["与大语言模型",{"2":{"82":1}}],["都可以通过我们的fo",{"2":{"791":1}}],["都有",{"2":{"681":1}}],["都为",{"2":{"652":1}}],["都平等地描述每个体素",{"2":{"599":1}}],["都达到了最先进的精度",{"2":{"425":1}}],["都得到77x768大小的特征",{"2":{"373":1}}],["都需要经过一个alexnet提特征",{"2":{"207":1}}],["都以恒定时间运行",{"2":{"141":1}}],["都没有考虑到或建模环境中的动态实体",{"2":{"116":1}}],["都必须在复杂",{"2":{"90":1}}],["都是在小点云上工作的",{"2":{"996":1}}],["都是可学习的并且由输入",{"2":{"844":1}}],["都是可以的",{"2":{"685":1}}],["都是从一个潜在的数据分布",{"2":{"193":1}}],["都是这个命令",{"2":{"76":1}}],["都是用于三维空间中表示物体表面和障碍物距离的函数",{"2":{"31":1}}],["都是不真实的",{"2":{"13":1}}],["智能决策模块生成驾驶行为的控制和规划",{"2":{"691":1}}],["智能代理",{"2":{"90":1}}],["智能体到达目标并主动发出停止",{"2":{"806":1}}],["智能体仍可借助",{"2":{"765":1}}],["智能体在每个环境中沿多条随机轨迹行走",{"2":{"525":1}}],["智能体只能按顺序在有限视角下观测并累积信息",{"2":{"435":1}}],["智能体首先需要知道自己的位置",{"2":{"435":1}}],["智能体可选择预训练大视觉",{"2":{"274":1}}],["智能体",{"2":{"80":1}}],["至于评估指标",{"2":{"770":1}}],["至于标签效率",{"2":{"665":1}}],["至少有一个体素为空",{"2":{"707":1}}],["至少要训练500个epoch",{"2":{"386":1}}],["至",{"2":{"173":1}}],["至关重要",{"2":{"116":1}}],["至此",{"2":{"87":1,"648":1}}],["至学者",{"2":{"41":1}}],["会检查是否越界",{"2":{"904":1}}],["会导致观测误差",{"2":{"864":1}}],["会带来巨大的计算量",{"2":{"695":1}}],["会使kimera的误差更小",{"2":{"634":1}}],["会使用",{"2":{"205":1}}],["会返回一个",{"2":{"571":1}}],["会议室",{"2":{"374":1}}],["会出现野指针问题",{"2":{"115":1}}],["会自动下载和完成rosdep",{"2":{"87":1}}],["会话id|会话名称",{"2":{"88":1}}],["会话",{"0":{"68":1,"88":1},"2":{"88":1,"99":1}}],["每层将尺寸加倍",{"2":{"982":1}}],["每层通过下采样将尺寸减半",{"2":{"982":1}}],["每层使用反卷积",{"2":{"982":1}}],["每层包含",{"2":{"982":1}}],["每层由一个",{"2":{"562":1}}],["每组具有独立的采样偏移",{"2":{"863":1}}],["每块",{"2":{"744":1,"867":1}}],["每块大小是3×5",{"2":{"554":1}}],["每辆自动驾驶车辆上部署激光雷达套件是昂贵的",{"2":{"667":1}}],["每点带语义标签",{"2":{"648":1}}],["每类随机选三个点作为点提示生成语义掩码",{"2":{"617":1}}],["每到一个新位置就创建节点",{"2":{"525":1}}],["每回合开始时",{"2":{"495":1}}],["每片段配对专家轨迹与高层指令",{"2":{"360":1}}],["每当我们在给定层有一个匹配项时",{"2":{"352":1}}],["每帧提供",{"2":{"742":1}}],["每帧可达数百gflops",{"2":{"417":1}}],["每帧学习未来路径与场景描述",{"2":{"417":1}}],["每帧",{"2":{"349":1}}],["每帧和多帧3d网格都编码为顶点位置列表",{"2":{"336":1}}],["每帧和多帧网格生成器",{"2":{"285":1}}],["每帧网格",{"2":{"336":1}}],["每帧3d网格",{"2":{"336":1}}],["每种传感器各有优劣",{"2":{"503":1}}],["每种表示方式都有其优缺点",{"2":{"331":1}}],["每种面积又包含三种长宽比",{"2":{"321":1}}],["每通道尺度为",{"2":{"305":1}}],["每一列都增加了提高性能的模型特征",{"2":{"775":1}}],["每一列都是一个分类任务",{"2":{"184":1}}],["每一个内存空间包含对应object的时间间隔",{"2":{"718":1}}],["每一层应用一个球面卷积核",{"2":{"636":1}}],["每一层的步骤如下",{"2":{"594":1}}],["每一步都提供完美位姿",{"2":{"435":1}}],["每一步得到的图片都可以看成是初始值和标准高斯噪音的一个线性组合",{"2":{"279":1}}],["每一波由前代限制与新的跨模态预训练技术驱动",{"2":{"238":1}}],["每一行都是一个分类任务",{"2":{"184":1}}],["每秒最多约",{"2":{"173":1}}],["每圈约",{"2":{"173":1}}],["每次损失计算中使用的局部空间占用真值是从整个场景的空间占用中相应获得的",{"2":{"750":1}}],["每次我们将一些更新后的高斯分布放回记忆中时",{"2":{"728":1}}],["每次试验包括一个映射阶段和一个规划阶段",{"2":{"522":1}}],["每次检测到新的回路时",{"2":{"390":1}}],["每次检测到回路闭合时",{"2":{"390":1}}],["每次点击后",{"2":{"117":1}}],["每次推理都是对网络的微调",{"2":{"84":1}}],["每个关键帧附加的半密集局部地图相应更新",{"2":{"967":1}}],["每个掩码与相应的语义类别相关联",{"2":{"957":1}}],["每个摄像头的前视特征图描述了场景的一部分",{"2":{"957":1}}],["每个模型的性能变化趋势",{"2":{"944":1}}],["每个集中样本数为零的类别未在图中列出",{"2":{"900":1}}],["每个实例仅通过少量具有自适应形状的高斯来稀疏描述",{"2":{"885":1}}],["每个组件对深度估计模块都有影响",{"2":{"882":1}}],["每个组件可独立设计",{"2":{"103":1}}],["每个级别的3d体积特征和bev平面应用全局",{"2":{"875":1}}],["每个类别的百分比分布如图",{"2":{"828":1}}],["每个块对应场景中的一个",{"2":{"814":1}}],["每个块包括一个自编码模块",{"2":{"716":1}}],["每个块包括自编码",{"2":{"704":1}}],["每个雷达",{"2":{"809":1}}],["每个数据样本的真值分辨率为",{"2":{"787":1}}],["每个数据集对vio的难度不同",{"2":{"572":1}}],["每个驾驶场景包含20秒以2hz频率采集的标注感知数据",{"2":{"770":1}}],["每个矩阵a^m",{"2":{"752":1}}],["每个矩阵编码一种独特的体素关系",{"2":{"752":1}}],["每个层级的",{"2":{"746":1}}],["每个层由一个初始网格卷积",{"2":{"526":1}}],["每个场景的全局空间占用的分辨率由",{"2":{"793":1}}],["每个场景持续",{"2":{"749":1}}],["每个场景持续20秒",{"2":{"736":1}}],["每个场景以",{"2":{"739":1}}],["每个被占据的体素被分配了17个语义标签之一",{"2":{"736":1}}],["每个语义高斯分布可以描述一个局部区域",{"2":{"705":1}}],["每个3d高斯分布具有明确的语义意义",{"2":{"693":1}}],["每个3d高斯分布由一个",{"2":{"693":1}}],["每个存储值的含义明确可辨",{"2":{"675":1}}],["每个序列持续20秒",{"2":{"781":1}}],["每个序列持续",{"2":{"652":1}}],["每个深度bin对应于笛卡尔坐标系中的一个3d点",{"2":{"649":1}}],["每个深度bin的长度是固定的",{"2":{"621":1}}],["每个锚点车道由300个采样点组成",{"2":{"644":1}}],["每个区间对应一个深度bin",{"2":{"621":1}}],["每个分支都有自己的网络结构和参数",{"2":{"601":1}}],["每个分割结果都作为一个不同的实例输出",{"2":{"138":1}}],["每个网格被赋予一个语义属性",{"2":{"590":1}}],["每个子集群中的特征首先通过edgeconv模块学习",{"2":{"574":1}}],["每个子网络是hidden",{"2":{"562":1}}],["每个顶点的特征通常被赋予坐标",{"2":{"574":1}}],["每个顶点的法线指向相机",{"2":{"480":1}}],["每个高斯被建模为一个椭球体",{"2":{"916":1}}],["每个高斯分布由其位置",{"2":{"861":1}}],["每个高斯分布由一个向量表示",{"2":{"705":1}}],["每个高斯分布",{"2":{"705":1}}],["每个高斯分布实例化一个语义高斯分布",{"2":{"693":1}}],["每个高斯分布都有一个置信度值",{"2":{"568":1}}],["每个高斯仍然可以描述空区域",{"2":{"567":1}}],["每个高斯由均值",{"2":{"444":1}}],["每个边缘的分割预测显示在左侧",{"2":{"557":1}}],["每个面三个边缘的每个特征被合并为一个新的边缘特征",{"2":{"466":1}}],["每个房间re",{"2":{"437":1}}],["每个房间都有一个质心",{"2":{"210":1}}],["每个",{"2":{"412":1,"656":1,"982":2}}],["每个功能块都标有数字",{"2":{"408":1}}],["每个值都有明确",{"2":{"406":1}}],["每个点的最终语义标签是通过融合不同视图上的重新投影分数来获得的",{"2":{"955":1}}],["每个点的令牌只与前面未被掩码的令牌相互关联",{"2":{"549":1}}],["每个点",{"2":{"789":1}}],["每个点位于xy平面上占据网格的中心",{"2":{"638":1}}],["每个点由其自身的绝对位置和相对于其相邻点的相对位置表示",{"2":{"420":1}}],["每个点云的实例信息只能通过超点交叉注意力获得",{"2":{"405":1}}],["每个点上有k个anchor",{"2":{"321":1}}],["每个内核代表实例身份",{"2":{"384":1}}],["每个三角形的高",{"2":{"379":1}}],["每个单元格对应现实世界中一块固定大小的区域",{"2":{"495":1}}],["每个单元格",{"2":{"378":1}}],["每个物体query表示一个物体",{"2":{"341":1}}],["每个输入图像输出一个1",{"2":{"305":1}}],["每个障碍物距离小于δ的地方都将从图中消失",{"2":{"301":1}}],["每个注意力层都有",{"2":{"278":1}}],["每个地点节点被分配一个特征",{"2":{"228":1}}],["每个轨迹根据轨迹中的所有帧重建成3d对象原语",{"2":{"206":1}}],["每个新segment然后贪婪地关联到iouiouiou",{"2":{"206":1}}],["每个对象都有一个语义标签",{"2":{"210":1}}],["每个对象都连接到最近的可达地点节点",{"2":{"178":1}}],["每个对象节点都连接到度量",{"2":{"178":1}}],["每个对象是一个节点",{"2":{"178":1}}],["每个像素编码为",{"2":{"173":1}}],["每个节点具有以下属性",{"2":{"162":1}}],["每个节点都有一个唯一的id",{"2":{"147":1}}],["每个抽象层次都在模型保真度和计算效率之间进行权衡",{"2":{"116":1}}],["每个体素采用",{"2":{"962":1}}],["每个体素标记被输入到二元分类器中以预测体素是否为空",{"2":{"922":1}}],["每个体素被标记为19个类别之一",{"2":{"781":1}}],["每个体素被标记为18个类别之一",{"2":{"781":1}}],["每个体素被分类为",{"2":{"749":1}}],["每个体素被分配一个特征向量",{"2":{"612":1}}],["每个体素的状态由",{"2":{"780":1}}],["每个体素的边长为",{"2":{"749":1}}],["每个体素的大小为",{"2":{"736":2}}],["每个体素的形状为",{"2":{"712":1}}],["每个体素的分辨率为",{"2":{"652":1}}],["每个体素网格由语义类别表示",{"2":{"613":1}}],["每个体素最多保留10个点",{"2":{"609":1}}],["每个体素都有一个标签概率向量",{"2":{"362":1}}],["每个体素",{"2":{"31":1}}],["非叶节点的表示是使用mlp从其子节点的表示中计算出来的",{"2":{"636":1}}],["非立体的平面目标画像问题",{"2":{"630":1}}],["非空区域可能会被错误地归类为未占用区域",{"2":{"599":1}}],["非常适合实时应用",{"2":{"857":1}}],["非常高效的完成了这个任务",{"2":{"751":1}}],["非常准确",{"2":{"709":1}}],["非常简洁",{"2":{"576":1}}],["非常重要",{"2":{"66":1}}],["非最大抑制阈值为10^",{"2":{"449":1}}],["非极大抑制",{"2":{"328":1}}],["非归一化的概率模型",{"2":{"213":1}}],["非刚性",{"2":{"178":1}}],["非商业用途的例子包括但不限于个人使用",{"2":{"126":1,"302":1}}],["非商业用途是指不主要以获取商业利益或金钱补偿为目的",{"2":{"126":1,"302":1}}],["非实时系统",{"2":{"125":1}}],["非结构化的环境中运行",{"2":{"90":1}}],["非冻结的网络结构",{"2":{"84":1}}],["新旗手模式在x",{"2":{"507":1}}],["新加坡",{"2":{"157":3,"360":2,"995":1}}],["新数据可能只影响场景的一小部分",{"2":{"153":1}}],["新测量的影响",{"2":{"153":1}}],["新的",{"2":{"570":1}}],["新的增强方法",{"2":{"424":1}}],["新的维度",{"2":{"351":1}}],["新的子任务",{"2":{"117":1}}],["新的迭代训练策略",{"2":{"84":1}}],["新开一个终端",{"2":{"97":1}}],["新名字1",{"2":{"24":1}}],["由slam++",{"2":{"967":1}}],["由多个3d卷积层组成",{"2":{"957":1}}],["由下式给出",{"2":{"916":1}}],["由下面公式得到",{"2":{"329":1}}],["由缩放规则对模型扩展",{"2":{"912":1}}],["由四个超参控制搜索空间",{"2":{"896":1}}],["由四元数",{"2":{"656":1}}],["由橙色实线矩形指示",{"2":{"791":1}}],["由橙色虚线指示",{"2":{"791":1}}],["由红色椭圆指示",{"2":{"791":1}}],["由红色虚线指示",{"2":{"791":1}}],["由6个周围相机收集rgb图像",{"2":{"781":1}}],["由microsoft",{"2":{"757":1}}],["由48变成c",{"2":{"659":1}}],["由k个最近邻构成",{"2":{"607":1}}],["由kimera",{"2":{"480":1}}],["由它生成的token",{"2":{"559":1}}],["由均值",{"2":{"532":1,"693":1}}],["由两个类似房间的区域组成",{"2":{"522":1}}],["由符号验证器执行",{"2":{"507":1}}],["由房间检测和场景图优化计算成本驱动",{"2":{"437":1}}],["由3d坐标生成器产生的3d坐标通过一个多层感知机",{"2":{"427":1}}],["由过多的网络参数和标注需求导致的模型和数据低效性",{"2":{"425":1}}],["由回路闭合引起的网格变形基于变形图",{"2":{"390":1}}],["由回路闭合检测产生",{"2":{"390":1}}],["由里程计和回路l1形成的循环中的位姿必须组合为恒等式",{"2":{"390":1}}],["由包括里程计和环路闭合边的姿态图组成",{"2":{"380":1}}],["由th和ty决定",{"2":{"375":1}}],["由tx和ty决定",{"2":{"375":1}}],["由感知损失perceptual",{"2":{"371":1}}],["由近大远小原理可知能被当前位置的相机看到的特征点数量随着深度减小而减小",{"2":{"355":1}}],["由vio前端生成",{"2":{"336":1}}],["由",{"2":{"149":2,"162":1,"670":1}}],["由隐藏变量",{"2":{"133":1}}],["由图组成",{"2":{"116":1}}],["由此可见",{"2":{"844":1}}],["由此可以大致推断",{"2":{"181":1}}],["由此得到d=",{"2":{"355":1}}],["由此",{"2":{"84":1,"106":1,"117":1}}],["由于激光雷达传感提供了精确的深度信息",{"2":{"1000":1}}],["由于激光雷达传感的不平衡分布和遮挡",{"2":{"998":1}}],["由于激光雷达点云的稀疏性和遮挡性",{"2":{"988":1}}],["由于强监督和弱监督学习都预测几何和语义占用",{"2":{"988":1}}],["由于估计深度值可能会引入误差",{"2":{"950":1}}],["由于单目图像的视角限制",{"2":{"945":1}}],["由于单个传感器固有的优势和劣势",{"2":{"625":1}}],["由于前视仅提供2d视角",{"2":{"942":1}}],["由于缺乏点云中固有的精确深度和几何信息",{"2":{"949":1}}],["由于缺乏几何先验",{"2":{"941":1}}],["由于缺乏足够的特征来进行可靠预测",{"2":{"700":1}}],["由于环视相机对不同光照条件敏感",{"2":{"936":1}}],["由于环视相机在自动驾驶汽车",{"2":{"564":1}}],["由于这种过度分割通常很小",{"2":{"930":1}}],["由于这些研究通常聚焦单一任务",{"2":{"786":1}}],["由于结果是从不同论文中收集的",{"2":{"922":1}}],["由于引入了激光雷达传感器",{"2":{"914":1}}],["由于篇幅限制",{"2":{"902":1}}],["由于该数据集中缺乏雷达传感器",{"2":{"900":1}}],["由于该数据集中没有动态",{"2":{"572":1}}],["由于测试集标签不可用",{"2":{"900":1}}],["由于测试集中缺乏注释",{"2":{"787":1}}],["由于cbgs涉及重采样",{"2":{"876":1}}],["由于伪",{"2":{"865":1}}],["由于radocc的源代码不可用",{"2":{"859":1}}],["由于内存限制",{"2":{"853":1}}],["由于内存原因",{"2":{"853":1}}],["由于真实世界的数据由于遮挡而具有稀疏的真实标签yyy",{"2":{"834":1}}],["由于以目标为中心的概率设计和有效的初始化模块",{"2":{"832":1}}],["由于相机在低光照条件下提供的语义信息有限",{"2":{"827":1}}],["由于相机没有共享相同的视野",{"2":{"605":2}}],["由于bevdetocc中实现的时间方法是立体匹配",{"2":{"811":1}}],["由于自动驾驶场景中存在大量空体素",{"2":{"808":1}}],["由于当前的3d占用注释是从lidar点云真实标签生成的",{"2":{"778":1}}],["由于将3d卷积替换为2d卷积时会改变通道数量",{"2":{"770":1}}],["由于它基于kitti数据集",{"2":{"757":1}}],["由于它们在测试集中出现频率低",{"2":{"700":1}}],["由于特征与策略同步优化",{"2":{"743":1}}],["由于权重",{"2":{"738":1}}],["由于高斯混合的通用近似能力",{"2":{"738":1}}],["由于3d空间中的体素数量庞大",{"2":{"735":1}}],["由于3d高斯分布的数量",{"2":{"716":1}}],["由于体素关系是贪婪的",{"2":{"707":1}}],["由于室内物体的可变尺度和紧密排列",{"2":{"705":1}}],["由于多传感器融合的互补性",{"2":{"678":1}}],["由于多头注意力机制",{"2":{"278":1}}],["由于fisher向量的分量为在所有点上求和",{"2":{"664":1}}],["由于雷达的成本效益以及其检测远距离物体的能力",{"2":{"653":1}}],["由于点云的稀疏性",{"2":{"638":1}}],["由于点云数据的信息密度有限以及生成和下游任务之间存在差距",{"2":{"488":1}}],["由于从",{"2":{"632":1}}],["由于所提出的范式不受限于特定架构",{"2":{"627":1}}],["由于深度假设是沿着相机平截头体离散采样的",{"2":{"622":1}}],["由于网络结构的巧妙",{"2":{"618":1}}],["由于驾驶场景的稀疏性和传统体素表示的高分辨率",{"2":{"612":1}}],["由于驾驶数据昂贵且风险高",{"2":{"388":1}}],["由于其广泛的范围和复杂的数据性质",{"2":{"892":1}}],["由于其紧凑性和多功能性",{"2":{"629":1}}],["由于其全面的感知能力",{"2":{"610":1}}],["由于其生成过程的随机性",{"2":{"289":1}}],["由于uhumans和uhumans2数据集是模拟的",{"2":{"605":1}}],["由于unordered",{"2":{"571":1}}],["由于任务间的冲突和信息丢失等问题",{"2":{"601":1}}],["由于没有规定高斯不能代表空区域",{"2":{"599":1}}],["由于避免了昂贵的体素级特征处理",{"2":{"598":1}}],["由于中心点采样过程可能会影响点块的顺序",{"2":{"549":1}}],["由于在3d空间中是物体而不是网格在移动",{"2":{"547":1}}],["由于大多数体素空间是未被占用的",{"2":{"547":1}}],["由于手动标记开放集3d区域是一项高度主观的任务",{"2":{"522":1}}],["由于摄像头容易受到光照和天气变化的影响",{"2":{"482":1}}],["由于",{"2":{"474":1,"656":1,"684":2,"900":1,"995":1}}],["由于占据标注是基于点云分割和物体检测标注的二次标注",{"2":{"455":1}}],["由于图像中的透视效应",{"2":{"438":1}}],["由于忽略了每种传感器的信息分布特性",{"2":{"438":1}}],["由于不同模态传感器之间的互补信息以及对复杂光照和天气条件的鲁棒性",{"2":{"438":1}}],["由于传感器噪声",{"2":{"495":1}}],["由于传感器与执行器存在噪声",{"2":{"435":1}}],["由于传统的指标如精确度和召回率不能完全捕捉开放集对象检测的性能",{"2":{"402":1}}],["由于一对一的匹配方式",{"2":{"434":1}}],["由于pointnet中每个点的特征都是独立学习的",{"2":{"420":1}}],["由于感知别名",{"2":{"390":1}}],["由于视点或光照变化",{"2":{"352":1}}],["由于transformer本质上是一个序列转换的作用",{"2":{"333":1}}],["由于马尔可夫链的目的是对点分布进行建模",{"2":{"314":1}}],["由于我们利用",{"2":{"945":1}}],["由于我们考虑了被遮挡的体素",{"2":{"917":1}}],["由于我们考虑的是单个建筑物的表示",{"2":{"240":1}}],["由于我们提出的daocc将一个辅助三维目标检测分支整合到占据预测框架中",{"2":{"893":1}}],["由于我们使用了比其他",{"2":{"865":1}}],["由于我们首次尝试仅从单张",{"2":{"853":1}}],["由于我们已知最终3d占据体积在3d空间中每个尺度体素网格的笛卡尔坐标",{"2":{"699":1}}],["由于我们是迭代地预测深度残差",{"2":{"464":1}}],["由于我们的flashocc设计为即插即用方式",{"2":{"770":1}}],["由于我们的轨迹高度估计",{"2":{"709":1}}],["由于我们的表示仅对占用区域进行建模",{"2":{"567":1}}],["由于我们的查询不包括否定或多步可供性",{"2":{"431":1}}],["由于我们的机器人在拥挤",{"2":{"310":1}}],["由于gp",{"2":{"301":1}}],["由于每个柱坐标体素可能包含多个点",{"2":{"676":1}}],["由于每一次采样的随机性",{"2":{"180":1}}],["由于每次需要将所有的点击作为输入",{"2":{"117":1}}],["由于分辨率和判别力之间的良好权衡",{"2":{"143":1}}],["由于初始前向传播的分割结果可能存在于用户标注不匹配的部分",{"2":{"75":1}}],["由于第一个点击一般都会点在目标物体的中心区域",{"2":{"65":1}}],["容量函数",{"2":{"904":1}}],["容量会增倍",{"2":{"83":1}}],["容器判空",{"2":{"904":1}}],["容器最大容量",{"2":{"904":1}}],["容器大小",{"2":{"904":1}}],["容器适配器",{"2":{"685":1}}],["容器的迭代器",{"2":{"217":1}}],["容器类模板中未提供",{"2":{"217":1}}],["容器内部存储的各个元素的值都互不相等",{"2":{"217":1}}],["容器不会",{"2":{"217":1}}],["容器会自行对存储的数据进行排序",{"2":{"217":1}}],["容器很像",{"2":{"217":1}}],["容器和",{"2":{"217":1}}],["容器中存储的元素",{"2":{"217":1}}],["容器中所有的键值对",{"2":{"196":1}}],["容器中安装",{"2":{"78":1}}],["容器",{"2":{"196":1,"217":2}}],["容器通过key访问单个元素比map快",{"2":{"196":1}}],["容易使gan训练不稳定",{"2":{"129":1}}],["当加入激光雷达数据时",{"2":{"952":1}}],["当仅使用2d渲染监督时",{"2":{"949":1}}],["当测试集的相机设置与训练集相差较大时",{"2":{"945":1}}],["当存在整合的激光雷达数据时",{"2":{"944":1}}],["当daocc在occ3d",{"2":{"893":1}}],["当框架不合并激光雷达和雷达信息时",{"2":{"867":1}}],["当3d高斯分布的数量大于38400时",{"2":{"842":1}}],["当视角",{"2":{"826":1}}],["当引入大尺度参数",{"2":{"824":1}}],["当引入时间信息时",{"2":{"811":1}}],["当不使用相机可见掩码时",{"2":{"893":1}}],["当不使用相机可见掩码进行训练时",{"2":{"800":1}}],["当不使用掩码时",{"2":{"800":1}}],["当在训练期间使用相机可见掩码时",{"2":{"800":2}}],["当在训练阶段排除相机可见掩码时",{"2":{"736":1}}],["当训练数据非常有限时",{"2":{"782":1}}],["当预测深度有较小偏差时",{"2":{"778":1}}],["当定位漂移较低时",{"2":{"775":1}}],["当两物体点云在几何上足够接近",{"2":{"765":1}}],["当某单元格内的相似度超过阈值时",{"2":{"765":1}}],["当指令要求",{"2":{"765":1}}],["当然不包括arr",{"2":{"888":1}}],["当然",{"2":{"732":1}}],["当新观测到达时",{"2":{"525":1}}],["当新的测量数据",{"2":{"153":1}}],["当使用surroundocc",{"2":{"893":1}}],["当使用更多参数的图像backbone时",{"2":{"803":1}}],["当使用occ3d",{"2":{"736":1}}],["当使用vio姿态时",{"2":{"709":1}}],["当使用",{"2":{"498":1}}],["当使用gt",{"2":{"437":1}}],["当使用相机掩码进行训练时",{"2":{"421":1}}],["当位姿图的节点很少时",{"2":{"419":1}}],["当网格尚未变形时",{"2":{"390":2}}],["当网格和地点移出活动窗口时",{"2":{"253":1}}],["当回路闭合通过异常值拒绝时",{"2":{"390":1}}],["当pcm",{"2":{"390":1}}],["当检测到环路闭合时",{"2":{"380":1}}],["当我们比较两个节点的描述符时",{"2":{"352":1}}],["当我们计划长途旅行时",{"2":{"116":1}}],["当输入分辨率低且放大因子大时",{"2":{"382":1}}],["当输入text的tokens数量超过77后",{"2":{"373":1}}],["当输入图像为512x512大小时将得到64x64x4大小的latent",{"2":{"345":1}}],["当输入是一个粗体素形状时",{"2":{"318":1}}],["当fff在4～16时",{"2":{"345":1}}],["当从esdf提取地点时",{"2":{"253":1}}],["当噪声十分小的时候",{"2":{"235":1}}],["当送入降质图像时",{"2":{"220":1}}],["当顶部激光雷达扫描经过摄像头视场中心时",{"2":{"211":1}}],["当成指针用",{"2":{"177":1}}],["当vector内元素超过开始设定的size",{"2":{"146":1}}],["当vector的元素数量超过他的容量时",{"2":{"83":1}}],["当前自监督占用感知的性能",{"2":{"1006":1}}],["当前挑战",{"2":{"935":1}}],["当前室内建图普遍假设环境静态",{"2":{"926":1}}],["当前室内具身智能研究普遍采用",{"2":{"495":1}}],["当前依赖的类无关检测器对小",{"2":{"897":1}}],["当前视锥体内的高斯分布的更新可能会破坏之前的预测",{"2":{"833":1}}],["当前具身智能系统普遍假设无传感器",{"2":{"826":1}}],["当前主流的",{"2":{"824":1}}],["当前主要瓶颈在于大型基础模型的计算开销较大",{"2":{"765":1}}],["当前层神经元的值被确定为前一层所有相关子节点的平均值",{"2":{"636":1}}],["当前的3d占用感知只能识别一组预定义的对象类别",{"2":{"1006":1}}],["当前的自监督方法需要更多的数据进行训练和评估",{"2":{"1006":1}}],["当前的高斯分布通过三个优化层进行优化",{"2":{"833":1}}],["当前的研究主要集中在bev摄像头上",{"2":{"821":1}}],["当前的",{"2":{"567":1}}],["当前基于视觉的占据网络在前景障碍物上的精度较低",{"2":{"548":1}}],["当前基于高斯的方法仅依赖于2d图像反馈来更新3d高斯",{"2":{"444":1}}],["当前提出的3d占据预测模型",{"2":{"503":1}}],["当前vla4ad以相机为中心",{"2":{"478":1}}],["当前套件分别覆盖这些方面",{"2":{"447":1}}],["当前工作依赖",{"2":{"417":1}}],["当前工作常冻结llm",{"2":{"417":1}}],["当前机器人姿态对应的最新代理节点",{"2":{"352":1}}],["当前机器人的内部表征仍然只能提供对环境的部分和碎片化的理解",{"2":{"105":1}}],["当前方法仍以感知为中心",{"2":{"128":1}}],["当切换到别的工具标好了头发后",{"2":{"117":1}}],["当被要求在建筑物中指路时",{"2":{"116":1}}],["当体素距离物体表面非常远时",{"2":{"31":1}}],["当体素距离物体表面非常近时",{"2":{"31":1}}],["动如脱兔",{"2":{"410":1}}],["动力学的一个步骤",{"2":{"354":1}}],["动物",{"2":{"277":1,"534":1}}],["动态感知",{"2":{"1003":2}}],["动态生成",{"2":{"957":1}}],["动态环境中的slam和vio",{"0":{"967":1}}],["动态环境中的可扩展性与鲁棒性",{"2":{"951":1}}],["动态环境部署方面仍存瓶颈",{"2":{"619":1}}],["动态体素可以移动到时间帧中的正确位置",{"2":{"941":1}}],["动态数据既要实时更新",{"2":{"926":1}}],["动态数组",{"2":{"83":1}}],["动态地图",{"0":{"926":1}}],["动态编码实例中心语义以实现图像和体积域之间的复杂交互",{"2":{"875":1}}],["动态且多样的环境中",{"2":{"864":1}}],["动态融合",{"0":{"829":1},"2":{"829":2,"971":1}}],["动态或杂乱场景下的准确性评估极少被研究",{"2":{"826":1}}],["动态实体",{"2":{"709":1}}],["动态掩蔽的优势得以保持",{"2":{"709":1}}],["动态掩蔽",{"2":{"709":1}}],["动态车辆",{"2":{"700":1}}],["动态车辆和大平面类别的表现上超越了它们",{"2":{"700":1}}],["动态场景",{"2":{"864":1}}],["动态场景中网格重建的鲁棒性",{"0":{"709":1}}],["动态场景中姿态估计的鲁棒性",{"0":{"662":1}}],["动态场景和slam等研究领域的快速发展",{"2":{"629":1}}],["动态场景下一致语义维护等挑战",{"2":{"588":1}}],["动态特征融合",{"0":{"464":1}}],["动态路由",{"2":{"334":1}}],["动态",{"2":{"310":1}}],["动态调整输入分辨率以平衡速度与细节",{"2":{"260":1}}],["动态调整粒度以应对实时或长尾场景",{"2":{"176":1}}],["动态图边卷积网络dgcnn",{"2":{"258":1}}],["动作对齐仍开放",{"2":{"507":1}}],["动作系统在规模化真实部署前仍面临重大障碍",{"2":{"478":1}}],["动作数据上微调以对齐模态",{"2":{"417":1}}],["动作映射上高度反应且有效",{"2":{"308":1}}],["动作想象",{"2":{"308":1,"334":1}}],["动作输出",{"2":{"334":1}}],["动作输出形式",{"2":{"238":1}}],["动作输出通常表示为未来轨迹或控制信号",{"2":{"114":1}}],["动作解码器",{"2":{"195":1}}],["动作模型",{"2":{"92":1,"538":1}}],["动作模型综述",{"2":{"62":1}}],["动作",{"2":{"72":1,"114":1,"334":1,"765":1}}],["顺序序列",{"2":{"83":1}}],["概览",{"0":{"359":1,"423":1,"573":1,"620":1},"1":{"453":1,"484":1,"514":1,"545":1,"578":1,"606":1,"635":1,"663":1,"687":1,"710":1,"733":1,"755":1,"776":1,"797":1,"817":1,"837":1,"856":1,"873":1,"890":1,"906":1,"920":1}}],["概括了kimera",{"2":{"285":1}}],["概率建模和基于分布的初始化模块均带来了一致的提升",{"2":{"812":1}}],["概率高斯属性稳步改进",{"2":{"704":1}}],["概率高斯叠加",{"0":{"681":1}}],["概率图",{"2":{"622":1}}],["概率围绕均值分布",{"2":{"599":1}}],["概率密度函数",{"0":{"213":1}}],["概率p",{"2":{"137":1}}],["概念",{"0":{"83":1}}],["概述",{"0":{"126":1},"2":{"41":1}}],["基线方法在所有指标上都明显超过了我们",{"2":{"917":1}}],["基线方法本身并未改变",{"2":{"870":1}}],["基线方法",{"0":{"870":1,"978":1},"2":{"853":1,"870":1,"989":1}}],["基线是基于视觉的先进模型以及",{"2":{"803":1}}],["基线ts",{"2":{"360":1}}],["基方法",{"2":{"564":1}}],["基本需求",{"0":{"597":1}}],["基本结构",{"0":{"476":1},"1":{"504":1,"534":1}}],["基本上是一个拓扑图",{"2":{"210":1}}],["基准是自动驾驶领域最具影响力的数据集之一",{"2":{"931":1}}],["基准相比",{"2":{"803":1}}],["基准上的",{"2":{"688":1}}],["基准测试结果如表",{"2":{"927":1}}],["基准测试",{"2":{"770":1}}],["基准测试的相机掩码",{"2":{"761":1}}],["基准测试实验仅使用交叉熵损失以节省训练阶段的",{"2":{"670":1}}],["基准测试上帮助较小",{"2":{"670":1}}],["基准测试上有显著提升",{"2":{"670":1}}],["基准测试中",{"2":{"425":1}}],["基准测试中建立了新的最高水平性能",{"2":{"421":1}}],["基准的大量实验验证了我们的方法简洁而高效",{"2":{"349":1}}],["基比",{"2":{"379":1}}],["基点",{"2":{"276":1}}],["基础网络",{"0":{"609":1}}],["基础规模驾驶模型",{"2":{"507":1}}],["基础",{"0":{"171":1}}],["基础模型用于3d映射",{"2":{"121":1}}],["基础llm现可通过低秩更新高效适配",{"2":{"82":1}}],["基于占用的自动驾驶应用",{"0":{"1003":1}}],["基于强监督学习的占用网络表现出色",{"2":{"1000":1}}],["基于强大的基线bevformer",{"2":{"839":1}}],["基于一个非常大的数据集nuplan",{"2":{"997":1}}],["基于nuscenes的约40k帧和基于waymo的约200k帧",{"2":{"997":1}}],["基于nuscenes数据集开发",{"2":{"997":1}}],["基于nuscenes和waymo等先前数据集开发",{"2":{"997":1}}],["基于nuscenes和waymo",{"2":{"757":1}}],["基于kitti",{"2":{"997":1}}],["基于semantickitti和kitti数据集以及nyuv2",{"2":{"997":1}}],["基于建议的方法和无建议的方法",{"2":{"983":1}}],["基于rnn的方法和基于图的方法",{"2":{"974":1}}],["基于resnetblock",{"2":{"345":1}}],["基于proposal的方法",{"0":{"987":1}}],["基于pointnet",{"2":{"974":1}}],["基于pixel的方法往往限于算力只生成64x64大小的图像",{"2":{"205":1}}],["基于对象的图不能为导航和避障提供足够的分辨率",{"2":{"967":1}}],["基于对象的方法计算对象图",{"2":{"967":1}}],["基于体积的网络可以在不同空间大小的点云上自由地进行训练和测试",{"2":{"962":1}}],["基于体素网格算法实现图形粗化",{"2":{"574":1}}],["基于体素的表示带来的计算复杂性和部署挑战促使我们寻求更高效的替代方案",{"2":{"566":1}}],["基于体素的方法的示意图如图9所示",{"2":{"875":1}}],["基于体素的方法利用离散化的体素来表示",{"2":{"808":1}}],["基于体素的方法使用密集的",{"2":{"567":1}}],["基于体素的方法",{"0":{"875":1},"2":{"547":1}}],["基于线性投影的头部",{"2":{"957":1}}],["基于掩码解码器的头部",{"2":{"957":1}}],["基于交叉注意力的转换旨在以可学习的方式在特征体积和特征图之间进行交互",{"2":{"950":1}}],["基于交通规则",{"2":{"334":1}}],["基于投影的网络",{"0":{"955":1}}],["基于投影的2d到3d转换的问题是",{"2":{"950":1}}],["基于投影的方法",{"2":{"948":1}}],["基于投影和离散化的方法的第一步是将点云转换为中间正则表示",{"2":{"948":1}}],["基于点的网络是最常用的研究方法",{"2":{"996":1}}],["基于点的网络直接在不规则点云上工作",{"2":{"974":1}}],["基于点的方法",{"0":{"974":1}}],["基于点的方法直接作用于不规则点云",{"2":{"948":1}}],["基于点的方法和混合方法",{"2":{"948":1}}],["基于点云序列的世界模型",{"2":{"1003":1}}],["基于点云是从局部欧几里得表面采样的假设",{"2":{"955":1}}],["基于点云的方法",{"0":{"891":1}}],["基于点云的k个最近邻构造一个图",{"2":{"607":1}}],["基于点云的建图技术随着传感器",{"2":{"588":1}}],["基于离散化的方法",{"0":{"962":1},"2":{"948":1}}],["基于3d边界框预测每个动态体素的场景流",{"2":{"941":1}}],["基于3d高斯表示",{"2":{"547":1,"861":1}}],["基于3d高斯的场景表示",{"0":{"532":1}}],["基于查询的方法具有更大的灵活性",{"2":{"875":1}}],["基于查询的方法",{"2":{"875":1}}],["基于卷积的头部",{"2":{"957":1}}],["基于卷积的方法",{"2":{"875":1}}],["基于卷积的网络",{"0":{"450":1},"1":{"481":1,"511":1}}],["基于学习到的3d表示",{"2":{"875":1}}],["基于三视角",{"2":{"858":1,"875":1}}],["基于tpv的方法的示意图如图7所示",{"2":{"858":1}}],["基于tpv的方法",{"0":{"858":1}}],["基于先验知识",{"2":{"841":1}}],["基于fb",{"2":{"839":1}}],["基于此分析",{"2":{"836":1}}],["基于知识蒸馏的视觉",{"0":{"823":1}}],["基于视锥的方法",{"0":{"818":1}}],["基于视觉的bev感知系统",{"2":{"957":1}}],["基于视觉的三维占用感知的关键组件",{"2":{"942":1}}],["基于视觉的占用感知架构",{"2":{"942":1}}],["基于视觉的以及经过蒸馏的占用预测示例",{"2":{"843":1}}],["基于视觉的3d语义占用预测旨在通过多视图相机图像作为输入",{"2":{"693":1}}],["基于视觉的3d占用预测在实现准确预测方面面临重大挑战",{"2":{"941":1}}],["基于视觉的3d占用预测任务涉及从2d图像空间预测3d体素空间的占用状态和语义信息",{"2":{"819":1}}],["基于视觉的3d占用预测的研究工作逐渐形成了三条主线",{"2":{"799":1}}],["基于视觉的3d占用预测的目标是从图像输入中实现对3d场景的详细感知和理解",{"2":{"799":1}}],["基于视觉的3d占用预测的定义",{"0":{"712":1}}],["基于视觉的3d占用预测方法的时间线概述如图3所示",{"2":{"665":1}}],["基于视觉的3d占用预测从图像输入中预测自动驾驶车辆周围3d体素网格的空间占用状态和语义类别",{"2":{"665":1}}],["基于视觉的3d占用预测是一种新兴的感知任务",{"2":{"637":1}}],["基于视觉和激光雷达的流程首先被探索",{"2":{"808":1}}],["基于该数据集",{"2":{"793":1}}],["基于区域的全卷积神经网络",{"2":{"763":1}}],["基于区域建议的方法是这两类方法中最常被研究的方法",{"2":{"931":1}}],["基于区域建议的方法",{"0":{"756":1},"1":{"777":1,"798":1,"818":1,"838":1}}],["基于分割的方法",{"0":{"798":1}}],["基于分割的方法和基于视锥的方法",{"2":{"756":1}}],["基于分布的初始化",{"0":{"704":1},"2":{"681":1}}],["基于大规模公开可用的",{"2":{"739":2}}],["基于场景的3d语义高斯表示",{"2":{"716":1}}],["基于平面的表示方法",{"2":{"693":1}}],["基于bev表示的以视觉为中心的3d物体检测在复杂的开放场景中仍然面临固有的局限性",{"2":{"665":1}}],["基于bev的方法在改进3d占用预测方面也具有巨大潜力",{"2":{"875":1}}],["基于bev的方法和基于点云的方法",{"2":{"857":1}}],["基于bev的方法的示意图如图5所示",{"2":{"839":1}}],["基于bev的方法",{"0":{"839":1,"874":1}}],["基于bev的方法使用一个向量表示bev网格上整个柱的特征",{"2":{"566":1}}],["基于bev的检测特别容易受到干扰",{"2":{"665":1}}],["基于bev的3d场景感知",{"2":{"566":1}}],["基于不同传感器数据模态的研究形成了三个分支",{"2":{"665":1}}],["基于关联度评分",{"2":{"664":1}}],["基于八叉树",{"2":{"636":1}}],["基于数据索引的网络",{"0":{"636":1}}],["基于预训练的",{"2":{"632":1}}],["基于实时单目视觉输入的在线三维场景感知更符合具身智能体的要求",{"2":{"629":1}}],["基于多视图的方法",{"0":{"777":1},"2":{"756":1}}],["基于多视角图像或额外三维信息的方法在许多场景中都取得了显著进展",{"2":{"629":1}}],["基于多传感器融合的方法将环视摄像头",{"2":{"438":1}}],["基于相机",{"0":{"625":1,"653":1,"678":1}}],["基于相机的方法越来越受到关注",{"2":{"599":1}}],["基于相机的环境感知",{"0":{"564":1}}],["基于相机的可见性",{"2":{"390":1}}],["基于开源的internimage",{"2":{"617":1}}],["基于提升",{"2":{"612":1}}],["基于网格的方法很难适应不同场景的兴趣区域",{"2":{"693":1}}],["基于网格的场景表示",{"2":{"599":1}}],["基于网格投影到相机框架中的重投影误差来优化相机姿态",{"2":{"419":1}}],["基于上述方法",{"2":{"566":1}}],["基于上述观察",{"2":{"444":1}}],["基于环视相机的环境感知算法受到了广泛关注",{"2":{"564":1}}],["基于鸟瞰图",{"2":{"547":1,"564":1}}],["基于图像主干网络",{"2":{"898":1}}],["基于图像的3d重建的目标是根据从一个或多个视角捕获的2d图像构建物体或场景的3d模型",{"2":{"860":1}}],["基于图像的3d重建",{"0":{"860":1}}],["基于图像的3d感知因其比依赖激光雷达的解决方案更低的成本及其有前景的性能",{"2":{"535":1}}],["基于图像的方法",{"2":{"665":1}}],["基于图的谱域",{"0":{"607":1}}],["基于图的空间域",{"0":{"574":1}}],["基于图的网络因其固有的处理不规则数据的能力",{"2":{"688":1}}],["基于图的网络将点云中的每个点视为图的顶点",{"2":{"542":1}}],["基于图的网络",{"0":{"542":1},"1":{"574":1,"607":1}}],["基于行车记录仪",{"2":{"507":1}}],["基于摄像头的bev感知在下游任务中的表现现已与基于激光雷达的方法相当",{"2":{"821":1}}],["基于摄像头的三维空间占用预测在室外驾驶场景中最近受到了越来越多的关注",{"2":{"544":1}}],["基于摄像头的三维占据预测因其成本效益高而受到广泛关注",{"2":{"482":1}}],["基于摄像头",{"0":{"497":1,"527":1}}],["基于隐式分类器的文生图大模型",{"0":{"483":1},"1":{"513":1}}],["基于融合的教师模型与仅视觉占据网络在不同标注数据规模下从头训练和通过蒸馏训练的性能对比统计图",{"2":{"455":1}}],["基于激光雷达的方法能够实现高度精确的",{"2":{"596":1}}],["基于激光雷达的环境感知",{"0":{"596":1}}],["基于激光雷达的流程可能在捕捉小物体的准确语义信息方面存在困难",{"2":{"444":1}}],["基于激光雷达的三维检测器",{"2":{"421":1}}],["基于这些工作",{"2":{"1005":1}}],["基于这些观察结果",{"2":{"421":1}}],["基于这两个挑战",{"2":{"631":1}}],["基于这种情况",{"2":{"629":1}}],["基于这一观察",{"2":{"622":1}}],["基于这样的想法",{"2":{"411":1}}],["基于clip模型的多模态图像引导生成",{"0":{"393":1},"1":{"422":1,"452":1}}],["基于循环闭合和里程计测量值",{"2":{"390":1}}],["基于优化结果更新了",{"2":{"390":1}}],["基于显式分类器的图像引导生成",{"0":{"338":1},"1":{"365":1}}],["基于语言的车",{"2":{"334":1}}],["基于语义高斯分布的局部性",{"2":{"738":1}}],["基于语义的全局网格",{"2":{"285":1}}],["基于语义推理的最有前景点",{"2":{"274":1}}],["基于以上的思考",{"2":{"313":1}}],["基于以上几个问题",{"2":{"265":1}}],["基于lyft",{"2":{"997":1}}],["基于lidar的方法",{"2":{"665":1}}],["基于llava在carla模拟器中微调以遵循语言指令驾驶",{"2":{"308":1}}],["基于latent的扩散模型的优势在于计算效率更高效",{"2":{"205":1}}],["基于稀疏全卷积网络的点云特征描述子提取",{"2":{"243":1}}],["基于迭代去噪过程的图像编辑",{"0":{"242":1},"1":{"264":1,"287":1,"312":1}}],["基于迭代去噪过程的图像编辑ivlr",{"2":{"201":1}}],["基于地标的场景图",{"2":{"648":1}}],["基于地标",{"2":{"190":1}}],["基于力控制的经典方法",{"2":{"123":1}}],["基于",{"2":{"117":1,"123":1,"467":1,"564":1,"765":1,"808":2,"828":1}}],["基于样本",{"2":{"8":1}}],["等开创性工作引发",{"2":{"967":1}}],["等开放世界场景",{"2":{"90":1}}],["等方法",{"2":{"839":1}}],["等多源值图与语义值图融合",{"2":{"765":1}}],["等对自动驾驶任务至关重要的类别时表现出色",{"2":{"700":1}}],["等等接口",{"2":{"685":1}}],["等系统率先将语义融合引入稠密",{"2":{"588":1}}],["等新兴任务提供了便利",{"2":{"547":1}}],["等检索增强规划器提示一条路径",{"2":{"507":1}}],["等编码器提取特征后",{"2":{"495":1}}],["等token缩减设计",{"2":{"478":1}}],["等token缩减设计将在线计算成本降低一个数量级",{"2":{"82":1}}],["等低级感知任务",{"2":{"408":1}}],["等同于姿态图优化",{"2":{"390":1}}],["等模型提供解释真值",{"2":{"360":1}}],["等距的体素集合",{"2":{"276":1}}],["等变卷积运算",{"2":{"275":1}}],["等预训练模型日益成为构建开放词汇地图的基础",{"2":{"274":1}}],["等目标检测器",{"2":{"274":1}}],["等优化响应",{"2":{"260":1}}],["等有意义的概念",{"2":{"209":1}}],["等特征检测算法",{"2":{"189":1}}],["等算法将连续帧的观测对齐成一致的",{"2":{"189":1}}],["等价于n个类别的cross",{"2":{"184":1}}],["等的",{"2":{"177":1}}],["等问题",{"2":{"176":1}}],["等基于逻辑的安全否决是第一步",{"2":{"478":1}}],["等基准测试的发布",{"2":{"139":1}}],["等基础模型进展",{"2":{"82":1}}],["等仿真环境",{"2":{"139":1}}],["等",{"2":{"139":4,"507":1,"603":1,"690":1,"806":1}}],["等待结果",{"2":{"136":1}}],["等上下文学习方法利用记忆库存储关键驾驶信息",{"2":{"128":1}}],["等人的方法",{"2":{"609":1}}],["等人在pointnet中提出的常用做法",{"2":{"407":1}}],["等人提出了一种基于八叉树的cnn用于三维形状分类方法",{"2":{"363":1}}],["等人",{"2":{"121":1,"481":1,"955":4,"962":1}}],["等下可以继续输入",{"2":{"87":1}}],["等交互数据集使研究人员能在真实部署前对语言条件行为进行压力测试",{"2":{"82":1}}],["等合成语料和nuinteract",{"2":{"82":1}}],["等pb级多传感器日志提供丰富多模态监督",{"2":{"82":1}}],["若新检测物体与已有节点相似",{"2":{"765":1}}],["若多像素落入同一单元格",{"2":{"765":1}}],["若多个点落在同一网格单元",{"2":{"435":1}}],["若",{"2":{"563":1}}],["若距离小于阈值",{"2":{"525":1}}],["若相似",{"2":{"525":1}}],["若定位失败",{"2":{"525":1}}],["若定位成功",{"2":{"525":1}}],["若同一环境由多条轨迹生成多个子图",{"2":{"525":1}}],["若两节点间可导航",{"2":{"525":1}}],["若能结合这三种传感器的信息",{"2":{"503":1}}],["若单元已占用",{"2":{"495":1}}],["若容器为空",{"2":{"479":1}}],["若环境变化",{"2":{"435":1}}],["若某个像素真实深度接近",{"2":{"411":1}}],["若某物体在",{"2":{"378":1}}],["若编码器基于大规模互联网图文数据训练",{"2":{"406":1}}],["若编码器仅针对有限类别图像训练",{"2":{"406":1}}],["若我们已知两个位姿的相机参数",{"2":{"355":1}}],["若干方法尝试缓解这些问题",{"2":{"114":1}}],["若干汇聚趋势凸显了该新兴研究前沿的及时性",{"2":{"82":1}}],["若不是",{"2":{"78":1}}],["预定义了一组深度bin",{"2":{"621":1}}],["预定义的深度分布坐标",{"2":{"621":1}}],["预探索",{"2":{"525":1}}],["预训练的",{"2":{"743":1,"765":1}}],["预训练语义分割模型",{"2":{"437":1}}],["预训练大型视觉编码器",{"2":{"417":1}}],["预训练好的模型往往已经在大规模数据集上进行了训练",{"2":{"373":1}}],["预训练是否可以被拉长训练回合替代",{"2":{"366":1}}],["预训练是在shapnet上进行的",{"2":{"313":1}}],["预训练",{"2":{"334":1,"822":1}}],["预训练后的阶段",{"2":{"315":1}}],["预训练后的模型就可以直接进行zero",{"2":{"151":1}}],["预训练几乎没有给下游任务带来任何收益",{"2":{"313":1}}],["预示着我们称之为",{"2":{"82":1}}],["预测深度与真实深度之间的l1误差低于给定阈值",{"2":{"998":1}}],["预测bev或tpv特征的符号距离场值以渲染2d深度图",{"2":{"949":1}}],["预测结果的失真程度也随之增加",{"2":{"945":1}}],["预测的伪点云和真实点云",{"2":{"934":1}}],["预测3d占用需要详细的几何表示",{"2":{"922":1}}],["预测3d占据对开发安全",{"2":{"520":1}}],["预测与分割",{"2":{"877":1}}],["预测数据",{"2":{"850":1}}],["预测每个体素网格的密集占用状态和语义",{"2":{"693":1}}],["预测每个体素的分割标签",{"2":{"598":1}}],["预测一组和object",{"2":{"594":1}}],["预测稠密",{"2":{"588":1}}],["预测头将令牌",{"2":{"549":1}}],["预测头用于在坐标空间中预测后续的点块",{"2":{"549":1}}],["预测头生成实例预测",{"2":{"377":1}}],["预测vsurfv",{"2":{"372":1}}],["预测并执行长时域推理后再输出动作",{"2":{"334":1}}],["预测匹配的那张图像是谁",{"2":{"184":1}}],["预测匹配的那个文本是谁",{"2":{"184":1}}],["预测和规划模块",{"2":{"114":1}}],["预测",{"2":{"82":1,"103":1,"114":2,"423":2,"850":1,"905":1}}],["预测目标掩码",{"2":{"54":1}}],["给3d占用感知的发展带来了困难",{"2":{"997":1}}],["给机器人受限硬件的内存与存储带来严峻挑战",{"2":{"864":1}}],["给定要遍历的房间节点",{"2":{"930":1}}],["给定要遍历的建筑物节点",{"2":{"930":1}}],["给定输入点云",{"2":{"858":1}}],["给定输入文本t",{"2":{"184":1}}],["给定来自多视角相机的图像",{"2":{"712":1}}],["给定一组多视图图像",{"2":{"693":1}}],["给定一个",{"2":{"588":1}}],["给定一个点云",{"2":{"579":1,"910":1,"948":1}}],["给定一个包含m个点的点云x",{"2":{"396":1}}],["给定一个输入图像i",{"2":{"184":1}}],["给定一个大小为",{"2":{"5":1}}],["给定柱坐标系下的真实3d点云",{"2":{"676":1}}],["给定细化后的bev特征fr",{"2":{"666":1}}],["给定的参考点不一定在所有的摄像机图像中都可见",{"2":{"623":1}}],["给定环视图像后",{"2":{"768":1}}],["给定环视图像",{"2":{"621":1,"746":1}}],["给定融合后的特征",{"2":{"609":1}}],["给定预测的点patch",{"2":{"582":1}}],["给定有限标签和足够数据",{"2":{"548":1}}],["给定多视角相机图像",{"2":{"532":1}}],["给定轨迹",{"2":{"437":1}}],["给定像素级的2d分割图像",{"2":{"419":1}}],["给定rgb",{"2":{"206":1}}],["给定",{"2":{"153":1}}],["给出的最高文本",{"2":{"274":1}}],["给出了",{"2":{"254":1}}],["给出目标图像",{"2":{"139":1}}],["给出相对于起点的目标坐标",{"2":{"139":1}}],["给我拿一杯咖啡",{"2":{"116":1}}],["给救护车让行",{"2":{"82":1}}],["遵循表5中的设置",{"2":{"811":1}}],["遵循solofusion",{"2":{"764":1}}],["遵循先前的方法",{"2":{"736":1}}],["遵循",{"2":{"492":1,"512":1,"677":2,"848":1}}],["遵循本文中描述的方法",{"2":{"437":1}}],["遵循自由形式指令",{"2":{"82":1}}],["遵循cc",{"2":{"41":1,"48":1,"220":1,"351":1}}],["行和第",{"2":{"992":1}}],["行止ac的博客",{"2":{"946":1}}],["行中",{"2":{"992":1}}],["行中尤为突出",{"2":{"903":1}}],["行中建筑物的孔洞",{"2":{"903":1}}],["行",{"2":{"903":3,"989":2,"992":3}}],["行的家具",{"2":{"992":1}}],["行的床",{"2":{"992":1}}],["行的跑步机",{"2":{"992":1}}],["行的书架",{"2":{"992":1}}],["行的树干",{"2":{"989":1}}],["行的交通标志",{"2":{"989":2}}],["行的行人",{"2":{"989":2}}],["行的汽车",{"2":{"989":1}}],["行的汽车形状中尤为明显",{"2":{"903":1}}],["行的天花板",{"2":{"903":1}}],["行的窗户",{"2":{"903":1,"992":1}}],["行为决策和运动控制",{"2":{"665":1}}],["行人检测",{"2":{"1003":1}}],["行人和交通锥的性能提升了15",{"2":{"800":1}}],["行人",{"2":{"277":10,"534":7,"630":1,"700":1,"893":2,"975":1,"1000":1}}],["行动",{"2":{"116":1}}],["行动缺口",{"2":{"82":1}}],["行内脚注文本",{"2":{"57":1}}],["行内的脚注",{"2":{"57":1}}],["简化了姿态估计",{"2":{"967":1}}],["简化了融合过程并减少了计算成本",{"2":{"957":1}}],["简化了模型训练过程并实现了更好的性能",{"2":{"779":1}}],["简化为一个简单的步骤",{"2":{"574":1}}],["简单而有效的模型",{"2":{"306":1}}],["简单启发式方法包括",{"2":{"274":1}}],["简单来说",{"2":{"220":2}}],["简单的说就是将硬盘当内存用",{"2":{"18":1}}],["简介",{"2":{"129":1}}],["简言之",{"2":{"82":1,"216":1,"334":1,"360":1,"478":1,"507":1}}],["模仿激光雷达的射线投射",{"2":{"998":1}}],["模仿学习与强化学习",{"2":{"388":1}}],["模糊或上下文相关的语义",{"2":{"864":1}}],["模糊",{"2":{"447":1}}],["模糊包",{"2":{"351":1}}],["模态比较",{"2":{"1000":1}}],["模态比较和监督比较",{"2":{"999":1,"1000":1}}],["模态是",{"2":{"931":1}}],["模态对齐困难",{"2":{"864":1}}],["模态和帧的信号",{"2":{"780":1}}],["模态和时间序列",{"2":{"667":1}}],["模态融合视角",{"0":{"577":1},"1":{"610":1,"639":1,"667":1,"691":1,"714":1,"737":1,"759":1,"780":1,"801":1,"821":1,"841":1,"860":1,"877":1,"894":1,"910":1,"923":1,"933":1,"942":1,"950":1,"957":1,"964":1,"970":1,"976":1,"981":1,"985":1,"988":1,"991":1,"994":1,"997":1,"998":1,"999":1,"1000":1,"1001":1,"1002":1,"1003":1,"1004":1,"1005":1,"1006":1,"1007":1,"1008":1},"2":{"573":1}}],["模态",{"2":{"360":1,"630":1,"667":1,"840":1,"877":1,"997":1,"1000":1}}],["模拟的uhumans2",{"2":{"947":1}}],["模拟器中的人类都有在已知范围内随机化的beta参数",{"2":{"775":1}}],["模拟一个位置相对于所有其他位置",{"2":{"636":1}}],["模拟局部区域内各点之间的相互依赖关系",{"2":{"636":1}}],["模拟人类在陌生环境中",{"2":{"525":1}}],["模拟网格顶点属于一个对象",{"2":{"210":1}}],["模拟地点或房间之间的可达性",{"2":{"210":1}}],["模拟对象",{"2":{"125":1}}],["模块来整合不同模态的特征",{"2":{"977":1}}],["模块的消融研究结果",{"2":{"971":1}}],["模块的详细处理过程",{"2":{"829":2}}],["模块的详细信息如图",{"2":{"829":1}}],["模块的具体内容则展示在图",{"2":{"829":1}}],["模块在时间配置下运行时表现出明显更长的推理时间",{"2":{"811":1}}],["模块中",{"2":{"746":2}}],["模块以",{"2":{"698":1}}],["模块以及图像深度估计的需求",{"2":{"421":1}}],["模块提取每个点的旋转不变特征",{"2":{"574":1}}],["模块解码特征以预测语义占据",{"2":{"474":1}}],["模块或",{"2":{"425":1}}],["模块",{"2":{"131":1,"544":2,"591":1,"829":1,"945":1,"976":1}}],["模块化的任务范式",{"2":{"975":1}}],["模块化vla4ad",{"2":{"238":1,"538":1}}],["模块化流水线透明度高",{"2":{"299":1}}],["模块化流水线的优势在于",{"2":{"274":1}}],["模块化流水线",{"0":{"274":1},"2":{"231":1}}],["模块化设计在感知",{"2":{"114":1}}],["模块化栈",{"2":{"92":1}}],["模块间目标不一致阻碍端到端优化",{"2":{"103":1}}],["模块实现这一目标",{"2":{"82":1}}],["模型的",{"2":{"971":1}}],["模型的预测结果进一步得到显著改善",{"2":{"952":1}}],["模型仍未能正确分类附近的人行道",{"2":{"952":1}}],["模型在预测静态物体",{"2":{"952":1}}],["模型在处理小物体时表现不佳",{"2":{"945":1}}],["模型通过分析来自不同相机视锥的光线交点来学习多视角一致性",{"2":{"941":1}}],["模型通过变化语言指令想象给定场景多样结果",{"2":{"308":1}}],["模型由于丢失更多的细粒度几何信息而出现性能下降",{"2":{"882":1}}],["模型组件的消融研究",{"0":{"882":1}}],["模型效率研究",{"0":{"865":1}}],["模型效率评估及高斯数量的影响",{"2":{"700":1}}],["模型压缩",{"2":{"864":1}}],["模型放大以及有效的后处理策略",{"2":{"839":1}}],["模型进行了蒸馏",{"2":{"823":1}}],["模型性能分析",{"0":{"827":1,"927":1}}],["模型性能进一步提升",{"2":{"803":1}}],["模型性能提升至",{"2":{"803":1}}],["模型可以通过深度分布实现这种不确定性",{"2":{"950":1}}],["模型可以忽略这些不可见的区域",{"2":{"800":1}}],["模型可以计算输入图像与一段自然语言描述之间的相似度分数",{"2":{"765":1}}],["模型使用焦点损失",{"2":{"766":1}}],["模型仅使用单尺度特征图和单阶段粗预测",{"2":{"670":1}}],["模型会学习分配更多高斯来描述同一区域",{"2":{"656":1}}],["模型会对所有像素全局重新预测",{"2":{"117":1}}],["模型复杂度高",{"2":{"601":1}}],["模型设计",{"0":{"585":1}}],["模型规模化以及有效的后处理策略",{"2":{"490":1}}],["模型需在传感器损坏",{"2":{"478":1}}],["模型需要更多的步骤来更正语义的不一致性",{"2":{"312":1}}],["模型参数大小是123m",{"2":{"373":1}}],["模型来过滤噪声并提取全局网格",{"2":{"362":1}}],["模型先言语化决策路径再行动",{"2":{"334":1}}],["模型输入包括",{"2":{"329":1}}],["模型学习共享表示服务两任务",{"2":{"308":1}}],["模型fθ",{"2":{"304":1}}],["模型容易根据错误的梯度二脱轨",{"2":{"267":1}}],["模型扩散过程中",{"2":{"235":1}}],["模型",{"0":{"397":1},"1":{"427":1,"457":1,"489":1},"2":{"225":1,"334":2,"695":1,"712":1,"900":1}}],["模型都会有一个mask预测的结果",{"2":{"106":1}}],["模型对于特定的图片和特定的点击都会进行case",{"2":{"84":1}}],["模型泛化问题",{"2":{"54":1}}],["引发了基于视觉的3d占用预测的研究热潮",{"2":{"665":1}}],["引用",{"2":{"126":1}}],["引用内容",{"2":{"57":2}}],["引入一个多类别版本",{"2":{"794":1}}],["引入一个vq",{"2":{"345":1}}],["引入点统计和表面属性预测目标来指导模型学习点云的几何特征",{"2":{"715":1}}],["引入图片特征加入",{"2":{"615":1}}],["引入可学习卷积",{"2":{"588":1}}],["引入跨模态融合模块将这两个3d特征体进行整合",{"2":{"527":1}}],["引入的深度编码器模块对伪3d点云进行细化",{"2":{"527":1}}],["引入的捆绑射线投射",{"2":{"362":1}}],["引入了几何和语义感知融合",{"2":{"976":1}}],["引入了基于内核的插值变分自动编码器架构来编码每个体素内的局部几何结构",{"2":{"962":1}}],["引入了基于隐式体绘制的正则化来监督融合特征",{"2":{"421":1}}],["引入了",{"2":{"955":1}}],["引入了切线卷积来进行密集点云分割",{"2":{"955":1}}],["引入了一种稀疏体素解码器来重建场景的稀疏几何结构",{"2":{"922":1}}],["引入了一种新的3d重建范式",{"2":{"860":1}}],["引入了一个深度自动编码器网络来学习点云表示",{"2":{"420":1}}],["引入了多粒度的体素查询以提高效率",{"2":{"612":1}}],["引入了新的",{"2":{"603":1}}],["引入了通道到高度变换",{"2":{"505":1}}],["引入",{"2":{"405":1,"414":1}}],["引入延迟与模块边界级联失败风险",{"2":{"283":1}}],["引入检索增强规划机制",{"2":{"283":1}}],["引入以形式逻辑表达的符号交通规则",{"2":{"283":1}}],["引入动态更新的图模型",{"2":{"258":1}}],["引入3d先验",{"2":{"195":1}}],["引入并行流水线架构",{"2":{"114":1}}],["引入基于距离的重要性加权先验",{"2":{"114":1}}],["引入自然语言推理与可解释性",{"2":{"92":1}}],["引言",{"0":{"82":1,"90":1,"109":1,"116":1,"125":1,"438":1,"455":1,"503":1,"520":1,"535":1,"547":1,"567":1,"570":1,"600":1,"639":1,"665":1},"1":{"131":1,"141":1,"667":1,"691":1,"714":1}}],["推断出场景的完整和密集占用",{"2":{"910":1}}],["推断出它们的",{"2":{"870":1}}],["推断的",{"2":{"870":1}}],["推动该领域需强化地图层面的评估",{"2":{"943":1}}],["推动了近年来自动驾驶占用感知研究的激增",{"2":{"759":1}}],["推动语义地图技术在具身智能系统中的发展",{"2":{"80":1}}],["推导",{"2":{"316":1}}],["推导出最小充分场景表示的表达式",{"2":{"121":1}}],["推理速度",{"0":{"1001":1}}],["推理速度由单块",{"2":{"761":1}}],["推理版本",{"2":{"978":1}}],["推理版本上进行了评估",{"2":{"870":1}}],["推理对象的功能",{"2":{"967":1}}],["推理基线在",{"2":{"903":1}}],["推理基线",{"2":{"870":1}}],["推理内存消耗大幅节省了68",{"2":{"811":1}}],["推理内存消耗和训练时长的详细信息",{"2":{"811":1}}],["推理时长",{"2":{"811":1}}],["推理时",{"2":{"765":2}}],["推理和训练过程类似",{"2":{"493":1}}],["推理链一致性",{"2":{"447":1}}],["推理期间将它们输入到二分匹配或排名中",{"2":{"377":1}}],["推理过程",{"0":{"354":1}}],["推理",{"0":{"493":1},"2":{"334":1,"783":1,"870":1}}],["推理与控制",{"2":{"145":1}}],["推理与动作整合于一体",{"2":{"92":1}}],["推理的以推理为核心的智能体等广泛的vla架构",{"2":{"82":1}}],["推理复杂交通场景并自主决策",{"2":{"72":1}}],["高于semantickitti和sscbench",{"2":{"1000":1}}],["高流量环境中构建",{"2":{"926":1}}],["高分辨率会导致较高的内存和计算成本",{"2":{"962":1}}],["高分辨率",{"2":{"864":1}}],["高分辨率的style控制肤色",{"2":{"181":1}}],["高维神经特征",{"2":{"864":1}}],["高置信度或低方差对应更鲁棒的地图",{"2":{"826":1}}],["高出",{"2":{"782":1,"803":1}}],["高度混乱的场景时表现不佳",{"2":{"989":1}}],["高度依赖于上下文",{"2":{"684":1}}],["高度通道从特征通道分离以生成最终",{"2":{"670":1}}],["高度",{"2":{"655":1}}],["高度方向",{"2":{"378":1}}],["高保真的",{"2":{"619":1}}],["高保真且与传感器数据直接对应",{"2":{"588":1}}],["高精地图与文本道路规则训练",{"2":{"507":1}}],["高精地图与时序状态仅部分融合",{"2":{"478":1}}],["高效的工具",{"2":{"935":1}}],["高效的子像素范式",{"2":{"566":1}}],["高效融合网络",{"0":{"670":1}}],["高效提取和聚合高斯信息以更新查询",{"2":{"563":1}}],["高效llm",{"2":{"478":1}}],["高效训练基于融合和视觉的",{"2":{"455":1}}],["高斯之间的个体重叠比率",{"2":{"916":1}}],["高斯仍可能被发现在未占用空间中",{"2":{"916":1}}],["高斯根据它们所描述的具体物体具有自适应的尺度",{"2":{"901":1}}],["高斯参数和深度感知分支的分析",{"2":{"833":1}}],["高斯成功地学习了向占用区域移动",{"2":{"832":1}}],["高斯具有更适应性的形状",{"2":{"832":1}}],["高斯过程或学习式模型显式表示并传播地图内部的不确定性",{"2":{"826":1}}],["高斯处于正确位置的百分比",{"2":{"812":1}}],["高斯数量",{"2":{"812":1}}],["高斯绘制",{"2":{"808":1}}],["高斯绘制流程以渲染激光雷达和摄像头数据",{"2":{"474":1}}],["高斯场景表示在多机器人协调中的应用",{"2":{"767":1}}],["高斯场景表示和",{"2":{"767":1}}],["高斯提供来自激光雷达数据的准确位置和几何先验",{"2":{"899":1}}],["高斯提供来自激光雷达数据的准确几何先验",{"2":{"767":1}}],["高斯提供来自激光雷达数据的几何先验",{"2":{"444":1}}],["高斯和占据",{"2":{"745":1}}],["高斯到体素的溅射实现并非易事",{"2":{"738":1}}],["高斯到体素的溅射",{"0":{"738":1}}],["高斯到体素的泼溅模块仅聚合目标体素邻域内的高斯",{"2":{"532":1}}],["高斯属性",{"2":{"716":1}}],["高斯属性和查询",{"2":{"716":1}}],["高斯的总体重叠比率",{"2":{"916":1}}],["高斯的利用率",{"2":{"812":1}}],["高斯的局部感受野限制了它们的移动性",{"2":{"704":1}}],["高斯的数量在我们的主要实验中设置为",{"2":{"677":1}}],["高斯的数量有所减少",{"2":{"656":1}}],["高斯查询",{"2":{"595":1,"716":1}}],["高斯查询更新",{"2":{"595":1}}],["高斯泼溅",{"2":{"588":1}}],["高斯分布",{"2":{"916":1}}],["高斯分布的",{"2":{"916":2}}],["高斯分布的密度函数可以写成",{"2":{"140":1,"280":1}}],["高斯分配为仅对非空区域进行建模",{"2":{"567":1}}],["高斯占据模型通过交叉熵损失",{"2":{"532":1}}],["高斯",{"2":{"532":1,"588":1,"767":1,"808":1}}],["高斯位置和不透明度的非空体素特征",{"2":{"502":1}}],["高斯表示通过高斯到体素绘制模块",{"2":{"502":1}}],["高斯表示",{"2":{"474":1}}],["高斯作为驾驶世界表示",{"2":{"474":1}}],["高斯还因其在实时图像渲染和新视图合成方面的优势而被采用",{"2":{"474":1}}],["高斯已被采用作为传统基于网格解决方案在",{"2":{"474":1}}],["高斯在明确且连续地建模场景方面的固有优势",{"2":{"474":1}}],["高斯在自动驾驶中的应用",{"2":{"474":1}}],["高斯来建模场景",{"2":{"444":1}}],["高斯而不是密集网格来减少内存消耗",{"2":{"444":1}}],["高层问答",{"2":{"360":1}}],["高带宽切入",{"2":{"334":1}}],["高",{"2":{"254":1,"654":1}}],["高级理解",{"2":{"961":1}}],["高级感知过程执行环路闭合检测",{"2":{"408":1}}],["高级表示还使得快速规划成为可能",{"2":{"125":1}}],["高级表示是理解和执行人类指令",{"2":{"125":1}}],["高级场景理解是机器人和自动驾驶车辆安全长期运行以及与人机有效交互的先决条件",{"2":{"116":1}}],["高内存需求和计算效率低下仍是尚未解决的难题",{"2":{"80":1}}],["高版本可能会带来兼容性问题",{"2":{"40":1}}],["或雷达",{"2":{"997":1}}],["或ball查询",{"2":{"996":1}}],["或罕见物体",{"2":{"992":1}}],["或整个场景",{"2":{"989":1}}],["或从众包手机轨迹",{"2":{"967":1}}],["或联合跟踪相机和动态对象",{"2":{"967":1}}],["或具有3d姿态",{"2":{"967":1}}],["或slam和检测与跟踪移动对象",{"2":{"967":1}}],["或使用拓扑地图来模拟基于地标的关联",{"2":{"958":1}}],["或使用microsoft的azure",{"2":{"855":1}}],["或反向投影和垂直池化",{"2":{"950":1}}],["或交叉注意力",{"2":{"942":1}}],["或体积模型",{"2":{"967":1}}],["或体积特征",{"2":{"950":1}}],["或体积分特征",{"2":{"942":1}}],["或体素过滤",{"2":{"547":1}}],["或体素模块",{"2":{"195":1}}],["或mlp",{"2":{"910":1}}],["或直接计算体素内点的几何特征",{"2":{"910":1}}],["或直接采用",{"2":{"274":1}}],["或三个2d三视角平面",{"2":{"910":1}}],["或三维空间中的二维曲面",{"2":{"500":1}}],["或保留长期自主性中的信息提供了自然方式",{"2":{"905":1}}],["或语义分割",{"2":{"877":1}}],["或语义区域",{"2":{"384":1}}],["或掩码解码器",{"2":{"877":1}}],["或点特征",{"2":{"877":1}}],["或点云",{"2":{"556":1,"603":1}}],["或通过在此场景中重新训练mask",{"2":{"872":1}}],["或漏检遮挡",{"2":{"864":1}}],["或运动结构",{"2":{"860":1}}],["或局部",{"2":{"773":1}}],["或复杂的多尺度特征融合模块",{"2":{"703":1}}],["或混叠伪影",{"2":{"680":1}}],["或混合地图",{"2":{"80":1}}],["或更稠密的几何地图",{"2":{"648":1}}],["或颜色纹理非常奇怪",{"2":{"630":1}}],["或可变形注意力",{"2":{"609":1}}],["或隐式",{"2":{"603":1}}],["或特征柱",{"2":{"596":1}}],["或负样本",{"2":{"591":1}}],["或深度引导的体素过滤",{"2":{"612":1}}],["或深度相机",{"2":{"570":1}}],["或深度学习",{"2":{"190":1}}],["或创建新地标",{"2":{"525":1}}],["或其他兴趣区域",{"2":{"525":1}}],["或其他下游规划器执行",{"2":{"216":1}}],["或token缩减lm",{"2":{"507":1}}],["或cot计划",{"2":{"507":1}}],["或clip",{"2":{"195":1}}],["或求和",{"2":{"495":1}}],["或高精度和低召回率估计",{"2":{"437":1}}],["或rg",{"2":{"437":1}}],["或提出的场景图环路闭合",{"2":{"437":1}}],["或采用全局坐标系",{"2":{"435":1}}],["或平均值",{"2":{"435":1}}],["或基于图像的",{"2":{"421":1}}],["或在对象层的对象描述符之间",{"2":{"352":1}}],["或对特定物体执行动作",{"2":{"350":1}}],["或好奇心奖励",{"2":{"274":1}}],["或选择最可能包含目标的新区域",{"2":{"274":1}}],["或连续动作",{"2":{"252":1}}],["或一个房间属于一个建筑物",{"2":{"210":1}}],["或跨层",{"2":{"210":1}}],["或dpo",{"2":{"195":1}}],["或gpt式transformer",{"2":{"195":1}}],["或等价地",{"2":{"137":1}}],["或",{"2":{"109":1,"116":1,"195":1,"204":1,"209":1,"274":2,"276":1,"283":1,"285":1,"325":1,"435":1,"465":1,"467":1,"539":1,"632":1,"678":1,"694":1,"698":1,"739":1,"761":1,"780":4,"806":2,"808":1,"826":2,"905":1}}],["或显式环境数据",{"2":{"80":1}}],["或者画框和尺寸合适的电视",{"2":{"903":1}}],["或者仅仅是由于我们没有进行大量的超参数调整",{"2":{"878":1}}],["或者将其离散化为占用网格",{"2":{"870":1}}],["或者map",{"2":{"685":1}}],["或者使用基于查询的方法直接获取3d表示",{"2":{"875":1}}],["或者使用扩张卷积来获得较大的感受野",{"2":{"603":1}}],["或者使用轻量级网络",{"2":{"603":1}}],["或者使用多个模型",{"2":{"601":1}}],["或者使用激光雷达信息来监督深度估计",{"2":{"564":1}}],["或者使用作者预处理好的数据集",{"2":{"32":1}}],["或者如果可用",{"2":{"362":1}}],["或者如果体素的邻域与",{"2":{"276":1}}],["或者后向时注入信息的时间步的多少",{"2":{"264":1,"266":1}}],["或者森林应该被表示为单一的景观区域还是作为树枝",{"2":{"109":1}}],["或者append函数",{"2":{"52":1}}],["或者通过运行使用fastsam而不是sam",{"2":{"38":1}}],["或者",{"2":{"36":1,"197":1,"285":1,"351":1,"752":1,"929":1}}],["但值得注意的是",{"2":{"1000":1}}],["但与",{"2":{"967":1}}],["但通过处理过去的多视角图像预测未来的3d占用数据",{"2":{"963":1}}],["但通常是非层次的",{"2":{"967":1}}],["但通常其运行时间取决于姿态图的大小",{"2":{"816":2}}],["但通常为车载部署带来巨大的计算负载",{"2":{"517":1}}],["但专注于2d占用地图",{"2":{"961":1}}],["但节点和层次的集合较少",{"2":{"961":1}}],["但只包括对象作为节点",{"2":{"961":1}}],["但只有",{"2":{"903":1}}],["但场景图主要用于计算机视觉中抽象2d图像的内容",{"2":{"961":1}}],["但场景中由于物体遮挡导致的遮挡仍然导致显著误差",{"2":{"775":1}}],["但模型在预测悬挂在空中的人造建筑方面仍存在困难",{"2":{"952":1}}],["但模块边界脆弱",{"2":{"82":1}}],["但要达到令人满意的性能仍需进一步探索",{"2":{"949":1}}],["但dsg正确地将场景抽象为三个房间和一个走廊",{"2":{"947":1}}],["但表9中的轨迹与esdf的轨迹几乎一样短",{"2":{"947":1}}],["但会出现更大的失真现象",{"2":{"945":1}}],["但该框架在推断精细几何结构方面仍然存在挑战",{"2":{"945":1}}],["但并未显示出显著的改进",{"2":{"934":1}}],["但类似的查询在更高抽象层次上在毫秒级完成",{"2":{"930":1}}],["但还是可以通过其他方式修改的",{"2":{"918":1}}],["但可以选择性地忘记网格模型",{"2":{"905":1}}],["但可解释性差",{"2":{"299":1}}],["但kimera",{"2":{"872":2}}],["但稳健的多模态融合仍是核心难题",{"2":{"864":1}}],["但查询",{"2":{"864":1}}],["但冗余大",{"2":{"864":1}}],["但分辨率高时内存爆炸",{"2":{"864":1}}],["但分布漂移仍可能级联",{"2":{"417":1}}],["但gaussianformer在所有基于密集网格的表示方法中实现了最低的延迟",{"2":{"842":1}}],["但tpvformer",{"2":{"842":1}}],["但对天气条件变化敏感",{"2":{"970":1}}],["但对于计算机和机器来说",{"2":{"841":1}}],["但对小感知误差敏感且缺乏长时域规划能力",{"2":{"216":1}}],["但沿投影光线的点会获得相同的特征",{"2":{"839":1}}],["但往往会产生稀疏的bev投影",{"2":{"839":1}}],["但尚未被广泛采用",{"2":{"1000":1}}],["但尚未作为正式指标",{"2":{"826":1}}],["但尚未涉及ad中迅速出现的vla范式",{"2":{"82":1}}],["但后者并不能保证地图已完整",{"2":{"826":1}}],["但目前尚无工作对此进行度量",{"2":{"826":1}}],["但目前缺乏可跨不同地图结构",{"2":{"826":1}}],["但目前仍缺乏专门针对这一快速发展领域的综述",{"2":{"637":1}}],["但运行速度显著更快",{"2":{"803":1}}],["但图像中固有的深度和几何信息的缺失对直接从图像中学习3d特征表示提出了重大挑战",{"2":{"799":1}}],["但图像里的未掩码区域都会在下一步被替换成没有考虑后向生成过程的前向扩散输出",{"2":{"312":1}}],["但视觉网络的性能较低",{"2":{"782":1}}],["但实现了超过两倍的加速",{"2":{"811":1}}],["但实现了显著更好的性能",{"2":{"779":1}}],["但实现这一目标通常需要对每个体素进行细粒度的语义注释",{"2":{"799":1}}],["但实际不可能这么用",{"2":{"220":1}}],["但许多工作",{"2":{"765":1}}],["但一些研究已将该数据集用于3d占用预测",{"2":{"757":1}}],["但也会削弱实时性能",{"2":{"922":1}}],["但也带来了大量的人力成本",{"2":{"735":1}}],["但也可以包括语义类别",{"2":{"197":1}}],["但能保留该位置视觉信息的特征",{"2":{"721":1}}],["但能够以可变形的方式灵活适应不同物体尺度和区域复杂性",{"2":{"612":1}}],["但先分割后投影易出现",{"2":{"698":1}}],["但未能提升精度",{"2":{"694":1}}],["但共享相同的坐标系",{"2":{"682":1}}],["但整个物体丢失",{"2":{"665":1}}],["但基于图像的方法由于其较低的经济成本和更好的实时性",{"2":{"665":1}}],["但源码中是这样做的",{"2":{"659":1}}],["但大多数都专注于",{"2":{"653":1}}],["但大多数高斯仍然以低效的方式描述空区域",{"2":{"536":1}}],["但检测领域会有明显的长尾效应",{"2":{"630":1}}],["但计算速度低两个数量级",{"2":{"686":1}}],["但计算速度较慢",{"2":{"362":1}}],["但计算开销大",{"2":{"619":1,"864":1}}],["但将预训练模型应用于下游3d感知任务仍存在领域差距",{"2":{"617":1}}],["但直接应用此主干会因训练样本有限",{"2":{"617":1}}],["但轨迹不同",{"2":{"605":1}}],["但lss计算成本高",{"2":{"595":1}}],["但相比meshcnn直接用下采样的mesh结构来进行上采样",{"2":{"589":1}}],["但相比纯驾驶rl仍待发展",{"2":{"417":1}}],["但meshcnn的下采样是与具体task密切相关的",{"2":{"589":1}}],["但面临噪声处理",{"2":{"588":1}}],["但数十年的研究表明",{"2":{"570":1}}],["但bev级特征可以隐式捕捉高度信息",{"2":{"566":1}}],["但任务要求将它们区分为不同的对象",{"2":{"553":1}}],["但考虑更基础的方法来组合语义描述将是有趣的",{"2":{"553":1}}],["但包含较少的",{"2":{"549":1}}],["但由于其提供的密集",{"2":{"936":1}}],["但由于其连续建模属性",{"2":{"899":1}}],["但由于鸟瞰图中包含的丰富信息及其对遮挡和尺度变化的不敏感性",{"2":{"875":1}}],["但由于它们",{"2":{"858":1}}],["但由于基于体素的表示的密集性",{"2":{"808":1}}],["但由于计算和存储复杂度",{"2":{"738":1}}],["但由于计算和内存占用随着分辨率呈指数增长",{"2":{"363":1}}],["但由于3d空间的稀疏性",{"2":{"693":1}}],["但由于高度压缩导致的信息丢失",{"2":{"612":1}}],["但由于高斯混合的通用近似能力",{"2":{"547":1}}],["但由于室内场景的多样性和复杂性",{"2":{"600":1}}],["但3d标签成本高昂",{"2":{"1006":1}}],["但3d占用预测的密集输出空间如何高效且有效地表示3d场景仍然是一个巨大挑战",{"2":{"547":1}}],["但3d高斯的出现提供了一种紧凑且连续的对象中心表示法",{"2":{"415":1}}],["但使用三维体素级表示引入了复杂的计算",{"2":{"535":1}}],["但使用可变形注意力会带来更大的计算负担",{"2":{"482":1}}],["但仅消耗其17",{"2":{"516":1,"547":1}}],["但仅能提供稀疏且常含噪声的特征",{"2":{"503":1}}],["但仅限于",{"2":{"125":1}}],["但多模态方法在实际应用中",{"2":{"482":1}}],["但非英语方言",{"2":{"478":1}}],["但形式化验证与",{"2":{"478":1}}],["但引入新失效模式",{"2":{"478":1}}],["但无法充分利用深度信息的潜力",{"2":{"705":1}}],["但无法完全解决",{"2":{"693":1}}],["但无法提供精确的深度信息",{"2":{"564":1}}],["但无法将给定房间标记为",{"2":{"467":1}}],["但无法在形成对象时考虑任务",{"2":{"462":1}}],["但hydra可以在许多方向上进行改进",{"2":{"467":1}}],["但论文说",{"2":{"440":1}}],["但我们观察到通过整合环视相机与雷达",{"2":{"936":1}}],["但我们在表",{"2":{"928":1}}],["但我们在封闭集replica",{"2":{"492":1}}],["但我们也理解可能有对延迟或处理时间更敏感的应用",{"2":{"836":1}}],["但我们的框架仍然存在一些局限性",{"2":{"937":1}}],["但我们的模型能够准确地恢复这些未标注区域的语义信息",{"2":{"899":1}}],["但我们的flashocc实现了更优的5",{"2":{"811":1}}],["但我们的方法有多个限制",{"2":{"553":1}}],["但我们更倾向于se",{"2":{"634":1}}],["但我们注意到对于那些错误匹配的像素",{"2":{"622":1}}],["但我们使用了两个没有重叠视野的相机",{"2":{"605":1}}],["但我们再次声明hydra可以在通常用于机器人应用的嵌入式计算机上实时运行",{"2":{"437":1}}],["但我们建议读者参考",{"2":{"178":1}}],["但很少有与我们的推理工具链",{"2":{"437":1}}],["但需同时维护两层",{"2":{"864":1}}],["但需要繁琐的体素级标注",{"2":{"988":1}}],["但需要人工标注的正负样本对",{"2":{"525":1}}],["但需要访问场景的完整3d重建",{"2":{"492":1}}],["但需要更昂贵的特征值分解的拉普拉斯算子gp",{"2":{"301":1}}],["但需额外探索时间",{"2":{"435":1}}],["但需奖励事实准确性而非修辞",{"2":{"417":1}}],["但镜像训练分布",{"2":{"417":1}}],["但忽略了传感器读数的分布特性",{"2":{"409":1}}],["但因为卷积作用于邻域输入顺序在卷积阶段不产生影响",{"2":{"407":1}}],["但具有许多改进",{"2":{"384":1}}],["但广泛用于vla4ad研究",{"2":{"360":1}}],["但这并不支持无结构的3d高斯表示",{"2":{"716":1}}],["但这并不直接适用于多层建筑",{"2":{"172":1}}],["但这些标签是稀疏的",{"2":{"735":1}}],["但这些工作主要集中在",{"2":{"678":1}}],["但这些不太保守",{"2":{"634":1}}],["但这些初步结果强调了hydra在构建3d场景图方面的实用性和实时能力",{"2":{"437":1}}],["但这种全局的注意力机制其计算和存储需求量巨大",{"2":{"824":1}}],["但这种偏置对于语义层面",{"2":{"343":1}}],["但这种普适泛化性也意味着你需要更充足的训练和更广泛的搜索范围",{"2":{"343":1}}],["但如果将自然语言模型里的transformer用来自回归式逐位生成像素的话",{"2":{"343":1}}],["但如何在实时构建这样的丰富表示仍然是未知领域",{"2":{"112":1,"125":1}}],["但带来新挑战",{"2":{"334":1}}],["但略有不同的是针对其只能全局修改的痛点增添了对图像的mask操作",{"2":{"312":1}}],["但出现新限制",{"2":{"308":1}}],["但立方体缺乏捕捉关节目标的精细形状细节的能力",{"2":{"302":1}}],["但允许应用于图形数据",{"2":{"275":1}}],["但适用场景也比较局限无法局部调整只能全局修改",{"2":{"264":1}}],["但它用深度分布估计替代了逐像素深度估计",{"2":{"950":1}}],["但它仍然优于一些使用",{"2":{"989":1}}],["但它仍然面临特征表示",{"2":{"799":1}}],["但它仍然遵循预定义的规则划分模式",{"2":{"612":1}}],["但它与3d",{"2":{"641":1}}],["但它确实继承了实现中使用的基础模型的一些限制",{"2":{"553":1}}],["但它严重依赖激光雷达分支的三维目标检测预训练来获得最佳结果",{"2":{"482":1}}],["但它们仍然存在局限性",{"2":{"998":1}}],["但它们仍被视为独立的任务进行优化",{"2":{"975":1}}],["但它们大多局限于表示当前的3d空间",{"2":{"975":1}}],["但它们无法保证空间信息的准确性",{"2":{"963":1}}],["但它们无法捕捉任意形状的障碍物",{"2":{"547":1}}],["但它们对内存的需求高",{"2":{"958":1}}],["但它们可以将高度信息编码到特征通道维度中",{"2":{"950":1}}],["但它们可能会导致细节丢失",{"2":{"693":1}}],["但它们任务相关",{"2":{"826":1}}],["但它们的压缩方案不可避免地导致了信息丢失",{"2":{"808":1}}],["但它们总是与其他几何输入",{"2":{"603":1}}],["但它们在恶劣天气条件下以及检测远距离物体方面存在局限性",{"2":{"599":1}}],["但它们忽略了",{"2":{"567":1}}],["但它们通常需要后处理",{"2":{"547":1}}],["但它们通常需要大量标注数据才能训练到高精度",{"2":{"455":1}}],["但它们依赖于笛卡尔坐标系下的体素化",{"2":{"527":1}}],["但它们有明显的缺点",{"2":{"116":1}}],["但它仅利用了原始点云数据中的距离真值",{"2":{"421":1}}],["但它遍历元素子集的范围和迭代方面效率较低",{"2":{"196":1}}],["但已知会受到外观和视点变化的影响",{"2":{"190":1}}],["但在occ3d",{"2":{"1000":1}}],["但在应用上有所不同",{"2":{"998":1}}],["但在具身智能研究中",{"2":{"958":1}}],["但在具身智能中仍属空白",{"2":{"648":1}}],["但在户外面对行人",{"2":{"926":1}}],["但在严格延迟约束下维持高保真语义理解",{"2":{"864":1}}],["但在mhsa中得到广泛应用",{"2":{"863":1}}],["但在体素化后仍然存在一些间隙",{"2":{"735":1}}],["但在从离线预测过渡到在线预测时",{"2":{"728":1}}],["但在细微地形变化",{"2":{"700":1}}],["但在小物体",{"2":{"700":1}}],["但在",{"2":{"670":1,"917":1,"928":1}}],["但在我们的实验中",{"2":{"622":1}}],["但在实时训练",{"2":{"619":1}}],["但在实际情况中",{"2":{"149":1}}],["但在深度学习时代",{"2":{"603":1}}],["但在公寓中的f1分数表现相对较差",{"2":{"522":1}}],["但在其他指标上表现不佳",{"2":{"462":1}}],["但在全局语义上这张图明显是不自洽的",{"2":{"312":1}}],["但在使用密集表示时实时执行这个操作是非平凡的",{"2":{"190":1}}],["但在多篇paper中有提到",{"2":{"165":1}}],["但其余的场景图是在运行结束时构建的",{"2":{"973":1}}],["但其准确性仍需进一步提高",{"2":{"922":1}}],["但其性能仍略逊于最先进的方法",{"2":{"878":1}}],["但其性能超过了",{"2":{"827":1}}],["但其和并不稳定",{"2":{"863":1}}],["但其探索的数据和模型规模仍然比nlp",{"2":{"643":1}}],["但其感知能力极易受到雨雾等恶劣天气条件以及夜间光照变化的影响",{"2":{"503":1}}],["但其需要预设固定宽高",{"2":{"495":1}}],["但其房间的计算成本最高",{"2":{"437":1}}],["但其关注范围与目的并不相同",{"2":{"155":1}}],["但其重点在于获取的语义类型及其提取技术",{"2":{"90":1}}],["但鉴于其与语义建图",{"2":{"155":1}}],["但迄今为止还没有一个通用框架来确定机器人的度量",{"2":{"137":1}}],["但本文通过提出一种新的环境表示和实用的算法来推断数据",{"2":{"131":1}}],["但本文针对室内导航",{"2":{"80":1}}],["但有时候做不到",{"2":{"129":1}}],["但不覆盖整个场景",{"2":{"988":1}}],["但不同之处在于3d空间中的体素被投影到2d多帧特征图",{"2":{"957":1}}],["但不同于其使用随机初始化参数作为bev查询",{"2":{"585":1}}],["但不过滤查询以保留所有输入信息",{"2":{"471":1}}],["但不可避免地会受到冗余空网格和高计算成本的困扰",{"2":{"444":1}}],["但不直接输出控制",{"2":{"260":1}}],["但不在实时运行",{"2":{"121":1}}],["但不决定行动",{"2":{"82":1}}],["但没有捕捉到关键的可操作信息",{"2":{"116":1}}],["但仍然有待进一步开发",{"2":{"958":1}}],["但仍然能够生成全面的占用预测",{"2":{"832":1}}],["但仍有诸多难题与改进空间",{"2":{"881":1}}],["但仍存在诸多待解决的关键难题",{"2":{"864":1}}],["但仍存在语义鸿沟",{"2":{"260":1}}],["但仍可分解为五个基本模块",{"2":{"598":1}}],["但仍面临挑战",{"2":{"114":1}}],["但仍以感知为中心",{"2":{"92":1}}],["但缺乏可解释性与泛化能力",{"2":{"92":1}}],["但",{"2":{"80":1,"382":1,"567":1,"656":1,"872":1,"927":1}}],["但是在硬景观类别上只有41",{"2":{"996":1}}],["但是在rosdep",{"2":{"87":1}}],["但是它们在少数类别上的性能依然有限",{"2":{"996":1}}],["但是它需要一组有限的时间作为其网络的输入",{"2":{"420":1}}],["但是论文观察到当尽管比普通卷积网络能够更适应物体形变",{"2":{"804":1}}],["但是由于每次都要查询之前所有的帧",{"2":{"695":1}}],["但是由于autoencoder的模型是全卷积结构的",{"2":{"345":1}}],["但是直接把transformer从",{"2":{"631":1}}],["但是并不确定transformer能不能把所有视觉的任务都做掉",{"2":{"631":1}}],["但是消耗上升",{"2":{"489":1}}],["但是最新的工作都是采用预训练好的text",{"2":{"373":1}}],["但是这种方法如果想对移动的物体建模",{"2":{"695":1}}],["但是这种生成是没有任何约束的",{"2":{"224":1}}],["但是这两张表之间的序号是不统一的现在需要额外构建一张rulebook表将输入和输出这两张表对应起来",{"2":{"561":1}}],["但是这个简单的做法会有一个很大的弊端就是掩码的区域里所有的信息实质上是被全部丢弃的",{"2":{"312":1}}],["但是含有梯度计算",{"2":{"235":1}}],["但是从3d重建中构建的",{"2":{"190":1}}],["但是肤色依然随a",{"2":{"181":1}}],["但是肤色等细节随source",{"2":{"181":1}}],["但是数据有很多特征",{"2":{"149":1}}],["但是stylegan",{"2":{"133":1}}],["但是",{"2":{"129":1,"337":1,"818":1}}],["但是有些人禁用后",{"2":{"66":1}}],["但是碰到",{"2":{"48":1}}],["但是提取的图片特征不一定是符合多元正态分布的",{"2":{"20":1}}],["操作和渲染复杂场景",{"2":{"961":1}}],["操作函数",{"0":{"904":1}}],["操作以加速",{"2":{"812":1}}],["操作等",{"2":{"786":1}}],["操作将通道维度转换为高度维度",{"2":{"421":1}}],["操作任务",{"2":{"139":1,"806":1}}],["操作",{"2":{"80":1,"525":1,"806":1,"812":1,"881":1,"897":1}}],["使机器人能在未知或杂乱场景下扩展语义理解",{"2":{"897":1}}],["使机器人能够利用多种传感器",{"2":{"171":1}}],["使同一语义地图无需重新训练即可支撑导航",{"2":{"881":1}}],["使它们能够相互增强以获得更高质量的bev表示",{"2":{"875":1}}],["使噪声与不确定性的处理成为根本挑战",{"2":{"864":1}}],["使融合网络能够提升轻量级仅视觉占据网络的精度",{"2":{"862":1}}],["使网络自动存储对任务最有用的信息",{"2":{"743":1}}],["使主流的离线框架具备了在线场景感知的能力",{"2":{"629":1}}],["使地图能够存储",{"2":{"765":1}}],["使地图不仅几何准确",{"2":{"588":1}}],["使地点子图连接",{"2":{"276":1}}],["使邻近位置的嵌入聚集",{"2":{"525":1}}],["使我们能够采用简单但有效的方法将环境划分为不同的房间",{"2":{"480":1}}],["使基于视觉的检测参数更宽容会导致更多的但质量较低的环路闭合",{"2":{"437":1}}],["使模型更具鲁棒性和泛化能力",{"2":{"908":1}}],["使模型能够确定当前的体素网格是被占用还是未被占用",{"2":{"768":1}}],["使模型能够检索到近路和近路物体的聚合融合特征",{"2":{"723":1}}],["使模型能够在较远距离处生成相对准确的检测结果",{"2":{"625":1}}],["使模型能在不同距离更有效地关注关键目标",{"2":{"114":1}}],["使模型了解噪声水平",{"2":{"304":1}}],["使智能体",{"2":{"864":1}}],["使智能体可在节点内局部规划",{"2":{"525":1}}],["使智能体可以先独立习得这些技能",{"2":{"274":1}}],["使智能体不再被动地随移动而制图",{"2":{"189":1}}],["使智能体能在复杂动态环境中运行",{"2":{"123":1}}],["使其能够进行开放词汇预测",{"2":{"975":1}}],["使其能够直接从二维图像",{"2":{"870":1}}],["使其成为",{"2":{"599":1}}],["使其成为一个模块",{"2":{"131":1}}],["使其与对应文本和图像在",{"2":{"588":1}}],["使其更加密集",{"2":{"735":1}}],["使其更适合在自动驾驶车辆上进行车载运行",{"2":{"700":1}}],["使其更适合3d下游任务",{"2":{"667":1}}],["使其更易于部署",{"2":{"566":1}}],["使其更接近成熟的激光雷达检测网络",{"2":{"482":1}}],["使其容易受到光照和天气条件变化的影响",{"2":{"475":1}}],["使其和初始深度图尺寸相同",{"2":{"470":1}}],["使其在理论上每个object",{"2":{"358":1}}],["使其仅包含对相似变换本质上不变的相对几何特征",{"2":{"325":1}}],["使其具有与最终图像相同的分辨率",{"2":{"143":1}}],["使得直接应用标准",{"2":{"974":1}}],["使得对这些类别的可靠推断变得更加困难",{"2":{"828":1}}],["使得对象定位几乎与漂移无关",{"2":{"775":1}}],["使得从场景表示到占用预测的转换比其他表示方法",{"2":{"693":1}}],["使得不同视点之间的深度遮挡和冲突最小化",{"2":{"650":1}}],["使得该proposal不超过图像范围",{"2":{"493":1}}],["使得文本引导可以只针对具体的某个区域更改",{"2":{"452":1}}],["使得模型输出的噪声与随机采样的高斯噪声差距尽可能小",{"2":{"329":1}}],["使得更正语义变得更为困难",{"2":{"312":1}}],["使得局部修改成为可能",{"2":{"312":1}}],["使得概率密度函数积分为一",{"2":{"213":1}}],["使得学习效率低下",{"2":{"149":1}}],["使得进度条全部变绿",{"2":{"136":1}}],["使得智能体在整个任务过程中能够引用它来进行高级推理",{"2":{"80":1}}],["使dsg成为可操作的表示",{"2":{"131":1}}],["使驾驶系统面临潜在不安全控制",{"2":{"128":1}}],["使用强监督训练",{"2":{"1000":1}}],["使用的评估数据集包括semantickitti",{"2":{"999":1}}],["使用的损失函数类型",{"2":{"877":1}}],["使用软iou损失来更好地优化交并比",{"2":{"985":1}}],["使用共享",{"2":{"974":1}}],["使用共享窗口注意力捕捉细粒度细节",{"2":{"875":1}}],["使用神经网络",{"2":{"967":1}}],["使用图结构的求和积网络推断网格地图的拓扑结构",{"2":{"967":1}}],["使用图神经网络实时预测对象和关系",{"2":{"172":1}}],["使用马尔可夫随机场来分割2d网格地图",{"2":{"967":1}}],["使用orb",{"2":{"967":1}}],["使用open3d",{"2":{"510":1}}],["使用openclip模型vit",{"2":{"431":1}}],["使用优化后的姿态图作为测量约束来变形网格",{"2":{"967":1}}],["使用优先队列",{"2":{"466":1}}],["使用对称群和等价",{"2":{"962":1}}],["使用两个并行的层次表示",{"2":{"961":1}}],["使用两个独立的mlp将3d体素逻辑转换为体素的密度和体素的语义逻辑",{"2":{"941":1}}],["使用场景图来模拟2d图像中对象的属性和关系",{"2":{"961":1}}],["使用交叉注意力进行融合",{"2":{"957":1}}],["使用交叉熵损失训练",{"2":{"782":3}}],["使用残差校正进一步融合从",{"2":{"955":1}}],["使用普通的交叉注意力进行2d到3d转换需要大量的计算开销",{"2":{"950":1}}],["使用单视角图像序列重建驾驶场景",{"2":{"949":1}}],["使用自制传感装置和intel",{"2":{"947":1}}],["使用a",{"2":{"930":1}}],["使用更多的关系",{"2":{"928":1}}],["使用更多的",{"2":{"928":1}}],["使用所有3d体素标记与多视图图像中的roi进行交互将产生显著的计算和内存成本",{"2":{"922":1}}],["使用相同的一组参数",{"2":{"947":1}}],["使用相同的自制传感装置",{"2":{"605":1}}],["使用相同尺度的",{"2":{"928":1}}],["使用相机投影矩阵将3d位置与图像流链接",{"2":{"875":1}}],["使用基于查询的技术生成查询提议",{"2":{"875":1}}],["使用基于可见性的融合算法",{"2":{"650":1}}],["使用各向异性卷积实现灵活的感受野",{"2":{"875":1}}],["使用u",{"2":{"875":1}}],["使用求和将这些特征从三视角平面聚合为最终的3d特征表示",{"2":{"858":1}}],["使用最近邻",{"2":{"850":1}}],["使用最近邻算法为每个体素分配语义标签",{"2":{"735":1}}],["使用后向投影来细化必要的bev网格以减少稀疏性",{"2":{"839":1}}],["使用概率占用网格",{"2":{"826":1}}],["使用概率分布p",{"2":{"137":1}}],["使用4个gpu时设置为1e",{"2":{"813":1}}],["使用8个gpu时的最大学习率设置为2e",{"2":{"813":1}}],["使用我们的flashocc导致bev编码器和占据预测头的推理时长显著减少了58",{"2":{"811":1}}],["使用我们的完成头模块获得",{"2":{"632":1}}],["使用多流",{"2":{"955":1}}],["使用多尺度全局",{"2":{"875":1}}],["使用多种损失函数会使训练时间翻倍",{"2":{"803":1}}],["使用多个3d高斯分布进行辐射场渲染",{"2":{"641":1}}],["使用多个mlp学习点特征",{"2":{"420":1}}],["使用全部四种损失",{"2":{"782":1}}],["使用全连接层",{"2":{"296":1}}],["使用在",{"2":{"771":1}}],["使用在esdf集成过程中实时构建的广义voronoi图",{"2":{"276":1}}],["使用二元交叉熵损失",{"2":{"766":1}}],["使用3d版本的resnet",{"2":{"875":1}}],["使用3d占用头完成最终预测",{"2":{"875":1}}],["使用3d场景图进行预测",{"2":{"467":1}}],["使用32块nvidia",{"2":{"764":1}}],["使用运动信息对",{"2":{"762":1}}],["使用初始学习率为",{"2":{"744":1,"867":1}}],["使用捆绑射线投射和",{"2":{"732":1}}],["使用网格重建方法",{"2":{"735":1}}],["使用网格地图存储与神经场对应的潜码",{"2":{"721":1}}],["使用网格池来学习折叠来自相同片段的边缘",{"2":{"557":1}}],["使用外参",{"2":{"716":1}}],["使用体积表示进行融合和变形",{"2":{"967":1}}],["使用体积方法",{"2":{"131":1}}],["使用体素或平面表示的方法通常使用可变形注意力实现自编码模块",{"2":{"716":1}}],["使用nni",{"2":{"697":1}}],["使用2d图像骨干网络对每个三视角特征平面进行编码",{"2":{"858":1}}],["使用2d平面来描述3d空间",{"2":{"693":1}}],["使用2d语义分割",{"2":{"362":1}}],["使用稀疏的",{"2":{"678":1}}],["使用稀疏的3d语义高斯分布来描述3d场景",{"2":{"516":1}}],["使用函数",{"2":{"656":1}}],["使用匈牙利算法匹配预测与真实框",{"2":{"651":1}}],["使用类似于pointnet的方法从节点特征中学习最终特征",{"2":{"636":1}}],["使用类似的基于对象的描述符",{"2":{"190":1}}],["使用标准的平衡k",{"2":{"636":1}}],["使用标定结果更新",{"2":{"152":1}}],["使用surroundocc",{"2":{"842":1}}],["使用sim",{"2":{"634":1}}],["使用string类的find成员函数可以找到一个字符串在另一个字符串中的位置",{"2":{"52":1}}],["使用三维高斯表示是一种更灵活的方法",{"2":{"629":1}}],["使用预训练",{"2":{"743":1}}],["使用预训练好的mvsnet生成低分辨率的初始深度图",{"2":{"376":1}}],["使用预先获取和重建的三维数据来获得相对滞后的感知",{"2":{"629":1}}],["使用框提示生成高质量语义掩码",{"2":{"617":1}}],["使用来自左",{"2":{"900":1}}],["使用来自反向投影的密集bev特征来优化来自前向投影的稀疏体素特征",{"2":{"612":1}}],["使用来自实例分支的查询向量",{"2":{"434":1}}],["使用kalibr工具包",{"2":{"605":1}}],["使用kimera",{"2":{"285":1,"732":1}}],["使用转移构造函数添加新元素3",{"2":{"604":1}}],["使用范围迭代器插入",{"2":{"571":1}}],["使用采样点从特征图中聚合视觉特征",{"2":{"564":1}}],["使用resnet作为backbone从相机图像中提取特征",{"2":{"562":1}}],["使用双线性插值来更精确地找到每个块对应的特征",{"2":{"554":1}}],["使用六个多相机图像",{"2":{"545":1,"965":1}}],["使用evo",{"2":{"510":1}}],["使用阈值为0",{"2":{"493":1}}],["使用鸟瞰图特征和二维卷积实现高效的特征提取",{"2":{"482":1}}],["使用高级策略初始化查询",{"2":{"471":1}}],["使用期望的优势",{"2":{"470":1}}],["使用深度学习技术将视觉特征投影到",{"2":{"455":1}}],["使用编码器",{"2":{"440":1}}],["使用地面真实姿态",{"2":{"709":1}}],["使用地面真实姿态增量构建场景图",{"2":{"437":1}}],["使用地点层的最小生成树的选择主要是出于计算原因",{"2":{"380":1}}],["使用可微分体积渲染生成透视视图中的深度和语义图",{"2":{"941":1}}],["使用可学习的神经网络",{"2":{"435":1}}],["使用可同时获取彩色图与深度图的",{"2":{"189":1}}],["使用步幅为",{"2":{"433":1}}],["使用decor",{"2":{"429":1}}],["使用mlp从非叶节点的子节点计算非叶节点的特征",{"2":{"636":1}}],["使用microsoft",{"2":{"947":1}}],["使用microsoft的azure",{"2":{"605":1}}],["使用mit场景解析挑战",{"2":{"437":1}}],["使用morton编码",{"2":{"426":1}}],["使用mcmc方法",{"2":{"172":1}}],["使用数据增强获得两个增强视图",{"2":{"424":1}}],["使用数组作为初值构造",{"0":{"361":1}}],["使用方程的梯度来计算缩小这个距离的方向",{"2":{"422":1}}],["使用静止运动先验",{"2":{"419":1}}],["使用姿态图来模拟人类和机器人的全局轨迹允许两者之间的统一可视化工具",{"2":{"419":1}}],["使用姿态图模型",{"2":{"131":1}}],["使用每个人类的轨迹的姿态图允许应用姿态图优化技术",{"2":{"419":1}}],["使用pointpillars",{"2":{"910":1}}],["使用pcl",{"2":{"449":1}}],["使用pnp",{"2":{"419":1}}],["使用pvcnn作为输入编码器",{"2":{"318":1}}],["使用待处置的列表构造",{"0":{"418":1}}],["使用跨模态对比损失与序列建模目标绑定场景特征",{"2":{"417":1}}],["使用指定的内核映射将输入与内核进行卷积",{"2":{"413":1}}],["使用gtsam优化姿态图",{"2":{"390":1}}],["使用graphcmr",{"2":{"285":1}}],["使用卡方检验",{"2":{"390":1}}],["使用修改版的pcm",{"2":{"390":1}}],["使用生成树保留了图的稀疏性",{"2":{"380":1}}],["使用变形图方法优化图",{"2":{"380":1}}],["使用迭代器构造",{"0":{"335":1}}],["使用学习到的潜变量",{"2":{"314":1}}],["使用lukas",{"2":{"310":1}}],["使用一组可学习的核心一致地执行实例和语义分割",{"2":{"306":1}}],["使用一个全连接的网络s",{"2":{"344":1}}],["使用一个roi",{"2":{"250":1}}],["使用一个神经网络对全图进行特征提取",{"2":{"250":1}}],["使用边界框或立方体来表示",{"2":{"302":1}}],["使用立体图像",{"2":{"285":1}}],["使用贝叶斯更新",{"2":{"285":1}}],["使用紧凑mlp将选定动作token",{"2":{"283":1}}],["使用无条件的",{"2":{"278":1}}],["使用imagenet",{"2":{"822":1}}],["使用icp阈值为1",{"2":{"686":1}}],["使用isam2",{"2":{"310":1}}],["使用initializer",{"2":{"261":1,"571":1}}],["使用ib进行vlms的图像和文本输入之间的归因",{"2":{"121":1}}],["使用文本引导软注意力池化聚焦关键区域",{"2":{"260":1}}],["使用vector为底层容器的栈",{"2":{"685":1}}],["使用vector容器的头文件是",{"2":{"73":1}}],["使用vio+sg",{"2":{"437":1}}],["使用voxblox",{"2":{"253":1}}],["使用简单的用户指导生成精细的3d形状",{"2":{"247":1}}],["使用这种稀疏的真实标签监督模型会导致模型性能下降",{"2":{"735":1}}],["使用这种score",{"2":{"235":1}}],["使用这些见解",{"2":{"137":1}}],["使用者可以按照prompt",{"2":{"204":1}}],["使用从激光雷达体素特征初始化的",{"2":{"444":1}}],["使用从2d图像构建的随机游走描述符执行基于对象图的环路闭合检测",{"2":{"190":1}}],["使用从全方位相机的密集立体视觉拟合立方体到对象和房间",{"2":{"172":1}}],["使用bounding",{"2":{"187":1}}],["使用了卷积神经网络进行特征提取",{"2":{"187":1}}],["使用find",{"2":{"177":1}}],["使用cbgs",{"2":{"876":1}}],["使用cuda可以加快计算速度",{"2":{"481":1}}],["使用count",{"2":{"177":1}}],["使用clip构建了一个可以通过文本查询的隐式网格图",{"2":{"121":1}}],["使用调频连续波在一次扫描周期内独立测量距离和速度",{"2":{"173":1}}],["使用混合整数规划将对象和关系解析到场景文法模型中",{"2":{"172":1}}],["使用层次化描述符",{"2":{"141":1}}],["使用几何分割技术",{"2":{"137":1}}],["使用目标中心token表示",{"2":{"128":1}}],["使用增强的余弦相似度分数",{"2":{"121":1}}],["使用系统的",{"2":{"107":1}}],["使用项目自带的编译脚本",{"2":{"58":1}}],["使用",{"0":{"50":1},"1":{"60":1,"69":1,"78":1},"2":{"125":2,"136":1,"355":1,"419":1,"437":1,"456":2,"473":1,"492":1,"499":1,"562":1,"570":1,"579":1,"582":1,"632":1,"634":1,"743":1,"744":1,"771":1,"782":1,"803":3,"816":1,"866":1,"867":1,"900":1,"917":1,"928":1,"930":1,"968":1,"978":2,"982":1,"1000":1}}],["使用下面命令创建交换文件",{"2":{"26":1}}],["语音往往给出高层",{"2":{"864":1}}],["语音等多源感知来构建丰富且可解释的环境表征",{"2":{"864":1}}],["语音与标志作为",{"2":{"507":1}}],["语码转换",{"2":{"447":1}}],["语义激光雷达点云的收集和标注成本高昂",{"2":{"1000":1}}],["语义激光雷达点云可以监督3d占用网络的训练",{"2":{"1000":1}}],["语义时空信息有助于提高三维目标识别",{"2":{"996":1}}],["语义标签直接来自预训练的语义分割模型",{"2":{"988":1}}],["语义标签结合得到的",{"2":{"978":1}}],["语义标签可以是",{"2":{"302":1}}],["语义权重",{"2":{"976":1}}],["语义信息",{"2":{"961":1}}],["语义信息与实际环境的一致程度",{"2":{"943":1}}],["语义信息也可以直接累积在场景的",{"2":{"556":1}}],["语义层面实现高效推理",{"2":{"881":1}}],["语义损失",{"2":{"877":1,"985":1}}],["语义感知的组解码器根据语义粒度和样本数量将真实标签划分为多个组",{"2":{"875":1}}],["语义复杂度提升",{"2":{"864":1}}],["语义丰富度与效率的平衡",{"2":{"951":1}}],["语义丰富",{"2":{"864":2}}],["语义丰富的表征转变",{"2":{"588":1}}],["语义丰富的",{"2":{"123":1}}],["语义一致性",{"2":{"826":1}}],["语义覆盖",{"2":{"826":1}}],["语义完整度",{"2":{"826":1}}],["语义图",{"2":{"826":1}}],["语义评估",{"2":{"754":1}}],["语义embedding",{"2":{"718":1}}],["语义预测",{"2":{"681":1}}],["语义预训练",{"2":{"490":1,"785":1,"839":1}}],["语义点云",{"2":{"648":1}}],["语义统一表达",{"2":{"619":1}}],["语义分割有四种范式",{"2":{"948":1}}],["语义分割的目标是根据点的语义将其分成几个子集",{"2":{"948":1}}],["语义分割的模型来实现",{"2":{"349":1}}],["语义分割以及实例分割等任务实验结果验证了所提方案的有效性",{"2":{"824":1}}],["语义分割",{"2":{"601":1,"619":1,"940":1}}],["语义场景重建",{"2":{"967":1}}],["语义场景表示",{"2":{"588":1}}],["语义场景补全",{"2":{"539":1,"570":2}}],["语义高斯分布在点",{"2":{"693":1}}],["语义高斯的上述限制并提高其利用效率",{"2":{"567":1}}],["语义高斯表示采用可学习的初始化策略",{"2":{"704":1}}],["语义高斯表示采用一组",{"2":{"656":1}}],["语义高斯表示鼓励高斯之间重叠",{"2":{"656":1}}],["语义高斯表示及其限制",{"2":{"628":1}}],["语义高斯表示",{"0":{"656":1},"2":{"599":1}}],["语义高斯表示的效率和有效性",{"2":{"656":1}}],["语义高斯表示的效率",{"2":{"567":1}}],["语义高斯表示仍存在一些限制",{"2":{"567":1,"656":1}}],["语义高斯通过为每个高斯学习均值",{"2":{"567":1}}],["语义高斯",{"2":{"536":1}}],["语义相似但相连的区域",{"2":{"522":1}}],["语义相似度",{"2":{"223":1}}],["语义占用感知本质上可以被视为3d语义分割任务",{"2":{"1003":1}}],["语义占用感知起源于ss",{"2":{"759":1}}],["语义占用注释进行监督和评估",{"2":{"749":1}}],["语义占用预测和3d目标检测",{"2":{"1003":1}}],["语义占用预测的视频演示的一个样本帧",{"2":{"885":1}}],["语义占用预测的概率高斯叠加方法",{"2":{"628":1}}],["语义占用预测实现了最先进的性能",{"2":{"851":1}}],["语义占用预测结果",{"2":{"792":1}}],["语义占用预测旨在获得",{"2":{"656":1}}],["语义占用预测工作采用密集网格表示作为直接方法来得出占用情况",{"2":{"599":1}}],["语义占用预测已成为自动驾驶中一种有前景的环境建模方法",{"2":{"599":1}}],["语义占用预测",{"2":{"567":1,"749":1,"792":2}}],["语义占用预测本质上是一个密集的三维分割任务",{"2":{"567":1}}],["语义占用预测方法的出现缓解了这一限制",{"2":{"567":1}}],["语义占用预测是自动驾驶中一项重要的任务",{"2":{"536":1}}],["语义占有率",{"2":{"977":1}}],["语义占有率网格",{"2":{"724":1}}],["语义占有率任务",{"2":{"564":1}}],["语义占有率预测方面的有效性并将其与我们的方法进行对比时",{"2":{"915":1}}],["语义占有率预测和",{"2":{"900":1}}],["语义占有率预测的性能",{"2":{"596":1}}],["语义占有率预测任务性能的有效性",{"2":{"927":1}}],["语义占有率预测任务的研究",{"2":{"678":1}}],["语义占有率预测任务的影响",{"2":{"653":1}}],["语义占有率预测任务的相机",{"2":{"653":1}}],["语义占有率预测任务",{"2":{"596":1}}],["语义占有率预测任务中的性能",{"2":{"678":1}}],["语义占有率预测任务中的性能的影响",{"2":{"503":1}}],["语义占有率预测任务中的最新",{"2":{"503":1}}],["语义占有率预测任务中",{"2":{"503":1}}],["语义占有率预测",{"2":{"503":1,"625":1}}],["语义占据数据集",{"2":{"828":1}}],["语义占据的",{"2":{"787":1}}],["语义占据预测",{"2":{"808":2}}],["语义占据预测实验使用",{"2":{"787":1}}],["语义占据预测性能",{"2":{"700":1}}],["语义占据预测的目标是同时理解环境的语义信息和几何结构",{"2":{"532":1}}],["语义占据预测中的场景表示",{"2":{"474":1}}],["语义占据",{"2":{"502":1}}],["语义映射的兴趣激增",{"2":{"967":1}}],["语义映射的日益增长的文献",{"2":{"116":1}}],["语义映射表述",{"2":{"586":1}}],["语义映射需要是任务驱动的",{"2":{"462":1}}],["语义掩码",{"2":{"441":1}}],["语义和运动流",{"2":{"455":1}}],["语义和",{"2":{"384":1}}],["语义和物理",{"2":{"116":1}}],["语义注释",{"2":{"362":1}}],["语义编码",{"2":{"324":1}}],["语义压缩",{"0":{"294":1}}],["语义节点属性",{"2":{"262":1}}],["语义元素",{"2":{"209":1}}],["语义",{"0":{"209":1},"2":{"209":1,"285":1,"525":1,"967":1}}],["语义类别集合和目标体素网格分辨率",{"2":{"693":1}}],["语义类别集合和体素网格大小",{"2":{"532":1}}],["语义类别",{"0":{"769":1},"1":{"790":1},"2":{"178":1,"197":1,"218":1,"240":1,"262":1}}],["语义路径规划",{"0":{"939":1},"2":{"131":1}}],["语义重建的创建是实时的",{"2":{"973":1}}],["语义重建的影响",{"2":{"754":1}}],["语义重建的准确性和对动态元素的鲁棒性",{"2":{"605":1}}],["语义重建在uhumans数据集上的详细评估",{"2":{"541":1}}],["语义重建",{"0":{"362":1,"732":1},"2":{"131":1,"285":1,"510":1}}],["语义建图在多个维度仍面临关键开放问题",{"2":{"864":1}}],["语义建图领域最突出的难题之一",{"2":{"864":1}}],["语义建图必须满足严苛的实时性",{"2":{"864":1}}],["语义建图的分类体系为基准",{"2":{"209":1}}],["语义建图",{"2":{"123":1}}],["语义建图逐渐兴起",{"2":{"123":1}}],["语义网格后顺序运行",{"2":{"816":1}}],["语义网格重建的影响",{"2":{"709":1}}],["语义网格已经包含语义标签",{"2":{"449":1}}],["语义网格最终也使用游行立方体",{"2":{"362":1}}],["语义网格来识别结构",{"2":{"285":1}}],["语义网格构建dsg",{"2":{"285":1}}],["语义网格和代理节点是从传感器数据中实时增量构建的",{"2":{"285":1}}],["语义网格中分割对象实例需要几分钟",{"2":{"816":1}}],["语义网格中提取静态对象的模块",{"2":{"449":1}}],["语义网格中属于该对象的相应点集",{"2":{"178":1}}],["语义网格中已知形状的物体上",{"2":{"131":1}}],["语义网格包括环境中的所有静态元素",{"2":{"162":1}}],["语义网格解析为地点",{"2":{"131":1}}],["语义网格",{"0":{"162":1},"2":{"131":3,"147":1,"162":1,"285":6,"709":1,"816":1}}],["语义网格或体积模型",{"2":{"116":1}}],["语义网格模型和对代理的丰富描述",{"2":{"905":1}}],["语义网格模型",{"2":{"105":1}}],["语义理解",{"2":{"116":1}}],["语义3d网格",{"2":{"168":1}}],["语义3d地图中包含的语义概念的正确粒度",{"2":{"137":1}}],["语义3d地图",{"2":{"109":1}}],["语义3d重建",{"2":{"105":1}}],["语义概念",{"2":{"98":1}}],["语义地图必须保留物体之间精确的",{"2":{"913":1}}],["语义地图需",{"2":{"864":1}}],["语义地图可按以下四种方式组织",{"2":{"465":1}}],["语义地图可按结构划分为空间网格地图",{"2":{"378":1}}],["语义地图针对物理世界中的某一三维位置",{"2":{"406":1}}],["语义地图中",{"2":{"378":1}}],["语义地图正是这样一种超越几何",{"2":{"350":1}}],["语义地图正是承担这一角色的关键工具",{"2":{"90":1}}],["语义地图",{"0":{"324":1},"1":{"350":1,"378":1,"406":1,"435":1},"2":{"897":1}}],["语义地图能够提升",{"2":{"209":1}}],["语义地图能够以结构化的方式捕捉环境信息",{"2":{"80":1}}],["语义地图构建提供背景",{"2":{"100":1}}],["语义地图构建仍是一个开放且快速发展的研究领域",{"2":{"90":1}}],["语义地图被限制在数十或数百个语义类别",{"2":{"98":1}}],["语义地图在机器人学和具身智能中具有基础性地位",{"2":{"90":1}}],["语言特征之间的l2均方误差作为模态对齐损失",{"2":{"988":1}}],["语言特征进行任务感知场景理解",{"2":{"153":1}}],["语言预训练模型提取特征",{"2":{"721":1}}],["语言预训练模型和开放词汇检测器的出现",{"2":{"274":1}}],["语言条件策略形式化验证",{"2":{"538":1}}],["语言条件vlm策略在零样本泛化至新目标",{"2":{"128":1}}],["语言落地语料在推进vla4ad能力中的关键作用",{"2":{"538":1}}],["语言落地解释",{"2":{"216":1}}],["语言理解与控制间循环",{"2":{"538":1}}],["语言理解与动作生成集成至单一可微分网络",{"2":{"283":1}}],["语言理解与动作生成",{"2":{"195":1}}],["语言接地",{"2":{"525":1}}],["语言推理增添语境",{"2":{"478":1}}],["语言保真度",{"2":{"447":1}}],["语言能力",{"2":{"447":1}}],["语言能力受限",{"2":{"114":1}}],["语言提示与控制token",{"2":{"417":1}}],["语言线索用于动态选择子规划器",{"2":{"283":1}}],["语言从被动场景描述演进为模块化架构内的主动规划组件",{"2":{"283":1}}],["语言仅为叠加而非决策核心部分",{"2":{"260":1}}],["语言集成方式",{"2":{"238":1}}],["语言处理器",{"2":{"195":1}}],["语言输入输出开始直接为规划决策提供信息",{"2":{"283":1}}],["语言输入",{"2":{"176":1}}],["语言指令常被表示为初始不确定的图",{"2":{"525":1}}],["语言指令",{"2":{"145":1}}],["语言与动作驱动的透明",{"2":{"538":1}}],["语言与动作",{"2":{"145":1}}],["语言与动作成为自动驾驶新趋势",{"2":{"145":1}}],["语言与动作如何汇聚以塑造下一代透明",{"2":{"82":1}}],["语言和动作",{"2":{"139":1}}],["语言导航",{"2":{"139":1}}],["语言等",{"2":{"110":1}}],["语言等方式理解世界",{"2":{"100":1}}],["语言基础模型来实现开放集的语义理解",{"2":{"109":1}}],["语言模型作为解释器",{"0":{"260":1}}],["语言模型将这些指令与视觉数据关联起来",{"2":{"137":1}}],["语言模型的进步以前所未有地将视觉信息和文本描述结合起来",{"2":{"137":1}}],["语言模型",{"2":{"82":1,"92":1,"109":1,"121":3,"274":1,"334":1,"765":1}}],["语言",{"2":{"62":1,"72":1,"92":1,"478":1,"507":2,"538":1}}],["断开连接",{"2":{"77":1}}],["断开与当前",{"0":{"77":1}}],["下相较于仅使用摄像头的基线展现出显著的性能提升",{"2":{"914":1}}],["下标访问",{"2":{"904":1}}],["下标的差异仅表示智能体在连续探索当前场景时位置和视角的变化",{"2":{"682":1}}],["下游任务集成",{"2":{"926":1}}],["下游任务表现",{"2":{"881":1}}],["下游推理与泛化",{"2":{"864":1}}],["下游控制通过",{"2":{"195":1}}],["下进行评估",{"2":{"853":1}}],["下的可视化结果",{"2":{"847":1}}],["下一节将专门讨论",{"2":{"806":1}}],["下一代研究可能将vla4ad范围从原型策略扩展至可扩展",{"2":{"507":1}}],["下一代机器人和自主系统将需要实时构建未知环境的持久性高级表示",{"2":{"125":1}}],["下一代机器人必须能够理解和执行高级指令",{"2":{"116":1}}],["下采样操作获得",{"2":{"789":1}}],["下采样是邻域32个点",{"2":{"589":1}}],["下面",{"2":{"1000":1}}],["下面将详细解释",{"2":{"735":1}}],["下面两三步复制粘贴的事",{"2":{"76":1}}],["下次回到这个场景或再次探索时",{"2":{"728":1}}],["下划线",{"2":{"700":1}}],["下文将结合图示",{"2":{"675":1}}],["下卷积的采样中心是基本一致的",{"2":{"589":1}}],["下",{"2":{"503":2,"622":1}}],["下降",{"2":{"352":1}}],["下收敛速度慢",{"2":{"345":1}}],["下个路口左转",{"2":{"176":1}}],["下图直观地体现了这个过程",{"2":{"287":1}}],["下图中分为三个部分",{"2":{"181":1}}],["下图",{"2":{"149":1}}],["下载安装",{"2":{"76":1}}],["下载源码",{"2":{"40":1}}],["下载对应版本",{"2":{"36":1}}],["下载",{"2":{"27":1,"32":1,"38":1,"58":1,"107":1}}],["强监督的cam4docc",{"2":{"1003":1}}],["强监督学习用于占用感知",{"2":{"985":1}}],["强监督训练虽然直接且有效",{"2":{"988":1}}],["强监督训练",{"0":{"985":1}}],["强化学习",{"2":{"417":1}}],["强调精度与回环闭合",{"2":{"588":1}}],["强调条件推理",{"2":{"360":1}}],["强调了它们作为不断发展的研究方向的演变",{"2":{"100":1}}],["强调同时衡量驾驶安全性",{"2":{"72":1}}],["强制结果在用户交互的部分具有正确的结果",{"2":{"75":1}}],["修复和语义合成等密集条件任务",{"2":{"552":1}}],["修复",{"2":{"552":1}}],["修修补补",{"2":{"106":1}}],["修正",{"2":{"75":1}}],["修改后的3d占用记录了3d位置信息",{"2":{"963":1}}],["修改cv",{"2":{"107":1}}],["修改sshd",{"2":{"78":1}}],["修改",{"2":{"67":1}}],["修改名字",{"2":{"24":1}}],["进而产生更强的特征表达能力",{"2":{"863":1}}],["进而可用于在该位置渲染可能的视角",{"2":{"721":1}}],["进而有助于实现更精确的占据预测",{"2":{"666":1}}],["进而在信息瓶颈框架下进行任务相关的聚类和压缩",{"2":{"271":1}}],["进而使",{"2":{"129":1}}],["进一步轻量化了flashocc",{"2":{"1004":1}}],["进一步应用三边平稳条件随机场来强制一致性",{"2":{"962":1}}],["进一步使用基于",{"2":{"955":1}}],["进一步使我们能够研究计算机视觉算法在不同地点",{"2":{"126":1}}],["进一步消除了对标签和lidar数据的需求",{"2":{"949":1}}],["进一步减少频繁实时更新的计算量",{"2":{"935":1}}],["进一步展示我们局部空间占用预测模块的视觉效果",{"2":{"902":1}}],["进一步展示了我们方法的优越性能",{"2":{"791":1}}],["进一步细化这三组tpv",{"2":{"898":1}}],["进一步加剧难度",{"2":{"864":1}}],["进一步增强了视觉特征在占用预测中的表示能力",{"2":{"858":1}}],["进一步探索了3d占用预测任务的新设计和优化",{"2":{"839":1}}],["进一步探索了通过引入",{"2":{"678":1}}],["进一步扩展了tpvformer的时间融合能力",{"2":{"858":1}}],["进一步扩展",{"2":{"765":1}}],["进一步合并",{"2":{"746":1}}],["进一步推理占用体素的语义类别",{"2":{"667":1}}],["进一步缩小了性能差距",{"2":{"665":1}}],["进一步提出了一种半自动标签生成管道",{"2":{"735":1}}],["进一步提出利用关系评分模块学习三维点云与其多视图之间的关系",{"2":{"664":1}}],["进一步提取地点的拓扑图",{"2":{"285":1}}],["进一步表明",{"2":{"662":1}}],["进一步优化了特征融合模块的内部结构",{"2":{"625":1}}],["进一步用于将每个体素内的点分布映射到紧凑的潜在空间",{"2":{"962":1}}],["进一步用",{"2":{"619":1}}],["进一步得到rulebook",{"2":{"561":1}}],["进一步处理三维特征以预测三维场景的占用情况",{"2":{"544":1}}],["进一步",{"2":{"495":1,"898":1}}],["进一步说",{"2":{"407":1}}],["进一步观察到这些项都是基于变形图中的边",{"2":{"390":1}}],["进一步将训练周期减少到",{"2":{"959":1}}],["进一步将bev范围扩展到",{"2":{"800":1}}],["进一步将两个点云变成不同的视角加大任务的难度",{"2":{"339":1}}],["进一步将其制定为封闭形式的易处理表达式",{"2":{"314":1}}],["进一步包括三个关键模块",{"2":{"285":1}}],["进一步利用",{"2":{"252":1}}],["进一步引入了占用流",{"2":{"941":1}}],["进一步引入了卷积占用网络",{"2":{"665":1}}],["进一步引入",{"2":{"189":1}}],["进一步发展引入任务级语言规范",{"2":{"176":1}}],["进展综述",{"2":{"138":1}}],["进行加速",{"2":{"1001":1}}],["进行加权",{"2":{"762":1}}],["进行处理",{"2":{"970":1,"976":1}}],["进行更广泛的回顾",{"2":{"967":1}}],["进行更新",{"2":{"728":1}}],["进行时间信息融合",{"2":{"957":1}}],["进行层次语义路径规划",{"2":{"947":1}}],["进行投影",{"2":{"928":1}}],["进行投影的效果",{"2":{"928":1}}],["进行3d语义占用预测的方法",{"2":{"875":1}}],["进行3d感知一直是各公司争论的核心问题",{"2":{"547":1}}],["进行归一化",{"2":{"863":1}}],["进行端到端的训练",{"2":{"834":1}}],["进行端到端监督",{"2":{"532":1}}],["进行模型训练",{"2":{"771":1}}],["进行训练",{"2":{"766":1,"770":1,"884":1}}],["进行监督",{"2":{"752":1}}],["进行了分类",{"2":{"958":1}}],["进行了定性分析",{"2":{"952":1}}],["进行了关于",{"2":{"882":1}}],["进行了对比",{"2":{"832":1}}],["进行了比较",{"2":{"745":1,"870":1,"928":1}}],["进行了问题1描述的取整",{"2":{"554":1}}],["进行压缩",{"2":{"676":1}}],["进行反向投影",{"2":{"660":1}}],["进行外积操作",{"2":{"649":1}}],["进行深度监督",{"2":{"621":1}}],["进行自动标注",{"2":{"617":1}}],["进行特征级融合",{"2":{"578":1}}],["进行",{"2":{"570":1,"816":1}}],["进行比较",{"2":{"522":1,"827":1}}],["进行损失计算",{"2":{"499":1}}],["进行构建",{"2":{"467":1}}],["进行优先级排序",{"2":{"466":1}}],["进行编码和解码",{"2":{"440":1}}],["进行里程计估计",{"2":{"437":1}}],["进行视觉",{"2":{"437":1}}],["进行2d语义分割",{"2":{"437":1}}],["进行融合",{"2":{"435":1,"942":2}}],["进行联合训练会有一个比较好的结果",{"2":{"394":1}}],["进行插值",{"2":{"380":1}}],["进行变换可以得到一张变换后的图片",{"2":{"355":1}}],["进行连接操作",{"2":{"351":1}}],["进行对比学习训练",{"2":{"339":1}}],["进行推理减少了环境中杂物的影响",{"2":{"301":1}}],["进行标注",{"2":{"277":1}}],["进行采样",{"2":{"277":1,"950":1}}],["进行强化学习",{"2":{"274":1}}],["进行规划",{"2":{"262":1}}],["进行mcmc采样",{"2":{"256":1}}],["进行替换即可",{"2":{"204":1}}],["进行排序",{"2":{"196":1}}],["进行表达",{"2":{"191":1}}],["进行地点识别",{"2":{"190":1}}],["进行数据关联与特征分类",{"2":{"189":1}}],["进行分类与包围框的修正",{"2":{"250":1}}],["进行分类",{"2":{"169":1,"209":1}}],["进行解耦",{"2":{"149":1}}],["进行校准",{"2":{"136":1}}],["进行相机标定",{"2":{"136":1}}],["进行参数化",{"2":{"131":1,"412":1,"967":1}}],["进行修正",{"2":{"75":1}}],["进入房间即新建局部度量图",{"2":{"648":1}}],["进入驱动目录",{"2":{"66":1}}],["进入硬盘",{"2":{"24":1}}],["服务自动驾驶",{"2":{"588":1}}],["服务",{"2":{"74":1}}],["本材料基于由国防研究与工程副部长办公室支持的工作",{"2":{"973":1}}],["本研究工作在香港赛马会慈善信托基金资助的jc",{"2":{"1008":1}}],["本研究部分得到了国家自然科学基金",{"2":{"980":1}}],["本研究提出了",{"2":{"977":1}}],["本研究提出了occcylindrical",{"2":{"898":1}}],["本研究考察了动态融合",{"2":{"971":1}}],["本研究使用了",{"2":{"960":1}}],["本研究通过连接它们的特征通道来合并两个",{"2":{"829":1}}],["本报告描述了我们在cvpr",{"2":{"845":1}}],["本体驱动消息集",{"2":{"507":1}}],["本技术报告总结了在cvpr",{"2":{"490":1}}],["本质上提供了3d空间的俯视投影",{"2":{"858":1}}],["本质上是病态的",{"2":{"482":1}}],["本质上",{"2":{"431":1}}],["本质还是估计",{"2":{"170":1}}],["本节总结了第",{"2":{"951":1}}],["本节介绍了解决3d场景占用估计中计算挑战的方法",{"2":{"892":1}}],["本节介绍了用于自动驾驶环境中感知的各种传感器融合算法的最新研究成果",{"2":{"533":1}}],["本节梳理了语义建图当前的挑战",{"2":{"881":1}}],["本节还提供了进一步的消融实验",{"2":{"876":1}}],["本节从多个维度归纳如下",{"2":{"864":1}}],["本节对评估的关键挑战与未来方向进行总结",{"2":{"846":1}}],["本节讨论",{"2":{"826":1}}],["本节讨论语义地图如何",{"2":{"675":1}}],["本节概述了用于评估具身任务中智能体表现的外部",{"2":{"806":1}}],["本节中呈现的所有实验均训练了15个epoch",{"2":{"800":1}}],["本节详细阐述了基于视觉的3d占用预测领域的任务定义",{"2":{"689":1}}],["本节将详细介绍这些网络训练技术及其相关的损失函数",{"2":{"981":1}}],["本节将详细介绍我们的解决方案",{"2":{"551":1}}],["本节将深入探讨先前工作中采用的各种地图结构",{"2":{"465":1}}],["本节展示了hydra能够实时构建3d场景图",{"2":{"437":1}}],["本节简要概述这两种范式",{"2":{"231":1}}],["本节简要概述了机器人学与具身智能中的具身任务",{"2":{"110":1}}],["本节描述了如何检测环路闭合",{"2":{"326":1}}],["本节描述了如何根据机器人轨迹的里程计估计",{"2":{"210":1}}],["本节描述了kimera",{"2":{"285":1}}],["本节描述了clio",{"2":{"168":1}}],["本节给出vla4ad基本架构",{"2":{"160":1}}],["本综述的主要贡献有三点",{"2":{"714":1}}],["本综述中的研究列表可在持续收集最新工作的公开存储库中找到",{"2":{"610":1}}],["本综述主要关注面向导航的房间级地图构建的最新研究",{"2":{"139":1}}],["本综述还建立了与基于slam",{"2":{"90":1}}],["本综述以室内移动机器人为背景",{"2":{"90":1}}],["本综述沿着两个基本轴对文献进行了分类",{"2":{"90":1}}],["本综述为可解释",{"2":{"72":1}}],["本文对近年来自动驾驶中的3d占用感知进行了全面综述",{"2":{"1007":1}}],["本文中表达的任何意见",{"2":{"973":1}}],["本文中的算法能够检测房间",{"2":{"467":1}}],["本文开辟了几个研究方向",{"2":{"973":1}}],["本文是第一个尝试执行视觉",{"2":{"967":1}}],["本文是第一个专门针对自动驾驶中基于视觉的3d占用预测方法的全面综述",{"2":{"665":1}}],["本文还涉及对场景中动态元素的建模和鲁棒性",{"2":{"967":1}}],["本文还提出了一种端到端无监督的深度自编码网络",{"2":{"574":1}}],["本文主要讨论了以最小标签和计算成本训练占据网络的最小工作流程设计",{"2":{"862":1}}],["本文从特征增强",{"2":{"665":1}}],["本文首先介绍了基于视觉的3d占用预测的背景",{"2":{"637":1}}],["本文首次全面综述面向自动驾驶的视觉",{"2":{"538":1}}],["本文首次给出面向自动驾驶的vla",{"2":{"72":1}}],["本文旨在通过整合环视相机",{"2":{"724":1}}],["本文旨在利用自动驾驶车辆上的环视摄像头和激光雷达传感器",{"2":{"590":1}}],["本文旨在为当前和未来的研究者提供指导",{"2":{"80":1}}],["本文工作的关键贡献是针对不规则和非均匀结构定制的卷积和池化操作的定义和应用",{"2":{"589":1}}],["本文介绍了pointgpt",{"2":{"643":1}}],["本文介绍了occfusion",{"2":{"475":1}}],["本文介绍了hydra",{"2":{"467":1}}],["本文件中的视图和结论是作者的观点",{"2":{"467":1}}],["本文针对检测",{"2":{"454":1}}],["本文利用这个过程来进行训练",{"2":{"410":1}}],["本文为什么这样构建",{"2":{"351":1}}],["本文为csdn博主",{"2":{"41":1,"48":1,"220":1,"351":1}}],["本文提出的daocc的整体框架如图2所示",{"2":{"576":1}}],["本文提出的petrv2框架示意图",{"2":{"550":1}}],["本文提出的",{"2":{"502":1}}],["本文提出了一些启发性的未来展望",{"2":{"665":1}}],["本文提出了一种直接在不规则三角网格上使用神经网络的通用方法meshcnn",{"2":{"589":1}}],["本文提出了一种高效占据学习框架",{"2":{"425":1}}],["本文提出了一种名为occcylindrical的方法",{"2":{"409":1}}],["本文提出了一种基于",{"2":{"349":1}}],["本文提出了一个统一",{"2":{"306":1}}],["本文提出了一个iterative",{"2":{"289":1}}],["本文提供了四项贡献",{"2":{"131":1}}],["本文提供了一个系统性的回顾",{"2":{"90":1}}],["本文系统梳理了近期方法如何组织地图结构",{"2":{"274":1}}],["本文的结构如下",{"2":{"665":1}}],["本文的作者就提出了",{"2":{"631":1}}],["本文的其余部分结构如下",{"2":{"438":1,"503":1,"714":1}}],["本文的主要贡献如下",{"2":{"665":1}}],["本文的主要贡献总结如下",{"2":{"438":1,"503":1}}],["本文的主要动机是克服这些挑战",{"2":{"141":1}}],["本文的成功可以推动更多在相关方面的研究",{"2":{"265":1}}],["本文的第一贡献是提出了一个任务驱动的3d场景理解问题",{"2":{"98":1}}],["本文将我们之前关于kimera",{"2":{"131":1}}],["本文描述了一个实时空间感知系统",{"2":{"112":1}}],["本文试图通过引入一种新的表示方法",{"2":{"105":1}}],["本文结构如下",{"2":{"90":1}}],["准确的3d占据预测需要在三个维度上进行体素感知表示",{"2":{"811":1}}],["准确理解三维场景是具身智能体的一个不可或缺的能力",{"2":{"629":1}}],["准确理解周围环境对于安全高效的导航至关重要",{"2":{"421":1}}],["准确率",{"2":{"447":1,"732":1}}],["准确性",{"2":{"686":1,"826":2,"943":1}}],["准确性评估",{"2":{"437":2}}],["准确性与解释质量的协议",{"2":{"72":1}}],["准确",{"2":{"435":1}}],["准备",{"0":{"32":1,"38":1}}],["准备数据集",{"0":{"25":1},"1":{"32":1,"38":1}}],["追溯从早期解释器到以推理为核心的vla模型的演进",{"2":{"72":1}}],["然而在纯视觉3d感知领域",{"2":{"617":1}}],["然而在某些情况下",{"2":{"227":1}}],["然而",{"2":{"72":1,"82":1,"90":1,"103":1,"109":2,"114":4,"252":2,"260":1,"283":1,"289":1,"349":1,"392":1,"419":1,"420":1,"421":1,"437":1,"438":1,"444":3,"471":1,"474":1,"475":1,"482":3,"488":1,"503":1,"505":1,"520":1,"525":2,"535":2,"544":1,"547":1,"548":1,"549":1,"553":1,"564":1,"566":1,"567":3,"570":2,"588":1,"591":1,"596":1,"599":5,"600":1,"609":1,"610":1,"612":3,"625":1,"629":2,"632":1,"638":1,"648":1,"655":1,"660":1,"665":1,"667":1,"682":1,"688":1,"691":1,"698":1,"704":1,"714":1,"735":1,"757":1,"759":2,"765":1,"786":1,"796":1,"803":1,"811":2,"826":4,"828":1,"860":1,"864":1,"865":1,"872":1,"882":1,"893":1,"923":1,"927":1,"941":1,"944":1,"949":1,"950":3,"953":1,"955":1,"957":1,"962":1,"963":1,"967":1,"969":1,"970":1,"974":1,"976":1,"988":1,"989":1,"992":1,"996":1,"997":2,"1000":4,"1003":2,"1004":1,"1005":1,"1006":1}}],["然后与点云特征融合",{"2":{"970":1}}],["然后进一步抽象为一个概念图",{"2":{"961":1}}],["然后进行流预测得到优化后的深度图",{"2":{"618":1}}],["然后进行排序以确定这些中心点的顺序o",{"2":{"426":1}}],["然后作为残差添加到查询特征中",{"2":{"957":1}}],["然后作者说这种层级式的结构不仅非常灵活",{"2":{"631":1}}],["然后按照nerf风格将其渲染为2d深度图",{"2":{"941":1}}],["然后逐步细化和恢复整个场景的细粒度表示",{"2":{"922":1}}],["然后用于学习3d场景的全面表示",{"2":{"875":1}}],["然后为每个2d候选区域提取3d视锥",{"2":{"818":1}}],["然后对所有类别的iou取平均值",{"2":{"998":1}}],["然后对每个输入图像进行归一化",{"2":{"761":1}}],["然后对特征进行加权融合",{"2":{"386":1}}],["然后根据给定的置信度阈值",{"2":{"957":1}}],["然后根据体素内点的语义标签通过投票生成3d占用预测的真实标签",{"2":{"735":1}}],["然后根据全局平均池和完全连接层生成分类分数",{"2":{"574":1}}],["然后编码点云作为到基点集的最小距离",{"2":{"664":1}}],["然后优化核位置和核大小",{"2":{"664":1}}],["然后优化机器人的姿态",{"2":{"390":1}}],["然后都是重复堆叠swin",{"2":{"659":1}}],["然后就是通过四个stage构建不同大小的特征图",{"2":{"659":1}}],["然后每个像素有r",{"2":{"659":1}}],["然后计算核与给定点邻域间的亲和力",{"2":{"574":1}}],["然后直接在表面几何上操作切线卷积",{"2":{"955":1}}],["然后直接从每块中找到最大值",{"2":{"554":1}}],["然后直行",{"2":{"283":1}}],["然后是两个完全连接的层",{"2":{"526":1}}],["然后是外观描述符",{"2":{"352":1}}],["然后利用网格顶点和姿态图中的姿态之间的关系",{"2":{"967":1}}],["然后利用标准",{"2":{"962":1}}],["然后利用摄像头的内参和外参矩阵将图像特征映射到3d空间",{"2":{"821":1}}],["然后利用该图规划到最相似目标节点的路径",{"2":{"525":1}}],["然后利用基于pointnet提取全局特征",{"2":{"420":1}}],["然后被指派导航到并抓取与提供的自然语言提示匹配的对象",{"2":{"522":1}}],["然后基于方差求匹配代价",{"2":{"464":1}}],["然后区域掩码同时适用于",{"2":{"455":1}}],["然后下另一楼梯重新访问音乐室和公共休息室",{"2":{"437":1}}],["然后从2d特征中恢复3d结构",{"2":{"693":1}}],["然后从观测中提取语义信息",{"2":{"435":1}}],["然后从中生成图像",{"2":{"205":1}}],["然后应用卷积层来融合信息",{"2":{"976":1}}],["然后应用平均池化操作以获得全局",{"2":{"809":1}}],["然后应用",{"2":{"666":1,"962":1}}],["然后应用雷达加权反向投影进行中期特征融合",{"2":{"497":1}}],["然后应用二维卷积来获得统一的鸟瞰图",{"2":{"421":1}}],["然后应用基础模型",{"2":{"109":1}}],["然后适当地链接它们",{"2":{"419":1}}],["然后随时间跟踪人类",{"2":{"419":1}}],["然后归一化以总和为一",{"2":{"390":1}}],["然后解决一个优化问题",{"2":{"380":1}}],["然后解压为3rscan",{"2":{"32":1}}],["然后通过双线性插值",{"2":{"950":1}}],["然后通过结合从这些不同视图中获得的见解来恢复完整的3d占用信息",{"2":{"908":1}}],["然后通过视角变换获得bev特征",{"2":{"839":1}}],["然后通过人工增强细化标签",{"2":{"757":1}}],["然后通过我们新提出的方法对结果高斯进行聚合",{"2":{"704":1}}],["然后通过",{"2":{"592":1}}],["然后通过上图所示的多模态占据预测网络进行特征提取",{"2":{"576":1}}],["然后通过max",{"2":{"574":1}}],["然后通过插值获得所有体素特征",{"2":{"566":1}}],["然后通过插值重建场景图的其他节点",{"2":{"380":1}}],["然后通过depthnet处理以生成最终的深度分布",{"2":{"544":1}}],["然后通过卷积maxpooling卷积结构对球面格顶点及其领域连接的特征进行卷积",{"2":{"511":1}}],["然后通过高效的高斯到体素绘制模块来预测语义占据",{"2":{"444":1}}],["然后通过共享的编码器",{"2":{"438":1}}],["然后通过对象注册计算环路闭合姿态",{"2":{"190":1}}],["然后场景图后端",{"2":{"380":1}}],["然后超点池化层将同质相邻点分组为超点特征s",{"2":{"377":1}}],["然后分别对两个点云进行编码",{"2":{"339":1}}],["然后分别对x1和x2进行随机刚体变换t1和t2",{"2":{"339":1}}],["然后聚合这些视图以获得有判别性的三维对象表示",{"2":{"337":1}}],["然后混合这些特征来以进行准确的形状分类",{"2":{"337":1}}],["然后将占用表示应用于广泛的驾驶任务",{"2":{"1003":1}}],["然后将组合数据输入卷积层",{"2":{"976":1}}],["然后将过滤后的输出插值回原始点云",{"2":{"962":1}}],["然后将中间分割结果投影回原始图像点云",{"2":{"948":1}}],["然后将它们合并为一个完整的场景",{"2":{"850":1}}],["然后将其用于3d检测",{"2":{"1003":1}}],["然后将其锚定在一起",{"2":{"961":1}}],["然后将其拆分为n=∣m∣n",{"2":{"752":1}}],["然后将其体素化",{"2":{"735":1}}],["然后将其作为输入提供给graphcmr",{"2":{"419":1}}],["然后将稀疏",{"2":{"670":1}}],["然后将每个波束反馈到共享的rnn中",{"2":{"664":1}}],["然后将每个3d点投影到深度感知上下文特征上以聚合语义信息",{"2":{"621":1}}],["然后将这些中间数据馈送到全3d",{"2":{"962":1}}],["然后将这些图像特征提升到三视角空间",{"2":{"858":1}}],["然后将这些特征进一步输入到多个独立的卷积层中",{"2":{"664":1}}],["然后将这些点patches按顺序排序和排列",{"2":{"315":1}}],["然后将",{"2":{"599":1}}],["然后将得到的feature",{"2":{"296":1}}],["然后将下载的场景放入名为",{"2":{"32":1}}],["然后到城市",{"2":{"262":1}}],["然后我们将这些高斯分布分离出来并放回高斯记忆中",{"2":{"728":1}}],["然后我们将这些深度感知特征",{"2":{"705":1}}],["然后我们将高斯集合",{"2":{"681":1}}],["然后我们通过dijkstra算法计算通过地点节点到达目标对象的最短路径",{"2":{"522":1}}],["然后我们通过插值重建图的其他部分",{"2":{"380":1}}],["然后我们使用在单目设置中训练好的局部空间占用预测模块来训练我们的embodiedocc模型",{"2":{"750":1}}],["然后我们使用",{"2":{"681":1}}],["然后我们使用检索到的地点的房间id为当前墙壁网格顶点的房间标签进行投票",{"2":{"480":1}}],["然后我们使用相机模型将人类网格顶点投影到图像帧中",{"2":{"419":1}}],["然后我们定义",{"2":{"390":1}}],["然后我们重新计算对象的质心和边界框",{"2":{"380":1}}],["然后我们建立一个图",{"2":{"372":1}}],["然后我们",{"2":{"352":1}}],["然后我们循环遍历多帧网格顶点",{"2":{"336":1}}],["然后我们计算连通分量的中位数数量nr",{"2":{"301":1}}],["然后我们展示表示是组合的",{"2":{"262":1}}],["然后我们提出了第一个算法",{"2":{"112":1}}],["然后再进行额外的表面细化步骤",{"2":{"372":1}}],["然后再通过超分辨模型将图像分辨率提升至256x256和1024x1024",{"2":{"205":1}}],["然后再使用一个额外的神经网络来产生更大分辨率的图像",{"2":{"205":1}}],["然后在前景点上生成大量高质量的建议以节省计算量",{"2":{"798":1}}],["然后在体素网格上应用稀疏卷积",{"2":{"716":1}}],["然后在通过linear",{"2":{"659":1}}],["然后在channel方向展平",{"2":{"659":1}}],["然后在窗口里面去做自注意力",{"2":{"631":1}}],["然后在每一块中分别选择最大值放入6×6的对应区域中",{"2":{"554":1}}],["然后在空间域或者谱域中执行特征学习",{"2":{"542":1}}],["然后在城市环境中收集雷达测量数据",{"2":{"191":1}}],["然后在",{"2":{"181":1}}],["然后在图片上提出了约2000个待检测区域",{"2":{"169":1}}],["然后这2000个待检测区域一个一个地",{"2":{"169":1}}],["然后以",{"2":{"153":1}}],["然后提取区域特征来确定每个建议的类别标签",{"2":{"756":1}}],["然后提出一个增量版本的聚合ib算法以支持实时映射",{"2":{"153":1}}],["然后提炼通用架构模式",{"2":{"82":1}}],["然后点击",{"2":{"136":1}}],["然后可以使用clip的余弦相似度或llm来查询对象",{"2":{"121":1}}],["然后更新",{"2":{"66":1}}],["然后保存退出",{"2":{"48":1}}],["然后回车",{"2":{"48":1}}],["然后输入",{"2":{"41":1}}],["然后使用3d卷积和加权平均池来提取特征并合并长程依赖性",{"2":{"962":1}}],["然后使用全连接",{"2":{"962":1}}],["然后使用一组3d残差卷积块进行融合",{"2":{"957":1}}],["然后使用一组稀疏的3d体素查询来索引这些2d特征",{"2":{"875":1}}],["然后使用双线性采样从三个视图中获取特征",{"2":{"858":1}}],["然后使用多头注意力通过引入目标之间的交互来细化目标查询",{"2":{"623":1}}],["然后使用泊松盘采样来构建点云层次结构",{"2":{"481":1}}],["然后使用基于距离的加权插值进行网格对齐",{"2":{"941":1}}],["然后使用基于卷积的专门设计机制来桥接2d和3d表示",{"2":{"875":1}}],["然后使用基于",{"2":{"481":1}}],["然后使用基于视觉的环路闭合",{"2":{"437":1}}],["然后使用扩散去噪和层次化",{"2":{"474":1}}],["然后使用对称函数聚合全局特征",{"2":{"420":1}}],["然后使用图形卷积网络",{"2":{"372":1}}],["然后使用contrastive",{"2":{"339":1}}],["然后使用方程",{"2":{"271":1}}],["然后使用变形图方法",{"2":{"190":1}}],["然后使用条件随机场进行标记",{"2":{"172":1}}],["然后使用受社区检测技术启发的方法将地点分割成房间",{"2":{"112":1}}],["然后使用",{"2":{"31":1,"276":1}}],["然后",{"2":{"5":1,"32":1,"38":1,"109":1,"141":1,"153":1,"184":1,"206":2,"210":1,"228":1,"250":1,"253":1,"285":2,"336":1,"362":4,"369":1,"380":1,"384":1,"390":2,"396":1,"420":1,"426":1,"427":1,"441":1,"480":1,"502":1,"511":2,"527":1,"547":1,"549":1,"550":1,"568":1,"574":1,"583":1,"609":2,"628":1,"636":1,"664":1,"665":1,"669":1,"676":1,"693":1,"704":2,"716":3,"735":1,"738":2,"748":1,"752":1,"816":1,"829":1,"858":3,"886":1,"916":2,"922":2,"950":1,"955":2,"962":1}}],["该指标评估射线到其最近接触表面的表现",{"2":{"998":1}}],["该指标的值大致表示单个高斯的体积平均与其他高斯完全重叠的次数",{"2":{"916":1}}],["该损失依赖于对数差异而不是绝对差异",{"2":{"985":1}}],["该损失通常是分类损失",{"2":{"712":1}}],["该基准包括多样化的指标",{"2":{"975":1}}],["该基准测试比",{"2":{"739":1}}],["该项目由",{"2":{"960":1}}],["该研究是在",{"2":{"960":1}}],["该研究表明二元上下文先验对于",{"2":{"684":1}}],["该过程类似于多摄像头交叉注意力",{"2":{"957":1}}],["该过程如图6a所示",{"2":{"950":1}}],["该投影过程可以表示为",{"2":{"950":1}}],["该映射通过透视投影模型",{"2":{"950":1}}],["该映射无需显式监督",{"2":{"495":1}}],["该转换可以分为三种类型",{"2":{"950":1}}],["该转换旨在将前视特征转换为bev特征",{"2":{"950":1}}],["该技术利用二维分支的结果来增强三维分支的输出密度",{"2":{"923":1}}],["该技术正成为自动驾驶感知系统的一个趋势",{"2":{"610":1}}],["该集合中的一个体素中心以及高斯均值与体素中心之间的",{"2":{"916":1}}],["该集合实际上就是一个可学习的位置编码",{"2":{"333":1}}],["该表详细说明了每种方法的发表场所",{"2":{"877":1}}],["该表征无需任务特定监督",{"2":{"765":1}}],["该层学习n路体素到体素的语义场景关系图",{"2":{"875":1}}],["该层学习nnn元体素",{"2":{"684":1}}],["该算子在计算量与内存方面更为高效",{"2":{"863":1}}],["该算子集成了cnn的归纳偏置",{"2":{"863":1}}],["该算子弥补了常规卷积在长程依赖与自适应空域聚合方面的不足",{"2":{"863":1}}],["该算法在参数少",{"2":{"481":1}}],["该算法在多个下游任务上取得了最佳的表现效果",{"2":{"394":1}}],["该算法适用于不同的模型框架",{"2":{"394":1}}],["该编码器由tpv网格查询和2d图像特征之间的多个交叉注意力组成",{"2":{"858":1}}],["该思路已被成功应用于建图",{"2":{"765":1}}],["该网络根据环视rgb图像全面理解车辆周围的3d环境",{"2":{"759":1}}],["该网格将在下面的变形图方法中被优化",{"2":{"380":1}}],["该网格代表dsg的第一层",{"2":{"285":1}}],["该地图中的每个栅格都被分配一个值",{"2":{"759":1}}],["该地图可通过可微分操作构建",{"2":{"252":1}}],["该权重可以忽略不计",{"2":{"738":1}}],["该范围在",{"2":{"900":1}}],["该范围被离散化为体素",{"2":{"736":1}}],["该范式将视觉感知",{"2":{"72":1}}],["该问题可以表述为",{"2":{"724":1}}],["该向量由均值",{"2":{"705":1}}],["该分布是从占用注释中得出的",{"2":{"704":1}}],["该分数是由同一模型估计的",{"2":{"471":1}}],["该类方法可以通过稀疏的query来对移动的物体进行建模",{"2":{"695":1}}],["该类方法可分为点式mlp",{"2":{"391":1}}],["该类方法是将之前帧的bev特征通过warp操作来转换到当前帧",{"2":{"695":1}}],["该值随着与中心",{"2":{"681":1}}],["该组件插入在",{"2":{"632":1}}],["该任务需要密集特征",{"2":{"653":1}}],["该任务涉及预测一定范围内所有体素的占用和语义状态",{"2":{"612":1}}],["该任务的目标是根据一种或多种传感器的输入",{"2":{"599":1}}],["该函数独立地考虑每个体素",{"2":{"570":1}}],["该函数根据上一时刻姿态和控制输入预测下一时刻姿态",{"2":{"171":1}}],["该数据集主要包含轻度至中度降雨场景",{"2":{"936":1}}],["该数据集的一个关键挑战是训练",{"2":{"828":1}}],["该数据集的规模是nyuv2数据集的40倍",{"2":{"544":1}}],["该数据集提供了从语义标注的激光雷达点派生的语义占据标签",{"2":{"828":1}}],["该数据集提供了八个前景对象的额外流注释",{"2":{"757":1}}],["该数据集覆盖了x和y轴上",{"2":{"770":1}}],["该数据集最初使用增强和净化",{"2":{"757":1}}],["该数据集使用nuscenes训练集来训练模型",{"2":{"736":1}}],["该数据集还提供了激光雷达和相机模式的可见性掩码",{"2":{"736":1}}],["该数据集包括由六个环绕摄像头捕获的rgb图像和激光雷达点云",{"2":{"736":1}}],["该数据集涵盖了在自我坐标系中x和y方向的",{"2":{"736":1}}],["该数据集具有地面真实语义和几何形状",{"2":{"732":1}}],["该数据集在所有数据集中都提供无人机的地面真实定位",{"2":{"572":1}}],["该数据集以一架小型无人机在室内飞行",{"2":{"572":1}}],["该数据集模拟了一系列拥挤的室内和室外场景",{"2":{"105":1}}],["该笔记本电脑配备了intel",{"2":{"522":1}}],["该挑战通过在实际场景中为最新3d占据预测算法提供试验场",{"2":{"520":1}}],["该策略在训练开始时随机初始化高斯的属性",{"2":{"704":1}}],["该策略在预训练期间另外屏蔽了每个标记的一部分先前标记",{"2":{"518":1}}],["该策略旨在通过从鸟瞰图视角扩大感知范围来丰富空间上下文语义信息",{"2":{"576":1}}],["该策略使用地点节点可见的最近图像中的嵌入向量",{"2":{"522":1}}],["该策略提供了一个更大的bev视野范围",{"2":{"421":1}}],["该框架采用焦点损失",{"2":{"884":1}}],["该框架在共享的鸟瞰图表示空间中统一多模态特征",{"2":{"512":1}}],["该框架通过动态融合3d",{"2":{"503":1}}],["该框架的代码将在https",{"2":{"475":1}}],["该框架的关键步骤是一种带有",{"2":{"349":1}}],["该卷积算子可用于在两种或多种采样方法之间执行卷积",{"2":{"481":1}}],["该图显示了批量方法的运行时间随时间增加而增加",{"2":{"437":1}}],["该因子模拟人类运动的零速度先验",{"2":{"419":1}}],["该特征富含空间信息",{"2":{"971":1}}],["该特征强度作为边折叠的l2范数",{"2":{"466":1}}],["该特征点真实深度就越可能是",{"2":{"411":1}}],["该特征是所有输入图像中节点中心可见的clip嵌入的平均值",{"2":{"228":1}}],["该点物体的类别等",{"2":{"406":1}}],["该物体的信息会被写入对应的网格单元",{"2":{"378":1}}],["该结构利用几个浅八叉树结构来表示三维场景",{"2":{"363":1}}],["该节点与",{"2":{"352":1}}],["该阶段将点云划分为不规则的点块",{"2":{"340":1}}],["该演进指向自动驾驶车辆作为会话式",{"2":{"334":1}}],["该论文的目标是提出一个基于transformer的模型",{"2":{"331":1}}],["该论文要解决的问题是点云分割的问题",{"2":{"331":1}}],["该论文取得了较大的提升",{"2":{"106":1}}],["该gvd体素具有最大偏差",{"2":{"276":1}}],["该公式允许vla模型在更长时域内进行推理并更有效地集成多模态语境",{"2":{"216":1}}],["该目标由三个带有已知图案的正交平面组成",{"2":{"191":1}}],["该方案展示了顶尖模型设计在bev感知中的卓越表现",{"2":{"845":1}}],["该方案将前一次迭代估计的对象边缘作为先验信息",{"2":{"96":1}}],["该方法直接应用基于点的网络从稀疏采样的点集中提取局部几何特征和全局上下文",{"2":{"968":1}}],["该方法直接从单个图像中回归smpl",{"2":{"419":1}}],["该方法还可以灵活地联合处理多视点图像和点云",{"2":{"962":1}}],["该方法通过限制卷积的输出仅与占用的体素相关",{"2":{"962":1}}],["该方法通过引入可解释语言中间步骤提升规划过程透明度与灵活性",{"2":{"283":1}}],["该方法可以处理大规模点云",{"2":{"962":1}}],["该方法引入了确定性三线性插值",{"2":{"962":1}}],["该方法的性能受到体素的粒度和点云划分引起的边界伪影的严重限制",{"2":{"962":1}}],["该方法的参数可以设置为适用于各种环境",{"2":{"301":1}}],["该方法具有很强的可扩展性",{"2":{"955":1}}],["该方法利用全卷积神经网络的可扩展性",{"2":{"962":1}}],["该方法利用预训练的开词汇语义分割模型生成2d语义标签",{"2":{"949":1}}],["该方法利用体素查询从多帧和多视图图像中聚合时空信息",{"2":{"922":1}}],["该方法利用嵌入式变形图在单次运行中优化环境和机器人轨迹",{"2":{"390":1}}],["该方法首先将原始点云插值到全面体稀疏晶格",{"2":{"962":1}}],["该方法首先将每个点周围的局部表面几何形状投影到虚拟切平面",{"2":{"955":1}}],["该方法首先将环绕视图输入2d骨干网络以提取多尺度图像特征",{"2":{"875":1}}],["该方法首先通过将稀疏雷达点云投影到环视视觉特征上进行早期特征融合",{"2":{"497":1}}],["该方法仅对每个体素聚合邻近的高斯分布",{"2":{"861":1}}],["该方法仅聚合特定位置的邻近高斯分布",{"2":{"516":1}}],["该方法显著增强了物体边界的形状",{"2":{"735":1}}],["该方法鼓励高斯的更高利用率",{"2":{"704":1}}],["该方法使用3d语义高斯分布自适应地描述兴趣区域",{"2":{"669":1}}],["该方法使用多个多层感知机",{"2":{"420":1}}],["该方法对点云的各个部分进行了随机重组",{"2":{"664":1}}],["该方法不需要离线计算图的拉普拉斯矩阵和图的粗化层次",{"2":{"607":1}}],["该方法以低阶旋转不变性的几何特征作为输入",{"2":{"511":1}}],["该方法在3d语义占据预测和3d目标检测任务上均取得了显著的性能表现",{"2":{"497":1}}],["该方法在柱坐标系下对不同模态的特征进行合并和细化",{"2":{"409":1}}],["该方法在几何地图上叠加",{"2":{"209":1}}],["该方法证明了",{"2":{"394":1}}],["该方法涉及迭代地尝试将图中的每个节点分配给社区",{"2":{"301":1}}],["该方法将任务相关聚类",{"2":{"153":1}}],["该机制可以变形度量",{"2":{"131":1}}],["该模拟器提供传感器流",{"2":{"605":1}}],["该模块利用k近邻",{"2":{"976":1}}],["该模块识别包含点云和视觉信息的体素",{"2":{"976":1}}],["该模块仅使用局部聚合操作将3d高斯表示高效地转换为3d语义占用预测",{"2":{"738":1}}],["该模块结合对齐特征及其时间上下文",{"2":{"726":1}}],["该模块由图像主干网络",{"2":{"704":1}}],["该模块沿通道维度执行简单的重塑操作",{"2":{"703":1}}],["该模块基于局部聚合生成密集的3d占用预测",{"2":{"669":1}}],["该模块包含一个",{"2":{"632":1}}],["该模块推导出当前的三维空间占用",{"2":{"600":1}}],["该模块增强了三维体素特征的学习能力",{"2":{"544":1}}],["该模块受到光学原理的启发",{"2":{"539":1}}],["该模块学习像素对齐的占用分布",{"2":{"536":1,"567":1}}],["该模块可以通过cuda高效实现",{"2":{"486":1}}],["该模块在柱坐标系下执行空间分组池化和基于注意力的特征融合",{"2":{"438":1}}],["该模块在每个时间步将智能体的观测编码成语义视觉特征与预测",{"2":{"274":1}}],["该模块使智能体能够高效探索环境",{"2":{"274":1}}],["该模块接收当前代理的行动以及任务和传感器数据",{"2":{"121":1}}],["该模型提供了紧凑的姿态和形状描述",{"2":{"967":1}}],["该模型在八块",{"2":{"867":1}}],["该模型在三块",{"2":{"744":1}}],["该模型从",{"2":{"823":1}}],["该模型将每个高斯解释为其邻域被占用的概率分布",{"2":{"536":1}}],["该模型由稀疏卷积和交叉注意力组成",{"2":{"486":1}}],["该模型由训练期间额外的客观性损失引导",{"2":{"471":1}}],["该模型被命名为oneformer3d",{"2":{"306":1}}],["该模型",{"2":{"125":1}}],["该领域已取得长足进步",{"2":{"881":1}}],["该领域的研究人员还研究了相机",{"2":{"678":1}}],["该领域还扩展到多任务与长程规划",{"2":{"123":1}}],["该领域不断演进",{"2":{"123":1}}],["该理论也提供了任务驱动聚类算法的方法",{"2":{"109":1}}],["该文章在每一次点击之后将上一次点击预测的mask和连同click",{"2":{"106":1}}],["该架构因模块化而被工业界广泛采用",{"2":{"103":1}}],["该篇为将深度学习引入交互式分割的开山之作",{"2":{"54":1}}],["摘要",{"0":{"72":1,"80":1,"105":1,"112":1,"349":1,"392":1,"415":1,"425":1,"475":1,"490":1,"505":1,"516":1,"536":1,"539":1,"568":1,"610":1,"637":1},"1":{"639":1,"667":1,"691":1,"714":1,"737":1,"759":1,"780":1,"801":1,"821":1,"841":1,"860":1,"877":1,"894":1,"910":1,"923":1,"933":1,"942":1,"950":1,"957":1,"964":1,"970":1,"976":1,"981":1,"985":1,"988":1,"991":1,"994":1,"997":1,"998":1,"999":1,"1000":1,"1001":1,"1002":1,"1003":1,"1004":1,"1005":1,"1006":1,"1007":1,"1008":1},"2":{"98":1,"306":1,"409":1}}],["加速后",{"2":{"1001":1}}],["加速推理过程",{"2":{"420":1}}],["加入激光雷达信息又额外带来了",{"2":{"936":1}}],["加入雷达数据显著提高了预测动态物体的能力",{"2":{"936":1}}],["加入来自激光雷达的密集",{"2":{"927":1}}],["加持了更鲜艳的成分",{"2":{"880":1}}],["加载常规卷积的预训练权值后进行微调以达成更优性能",{"2":{"863":1}}],["加大前景和背景的差异",{"2":{"591":1}}],["加权相加",{"2":{"499":1}}],["加权平方误差",{"2":{"171":1}}],["加密v2v与手势",{"2":{"478":1}}],["加上头文件",{"2":{"67":1}}],["加粗文字",{"2":{"57":1}}],["加粗",{"2":{"57":1}}],["未扫描的区域被标注为空",{"2":{"998":1}}],["未在图中报告",{"2":{"816":1}}],["未使用时间信息融合",{"2":{"758":1}}],["未有清晰语义的目标检出问题",{"2":{"658":1}}],["未有清晰语义的目标",{"2":{"630":1}}],["未知环境的空间占用预测逐渐变得更加准确和完整",{"2":{"568":1}}],["未知形状的对象",{"2":{"449":2}}],["未来投资计划",{"2":{"960":1}}],["未来展望",{"0":{"956":1},"1":{"963":1,"969":1,"975":1}}],["未来需研发无需大量重训练即可稳健识别新物体的开放词汇检测器",{"2":{"897":1}}],["未来需超越任务成功指标",{"2":{"881":1}}],["未来需着力提升效率",{"2":{"619":1}}],["未来研究方向",{"0":{"881":1},"1":{"897":1,"913":1,"926":1,"935":1,"943":1,"951":1}}],["未来若要应对动态障碍或噪声环境",{"2":{"826":1}}],["未来挑战包括",{"2":{"826":1}}],["未来的工作可以考虑仅对实体物体建模",{"2":{"878":1}}],["未来的工作包括将hydra与基于学习的方法",{"2":{"467":1}}],["未来的评估还应分析参数和推理时间",{"2":{"778":1}}],["未来",{"2":{"778":1}}],["未来工作将研究更有效的主动学习技术",{"2":{"862":1}}],["未来工作需在保持效率的同时",{"2":{"588":1}}],["未来工作可让神经vla栈输出结构化动作程序",{"2":{"507":1}}],["未来系统需解析手势",{"2":{"507":1}}],["未来方向",{"0":{"507":1}}],["未考虑分割任务",{"2":{"485":1}}],["未能考虑3d点云在空间中的非均匀分布",{"2":{"527":1}}],["未能分割大多数房间",{"2":{"437":1}}],["未能充分利用点云特征中固有的几何和结构信息",{"2":{"421":1}}],["未优化",{"2":{"408":1}}],["未声明",{"2":{"67":1}}],["未开源",{"2":{"30":2,"148":1,"175":1,"198":1,"668":1,"797":1}}],["此距离是相对于体素中心计算的",{"2":{"916":1}}],["此操作构建了3d特征体积或2d特征图",{"2":{"910":1}}],["此过程不涉及显式的高度维度表示学习",{"2":{"811":1}}],["此对齐过程确保历史特征被正确插值并与当前感知系统同步",{"2":{"726":1}}],["此采样过程中将丢弃形状的详细信息",{"2":{"688":1}}],["此处也可以使用标准偏差或熵等其他统计测量值",{"2":{"622":1}}],["此预训练任务与最终占据预测任务紧密相关",{"2":{"617":1}}],["此阶段使用bev表示而非3d体素表示",{"2":{"585":1}}],["此阶段典型流水线采用冻结视觉模型",{"2":{"260":1}}],["此类模型可通过提示或lora适配下游任务",{"2":{"507":1}}],["此类模型有望使自动驾驶车辆能够解释高层指令",{"2":{"72":1}}],["此步骤不同于基于成本体积的方法",{"2":{"464":1}}],["此步骤对构建一个稳定",{"2":{"270":1}}],["此注释的属性列表",{"2":{"254":1,"654":1}}],["此实例的注释数量",{"2":{"254":1}}],["此地限速是多少",{"2":{"176":1}}],["此后",{"2":{"123":1}}],["此外还需深度监督损失",{"2":{"585":1}}],["此外随着去噪过程的逐渐深入",{"2":{"312":1}}],["此外",{"2":{"114":1,"116":2,"125":1,"126":1,"128":2,"131":1,"139":1,"141":1,"153":2,"178":1,"209":1,"260":1,"262":1,"274":1,"277":1,"283":1,"302":1,"310":1,"337":1,"392":2,"419":2,"421":3,"425":2,"434":1,"467":1,"474":1,"475":1,"481":1,"482":1,"488":1,"503":1,"510":1,"516":1,"517":1,"536":1,"541":1,"544":1,"547":1,"552":1,"566":1,"567":2,"572":1,"574":1,"576":2,"585":2,"588":2,"598":1,"605":1,"610":1,"622":1,"634":1,"643":1,"648":1,"649":1,"653":3,"665":2,"667":1,"670":1,"681":1,"691":2,"693":1,"699":1,"700":2,"714":2,"721":1,"735":1,"736":1,"745":1,"746":1,"757":4,"758":1,"765":1,"778":1,"779":2,"787":1,"789":1,"791":3,"792":1,"793":1,"800":3,"808":1,"811":5,"826":1,"827":1,"828":1,"832":1,"836":1,"842":4,"861":1,"862":1,"864":1,"875":4,"877":1,"885":1,"889":1,"900":2,"901":1,"905":2,"915":2,"917":1,"922":5,"923":1,"927":1,"928":2,"934":1,"936":4,"941":1,"945":2,"947":1,"949":2,"950":1,"952":2,"955":1,"957":3,"958":1,"962":4,"968":1,"969":1,"970":1,"971":1,"973":1,"975":2,"977":2,"985":2,"988":2,"995":1,"998":1,"1000":2,"1001":1,"1002":1,"1004":1,"1005":2,"1006":2}}],["此外可能会出现部分未定义的变量的问题",{"2":{"67":1}}],["此时仍普遍采用预训练",{"2":{"743":1}}],["此时的检测任务可能无法准确建模",{"2":{"630":1}}],["此时的模型可以看成是一个vq",{"2":{"345":1}}],["此时attention的query是unet的中间特征",{"2":{"401":1}}],["此时压缩损失过大",{"2":{"345":1}}],["此时压缩率小",{"2":{"345":1}}],["此时图像的感知压缩率较小",{"2":{"345":1}}],["此时",{"2":{"315":1,"480":1,"495":1,"691":1,"863":1}}],["此时每个像素点的颜色向量由3维变成了1维度",{"2":{"227":1}}],["此时身份特征随a",{"2":{"181":1}}],["此时式",{"2":{"171":1}}],["此时互信息的单位是比特",{"2":{"137":1}}],["此时在++会出现段错误",{"2":{"115":1}}],["此时在外部访问宿主机",{"2":{"60":1}}],["此时可以输入命令",{"2":{"68":1}}],["回环",{"2":{"826":1}}],["回环检测",{"2":{"435":1,"864":1}}],["回顾与展望",{"0":{"608":1},"1":{"637":1,"665":1,"689":1,"712":1,"735":1,"757":1,"778":1,"799":1,"819":1,"839":1,"858":1,"875":1,"892":1,"908":1,"922":1,"932":1,"941":1,"949":1,"956":1,"963":1,"969":1,"975":1,"980":1,"984":1}}],["回顾现有的评估方法",{"2":{"90":1}}],["回路闭合检测依赖于dbow2库",{"2":{"390":1}}],["回路闭合检测",{"2":{"390":1}}],["回路闭合模块检测回路闭合以纠正全局轨迹和网格",{"2":{"390":1}}],["回归的技术相比差一些",{"2":{"382":1}}],["回到指定会话",{"2":{"88":1}}],["回到上面的第六步和第七步",{"2":{"66":1}}],["回答问题或检索传统检测器可能遗漏的语境信息",{"2":{"82":1}}],["回车",{"2":{"48":1}}],["回车符后跟换行符",{"2":{"41":1}}],["卸载文件内容",{"2":{"66":1}}],["点卷积方法",{"2":{"974":1}}],["点包含更丰富的信息",{"2":{"809":1}}],["点相比",{"2":{"809":1}}],["点作为查询来聚合来自三种传感器的特征",{"2":{"678":1}}],["点坐标在描述点云的几何结构中起着重要的作用",{"2":{"640":1}}],["点特征是沿着树从叶节点到根节点分层学习的",{"2":{"636":1}}],["点对齐",{"2":{"619":1}}],["点的表示自然没有明确的邻域信息",{"2":{"996":1}}],["点的平均值",{"2":{"809":1}}],["点的初始特征向量为",{"2":{"809":1}}],["点的体素网格被输入到",{"2":{"789":1}}],["点的体素网格中",{"2":{"789":1}}],["点的中心位置",{"2":{"789":1}}],["点的描述范围有限",{"2":{"599":1}}],["点的局部邻居的连续和离散卷积的图示",{"2":{"450":1}}],["点匹配",{"2":{"579":1}}],["点与其相邻点之间的几何关系是基于六个基显式建模的",{"2":{"511":1}}],["点都被记录",{"2":{"465":1}}],["点都用三种颜色",{"2":{"412":1}}],["点式mlp网络通常用作其他类型学习点特征的基本构建块",{"2":{"688":1}}],["点式mlp网络",{"0":{"420":1}}],["点边结合",{"2":{"351":1}}],["点块分割",{"0":{"396":1}}],["点块的顺序得到了定义",{"2":{"340":1}}],["点块划分",{"2":{"340":1}}],["点级别",{"2":{"313":1}}],["点比例",{"2":{"277":1,"534":2}}],["点",{"2":{"105":1,"189":1,"277":1,"378":1,"435":1,"495":1,"534":2,"556":1,"681":1,"693":1,"864":1,"916":1}}],["点`ok`",{"2":{"66":2}}],["点云进一步提升了",{"2":{"977":1}}],["点云进行体素化",{"2":{"809":1}}],["点云进行自监督预训练的多尺度掩码自编码器",{"2":{"692":1}}],["点云是无序且非结构化的",{"2":{"974":1}}],["点云和图像信息的融合",{"2":{"970":1}}],["点云和来自环视雷达的稀疏",{"2":{"867":1}}],["点云从多个虚拟摄像机视图投影到",{"2":{"955":1}}],["点云投影为",{"2":{"955":1}}],["点云较为稀疏",{"2":{"936":1}}],["点云信息可进一步将性能提升至约",{"2":{"927":1}}],["点云信息可使性能显著提高约",{"2":{"927":1}}],["点云在推理时会消耗更多的",{"2":{"882":1}}],["点云在z轴上的处理范围在所有实验中均为",{"2":{"638":1}}],["点云密度的消融研究",{"2":{"882":1}}],["点云或深度图",{"2":{"870":1}}],["点云或雷达返回",{"2":{"254":1}}],["点云体素化",{"2":{"789":1}}],["点云特征提取",{"0":{"789":1,"809":1}}],["点云特征扩展到了",{"2":{"596":1}}],["点云语义分割",{"0":{"725":1},"1":{"747":1,"769":1,"790":1}}],["点云纹理的重建很直接",{"2":{"640":1}}],["点云目标检测",{"0":{"626":1},"1":{"654":1,"679":1,"702":1}}],["点云转换为欧几里得特征空间",{"2":{"596":1}}],["点云后",{"2":{"588":1}}],["点云因其灵活性和精细空间分辨率成为核心表征",{"2":{"588":1}}],["点云因其易用性而大受欢迎",{"2":{"588":1}}],["点云因实现简单",{"2":{"556":1}}],["点云地图因简洁",{"2":{"588":1}}],["点云地图",{"0":{"588":1},"2":{"556":1}}],["点云输入",{"2":{"545":1,"746":1}}],["点云被投影到具有对齐球坐标的规则二十面晶格上",{"2":{"511":1}}],["点云被划分为有序的点块序列",{"2":{"340":1}}],["点云优化",{"0":{"494":1},"1":{"524":1,"555":1,"587":1}}],["点云渣的博客",{"2":{"426":1}}],["点云要稀疏得多",{"2":{"421":1}}],["点云作为输入",{"2":{"384":1}}],["点云序列",{"0":{"368":1}}],["点云序列模块",{"2":{"315":1}}],["点云缺乏预定义的词汇表",{"2":{"340":1}}],["点云的邻域结构",{"2":{"962":1}}],["点云的实时语义分割",{"2":{"955":1}}],["点云的实例分割",{"2":{"263":1}}],["点云的体素化和特征提取可以表示为",{"2":{"910":1}}],["点云的密度",{"2":{"882":1}}],["点云的密度较高",{"2":{"865":1}}],["点云的密度强烈影响模型的最终感知性能",{"2":{"596":1}}],["点云的特征",{"2":{"789":1}}],["点云的特征由两部分组成",{"2":{"640":1}}],["点云的卷积网络",{"2":{"481":1}}],["点云的刚性和可变形核点卷积",{"2":{"481":1}}],["点云的分辨率和密度不均匀",{"2":{"331":1}}],["点云的数据量大",{"2":{"331":1}}],["点云的表示方式多样",{"2":{"331":1}}],["点云生成",{"2":{"314":1}}],["点云分支",{"2":{"670":1}}],["点云分类",{"2":{"290":1}}],["点云分割的mask",{"2":{"747":1}}],["点云分割的难点主要有以下几个方面",{"2":{"331":1}}],["点云分割是三维计算机视觉中的一个重要和具有挑战性的任务",{"2":{"331":1}}],["点云分割",{"2":{"263":1,"588":1}}],["点云动态图卷积",{"2":{"258":1}}],["点云",{"2":{"31":1,"172":1,"564":1,"570":1,"588":1,"746":3,"765":1,"808":1,"867":1,"882":1,"936":1,"952":1,"955":1,"967":1,"977":1}}],["按此流程实现",{"2":{"495":1}}],["按照现有工作",{"2":{"813":1}}],["按照常见做法",{"2":{"802":1,"853":1}}],["按照gaussianformer的做法",{"2":{"705":1}}],["按照文献",{"2":{"649":1,"676":1,"787":1}}],["按照",{"2":{"412":1}}],["按照传统的基于深度学习的交互式分割框架训练模型",{"2":{"75":1}}],["按延迟时间递增的顺序排列",{"2":{"408":1}}],["按房间id分割的墙壁",{"2":{"197":1}}],["按vla在自动驾驶领域的进展对比20余个代表性模型",{"2":{"72":1}}],["按以下流程走",{"2":{"66":1}}],["按",{"2":{"66":6,"916":1}}],["就实现了相当的准确性",{"2":{"1004":1}}],["就会迅速收敛到平凡解",{"2":{"842":1}}],["就能把所有需要的自注意力值都算出来",{"2":{"751":1}}],["就能精确到位",{"2":{"435":1}}],["就需要很大的感受野",{"2":{"695":1}}],["就像我们人类总是对反复遇到的景象有更全面的理解一样",{"2":{"682":1}}],["就好了",{"2":{"631":1}}],["就得到对应像素点的初始深度值",{"2":{"470":1}}],["就显著超越了其他方法",{"2":{"392":1}}],["就可以找到ref图像上点p对应在src图像上点p",{"2":{"355":1}}],["就可以在反向过程将每一步t中的噪声信息从x中抽取出来",{"2":{"279":1}}],["就创建一个新的track",{"2":{"206":1}}],["就是",{"2":{"659":1}}],["就是用来控制生成图像的style",{"2":{"133":1}}],["就是通过生成网络",{"2":{"129":1}}],["就代表不可能是真实的数据",{"2":{"129":1}}],["就代表",{"2":{"129":1}}],["就无法切回交互式分割工具了",{"2":{"117":1}}],["就走如下流程",{"2":{"66":1}}],["就定义为",{"2":{"5":1}}],["更符合3d物理世界",{"2":{"1003":1}}],["更密集",{"2":{"995":1}}],["更密集的伪",{"2":{"882":1}}],["更好地捕捉了景观和物体",{"2":{"989":1}}],["更好地实现语言接地",{"2":{"698":1}}],["更精细的推理",{"2":{"983":1}}],["更精确地说",{"2":{"301":1}}],["更广泛的影响与伦理问题",{"0":{"953":1}}],["更混乱的室外场景有关",{"2":{"917":1}}],["更改容器大小",{"2":{"904":1}}],["更改权限",{"2":{"66":1}}],["更小的",{"2":{"865":1}}],["更高效的渲染",{"2":{"860":1}}],["更高效的语义占据预测",{"2":{"474":1}}],["更快",{"2":{"842":1}}],["更全面的评估框架",{"2":{"806":1}}],["更平滑的预测",{"2":{"745":1}}],["更有效的指导",{"2":{"705":1}}],["更优秀的具身智能体被期望能够处理实时收集的视觉输入",{"2":{"682":1}}],["更体现空间是否",{"2":{"658":1}}],["更近的",{"2":{"648":1}}],["更接近于挑选测地距离上的领域",{"2":{"589":1}}],["更低的召回率",{"2":{"522":1}}],["更复杂的趋势相反",{"2":{"505":1}}],["更均匀的点云投影到图像平面上",{"2":{"482":1}}],["更准确的深度图",{"2":{"605":1}}],["更准确的语义占据预测",{"2":{"444":1}}],["更准确地说",{"2":{"380":2}}],["更正式地",{"2":{"437":1}}],["更正式地说",{"2":{"147":1}}],["更详细的预测",{"2":{"415":1}}],["更具挑战性",{"2":{"739":1}}],["更具可扩展性",{"2":{"390":1}}],["更具体地说",{"2":{"109":1,"270":1}}],["更能交流并与人类对齐",{"2":{"334":1}}],["更长的场景描述",{"2":{"254":1}}],["更要鲁棒",{"2":{"216":1}}],["更别说要循环迭代多次直到100",{"2":{"205":1}}],["更自然",{"2":{"199":1}}],["更用其实现可解释与协作式自主",{"2":{"176":1}}],["更丰富视觉输入支持更鲁棒场景理解与多目标推理",{"2":{"176":1}}],["更人类对齐的自动驾驶铺平道路",{"2":{"145":1}}],["更泛化",{"2":{"145":1}}],["更安全",{"2":{"130":1}}],["更多的",{"2":{"928":2}}],["更多的可变形卷积层",{"2":{"804":1}}],["更多的异常值",{"2":{"634":1}}],["更多分析请参阅补充材料",{"2":{"700":1}}],["更多地保留与task密切相关的边",{"2":{"589":1}}],["更多细节和消融在下面",{"2":{"437":1}}],["更多细节请参阅我们的论文",{"2":{"173":1}}],["更多区域可以准确估计score",{"2":{"291":1}}],["更多近期的工作",{"2":{"125":1}}],["更多用于路径规划和机器人导航",{"2":{"31":1}}],["更重要的是",{"2":{"109":1,"905":1}}],["更需要形成结构化的内部表示",{"2":{"90":1}}],["更新并利用动态地图",{"2":{"926":1}}],["更新动态障碍",{"2":{"864":1}}],["更新代价高",{"2":{"864":1}}],["更新与计算复杂度增加",{"2":{"864":1}}],["更新高斯查询",{"2":{"595":1}}],["更新后的查询提议和掩码标记然后组合以重建体素特征",{"2":{"875":1}}],["更新后的查询被输入到特定任务的头部",{"2":{"550":1}}],["更新后的物体查询将进一步用于预测物体类别和",{"2":{"369":1}}],["更新物体query的表示",{"2":{"341":1}}],["更新环境变量或者重启电脑",{"2":{"87":1}}],["更新",{"2":{"76":1,"158":1}}],["$个高斯之间的",{"2":{"916":1}}],["$个和第",{"2":{"916":1}}],["$i",{"2":{"916":1}}],["$是平均协方差矩阵",{"2":{"916":1}}],["$是第",{"2":{"916":1}}],["$是在",{"2":{"916":1}}],["$缩放",{"2":{"916":1}}],["$定义为",{"2":{"916":1}}],["$m",{"2":{"916":1}}],["$从均值",{"2":{"916":1}}],["$分别是均值向量",{"2":{"916":1}}],["$分别是落在至少一个高斯的",{"2":{"916":1}}],["$|",{"2":{"916":1}}],["$x",{"2":{"916":2}}],["$n",{"2":{"916":2}}],["$的特征值的平方根决定",{"2":{"916":1}}],["$的马氏距离",{"2":{"916":1}}],["$的马氏距离导出的",{"2":{"916":1}}],["$的比率",{"2":{"916":1}}],["$之和与场景中所有高斯的总覆盖体积",{"2":{"916":1}}],["$表示将所有高斯组合成一个统一形状的体积",{"2":{"916":1}}],["$表示有效的标签像素点集",{"2":{"647":1}}],["$表示线性插值",{"2":{"221":1}}],["$满足",{"2":{"592":1}}],["$和",{"2":{"916":2}}],["$和重投影深度",{"2":{"592":1}}],["$和顶点",{"2":{"372":1}}],["$p",{"2":{"592":1}}],["$j",{"2":{"464":1,"916":1}}],["$查询作为输入",{"2":{"441":1}}],["$k",{"2":{"441":1}}],["$时",{"2":{"411":1}}],["$d",{"2":{"411":1,"592":1,"916":1}}],["$distrib",{"2":{"76":1}}],["$v",{"2":{"372":1,"916":4}}],["$z",{"2":{"256":1}}],["$来对真实数据分布p",{"2":{"256":1}}],["$∇",{"2":{"256":1}}],["$lerp",{"2":{"221":1}}],["$t+",{"2":{"221":1}}],["$",{"2":{"193":1,"221":1,"256":1,"390":2,"464":1,"623":1,"844":2,"848":4,"916":9}}],["$ros",{"2":{"120":4}}],["$cd",{"2":{"66":1}}],["$sudo",{"2":{"66":8}}],["$1",{"2":{"57":1}}],["$12",{"2":{"57":1}}],["$1600",{"2":{"57":1}}],["开创性工作可以分为基于语义占用序列的世界模型",{"2":{"1003":1}}],["开源",{"0":{"635":1}}],["开环预测",{"2":{"447":1}}],["开发能够增量运行并实时运行的空间感知引擎将是可取的",{"2":{"973":1}}],["开发能够处理大规模点云的网络仍处于初级阶段",{"2":{"688":1}}],["开发第一个实时空间感知系统",{"2":{"141":1}}],["开发了2d场景图生成算法",{"2":{"961":1}}],["开发了用于生成密集占据标签的方法",{"2":{"482":1}}],["开发了一种开放集实例分割的方法",{"2":{"121":1}}],["开发了langsplat",{"2":{"121":1}}],["开始迭代器指针",{"2":{"918":1}}],["开始",{"2":{"279":1,"408":1,"619":1}}],["开始将这些模型直接嵌入驾驶循环",{"2":{"128":1}}],["开始利用视觉",{"2":{"109":1}}],["开始操作",{"2":{"66":1}}],["开放挑战",{"0":{"478":1,"864":1}}],["开放集召回率",{"2":{"402":1}}],["开放集对象聚类评估",{"0":{"346":1},"1":{"374":1,"402":1,"431":1,"462":1}}],["开放词汇任务在2d图像感知中展示了强大的性能",{"2":{"975":1}}],["开放词汇和可查询地图表征日益增长的需求",{"2":{"958":1}}],["开放词汇检测器在未见类别上也缺乏鲁棒性",{"2":{"897":1}}],["开放词汇能力",{"2":{"897":1}}],["开放词汇预测",{"2":{"877":1}}],["开放词汇的真值注释",{"2":{"846":1}}],["开放词汇地图编码一次构建即可迁移至多种下游任务",{"2":{"765":1}}],["开放词汇地点聚类",{"0":{"522":1}}],["开放词汇",{"2":{"90":1,"406":1,"588":1,"881":1}}],["开放22端口",{"2":{"78":1}}],["开机～",{"2":{"66":1}}],["开启相机",{"2":{"120":1}}],["开启",{"0":{"11":1},"1":{"17":1}}],["输入数据模态显著影响3d占用感知的准确性",{"2":{"1000":1}}],["输入大小",{"2":{"928":1}}],["输入大小为",{"2":{"823":1}}],["输入基线的比较",{"0":{"917":1}}],["输入时",{"2":{"903":1}}],["输入模态",{"2":{"877":1}}],["输入用帽子表示",{"2":{"870":1}}],["输入版本和主要基线的",{"2":{"870":1}}],["输入尺寸为",{"2":{"853":1}}],["输入尺寸960×1760",{"2":{"805":1}}],["输入尺寸256×704",{"2":{"785":1}}],["输入图像大小",{"2":{"1001":1}}],["输入图像的分辨率为",{"2":{"900":1}}],["输入图像分辨率为704×256",{"2":{"811":1}}],["输入图像尺寸640×1600",{"2":{"764":1}}],["输入图像水平翻转",{"2":{"673":1}}],["输入点云首先经过体素化和特征提取",{"2":{"910":1}}],["输入点云范围设置为",{"2":{"758":1}}],["输入点云通过最远点采样",{"2":{"396":1}}],["输入为图像xrgbx",{"2":{"632":1}}],["输入为低分辨率图像x以及高斯噪声yt",{"2":{"354":1}}],["输入的",{"2":{"989":1}}],["输入的占用网格是通过对反投影点云进行离散化得到的",{"2":{"978":1}}],["输入的水平视场角比相机宽得多有关",{"2":{"917":1}}],["输入的基线方法上也表现优异",{"2":{"570":1}}],["输入的现有",{"2":{"539":1}}],["输入查询使用来自转换器编码器的特征进行初始化",{"2":{"471":1}}],["输入四层残差卷积网络进行信息融合",{"2":{"470":1}}],["输入特征",{"0":{"379":1}}],["输入通过公式重复迭代t次得到sr图像",{"2":{"354":1}}],["输入1个参考图像+n个原图像",{"2":{"305":1}}],["输入到动态融合",{"2":{"746":1}}],["输入到一个简单的",{"2":{"369":1}}],["输入到",{"2":{"181":1,"867":1}}],["输入命令",{"2":{"99":1}}],["输入命令回到",{"2":{"88":1}}],["输入回车",{"2":{"87":1}}],["输入",{"2":{"66":1,"305":1,"410":1,"632":1,"853":1,"870":2,"917":1}}],["输出查询被进一步用于生成检测结果",{"2":{"695":1}}],["输出图f3df^",{"2":{"660":1}}],["输出y^",{"2":{"632":1}}],["输出的细化后的bev特征可以表示为",{"2":{"609":1}}],["输出的摄像头体素特征可以表示为",{"2":{"609":1}}],["输出的特征图fcp具有",{"2":{"609":1}}],["输出四个特征图",{"2":{"562":1}}],["输出离散导航动作",{"2":{"525":1}}],["输出单通道特征图",{"2":{"470":1}}],["输出空间",{"2":{"423":1}}],["输出n+1个32通道的特征图",{"2":{"305":1}}],["输出是3d",{"2":{"285":1}}],["输出格式随时间从低层控制命令演进到更高层空间推理与技能条件动作",{"2":{"216":1}}],["输出size",{"2":{"146":1}}],["输出为密集占据预测结果",{"2":{"598":1}}],["输出为高分辨率图像",{"2":{"354":1}}],["输出为1",{"2":{"146":1}}],["输出为0",{"2":{"146":1}}],["输出为2",{"2":{"130":1}}],["输出为4",{"2":{"130":1}}],["输出显示",{"2":{"49":1}}],["输出",{"2":{"48":1,"129":1,"305":1,"410":1,"670":1,"903":1}}],["写上",{"2":{"66":1}}],["添加函数",{"2":{"904":1}}],["添加辅助检测分支分别使自行车",{"2":{"800":1}}],["添加网格可行性检查通过在检测注册后使数据关联更有效来减少误差",{"2":{"775":1}}],["添加到列表中",{"2":{"738":2}}],["添加到这些高斯分布的特征向量",{"2":{"705":1}}],["添加了一个时空一致性检查",{"2":{"419":1}}],["添加时间对齐人类理由",{"2":{"360":1}}],["添加ros的软件源",{"2":{"76":1}}],["添加黑名单",{"2":{"66":1}}],["添加新的源",{"2":{"36":1}}],["也很常见",{"2":{"1005":1}}],["也很可能是有行人正在过马路",{"2":{"116":1}}],["也有类似的情况",{"2":{"1000":1}}],["也有方法直接对像素强度进行操作",{"2":{"189":1}}],["也起到了重要作用",{"2":{"995":1}}],["也适用于弱监督学习",{"2":{"988":1}}],["也称为相对熵",{"2":{"985":1}}],["也称为语义场景补全",{"2":{"808":1}}],["也能显著增强基于视觉的方法",{"2":{"977":1}}],["也能辅助局部路径规划",{"2":{"503":1}}],["也使用变形图方法来变形模型点云",{"2":{"967":1}}],["也使用了",{"2":{"917":1}}],["也蕴含巨大研究空间",{"2":{"943":1}}],["也与更复杂",{"2":{"917":1}}],["也得到了提高或保持一致",{"2":{"903":1}}],["也表明",{"2":{"889":1}}],["也存在一些错误检测",{"2":{"872":1}}],["也指明了未来亟需开发可扩展",{"2":{"846":1}}],["也就鲜少报告几何一致性指标",{"2":{"826":1}}],["也就是连在一起的两个transformer",{"2":{"659":1}}],["也就是说窗口的数量没有增加",{"2":{"751":1}}],["也就是说我们可以控制使用哪种容器来实现栈的功能",{"2":{"685":1}}],["也就是说无论mesh被用于什么task",{"2":{"589":1}}],["也就是说对应的这个稀疏输入是需要被计算的",{"2":{"530":1}}],["也就是说给定纯高斯噪声",{"2":{"224":1}}],["也就是估计数据分布的对数梯度",{"2":{"398":1}}],["也就是在变形图中连接网格顶点的边",{"2":{"390":1}}],["也就是在增加新的维度进行堆叠",{"2":{"351":1}}],["也就是outputs的维度值",{"2":{"351":1}}],["也就是上一条中均匀采样的值",{"2":{"175":1}}],["也是有害的",{"2":{"842":1}}],["也是首个参数达1b",{"2":{"824":1}}],["也是一个基于nuscenes数据集构建的用于3d占用预测的数据集",{"2":{"757":1}}],["也是cnn架构",{"2":{"371":1}}],["也成为建议",{"2":{"756":1}}],["也被应用于语义占据预测",{"2":{"808":1}}],["也被应用于密集和稀疏的",{"2":{"746":1}}],["也被过度分割为",{"2":{"796":1}}],["也被输入到动态融合",{"2":{"746":1}}],["也被证明是很有用的",{"2":{"603":1}}],["也已被彻底综述",{"2":{"714":1}}],["也在俯视体素图中存储已探索信息",{"2":{"698":1}}],["也不提供迭代器",{"2":{"685":1}}],["也必须是",{"2":{"638":1}}],["也渲染语义",{"2":{"619":1}}],["也通过边折叠的方式在最小化损失信息的基础上",{"2":{"589":1}}],["也富含语义",{"2":{"588":1}}],["也没有语义上有意义的对象",{"2":{"572":1}}],["也没有推理算法",{"2":{"116":1}}],["也包括局部视锥范围",{"2":{"570":1}}],["也包括了f1分数作为总结统计量",{"2":{"522":1}}],["也叫权重移动平均",{"2":{"528":1}}],["也会传播到姿态图中",{"2":{"419":1}}],["也保证了转换不变性",{"2":{"407":1}}],["也排序",{"2":{"379":1}}],["也即将得到d幅变换后的图像",{"2":{"355":1}}],["也用于促进跨领域泛化",{"2":{"864":1}}],["也用于评估不考虑语义标签的场景完成质量",{"2":{"778":1}}],["也用于",{"2":{"263":1}}],["也未对",{"2":{"217":1}}],["也可使用其他网络结构",{"2":{"495":1}}],["也可将",{"2":{"378":1}}],["也可利用",{"2":{"274":1}}],["也可以采用下面方法",{"2":{"929":1}}],["也可以直接取自预训练视觉模型",{"2":{"743":1}}],["也可以存储并不一定支持语言查询",{"2":{"721":1}}],["也可以移动顶点从而改善局部几何",{"2":{"372":1}}],["也可以像图5",{"2":{"285":1}}],["也可以通过噪声在后向过程里添加的时间步多寡来调整控制的强弱",{"2":{"264":1}}],["也可以是会话id",{"2":{"88":1}}],["也可以由多个段落组成",{"2":{"57":1}}],["也可在首尾快速的删除或增加元素",{"2":{"83":1}}],["也达到了更好的分割结果",{"2":{"65":1}}],["所需的最小标签",{"2":{"862":1}}],["所需的概率密度",{"2":{"109":1}}],["所见物体",{"2":{"698":1}}],["所预期的",{"2":{"686":1}}],["所提出的dvio方法保持鲁棒",{"2":{"662":1}}],["所提出的方法与最新技术表现相当",{"2":{"662":1}}],["所提出的三维核为落入同一个网格的所有点分配相同的权重",{"2":{"511":1}}],["所描述的技术可以加快训练速度",{"2":{"471":1}}],["所述困难一致",{"2":{"826":1}}],["所述",{"2":{"336":1,"390":2,"634":1}}],["所谓压缩指的是用比原始表示更小的数位来编码信息的过程",{"2":{"227":1}}],["所有比较的方法均为以视觉为中心",{"2":{"1000":1}}],["所有指标均有所提升",{"2":{"928":1}}],["所有语义类别的平均",{"2":{"915":1}}],["所有方法都能正确捕捉到全局场景布局",{"2":{"903":1}}],["所有方法的低分数都证明了该任务的复杂性",{"2":{"903":1}}],["所有方法均采用",{"2":{"545":1,"965":1}}],["所有算法的",{"2":{"827":1}}],["所有算法的性能都有不同程度的下降",{"2":{"827":1}}],["所有实验均使用nuscenes",{"2":{"893":1}}],["所有实验均使用resnet",{"2":{"811":1}}],["所有实验均未使用类别平衡分组和采样",{"2":{"770":1}}],["所有四个类别都是前景目标",{"2":{"800":1}}],["所有结果均由作者直接提供或基于其官方代码实现",{"2":{"779":1}}],["所有模型均在3d物体检测任务上进行了预训练",{"2":{"811":1}}],["所有模型均使用adamw优化器",{"2":{"770":1}}],["所有模型都在8个nvidia",{"2":{"758":1}}],["所有基线都需要一个",{"2":{"870":1}}],["所有基准测试对",{"2":{"739":1}}],["所有基于摄像头的方法不可避免地需要应对恶劣光照和天气条件的挑战",{"2":{"482":1}}],["所有区域掩码均为二值",{"2":{"694":1}}],["所有元素必须符合先进后出规则",{"2":{"685":1}}],["所有的这些方法都是为了减少序列长度",{"2":{"631":1}}],["所有深度至少应在三个视图中保持一致",{"2":{"592":1}}],["所有这些方法都是基于网格的",{"2":{"547":1}}],["所有剩余的图5中的块都用c++实现",{"2":{"437":1}}],["所有分割任务的相似性和它们之间的隐含关系并未得到有效利用",{"2":{"306":1}}],["所有位置数据都是在全局坐标系下给出的",{"2":{"254":1,"654":1}}],["所有相机图像都没有失真和校正",{"2":{"254":1}}],["所有外部参数都是关于自我车体框架给出的",{"2":{"254":1}}],["所有房间都连接到它们所属的建筑物",{"2":{"218":1}}],["所有体素的",{"2":{"31":1}}],["所导致的关于任务信息的损失量",{"2":{"153":1}}],["所必需的",{"2":{"125":1}}],["所补充",{"2":{"123":1}}],["所示",{"2":{"114":1,"145":1,"417":1,"436":1,"444":1,"455":1,"502":1,"518":1,"535":1,"622":1,"632":1,"642":1,"656":1,"660":1,"670":1,"681":1,"704":1,"716":2,"730":1,"745":1,"777":1,"798":1,"814":1,"818":1,"828":2,"847":1,"882":2,"886":1,"900":1,"927":1,"928":2,"936":1,"944":1,"945":1,"952":1,"959":1,"971":1}}],["所以stl中栈往往不被归类为容器",{"2":{"685":1}}],["所以sd模型的总参数量约为1b",{"2":{"319":1}}],["所以栈不提供走访功能",{"2":{"685":1}}],["所以又提出了基于窗口和移动窗口的自注意力方式",{"2":{"659":1}}],["所以介绍了",{"2":{"659":1}}],["所以你会发现堆叠swin",{"2":{"659":1}}],["所以通过patch",{"2":{"659":1}}],["所以上下层之间就可以有",{"2":{"631":1}}],["所以这个序列的长度大大的降低了",{"2":{"631":1}}],["所以这两篇文章利用点击点的label信息对模型参数进行在线微调",{"2":{"84":1}}],["所以说它的计算复杂度是随着图像大小而线性增长",{"2":{"631":1}}],["所以说之前的工作要么就是用后续的特征图来当做transformer的输入",{"2":{"631":1}}],["所以说在",{"2":{"631":1}}],["所以与基于",{"2":{"382":1}}],["所以detr不需要nms进行后处理",{"2":{"358":1}}],["所以它很容易使用到下游任务里",{"2":{"631":1}}],["所以它可以扩展应用在尺寸",{"2":{"345":1}}],["所以它们属于这里",{"2":{"254":1,"654":1}}],["所以reg=4",{"2":{"321":1}}],["所以每个点由256d",{"2":{"321":1}}],["所以直接进行instance",{"2":{"313":1}}],["所以可以用",{"2":{"188":1}}],["所以返回值只能是1或0",{"2":{"177":1}}],["所以",{"2":{"140":1,"280":1,"631":1}}],["所以相对于",{"2":{"130":1}}],["所以训练",{"2":{"129":1}}],["所以使用rosdepc",{"2":{"87":1}}],["所以第一个点击提供的信息应该比其他的点击多",{"2":{"65":1}}],["\\t├──",{"2":{"327":1}}],["\\tt",{"2":{"188":1}}],["\\tthe",{"2":{"66":1}}],["\\t~",{"2":{"132":1}}],["\\t",{"2":{"66":11,"479":1,"509":1,"540":1,"623":2}}],["\\tcout",{"2":{"63":1}}],["\\tdouble",{"2":{"63":1}}],["\\tstring",{"2":{"63":1}}],["\\t\\tquery",{"2":{"623":1}}],["\\t\\t",{"2":{"52":1,"66":3}}],["例",{"2":{"63":1}}],["例如光照和天气变化会引入视觉偏差",{"2":{"1005":1}}],["例如摄像头",{"2":{"997":1}}],["例如广泛使用的kitti",{"2":{"997":1}}],["例如1m×1m",{"2":{"996":1}}],["例如12个和60个",{"2":{"605":1}}],["例如斯图加特",{"2":{"995":1}}],["例如城市",{"2":{"995":1}}],["例如床",{"2":{"992":1}}],["例如预训练的开源词汇模型grounded",{"2":{"988":1}}],["例如预测",{"2":{"877":1}}],["例如lovasz",{"2":{"985":1}}],["例如wald等人",{"2":{"967":1}}],["例如体积和稀疏置换面格",{"2":{"962":1}}],["例如体积分",{"2":{"877":1}}],["例如电线杆",{"2":{"924":1}}],["例如difs",{"2":{"923":1}}],["例如十字路口",{"2":{"903":1}}],["例如室内场景的地板",{"2":{"903":1}}],["例如多视图",{"2":{"948":1}}],["例如多层感知机",{"2":{"877":1}}],["例如多尺度融合",{"2":{"547":1}}],["例如稀疏表示或张量分解",{"2":{"877":1}}],["例如输入图像左前方和3d可视化右上角的卡车",{"2":{"842":1}}],["例如输出栈顶元素",{"2":{"774":1}}],["例如第1行",{"2":{"924":1}}],["例如第4行",{"2":{"924":1}}],["例如第",{"2":{"903":2,"989":4,"992":2}}],["例如第一行",{"2":{"842":1}}],["例如第三行",{"2":{"842":1}}],["例如以",{"2":{"842":1}}],["例如nyu",{"2":{"841":1}}],["例如使用",{"2":{"835":1}}],["例如使用900×1600分辨率的输入图像以及配备可变形卷积模块",{"2":{"421":1}}],["例如泥泞和水坑",{"2":{"745":1}}],["例如插入3",{"2":{"731":1}}],["例如人造结构",{"2":{"700":1}}],["例如汽车",{"2":{"700":1,"945":1}}],["例如摩托车",{"2":{"700":1}}],["例如结合几种或全部的焦点损失",{"2":{"690":1}}],["例如点云",{"2":{"632":1}}],["例如卸货卡车的千斤顶支撑架",{"2":{"630":1}}],["例如在家具重新摆放或人们走动的场景中",{"2":{"958":1}}],["例如在自动驾驶领域",{"2":{"953":1}}],["例如在",{"2":{"945":1}}],["例如在道路和墙壁表面的扁平形状的高斯分布",{"2":{"842":1}}],["例如在3d物体检测中使用bevdet",{"2":{"839":1}}],["例如在occcylindrical中",{"2":{"621":1}}],["例如在nuscenes",{"2":{"617":1}}],["例如0到50米",{"2":{"621":1}}],["例如resnet50",{"2":{"621":1}}],["例如流行的",{"2":{"603":1}}],["例如深度",{"2":{"603":1}}],["例如深度图",{"2":{"603":1}}],["例如深度神经网络",{"2":{"362":1}}],["例如占用网格",{"2":{"570":1,"870":1}}],["例如占用信息",{"2":{"274":1}}],["例如3d车道检测",{"2":{"566":1}}],["例如3d目标检测",{"2":{"444":1}}],["例如对提示调整的强大敏感性",{"2":{"553":1}}],["例如半参数化拓扑记忆",{"2":{"525":1}}],["例如常规的ddpm",{"2":{"513":1}}],["例如二维空间中的一维曲线",{"2":{"500":1}}],["例如欧几里德距离和相对位置",{"2":{"481":1}}],["例如门框",{"2":{"480":1}}],["例如激光雷达",{"2":{"444":1,"570":1}}],["例如环视摄像头",{"2":{"438":1}}],["例如用",{"2":{"435":1}}],["例如分类",{"2":{"407":1}}],["例如orb",{"2":{"390":1}}],["例如头发纹理",{"2":{"382":1}}],["例如导航到特定房间",{"2":{"350":1}}],["例如导航或物体操纵",{"2":{"100":1}}],["例如它的局部性",{"2":{"343":1}}],["例如平移不变性",{"2":{"343":1}}],["例如禾赛的",{"2":{"302":1}}],["例如从建筑物到社区",{"2":{"262":1}}],["例如特定的车辆",{"2":{"254":1}}],["例如车辆",{"2":{"254":1}}],["例如墙壁",{"2":{"197":1}}],["例如共视性",{"2":{"178":1}}],["例如自行车",{"2":{"157":1,"1000":1}}],["例如可见性",{"2":{"126":1}}],["例如可通行性",{"2":{"116":1}}],["例如目标检测和跟踪",{"2":{"126":1}}],["例如clip",{"2":{"98":1}}],["例如cat",{"2":{"41":1}}],["例如segmentanything或sam",{"2":{"109":1}}],["例如segmentanything",{"2":{"98":1}}],["例如描述救护车轨迹或证明红灯停车理由",{"2":{"82":1}}],["例如机器人",{"2":{"80":1}}],["例如",{"2":{"52":1,"90":1,"96":1,"105":3,"109":4,"112":2,"114":1,"116":10,"123":1,"125":2,"131":3,"137":2,"141":2,"147":2,"153":2,"162":6,"172":1,"178":2,"190":2,"197":3,"204":2,"209":1,"210":3,"218":1,"240":1,"254":1,"260":1,"262":5,"283":1,"285":1,"301":4,"325":3,"352":2,"390":4,"406":1,"408":5,"419":1,"421":1,"437":5,"438":1,"449":1,"462":3,"467":1,"510":1,"522":2,"553":2,"557":1,"572":1,"596":1,"601":1,"630":2,"648":1,"653":1,"660":1,"667":2,"691":3,"698":1,"705":1,"721":1,"746":2,"765":2,"777":1,"778":1,"814":1,"864":2,"870":2,"872":1,"889":1,"905":6,"910":2,"917":1,"931":1,"939":2,"950":1,"961":1,"967":4,"988":1,"996":1,"1000":3,"1003":4,"1004":1,"1005":1}}],["自注意力和扩散去噪",{"2":{"970":1}}],["自2019年以来逐渐受到重视",{"2":{"931":1}}],["自2023年以来",{"2":{"759":2}}],["自编码模块中的3d稀疏卷积对于性能至关重要",{"2":{"842":1}}],["自编码模块",{"2":{"716":1}}],["自车的传感器配置为",{"2":{"739":2}}],["自车位姿",{"2":{"597":1}}],["自车具在特定时间戳的姿势",{"2":{"254":1}}],["自监督方法的最高准确性远低于强监督方法",{"2":{"1006":1}}],["自监督学习代表了实现广义3d占用感知的潜在途径",{"2":{"1006":1}}],["自监督训练占用感知网络时不使用任何标签",{"2":{"988":1}}],["自监督分类和重构三个无监督任务组成",{"2":{"574":1}}],["自监督",{"2":{"507":1,"988":1}}],["自我中心",{"2":{"435":1}}],["自由形式解释使监督复杂化",{"2":{"417":1}}],["自适应混合的输出被展平",{"2":{"957":1}}],["自适应的语义建图方法",{"2":{"864":1}}],["自适应空域聚合引入到dcnv3",{"2":{"824":1}}],["自适应推理",{"2":{"334":1}}],["自适应地调整采样率",{"2":{"331":1,"356":1}}],["自然场景的ref图包含边界信息",{"2":{"470":1}}],["自然图像",{"2":{"382":1}}],["自然地将基于体素的地图划分为断开的组件",{"2":{"301":1}}],["自然语言",{"2":{"864":1}}],["自然语言模型往往将生成序列的长度控制在1024或512内",{"2":{"343":1}}],["自然语言通过预训练解码器",{"2":{"195":1}}],["自然语言输入",{"2":{"176":1}}],["自然语言处理与强化学习的交汇点",{"2":{"139":1}}],["自然语言指令和低层执行",{"2":{"82":1}}],["自然语言理解和控制统一在一个策略中",{"2":{"72":1}}],["自身",{"2":{"277":1,"534":1}}],["自行车头盔",{"2":{"462":1}}],["自行车",{"2":{"277":3,"534":1,"630":1,"893":2}}],["自行车架",{"2":{"277":2,"534":1}}],["自回归分词器顺序预测离散动作或轨迹航点",{"2":{"195":1}}],["自下而上的几何验证",{"2":{"141":1,"352":1}}],["自下而上的实例分割方法的思路是",{"2":{"138":1}}],["自上而下的环路闭合检测",{"2":{"141":1,"352":1}}],["自主性与复杂推理能力日益增强",{"2":{"123":1}}],["自动搜索不同权重值",{"2":{"697":1}}],["自动bleu",{"2":{"447":1}}],["自动标注数据",{"2":{"334":1}}],["自动编码和无监督表示学习",{"2":{"314":1}}],["自动编码器中的编码器将高维数据投影到潜在空间",{"2":{"270":1}}],["自动曝光",{"2":{"173":1}}],["自动清洁机器人",{"2":{"90":1}}],["自动驾驶算法框架",{"2":{"1003":1}}],["自动驾驶的世界模型日益突出",{"2":{"963":1}}],["自动驾驶数据集进一步构建了occ3d",{"2":{"757":1}}],["自动驾驶场景包含各种尺度的前景物体",{"2":{"693":1}}],["自动驾驶中3d占用感知方法的总结",{"2":{"877":1}}],["自动驾驶中提出了占用感知技术",{"2":{"667":1}}],["自动驾驶中的占用感知",{"0":{"667":1}}],["自动驾驶中的基于视觉的3d占用预测",{"0":{"608":1},"1":{"637":1,"665":1,"689":1,"712":1,"735":1,"757":1,"778":1,"799":1,"819":1,"839":1,"858":1,"875":1,"892":1,"908":1,"922":1,"932":1,"941":1,"949":1,"956":1,"963":1,"969":1,"975":1,"980":1,"984":1}}],["自动驾驶中的3d占用感知",{"2":{"577":1}}],["自动驾驶中的vlm",{"0":{"128":1}}],["自动驾驶可以提高城市交通效率并减少能源消耗",{"2":{"667":1}}],["自动驾驶系统通常由三个关键模块组成",{"2":{"665":1}}],["自动驾驶系统亦然",{"2":{"176":1}}],["自动驾驶取得了显著进展",{"2":{"665":1}}],["自动驾驶因其减轻驾驶员负担和提高驾驶安全的潜力而受到越来越多的关注",{"2":{"637":1}}],["自动驾驶感知中的知识蒸馏",{"0":{"548":1}}],["自动驾驶感知需要对环境有全面的理解",{"2":{"455":1}}],["自动驾驶推理增强vla模型",{"0":{"334":1}}],["自动驾驶",{"2":{"331":1,"610":1,"637":1}}],["自动驾驶统一端到端vla模型",{"0":{"308":1}}],["自动驾驶模块化vla模型",{"0":{"283":1}}],["自动驾驶车辆系统",{"2":{"691":1}}],["自动驾驶车辆通常还配备激光雷达和环视毫米波雷达",{"2":{"503":1}}],["自动驾驶车辆如何在受限且灵活的",{"2":{"478":1}}],["自动驾驶车辆的感知系统对于构建安全可靠的自动驾驶至关重要",{"2":{"444":1}}],["自动驾驶车辆",{"2":{"409":1,"475":1}}],["自动驾驶车辆日益利用多样传感器模态补充感知以增强空间能力",{"2":{"176":1}}],["自动驾驶车辆必须同时感知复杂三维场景",{"2":{"82":1}}],["自动驾驶研讨会中的",{"2":{"126":1}}],["自动驾驶研究人员正积极将这些方法迁移到车辆领域",{"2":{"72":1}}],["自动驾驶范式比较",{"2":{"92":1}}],["自动驾驶技术演进可划分为四大范式",{"2":{"92":1}}],["自动驾驶发展历程",{"0":{"92":1},"1":{"103":1,"114":1,"128":1,"145":1}}],["自动驾驶视觉",{"2":{"62":1}}],["自定义从大到小的比较器",{"2":{"929":1}}],["自定义属性",{"2":{"57":1}}],["自定义组件",{"0":{"4":1}}],["将深度学习算法部署到目标边缘设备上并非易事",{"2":{"1004":1}}],["将深度图",{"2":{"470":1}}],["将深度图转换为点云来进行场景优化",{"2":{"322":1}}],["将开放集动态占用预测与端到端自动驾驶任务集成",{"2":{"975":1}}],["将开放词汇视觉特征",{"2":{"588":1}}],["将2d图像特征映射到3d空间",{"2":{"970":1}}],["将2d特征图转换为bev",{"2":{"942":1}}],["将晶格特征反投影到点云",{"2":{"962":1}}],["将总训练周期减少到",{"2":{"959":1}}],["将前一帧的特征与当前帧的特征拼接",{"2":{"957":1}}],["将前面的",{"2":{"513":1}}],["将共同推动语义建图向前发展",{"2":{"951":1}}],["将动态物体单独维护",{"2":{"935":1}}],["将作为自注意力层",{"2":{"928":1}}],["将高度维度转换为特征通道维度",{"2":{"923":1}}],["将高斯属性初始化为可学习的向量",{"2":{"716":1}}],["将真实3d点云和伪3d点云转换至柱坐标系",{"2":{"898":1}}],["将n",{"2":{"888":1}}],["将数组n的前5个元素作为双端队列a的初值",{"2":{"888":1}}],["将双端队列a中从第0个到第2个",{"2":{"888":1}}],["将双重掩码策略的附加掩码应用于同一组随机token",{"2":{"315":1}}],["将训练时间从15个epoch延长至24个epoch",{"2":{"876":1}}],["将信息传播到所有体素",{"2":{"875":1}}],["将信息瓶颈扩展到将一组单独的图像压缩成聚类",{"2":{"121":1}}],["将当前队列中元素和que中元素交换",{"2":{"854":1}}],["将kitti",{"2":{"822":2}}],["将进一步分析模型训练和部署期间的资源消耗",{"2":{"811":1}}],["将进行截断",{"2":{"373":1}}],["将自动驾驶场景表示为一组",{"2":{"808":1}}],["将自由形式指令基于自车视觉语境落地并生成对应轨迹",{"2":{"145":1}}],["将大模型与占用感知结合",{"2":{"759":1}}],["将大基础模型集成至驾驶系统存在若干缺点",{"2":{"128":1}}],["将关系矩阵与超体素特征相乘",{"2":{"752":1}}],["将周围世界划分为分辨率为",{"2":{"739":1}}],["将它们的配对索引作为元组",{"2":{"738":1}}],["将它们放置在",{"2":{"660":1}}],["将连续的lidar帧叠加在动态前景上",{"2":{"735":1}}],["将连续的lidar帧叠加在静态背景上",{"2":{"735":1}}],["将连续路径分词为离散驾驶token",{"2":{"334":1}}],["将生成的点云进行体素化",{"2":{"716":1}}],["将体素分类为两种状态",{"2":{"712":1}}],["将体素分组为非重叠的超体素",{"2":{"707":1}}],["将额外的信息注入到后续的特征整合中",{"2":{"705":1}}],["将均值",{"2":{"705":1}}],["将最终四尺度3d特征体积从柱坐标系转换为笛卡尔坐标系",{"2":{"699":1}}],["将最近的",{"2":{"563":1}}],["将可直接解释的信息存入地图",{"2":{"698":1}}],["将四元数转换为旋转矩阵的函数",{"2":{"693":1}}],["将谱域中基于图的网络扩展到不同的图结构仍然具有挑战",{"2":{"688":1}}],["将文献",{"2":{"676":1}}],["将得到的",{"2":{"676":1}}],["将手工制作的基于点对函数的４d旋转不变描述子输入到４d卷积神经网络中",{"2":{"664":1}}],["将多尺度局部区域学习到的特征作为序列",{"2":{"664":1}}],["将多尺度",{"2":{"660":1}}],["将多尺度tpv",{"2":{"621":1}}],["将雷达特征与视觉特征整合可以使性能在",{"2":{"653":1}}],["将不同视点的深度图融合到统一的点云表示中",{"2":{"650":1}}],["将不同的maps聚类到不同的anchors上",{"2":{"328":1}}],["将两种或多种结构结合",{"2":{"648":1}}],["将两个步骤统一为单一的姿态图和网格优化",{"2":{"190":1}}],["将两个不同的latent",{"2":{"181":1}}],["将静态场景表示为多级层次结构",{"2":{"648":1}}],["将网格地图的度量信息与拓扑地图相结合",{"2":{"648":1}}],["将输入图像划分为小块并逐步处理",{"2":{"627":1}}],["将输入点云分为多个点patches",{"2":{"315":1}}],["将采样得到的特征fiℓf",{"2":{"623":1}}],["将伪3d点云转换为柱坐标系",{"2":{"621":1}}],["将提出的depthnet应用于视觉特征",{"2":{"621":1}}],["将提出的框架扩展到一组高级",{"2":{"553":1}}],["将属于这些类别的激光雷达点投影到图像上",{"2":{"617":1}}],["将原始激光雷达点嵌入三维体素化特征的方法与second",{"2":{"609":1}}],["将定位误差与场景中的动态人类和vio的固有漂移耦合在一起",{"2":{"605":1}}],["将参考像素",{"2":{"592":1}}],["将参考图像缩小1",{"2":{"470":1}}],["将摄像头和激光雷达信息整合在一起以进行3d语义占据预测",{"2":{"590":1}}],["将摄像头的帧率降低到",{"2":{"211":1}}],["将卷积的邻域扩大了",{"2":{"589":1}}],["将卷积核的权值定义为k个最近邻上的标准标量积",{"2":{"481":1}}],["将卷积核分为空间和特征部分",{"2":{"481":1}}],["将卷积核分为空间部分和特征部分",{"2":{"481":1}}],["将在3",{"2":{"576":1}}],["将pout转化到getoffset",{"2":{"561":1}}],["将特征学习和场景表示合并为统一的占用表示",{"2":{"922":1}}],["将特征图分成6块",{"2":{"554":1}}],["将特征投影到网格",{"2":{"435":1}}],["将roi对应的特征图分成6×6块",{"2":{"554":1}}],["将排序后的中心点的坐标映射到绝对位置编码",{"2":{"549":1}}],["将环视图像通过二维主干网络进行初步处理",{"2":{"578":1}}],["将环视图像输入",{"2":{"545":1,"746":1}}],["将环境建模为包括低层次几何形状",{"2":{"172":1}}],["将初始深度图经过相机参数映射到点云空间中",{"2":{"524":1}}],["将激光雷达信息与相机相结合",{"2":{"959":1}}],["将激光雷达和环视雷达生成的",{"2":{"545":1,"746":1}}],["将激光雷达",{"2":{"512":1}}],["将一个三维球面邻域划分为多个",{"2":{"511":1}}],["将bev范围从",{"2":{"800":1}}],["将bev特征从形状b×c×w×h转换为形状b×c",{"2":{"703":1}}],["将bev特征与语言集成以支持3d空间查询和多模态未来预测",{"2":{"128":1}}],["将bev推广到三视角",{"2":{"547":1}}],["将bev的输出逻辑提升到3d空间中",{"2":{"505":1}}],["将该局部地图旋转",{"2":{"495":1}}],["将该估计问题形式化为非线性最小二乘优化",{"2":{"171":1}}],["将其转换为柱坐标体积",{"2":{"676":1}}],["将其分配为正样本",{"2":{"591":1}}],["将其对齐到全局栅格",{"2":{"495":1}}],["将其与后向过程中的噪声图像混合",{"2":{"264":1,"266":1}}],["将现有3d占用预测方法的内存消耗降低了75",{"2":{"486":1}}],["将voxel",{"2":{"485":1}}],["将vlm",{"2":{"334":1}}],["将vlm作为中间模块为端到端系统提供反馈或辅助信号",{"2":{"128":1}}],["将fb",{"2":{"482":1}}],["将预定义的深度分布坐标",{"2":{"578":1}}],["将预处理的更密集",{"2":{"482":1}}],["将预积分的imu和视觉测量值添加到固定滞后平滑器",{"2":{"310":1}}],["将鸟瞰图的输出提升到三维空间",{"2":{"482":1}}],["将某个点周围的点的局部子集作为输入",{"2":{"481":1}}],["将加速迈向安全",{"2":{"478":1}}],["将上述两种或多种结构组合",{"2":{"465":1}}],["将源视图的特征图经过相机参数warp到参考视图",{"2":{"464":1}}],["将障碍物表示为边界框",{"2":{"455":1}}],["将相邻帧的2d特征和3d坐标分别串联在一起",{"2":{"583":1}}],["将相机坐标转换到世界坐标",{"2":{"435":1}}],["将相同哈希值的键值对放在对应的桶中",{"2":{"196":1}}],["将每个插件替换与其对应结构",{"2":{"770":1}}],["将每个层级的",{"2":{"746":1}}],["将每个层级的合并后的全局",{"2":{"545":1,"746":1}}],["将每个体素的中心点投影到图像特征平面上",{"2":{"609":1}}],["将每个点看作图的一个顶点",{"2":{"574":1}}],["将每个roi对应的特征的维度转化成某个定值",{"2":{"432":1,"741":1}}],["将每个剩余像素的原始邻域信息编码到32通道的像素描述符中",{"2":{"305":1}}],["将3d语义占用预测形式化为一组二进制3d掩码的估计",{"2":{"957":1}}],["将3d空间中的体素中心投影到2d前视特征图上",{"2":{"950":1}}],["将3d空间划分为体素",{"2":{"535":1}}],["将3d高斯分布嵌入到大小为",{"2":{"738":1}}],["将3d高斯分布投影到目标2d视图上",{"2":{"641":1}}],["将3d位置感知特征展平",{"2":{"427":1}}],["将3d位置嵌入与同一视角的2d图像特征相加",{"2":{"427":1}}],["将3d点云投影到2d地图上",{"2":{"172":1}}],["将中心点的坐标编码到一维空间中",{"2":{"426":1}}],["将这4个特征互相之间视为positive",{"2":{"424":1}}],["将这些基元解释为局部语义高斯分布",{"2":{"656":1}}],["将这些参考点投影至",{"2":{"595":1}}],["将这些pout点合并后可以获得hash",{"2":{"530":1}}],["将这些关系进行解耦",{"2":{"149":1}}],["将这些特征表示为图节点",{"2":{"114":1}}],["将新节点与最接近它的节点关联",{"2":{"419":1}}],["将新文本和图像送入clip模型后",{"2":{"204":1}}],["将集群规模策略压缩为嵌入式",{"2":{"417":1}}],["将逻辑交规嵌入为硬约束或附加惩罚",{"2":{"417":1}}],["将整个3d空间均匀划分为离散的体素",{"2":{"415":1}}],["将getoffset",{"2":{"561":1}}],["将gpu留给面向学习的成分",{"2":{"408":1}}],["将gan的感知能力",{"2":{"248":1}}],["将token",{"2":{"373":1}}],["将图像经",{"2":{"495":1}}],["将图像特征从2d空间提升到bev空间",{"2":{"839":1}}],["将图像特征从二维图像平面转换到三维体空间是一个关键步骤",{"2":{"609":1}}],["将图像特征从二维空间转换到三维体空间",{"2":{"421":1}}],["将图像特征投影到3d空间",{"2":{"585":1}}],["将图像特征和3d点云坐标进行拼接得到增广点云特征点如式2所示",{"2":{"464":1}}],["将图像编码成一个个具体且感知丰富",{"2":{"371":1}}],["将图像和任意的文本联系起来",{"2":{"167":1}}],["将叶子节点八分角点采样的法向量作为该三维模型的平均法向量输入到网络中",{"2":{"363":1}}],["将object",{"2":{"358":1}}],["将所有占据池化和",{"2":{"670":1}}],["将所有真实三维框的中心点映射到目标热图t上",{"2":{"666":1}}],["将所有proposal按照前景分数从高到低排序",{"2":{"493":1}}],["将所有坐标转换为哈希键",{"2":{"385":1}}],["将所有特征图变换到参考相机的锥形立体空间",{"2":{"355":1}}],["将所有其他值设置为",{"2":{"153":1}}],["将点云旋转为具有相对较小固定长度的向量",{"2":{"664":1}}],["将点云体素化为均匀的三维网格",{"2":{"664":1}}],["将点云特征",{"2":{"579":1}}],["将点云中自下而上的潜在特征分组为超级点",{"2":{"349":1}}],["将点聚过程",{"2":{"574":1}}],["将点特征插值到相邻的离散卷积核权坐标",{"2":{"511":1}}],["将点卷积运算定义为可学习的径向函数和球谐函数的乘积",{"2":{"481":1}}],["将点块按照相同的顺序排列",{"2":{"426":1}}],["将点之间的关系融入到点云处理中",{"2":{"258":1}}],["将向vio后端添加规则性因子",{"2":{"336":1}}],["将cot与动作对齐",{"2":{"334":1}}],["将cad模型拟合到度量",{"2":{"131":1}}],["将三维几何先验知识和纹理信息融入到点云中生成增强点云",{"2":{"322":1}}],["将以上这个过程重复nnn次",{"2":{"312":1}}],["将任务转变为了图像补全任务",{"2":{"312":1}}],["将传感器",{"2":{"308":1}}],["将噪声的方差",{"2":{"304":1}}],["将逐渐关闭",{"2":{"301":1}}],["将地点分割为房间以及找到房间之间的连通性需要几分钟",{"2":{"816":1}}],["将地点原语节点聚类成区域",{"2":{"295":1}}],["将地点图聚类成房间",{"2":{"141":1}}],["将语义标签嵌入高斯泼溅以执行",{"2":{"588":1}}],["将语义标记的点云集成到环境中的截断有符号距离场",{"2":{"253":1}}],["将语言模态引入驾驶任务有望提升自动驾驶系统的推理",{"2":{"128":1}}],["将隐式的",{"2":{"247":1}}],["将增强网络和高层模型",{"2":{"220":1}}],["将超分任务描述成一个有条件生成",{"2":{"175":1}}],["将之前两类扩散模型进行了理论上的统一",{"2":{"170":1}}],["将==我们之前的工作",{"2":{"141":1}}],["将",{"2":{"133":1,"137":1,"175":1,"435":1,"469":1,"488":1,"567":1,"570":1,"592":1,"621":2,"632":1,"654":2,"765":2,"824":1,"850":2,"962":1}}],["将度量",{"2":{"131":1}}],["将很快推出",{"2":{"126":1}}],["将物体识别和场景理解整合进空间地图",{"2":{"123":1}}],["将虚拟机的",{"2":{"120":1}}],["将驾驶任务显式分解为感知",{"2":{"103":1}}],["将感知",{"2":{"92":1}}],["将感知与推理",{"2":{"90":1}}],["将强语义先验引入驾驶感知",{"2":{"82":1}}],["将宿主机器的空闲端口映射到容器端口",{"2":{"60":1}}],["将尝试针对nvidia",{"2":{"27":1}}],["默认底层容器是deque",{"2":{"938":1}}],["默认设置",{"2":{"836":1}}],["默认",{"2":{"835":1}}],["默认是以deque为缺省情况下栈的底层结构",{"2":{"685":1}}],["默认k=9",{"2":{"321":1}}],["默认为",{"2":{"136":1}}],["默认端口是22",{"2":{"60":1}}],["默认情况下",{"2":{"27":1}}],["项目编号",{"2":{"960":1,"1008":1}}],["项目网站",{"2":{"415":1}}],["项目",{"2":{"58":1,"423":1}}],["↩︎",{"2":{"57":4,"914":3}}],[">c",{"2":{"208":1}}],[">a",{"2":{"208":1}}],[">xt",{"2":{"208":1}}],[">x2",{"2":{"208":1}}],[">x1",{"2":{"208":1}}],[">second",{"2":{"196":2}}],[">first",{"2":{"196":2}}],[">f",{"2":{"111":1,"236":1}}],[">d",{"2":{"111":1,"208":1,"236":1}}],[">b",{"2":{"111":1,"208":1,"236":1}}],[">>",{"2":{"78":2,"87":1}}],[">",{"2":{"57":1,"67":6,"76":1,"196":6,"685":1,"929":1}}],["链接",{"0":{"78":1},"2":{"57":3}}],["有多种数据集可用于评估占用预测方法的性能",{"2":{"997":1}}],["有三种主要的多模态信息融合技术用于整合不同模态分支的信息",{"2":{"976":1}}],["有三个关键挑战",{"2":{"799":1}}],["有",{"2":{"938":1}}],["有趣的是",{"2":{"903":1,"944":1}}],["有趣的驾驶操作",{"2":{"126":1}}],["有一个走廊",{"2":{"872":1}}],["有一些小但重要的修改",{"2":{"253":1}}],["有限标签下的高效学习结果",{"0":{"782":1}}],["有限状态机或图搜索生成路径",{"2":{"103":1}}],["有望减少繁琐的3d占用标注需求",{"2":{"759":1}}],["有望有效减少交通事故",{"2":{"665":1}}],["有必要探索基于弱监督或自监督的网络训练",{"2":{"1000":1}}],["有必要进一步研究大规模点云的有效分割问题",{"2":{"996":1}}],["有必要从多个特征图中进行空间信息融合",{"2":{"957":1}}],["有必要在世界坐标系中用均匀的高斯分布初始化整个场景",{"2":{"728":1}}],["有必要正确对齐这些",{"2":{"96":1}}],["有dm",{"2":{"709":2}}],["有和没有动态掩蔽",{"2":{"709":1}}],["有关teaser++的计时性能详细信息",{"2":{"816":1}}],["有关kimera",{"2":{"754":1}}],["有关指标计算细节",{"2":{"677":1}}],["有关每个类别的详细定义和示例图像",{"2":{"277":2,"302":1,"534":1}}],["有点不相关",{"2":{"668":1}}],["有了dsgs",{"2":{"930":1,"939":1}}],["有了这种多尺度的特征",{"2":{"631":1}}],["有了以上的定义",{"2":{"422":1}}],["有两种方式可以融合这些命中的2d特征",{"2":{"957":1}}],["有两种思路",{"2":{"138":1}}],["有两个关键步骤",{"2":{"932":1}}],["有两个不同时间出现的站立人类",{"2":{"605":1}}],["有两篇相关综述",{"2":{"714":1}}],["有些",{"2":{"603":1}}],["有些方法还在边中存储节点间的空间关系",{"2":{"525":1}}],["有些方法还使用现有的算法来执行卷积",{"2":{"481":1}}],["有相似之处",{"2":{"566":1}}],["有无动态代理",{"2":{"541":1}}],["有助于理解场景和物体",{"2":{"942":1}}],["有助于模型预测每个体素网格的语义类别",{"2":{"768":1}}],["有助于减少感知系统的计算",{"2":{"211":1}}],["有助",{"2":{"478":1}}],["有没有办法既兼具cnn的先验偏置",{"2":{"343":1}}],["有序的点块序列被输入到提取器中",{"2":{"315":1}}],["有序列表3",{"2":{"57":1}}],["有序列表2",{"2":{"57":1}}],["有序列表1",{"2":{"57":1}}],["有监督预训练测试",{"0":{"313":1}}],["有四个关键模块",{"2":{"285":1}}],["有骑手",{"2":{"277":1}}],["有非零的重叠区域",{"2":{"271":1}}],["有近似",{"2":{"235":1}}],["有效预训练方法是通过深度估计任务增强模型几何感知能力",{"2":{"617":1}}],["有效地处理了高斯之间的重叠区域",{"2":{"916":1}}],["有效地体素化",{"2":{"791":1}}],["有效地利用了这些信息",{"2":{"421":1}}],["有效地捕捉点云的局部和全局上下文信息",{"2":{"356":1}}],["有效从合理安全机动分布中采样",{"2":{"308":1}}],["有效将自然语言嵌入规划循环核心",{"2":{"283":1}}],["有效返回距离可达",{"2":{"173":1}}],["有效行为不仅依赖于低级感知与执行",{"2":{"90":1}}],["有时",{"2":{"992":1}}],["有时称为slammot",{"2":{"967":1}}],["有时还包含视角方向",{"2":{"619":1}}],["有时则有害",{"2":{"462":1}}],["有时则需保留更细粒度的信息",{"2":{"139":1}}],["有时仅在地图中存储物体类别即可",{"2":{"139":1}}],["有时候可以用梯度下降法做到",{"2":{"129":1}}],["有意识或无意识地",{"2":{"109":1}}],["有用性",{"2":{"109":1}}],["有部分包需要手动降级",{"2":{"27":1}}],["无lidar方法建立了全面的自监督框架",{"2":{"949":1}}],["无lidar方法",{"0":{"949":1}}],["无注释方法",{"0":{"941":1}}],["无",{"2":{"928":1}}],["无返回值",{"2":{"753":1}}],["无纹理的墙壁很难重建",{"2":{"732":1}}],["无dm",{"2":{"709":2}}],["无垂直方向的信息",{"2":{"630":1}}],["无人机的速度越快",{"2":{"572":1}}],["无人机",{"2":{"570":1}}],["无条件图像合成",{"2":{"552":1}}],["无监督嵌入聚类",{"2":{"525":1}}],["无监督预训练可以有效提高不同下游任务",{"2":{"265":1}}],["无分割任务",{"2":{"454":1}}],["无噪声传感器",{"2":{"435":1}}],["无保护转弯",{"2":{"360":1}}],["无结构视觉模型使用dlt",{"2":{"310":1}}],["无骑手",{"2":{"277":1}}],["无需任何体素化",{"2":{"968":1}}],["无需任务专用监督",{"2":{"619":1}}],["无需针对每个任务重新建图",{"2":{"897":1}}],["无需计算密集型3d体素级表示处理",{"2":{"811":1}}],["无需复杂3d卷积计算的高效通道到高度变换",{"2":{"811":1}}],["无需关心地图本身的质量",{"2":{"786":1}}],["无需额外监督",{"2":{"743":1}}],["无需额外训练",{"2":{"264":1}}],["无需跨模态信息和教师模型的参与",{"2":{"643":1}}],["无需人工标签",{"2":{"525":1}}],["无需人工标注",{"2":{"525":1}}],["无需相机位置",{"2":{"485":1}}],["无需多视图信息",{"2":{"485":1}}],["无需通过设计复杂的结构处理",{"2":{"235":1}}],["无序",{"2":{"217":1}}],["无序列表3",{"2":{"57":1}}],["无序列表2",{"2":{"57":1}}],["无序列表1",{"2":{"57":1}}],["无论机制如何",{"2":{"963":1}}],["无论数据是由真实生活",{"2":{"889":1}}],["无论地图采用何种结构",{"2":{"675":1}}],["无论环境的空间稀疏性如何",{"2":{"599":1}}],["无论环境的大小如何",{"2":{"141":1}}],["无论室内还是室外场景都能适用",{"2":{"570":1}}],["无论哪种方法",{"2":{"495":1}}],["无论采用何种地图表示或训练方式",{"2":{"252":1}}],["无论是明示的还是暗示的",{"2":{"467":1}}],["无论是基于融合还是仅视觉的",{"2":{"425":1}}],["无论是物理还是虚拟智能体",{"2":{"350":1}}],["无论是物理机器人还是模拟的身体",{"2":{"100":1}}],["无论是物理机器人还是虚拟具身系统",{"2":{"90":1}}],["无论是以几何原语的稀疏或密集集合",{"2":{"105":1}}],["无视它",{"2":{"66":1}}],["无法基于人类提示灵活扩展新类别感知",{"2":{"975":1}}],["无法提供足够细节",{"2":{"913":1}}],["无法满足自动驾驶对实时性的要求",{"2":{"601":1}}],["无法应用于需要逐步感知场景的具身智能体",{"2":{"568":1}}],["无法保留全局结构",{"2":{"495":1}}],["无法预先探索的场景",{"2":{"435":1}}],["无法在大多数区域准确估计score",{"2":{"291":1}}],["无法做到改变姿势角度等变化",{"2":{"264":1}}],["无法直接通过右键中的copy",{"2":{"24":1}}],["无法解决过拟合问题",{"2":{"20":1}}],["∂ωr∂r​",{"2":{"57":1}}],["∂r∂ωr",{"2":{"57":1}}],["数量",{"2":{"489":1}}],["数组构造",{"2":{"261":1}}],["数学运算",{"2":{"435":1}}],["数学",{"2":{"328":1}}],["数学上",{"2":{"137":2,"988":1}}],["数学表达式",{"2":{"57":1}}],["数值输出模糊",{"2":{"128":1}}],["数据生成是一个有前景的方向",{"2":{"963":1}}],["数据层面",{"0":{"963":1}}],["数据量激增",{"2":{"864":1}}],["数据量超过某阈值后收益递减",{"2":{"114":1}}],["数据转换为",{"2":{"850":2}}],["数据转换到",{"0":{"810":1},"1":{"830":1,"850":1}}],["数据采集车辆配备了一个激光雷达",{"2":{"770":1}}],["数据预处理",{"2":{"761":1}}],["数据来自",{"2":{"749":1}}],["数据增强",{"0":{"611":1}}],["数据需求少",{"2":{"507":1}}],["数据与标注瓶颈",{"2":{"478":1}}],["数据的查询选择的简化版本和非变换器编码器来缩小这一差距",{"2":{"471":1}}],["数据关联",{"2":{"419":1}}],["数据是按一个特定顺序输入网络的",{"2":{"407":1}}],["数据索引式等其他典型网络",{"2":{"391":1}}],["数据处理以生成稀疏张量",{"2":{"385":1}}],["数据作为输入",{"2":{"285":1}}],["数据标注",{"0":{"277":1}}],["数据文件格式",{"2":{"254":1}}],["数据格式",{"0":{"254":1}}],["数据",{"0":{"810":1},"1":{"830":1,"850":1},"2":{"171":1,"334":2,"652":1}}],["数据收集在",{"2":{"254":1}}],["数据收集",{"0":{"142":1},"1":{"157":1,"173":1,"191":1,"211":1,"233":1}}],["数据集创建",{"2":{"997":1}}],["数据集细节",{"0":{"886":1}}],["数据集类似",{"2":{"872":1}}],["数据集进行的",{"2":{"900":1}}],["数据集进行占据预测训练时",{"2":{"893":1}}],["数据集进行辅助三维目标检测训练",{"2":{"893":1}}],["数据集进行",{"2":{"787":1}}],["数据集通常提供相机可见性掩码",{"2":{"778":1}}],["数据集由来自不同室内场景的视频序列组成",{"2":{"757":1}}],["数据集含18类",{"2":{"742":1}}],["数据集与指标",{"0":{"742":1}}],["数据集与基准",{"0":{"360":1}}],["数据集包含",{"2":{"739":2}}],["数据集包括两个独立的记录",{"2":{"437":1}}],["数据集和我们使用的评估指标",{"2":{"793":1}}],["数据集和kitti",{"2":{"760":1}}],["数据集和指标",{"0":{"739":1,"994":1},"1":{"997":1,"998":1}}],["数据集和评估指标",{"0":{"736":1,"749":1}}],["数据集和代码",{"2":{"665":1}}],["数据集和代码的集合",{"2":{"637":1}}],["数据集是一个多模态非道路驾驶数据集",{"2":{"652":1}}],["数据集提供了语义占据标注",{"2":{"652":1}}],["数据集提供了",{"2":{"652":1}}],["数据集提供视觉",{"2":{"437":1}}],["数据集之前",{"2":{"605":1}}],["数据集构建要求",{"2":{"573":1}}],["数据集构建需求",{"0":{"446":1},"1":{"476":1,"504":1,"534":1,"565":1,"597":1,"626":1,"654":1,"679":1,"702":1,"725":1,"747":1,"769":1,"790":1,"810":1,"830":1,"850":1}}],["数据集上的语义分割结果比较",{"2":{"979":1}}],["数据集上进行训练",{"2":{"893":1}}],["数据集上进行了语义场景补全实验",{"2":{"900":1}}],["数据集上进行了占据预测实验",{"2":{"770":1}}],["数据集上进行了实验",{"2":{"760":1}}],["数据集上进行了广泛的实验",{"2":{"536":1,"567":1}}],["数据集上",{"2":{"889":1,"928":2}}],["数据集上评估了",{"2":{"853":1}}],["数据集上针对语义场景补全任务进行了对比实验",{"2":{"927":1}}],["数据集上针对",{"2":{"851":1}}],["数据集上包括结果",{"2":{"492":1}}],["数据集还提供了地面真实机器人轨迹",{"2":{"437":1}}],["数据集覆盖vla4ad研究全谱",{"2":{"360":1}}],["数据集覆盖广泛",{"2":{"360":1}}],["数据集标注了激光雷达分割标签",{"2":{"302":1}}],["数据集为著名的",{"2":{"302":1}}],["数据集中包含的语义类别数量",{"2":{"997":1}}],["数据集中包含的3d扫描总数",{"2":{"997":1}}],["数据集中包含的不同场景总数",{"2":{"997":1}}],["数据集中使用",{"2":{"982":1}}],["数据集中缺乏严重的雨天条件",{"2":{"936":1}}],["数据集中自由空间与占用空间体素的比例大约为",{"2":{"928":1}}],["数据集中随机采样的",{"2":{"886":1}}],["数据集中的场景进行了分组",{"2":{"914":1}}],["数据集中的帧",{"2":{"886":1}}],["数据集中的帧是从原始",{"2":{"886":1}}],["数据集中的体素标签中获得该场景的全局空间占用",{"2":{"886":1}}],["数据集中的所有场景",{"2":{"886":1}}],["数据集中的所有目标都配有语义类别",{"2":{"277":1}}],["数据集中没有冰箱",{"2":{"872":1}}],["数据集中",{"2":{"302":1}}],["数据集的dsg",{"2":{"872":2,"947":1}}],["数据集的22个序列和超过43",{"2":{"757":1}}],["数据集的数字索引越大",{"2":{"572":1}}],["数据集的训练集中",{"2":{"421":1}}],["数据集的语义分割",{"2":{"306":1}}],["数据集的性能",{"2":{"265":1}}],["数据集的启发",{"2":{"126":1}}],["数据集用于商业目的",{"2":{"126":1,"302":1}}],["数据集仅可用于非商业目的",{"2":{"126":1}}],["数据集受到开创性的",{"2":{"126":1}}],["数据集",{"0":{"108":1,"241":1,"327":1,"572":1,"652":1,"757":1,"781":1,"787":1,"828":1,"900":1,"997":1},"1":{"605":1},"2":{"32":1,"126":2,"157":2,"277":1,"437":1,"522":1,"605":1,"665":1,"709":1,"739":2,"742":1,"749":2,"793":1,"796":1,"841":1,"853":1,"855":2,"885":1,"886":1,"893":1,"901":1,"947":1}}],["数据集问题",{"2":{"13":1}}],["数十年研究使其在常见条件下可靠",{"2":{"82":1}}],["内部",{"2":{"846":1}}],["内在评估",{"2":{"786":1,"826":1}}],["内的占用状态",{"2":{"712":1}}],["内将场景划分为体素",{"2":{"652":2}}],["内将分割segments与现有track关联起来",{"2":{"206":1}}],["内点像素",{"2":{"622":1}}],["内存占用增加以及延迟更高",{"2":{"965":1}}],["内存友好且易于增量更新的稠密地图仍是值得深耕的未来方向",{"2":{"913":1}}],["内存友好",{"2":{"881":1}}],["内存消耗比其他",{"2":{"865":1}}],["内存消耗低的小数据集上具有较好的性能",{"2":{"481":1}}],["内存效率和部署友好性方面优于先前的最先进方法",{"2":{"831":1}}],["内存充足时最多用16帧",{"2":{"764":1}}],["内存队列存储历史对象查询",{"2":{"695":1}}],["内存需求及动态场景处理仍是挑战",{"2":{"619":1}}],["内存",{"2":{"545":1,"670":2,"744":1,"867":1,"882":1,"965":1}}],["内存开销低",{"2":{"525":1}}],["内存与延迟",{"2":{"417":1}}],["内核",{"2":{"441":1}}],["内置相机校准",{"2":{"254":1}}],["内",{"2":{"253":1}}],["内积",{"2":{"184":2}}],["内容嵌入",{"2":{"623":1}}],["内容右对齐",{"2":{"57":1}}],["内容居中",{"2":{"57":1}}],["内容",{"2":{"57":1}}],["内环境",{"0":{"50":1},"1":{"60":1,"69":1,"78":1}}],["斜体文字",{"2":{"57":1}}],["斜体",{"2":{"57":1}}],["设p^k",{"2":{"814":1}}],["设",{"2":{"682":1,"739":1}}],["设计能够从异构传感器和多个机器人收集的传感器数据估计dsg的引擎将是有趣的",{"2":{"973":1}}],["设计评估指标",{"0":{"943":1}}],["设计部署友好的3d表示的方法旨在减少计算成本并提高学习效率",{"2":{"892":1}}],["设计选择",{"2":{"812":1}}],["设计用于在垂直配置中安装两个intel",{"2":{"605":1}}],["设计了一个自监督框架",{"2":{"975":1}}],["设计了一个稀疏自动调优器",{"2":{"593":1}}],["设计了",{"2":{"591":1}}],["设计了首个",{"2":{"474":1}}],["设定了一个半监督知识蒸馏问题",{"2":{"548":1}}],["设定",{"2":{"193":1}}],["设定默认值以及定义该自定义属性是否可以被继承",{"2":{"57":1}}],["设置向量中前n个元素的值为x",{"2":{"161":1}}],["设置vector容器大小",{"2":{"146":1}}],["设置环境变量",{"2":{"87":1}}],["设置开机自启",{"2":{"26":1}}],["设置为1米",{"2":{"649":1}}],["设置为",{"2":{"26":1,"153":1}}],["设置",{"0":{"26":1},"2":{"78":1}}],["设置虚拟内存",{"0":{"18":1},"1":{"26":1,"33":1}}],["驱动",{"0":{"55":1},"1":{"66":1},"2":{"66":1}}],["检索增强控制",{"2":{"334":1}}],["检测基准的",{"2":{"931":1}}],["检测性能",{"0":{"893":1}}],["检测房间",{"2":{"816":1}}],["检测人类",{"2":{"816":1}}],["检测任务",{"2":{"806":1}}],["检测预训练和更长的训练计划有助于实现融合式",{"2":{"803":1}}],["检测所有物体",{"2":{"765":1}}],["检测器多阶段蒸馏实践的启发",{"2":{"694":1}}],["检测分数",{"2":{"653":1}}],["检测有限",{"2":{"630":1,"665":1}}],["检测头",{"0":{"594":1},"1":{"623":1}}],["检测查询",{"2":{"550":1,"644":1}}],["检测学习中",{"2":{"548":1}}],["检测即标记",{"2":{"512":1}}],["检测等",{"2":{"423":1}}],["检测",{"0":{"711":1},"1":{"734":1,"756":1,"777":1,"798":1,"818":1,"838":1,"857":1,"874":1,"891":1,"907":1,"921":1,"931":1},"2":{"220":1,"360":1,"691":1,"864":1,"1003":2}}],["检测模型如yolo",{"2":{"138":1}}],["检测挑战赛",{"2":{"126":1}}],["检测图像中的感兴趣区域",{"2":{"121":1}}],["检测为什么不能直接用于交互式分割的几个原因",{"2":{"54":1}}],["检查点初始化",{"2":{"822":1}}],["检查点",{"2":{"771":1}}],["检查图7中的回路l1和l2是否彼此一致",{"2":{"390":1}}],["检查",{"2":{"66":1}}],["检查是否已安装",{"0":{"49":1}}],["可实现约",{"2":{"936":1}}],["可实时地从传感器数据增量式构建",{"2":{"648":1}}],["可再引入层级结构",{"2":{"935":1}}],["可承担全局引导",{"2":{"935":1}}],["可复现的评估基准",{"2":{"864":1}}],["可复用的基础技能",{"2":{"274":1}}],["可扩展且实时的地图",{"2":{"864":1}}],["可扩展性",{"2":{"864":1}}],["可扩展性与效率",{"2":{"417":1}}],["可扩展",{"2":{"864":2,"881":1}}],["可存颜色",{"2":{"864":1}}],["可泛化的地图评估框架的重要研究方向",{"2":{"846":1}}],["可泛化到新场景的在线3d",{"2":{"641":1}}],["可改用",{"2":{"826":1}}],["可将性能提升0",{"2":{"800":1}}],["可将这些任务归为三类",{"2":{"139":1}}],["可借助从大规模视觉",{"2":{"765":1}}],["可用",{"2":{"826":1}}],["可用于在不同位置从不同表达子空间学习更丰富的信息",{"2":{"863":1}}],["可用于训练目的",{"2":{"736":1}}],["可用于路径规划",{"2":{"197":1}}],["可用的语义线索",{"2":{"698":1}}],["可离线建图后供多任务使用",{"2":{"698":1}}],["可分离的辅助检测头",{"0":{"666":1}}],["可分为多种路线",{"2":{"189":1}}],["可学习的3d坐标",{"2":{"623":1}}],["可学习的向量",{"2":{"623":1}}],["可学习的高斯物理属性",{"2":{"563":1}}],["可自然语言查询的",{"2":{"619":1}}],["可精确表示几何",{"2":{"619":1}}],["可为每个点附加语义标签",{"2":{"588":1}}],["可是对逐像素的预测目标是有害的",{"2":{"554":1}}],["可指令遵循且社会对齐的自动驾驶车辆",{"2":{"538":1}}],["可指令遵循且社会合规的自动驾驶车辆提供一致而前瞻的参考",{"2":{"82":1}}],["可变形卷积网络却可能扩展到感兴趣区域之外从而使得不相关的区域影响网络的性能",{"2":{"804":1}}],["可变形卷积能够很好地学习到发生形变的物体",{"2":{"804":1}}],["可变形卷积v2",{"2":{"804":1}}],["可变形卷积",{"2":{"616":1}}],["可变形卷机",{"2":{"562":1}}],["可变形",{"2":{"535":1,"598":1,"831":1}}],["可变形注意力的高斯细化铺平了道路",{"2":{"899":1}}],["可变形注意力的新型多模态语义占据预测框架",{"2":{"767":1}}],["可变形注意力运算符",{"2":{"866":1}}],["可变形注意力可以转换为深度加权的",{"2":{"866":1}}],["可变形注意力模块都为",{"2":{"723":1}}],["可变形注意力函数以及从世界坐标到像素坐标的转换",{"2":{"716":1}}],["可变形注意力操作引入的计算开销",{"2":{"700":1}}],["可变形注意力和属性细化模块迭代更新高斯",{"2":{"502":1}}],["可变形注意力将激光雷达和摄像头输入转换为多模态体素特征",{"2":{"474":1}}],["可变形注意力机制增强了模型对动态车辆",{"2":{"723":1}}],["可变形注意力机制",{"2":{"444":1,"767":1}}],["可变形注意力",{"2":{"444":1,"866":3}}],["可达性估计器",{"2":{"525":1}}],["可达性距离阈值",{"2":{"525":1}}],["可视化结果证明了3d高斯分布捕捉物体形状细节以及合理分配计算和存储资源的能力",{"2":{"861":1}}],["可视化结果如图",{"2":{"847":1}}],["可视化结果",{"2":{"842":1}}],["可视化结果令人信服地证明了flashocc成功保留了高度信息",{"2":{"831":1}}],["可视化",{"0":{"832":1,"909":1}}],["可视化和基准测试vio",{"2":{"510":1}}],["可视为带有可变密度的",{"2":{"378":1}}],["可快速适配",{"2":{"507":1}}],["可保持v2v链路带宽足够低",{"2":{"507":1}}],["可验证驾驶平台",{"2":{"507":1}}],["可减少噪声",{"2":{"495":1}}],["可信v2v或标准化评估",{"2":{"478":1}}],["可信评估必须衡量",{"2":{"447":1}}],["可构建为",{"2":{"465":1}}],["可表示为形状",{"2":{"495":1}}],["可表示为",{"2":{"435":1}}],["可靠且可查询的多模态融合仍是开放问题",{"2":{"864":1}}],["可靠且易于获取",{"2":{"126":1}}],["可靠的占据预测不仅需要准确的空间数据",{"2":{"421":1}}],["可训练的端到端的gumbel",{"2":{"420":1}}],["可微渲染",{"2":{"619":1}}],["可微",{"2":{"420":1}}],["可微的",{"2":{"247":1}}],["可选的细化模块",{"2":{"970":1}}],["可选的时序融合模块",{"2":{"908":1}}],["可选的时间融合模块",{"2":{"598":1}}],["可选",{"2":{"942":1}}],["可选辅助感知头map",{"2":{"447":1}}],["可选择以自我为中心的坐标系",{"2":{"435":1}}],["可选强化学习用于红灯惩罚",{"2":{"417":1}}],["可选地通过关系损失",{"2":{"752":1}}],["可选地",{"2":{"121":1}}],["可记录该位置是否存在障碍物",{"2":{"406":1}}],["可直接利用模型输出的置信度或预测方差",{"2":{"826":1}}],["可直接利用深度值和语义标签生成3d占据结果",{"2":{"617":1}}],["可直接用于各类下游任务",{"2":{"765":1}}],["可直接处理无序点集",{"2":{"588":1}}],["可直接优化任务性能",{"2":{"299":1}}],["可直译为",{"2":{"217":1}}],["可行驶表面",{"2":{"277":1,"534":1}}],["可推拉物体",{"2":{"277":1,"534":1}}],["可移动物体",{"2":{"277":4,"534":4}}],["可采用以下策略",{"2":{"274":1}}],["可形变的四面体网格",{"2":{"247":1}}],["可化简",{"2":{"235":1}}],["可灵活通过模型预测控制",{"2":{"216":1}}],["可供性预测与",{"2":{"588":1}}],["可供性",{"2":{"209":1}}],["可供性等",{"2":{"90":1,"588":1}}],["可写成",{"2":{"171":1}}],["可解释的决策制定和运动规划",{"2":{"630":1,"667":1}}],["可解释",{"2":{"145":1,"216":1,"334":1,"864":1}}],["可解释性差",{"2":{"864":1}}],["可解释性低",{"2":{"619":1}}],["可解释性和泛化能力",{"2":{"128":1}}],["可解释性有限",{"2":{"114":1}}],["可解释性",{"2":{"90":1,"252":1}}],["可能导致信息丢失和累积错误",{"2":{"975":1}}],["可能导致了错误的检测",{"2":{"775":1}}],["可能会引入更多噪声",{"2":{"893":1}}],["可能不在目标检测框内",{"2":{"630":1}}],["可能遗漏部分观测",{"2":{"525":1}}],["可能引发安全隐患",{"2":{"503":1}}],["可能影响任务性能",{"2":{"495":1}}],["可能由于误差累积而产生",{"2":{"480":1}}],["可能需要丢弃帧以跟上图像流",{"2":{"462":1}}],["可能具有边界边缘",{"2":{"325":1}}],["可能是多层",{"2":{"301":1}}],["可能有许多类型的动态实体",{"2":{"178":1}}],["可能产生幻觉或误解口语指令",{"2":{"82":1}}],["可能在前后和中间含有多个空格",{"2":{"52":1}}],["可查询的地图",{"2":{"951":1}}],["可查询的通用表征",{"2":{"881":1}}],["可查询的通用语义地图日益成为具身智能与现实机器人推理的核心",{"2":{"864":1}}],["可查询的语义地图",{"2":{"588":1}}],["可查询",{"2":{"80":1}}],["可以促进各种自动驾驶任务",{"2":{"1002":1}}],["可以同时优化语义和几何的损失包括场景类别亲和力损失",{"2":{"985":1}}],["可以扩展到改进3d占用预测任务",{"2":{"975":1}}],["可以提高准确性和可靠性",{"2":{"957":1}}],["可以提供各个尺度的特征信息",{"2":{"631":1}}],["可以帮助推理被遮挡区域并识别物体的运动状态",{"2":{"957":1}}],["可以得到以下观察",{"2":{"931":1}}],["可以得出以下几个结果",{"2":{"688":1}}],["可以采用先排序后反转的方式",{"2":{"929":1}}],["可以有效降低计算复杂性",{"2":{"908":1}}],["可以有效地捕捉局部细节",{"2":{"429":1}}],["可以有效地代替原始图像",{"2":{"270":1}}],["可以执行场景动态的短期预测",{"2":{"905":1}}],["可以加速障碍物避让和运动规划查询",{"2":{"905":1}}],["可以向两端发展",{"2":{"871":1}}],["可以恢复驾驶场景的整个3d结构",{"2":{"858":1}}],["可以更容易地获得更好的几何估计",{"2":{"853":1}}],["可以计算如下",{"2":{"848":1}}],["可以计算出该位置的占用预测",{"2":{"693":1}}],["可以并行化",{"2":{"816":1}}],["可以获得0",{"2":{"800":1}}],["可以处理户外场景",{"2":{"796":1}}],["可以避免这种过度分割",{"2":{"796":1}}],["可以观察到",{"2":{"759":1}}],["可以分为三类",{"2":{"756":1}}],["可以感知场景的精确深度",{"2":{"691":1}}],["可以为开发鲁棒占用感知提供灵感",{"2":{"1005":1}}],["可以为网络提供一组",{"2":{"660":1}}],["可以为某些对象类别提供cad模型目录",{"2":{"449":1}}],["可以根据不同的数据源和查询策略进行调整和优化",{"2":{"875":1}}],["可以根据视图变换范式将其分为两类",{"2":{"612":1}}],["可以根据点云的密度和复杂度",{"2":{"331":1,"356":1}}],["可以快速生成高性能的稀疏卷积核",{"2":{"593":1}}],["可以聚合高级语义的特性",{"2":{"591":1}}],["可以通过计算预测的点块",{"2":{"582":1}}],["可以通过添加一个超参数来定义池化网格中目标边缘的数量",{"2":{"466":1}}],["可以==验证插入元素是否重复==",{"2":{"571":1}}],["可以用一个迭代器作为insert",{"2":{"571":1}}],["可以用一个噪声估计网络来估计",{"2":{"316":1}}],["可以解决vit存在的过度平滑问题",{"2":{"559":1}}],["可以进一步近似为仅累加位置",{"2":{"532":1}}],["可以准确重建遮挡下的通用物体",{"2":{"517":1}}],["可以产生连续的深度估计",{"2":{"470":1}}],["可以动态地为给定的概念构建分割器",{"2":{"469":1}}],["可以使数据关联检查更加鲁棒",{"2":{"419":1}}],["可以使用迭代优化的思想来继续优化点云的精度",{"2":{"618":1}}],["可以使用像素级2d语义分割工具获得",{"2":{"362":1}}],["可以使用kimera",{"2":{"285":1}}],["可以使用字符串的加号运算符",{"2":{"52":1}}],["可以表示为",{"2":{"405":1,"638":1,"666":1}}],["可以被表述为一个增强的姿态图优化问题",{"2":{"390":1}}],["可以无缝解决语义",{"2":{"384":1}}],["可以撤销错误的环路闭合",{"2":{"380":1}}],["可以是交叉注意力",{"2":{"970":1}}],["可以是1维或者3维或者其它维度的",{"2":{"357":1}}],["可以是会话名称",{"2":{"88":1}}],["可以利用自注意力机制和跨注意力机制",{"2":{"356":1}}],["可以实现鲁棒的3d占用场景重建",{"2":{"839":1}}],["可以实现2",{"2":{"800":1}}],["可以实现较高的",{"2":{"778":1}}],["可以实现p",{"2":{"355":1}}],["可以实现无需中间聚合步骤的网络训练",{"2":{"349":1}}],["可以由两个视角的相机参数",{"2":{"355":1}}],["可以取得相对好的效果",{"2":{"345":1}}],["可以直接在3d环境下更新物体查询",{"2":{"341":1}}],["可以将3d占用映射到现实的多视角图像",{"2":{"963":1}}],["可以将网格模型输入到物理模拟器中",{"2":{"905":1}}],["可以将不同的点云表示转换为一致的特征向量",{"2":{"356":1}}],["可以将点云的结构分解成更小的部分",{"2":{"340":1}}],["可以将detr视为一个从图像序列到一个集合序列的转换过程",{"2":{"333":1}}],["可以统一处理不同的点云表示",{"2":{"331":1}}],["可以适应不同的点云表示",{"2":{"331":1}}],["可以控制所生成的图与原图的相似程度",{"2":{"264":1,"266":1}}],["可以轻松地在图1",{"2":{"262":1}}],["可以看出",{"2":{"833":1,"1000":1}}],["可以看到",{"2":{"938":1}}],["可以看到过小的fff",{"2":{"345":1}}],["可以看到当",{"2":{"345":1}}],["可以看到图像的身份特征随souce",{"2":{"181":1}}],["可以看见硬盘的名字",{"2":{"24":1}}],["可以多重建几次",{"2":{"180":1}}],["可以独立于不受新测量影响的连通分量进行计算",{"2":{"153":1}}],["可以很容易地证明",{"2":{"153":1}}],["可以过度分割图像成可能大量的片段",{"2":{"137":1}}],["可以从传感器数据中实时构建3d场景图",{"2":{"467":1}}],["可以从每个点块中提取丰富的几何特征",{"2":{"456":1}}],["可以从一段随机数中生成逼真的图像",{"2":{"129":1}}],["可以从视觉",{"2":{"105":1}}],["可以作为机器人的高级",{"2":{"125":1}}],["可以在训练和测试过程中适应不同的输入数据大小",{"2":{"962":1}}],["可以在训练过程中加入或替换一个占用头以获得最终结果",{"2":{"839":1}}],["可以在不规则的三维点云上获得优异的性能",{"2":{"688":1}}],["可以在不同的粒度级别渲染",{"2":{"121":1}}],["可以在扩大的设计空间中搜索最佳的数据流配置",{"2":{"593":1}}],["可以在occ任务的推理过程中移除",{"2":{"421":1}}],["可以在基于对象的几何验证期间成功地导致有效的环路闭合",{"2":{"352":1}}],["可以在具有复杂场景的数据集中训练",{"2":{"313":1}}],["可以在给定数据上通过梯度下降的方式估计得到",{"2":{"235":1}}],["可以在线执行",{"2":{"153":1}}],["可以在构建前通过运行catkin",{"2":{"27":1}}],["可以认为vector是存放任意类型的动态数组",{"2":{"83":1}}],["可以包含特殊标记",{"2":{"57":1}}],["可以",{"2":{"38":1}}],["可以链接到本文件夹",{"2":{"32":1}}],["分发不受限制",{"2":{"973":1}}],["分发声明a",{"2":{"973":1}}],["分裂和剪枝策略以及初始化方案的额外消融研究",{"2":{"934":1}}],["分布在8个gpu上",{"2":{"770":1}}],["分布在真实深度点附近且在其后的高斯分布可能表示有效的语义",{"2":{"705":1}}],["分布在真实深度点前方的高斯分布可能表示空闲语义",{"2":{"705":1}}],["分布预测器",{"2":{"704":1}}],["分布外事件及语言边缘案例",{"2":{"447":1}}],["分成",{"2":{"676":1}}],["分成几个阶段",{"2":{"659":1}}],["分为了",{"2":{"623":1}}],["分为4个bin",{"2":{"254":1}}],["分组和池化",{"2":{"574":1}}],["分组层和pointnet层",{"2":{"420":1}}],["分配一个与世界框架对齐的规范方向",{"2":{"480":1}}],["分配的关系连接对象",{"2":{"121":1}}],["分析了感知范围因素对我们框架在",{"2":{"503":1}}],["分析传感器扰动",{"2":{"447":1}}],["分析语义地图构建中的关键挑战",{"2":{"90":1}}],["分数",{"2":{"382":1}}],["分类模型的错误又会引入语义不一致",{"2":{"864":1}}],["分类损失",{"2":{"651":1}}],["分类网络预测图像时的激活区域",{"2":{"528":1}}],["分类器主要是分这个提取的roi具体是什么类别",{"2":{"463":1}}],["分类和边框修正",{"0":{"463":1}}],["分类loss采用的是交叉熵损失",{"2":{"358":1}}],["分类",{"0":{"286":1},"1":{"311":1,"337":1,"363":1,"391":1,"420":1,"450":1,"481":1,"511":1,"542":1,"574":1,"607":1,"636":1,"664":1,"688":1},"2":{"220":1,"806":1}}],["分辨率100×100×8",{"2":{"785":1}}],["分辨率增加对计算成本的影响比较",{"2":{"638":1}}],["分辨率",{"2":{"181":3,"739":2}}],["分辨率为256×256×32",{"2":{"781":1}}],["分辨率为200×200×16",{"2":{"781":1}}],["分辨率为",{"2":{"173":1,"652":2,"676":1,"749":1,"828":1}}],["分别代表简单",{"2":{"931":1}}],["分别代表两种不同的",{"2":{"181":1}}],["分别达到了",{"2":{"917":1}}],["分别拼接动态物体和静态场景的多帧激光雷达点云",{"2":{"850":1}}],["分别从yyy中简单地获得",{"2":{"834":1}}],["分别从第一个和最后一个块中提取两个特征图ff0和ff2",{"2":{"609":1}}],["分别仅占占据体素的",{"2":{"828":1}}],["分别比radocc",{"2":{"779":1}}],["分别有8487",{"2":{"781":1}}],["分别有",{"2":{"749":1}}],["分别为53",{"2":{"893":1}}],["分别为",{"2":{"749":1,"917":1}}],["分别提高了",{"2":{"700":1,"903":1,"917":1,"928":3}}],["分别提取图像特征和文本特征",{"2":{"184":1}}],["分别见表",{"2":{"700":1}}],["分别指单目rgb输入和获得的三维空间占用预测",{"2":{"682":1}}],["分别包含约230k和约80k标注帧",{"2":{"997":1}}],["分别包含",{"2":{"652":1}}],["分别解决全局对齐与局部分辨率问题",{"2":{"648":1}}],["分别记为",{"2":{"582":1}}],["分别编码为",{"2":{"579":1}}],["分别通过摄像头编码器和激光雷达编码器获取图像和点云的特征",{"2":{"576":1}}],["分别通过编码多模态输入产生体素融合特征",{"2":{"474":1}}],["分别用于基于周围和单目相机的3d语义占用预测",{"2":{"760":1}}],["分别用于训练",{"2":{"652":1,"749":2,"781":2,"828":1}}],["分别用于环绕视图和单目",{"2":{"567":1}}],["分别用于从周围和单目相机进行3d语义占用预测",{"2":{"547":1}}],["分别初始化于不同的空间",{"2":{"550":1}}],["分别表示特定语义类别",{"2":{"998":1}}],["分别表示我们在预测中针对第",{"2":{"915":1}}],["分别表示为",{"2":{"910":1}}],["分别表示真正例",{"2":{"848":1,"998":1}}],["分别表示预测中的真正例",{"2":{"807":1}}],["分别表示预测值和真实值",{"2":{"666":1}}],["分别表示非空类别",{"2":{"802":1}}],["分别表示占用体素的真阳性",{"2":{"778":1}}],["分别表示类别",{"2":{"742":1,"778":1}}],["分别表示某个高斯分布的邻近体素数量和某个体素的贡献高斯分布数量",{"2":{"738":1}}],["分别表示图像特征图",{"2":{"716":1}}],["分别表示均值",{"2":{"693":1}}],["分别表示视图数量",{"2":{"693":1}}],["分别表示热图在位置",{"2":{"666":1}}],["分别表示协方差矩阵",{"2":{"532":1}}],["分别表示相机视角数量",{"2":{"532":1}}],["分别表示3d连续和离散卷积",{"2":{"450":1}}],["分别对应类别",{"2":{"739":1}}],["分别对应于",{"2":{"707":1}}],["分别对应于旋转和平移权重",{"2":{"390":1}}],["分别对init",{"2":{"499":1}}],["分别生成两组tpv",{"2":{"676":1}}],["分别生成",{"2":{"441":1}}],["分别使用投影",{"2":{"950":1}}],["分别使用视觉",{"2":{"437":1}}],["分别使用voxel",{"2":{"424":1}}],["分别使用2点和1点ransac",{"2":{"310":1}}],["分别得到",{"2":{"181":1}}],["分别是语义和几何标签及其预测值",{"2":{"794":1}}],["分别是给定",{"2":{"137":1}}],["分别是",{"2":{"137":1}}],["分层控制器",{"2":{"195":1}}],["分层cot规划器",{"2":{"145":1}}],["分层语义",{"0":{"95":1},"2":{"2":1}}],["分割和完成等任务",{"2":{"996":1}}],["分割和跟踪方面优于基于透视视图",{"2":{"691":1}}],["分割密集对象模型",{"2":{"967":1}}],["分割网络对这些快照进行像素级标记",{"2":{"955":1}}],["分割网络是一个u",{"2":{"526":1}}],["分割模型",{"2":{"765":1}}],["分割体素并通过点投票分配标签来创建密集的3d占用注释",{"2":{"757":1}}],["分割是有益的",{"2":{"684":1}}],["分割查询",{"2":{"550":1}}],["分割",{"0":{"940":1},"1":{"948":1,"955":1,"962":1,"968":1,"974":1,"979":1,"983":1,"987":1,"990":1,"993":1,"996":1},"2":{"471":1,"667":1,"864":1,"1003":1}}],["分割任务也不受它的影响",{"2":{"407":1}}],["分割任务的miou分别为66",{"2":{"366":1}}],["分割等下游任务",{"2":{"394":1}}],["分割等",{"2":{"220":1}}],["分割地点",{"2":{"162":1}}],["分割对象",{"2":{"162":1}}],["分割房间",{"2":{"131":1}}],["分割以空格隔开的字符串",{"2":{"52":1}}],["分支提取",{"2":{"377":1}}],["分支",{"2":{"107":1}}],["标出",{"2":{"700":1}}],["标志着从纯几何地图向稠密",{"2":{"588":1}}],["标签高效方法应朝着减少昂贵注释需求的同时实现令人满意的性能发展",{"2":{"969":1}}],["标签高效方法",{"0":{"932":1},"1":{"941":1,"949":1}}],["标签高效方法期望在注释不足或完全缺失的情况下仍能实现令人满意的性能",{"2":{"799":1}}],["标签飞溅",{"2":{"698":1}}],["标签",{"2":{"662":1,"775":5}}],["标签分配给自由空间体素",{"2":{"437":1}}],["标签的概率的计算工作",{"2":{"362":1}}],["标识模块所属的",{"2":{"408":1}}],["标注这些密集的占用标签既耗时又费力",{"2":{"1000":1}}],["标注了3d占用信息的图像数量",{"2":{"997":1}}],["标注了3d占用信息的帧或剪辑数量",{"2":{"997":1}}],["标注了",{"2":{"853":2}}],["标注的视觉",{"2":{"782":1}}],["标注的体素网格在x和y轴上跨越",{"2":{"781":1}}],["标注",{"2":{"739":1}}],["标注格式",{"0":{"654":1,"747":1}}],["标注范围为",{"2":{"652":1}}],["标注需求",{"0":{"565":1},"1":{"597":1,"626":1,"654":1,"679":1,"702":1,"725":1,"747":1,"769":1,"790":1}}],["标注视觉",{"2":{"425":1}}],["标注序列和融合",{"2":{"425":1}}],["标注cot",{"2":{"360":1}}],["标注数量",{"2":{"277":1}}],["标注人员的指导说明可在开发工具包仓库中找到",{"2":{"157":1}}],["标准化的评估指标和框架仍是关键挑战",{"2":{"943":1}}],["标准化评估框架",{"2":{"864":1}}],["标准化交通语言",{"2":{"507":1}}],["标准高斯分布噪音",{"2":{"279":1}}],["标准图像模型联合训练图像特征提取器和线性分类器来预测某些标签",{"2":{"184":1}}],["标准库里没有",{"2":{"52":1}}],["标定格子的size指的是内部的格点",{"2":{"136":1}}],["标记当前局部体素与视锥体的交集",{"2":{"886":1}}],["标记当前帧的可见范围",{"2":{"793":1}}],["标记为",{"2":{"842":2}}],["标记",{"2":{"57":1}}],["标题",{"2":{"98":1}}],["标题4",{"0":{"57":1}}],["标题3",{"0":{"46":1},"1":{"57":1}}],["标题2",{"0":{"39":1},"1":{"46":1,"57":1}}],["标题h6",{"0":{"35":1}}],["标题h5",{"0":{"28":1},"1":{"35":1}}],["标题h4",{"0":{"21":1},"1":{"28":1,"35":1}}],["标题h3",{"0":{"14":1},"1":{"21":1,"28":1,"35":1}}],["标题h2",{"0":{"9":1},"1":{"14":1,"21":1,"28":1,"35":1}}],["请在补充材料中查看更多定性结果",{"2":{"745":1}}],["请参见",{"2":{"816":1}}],["请参见顶行",{"2":{"557":1}}],["请参见图18",{"2":{"754":1}}],["请参见图",{"2":{"325":1}}],["请参阅补充材料",{"2":{"677":1}}],["请参阅",{"2":{"277":1,"534":1}}],["请参阅标注人员指导说明",{"2":{"277":1,"302":1}}],["请参阅下图了解摄像头的方向和重叠区域",{"2":{"173":1}}],["请参阅上述图表以了解传感器的放置位置",{"2":{"173":1}}],["请使用以下引用格式",{"2":{"126":1}}],["请按",{"2":{"66":1}}],["请注意",{"2":{"52":1,"372":1,"390":4,"436":1,"437":1,"464":1,"605":1,"622":1,"634":1,"636":1,"754":1,"836":2,"870":1,"903":1,"916":1,"930":1}}],["请将此文件夹从3rscan",{"2":{"38":1}}],["函数沿维度",{"2":{"863":1}}],["函数进行归一化",{"2":{"844":1}}],["函数原型",{"2":{"835":1,"854":1}}],["函数为empty",{"2":{"795":1}}],["函数返回值",{"2":{"571":1}}],["函数中的输入inputs只允许是序列",{"2":{"351":1}}],["函数目的",{"2":{"351":1}}],["函数的主要作用是将数字转换为字符串",{"2":{"63":1}}],["函数",{"2":{"52":4,"63":1,"104":2,"938":3}}],["程序员小熊",{"2":{"48":1}}],["再切换到局部空间图实现避障或室内精细操作",{"2":{"935":1}}],["再用准确率",{"2":{"826":1}}],["再用相机位姿转到世界坐标系",{"2":{"495":1}}],["再对每个",{"2":{"765":1}}],["再提取对应特征",{"2":{"765":1}}],["再配准进全局坐标系",{"2":{"743":1}}],["再经去噪网络输出最终语义图",{"2":{"698":1}}],["再记录",{"2":{"698":1}}],["再学习多模态表征",{"2":{"648":1}}],["再沿",{"2":{"622":1}}],["再应用注意力机制",{"2":{"595":1}}],["再进行求和操作",{"2":{"544":1}}],["再将其压缩为扁平化的bev特征图",{"2":{"585":1}}],["再将其投影到嵌入空间",{"2":{"525":1}}],["再将每个roi对应的特征转化为固定大小的维度时",{"2":{"554":1}}],["再将w投喂给",{"2":{"133":1}}],["再产生显式人类可读响应",{"2":{"507":1}}],["再执行任务",{"2":{"435":1}}],["再由解码器",{"2":{"371":1}}],["再到外观描述符",{"2":{"352":1}}],["再到具备推理与对话的完全统一流水线",{"2":{"334":1}}],["再到低层次的控制和障碍物避让",{"2":{"116":1}}],["再重复同样的后向去噪步骤",{"2":{"312":1}}],["再重新设置下文件格式",{"2":{"48":1}}],["再转换为连续轨迹",{"2":{"283":1}}],["再在拓扑节点内生成高分辨率网格地图",{"2":{"648":1}}],["再在不同任务间灵活调用",{"2":{"274":1}}],["再在检测框内进行语义分割",{"2":{"138":1}}],["再通过全连接层",{"2":{"250":1}}],["再通过聚类",{"2":{"138":1}}],["再送入high",{"2":{"220":1}}],["再安装",{"2":{"66":1}}],["再求所有向量平均值",{"2":{"13":1}}],["只开通另一端就可以实现栈的逻辑了",{"2":{"685":1}}],["只要有足够的准确的深度传感器",{"2":{"889":1}}],["只要封住一段",{"2":{"685":1}}],["只要是高斯噪声就可以",{"2":{"224":1}}],["只传入单个参数",{"2":{"571":1}}],["只考虑gt中有深度信息的像素点",{"2":{"499":1}}],["只是额外添加了mask的操作",{"2":{"452":1}}],["只是把光标移到行首",{"2":{"48":1}}],["只需从自然语言查询中提取物体名称",{"2":{"765":1}}],["只需知道相对于起点的位移即可最终建成地图",{"2":{"435":1}}],["只需要二维特征图而不是三维特征体积",{"2":{"923":1}}],["只需要简单地提供包含新类别的文本描述就可以使用该模型来识别新类别",{"2":{"167":1}}],["只需要对球拍区域进行预测就好了",{"2":{"117":1}}],["只有arnab等人",{"2":{"967":1}}],["只有包含",{"2":{"789":1}}],["只有公寓场景没有遵循趋势",{"2":{"775":1}}],["只有encoder模块",{"2":{"373":1}}],["只有与这些数据直接相关的连通分量需要被更新",{"2":{"153":1}}],["只会返回一个迭代器",{"2":{"571":1}}],["只会收集投影点处的图像特征",{"2":{"341":1}}],["只会找到局部极小值",{"2":{"129":1}}],["只保留最重要的信息",{"2":{"227":1}}],["只能通过",{"2":{"835":1}}],["只能通过更复杂的图像编码器和更大的输入图像分辨率来实现卓越性能",{"2":{"576":1}}],["只能通过命令行中的sudo",{"2":{"24":1}}],["只能识别预设类别",{"2":{"406":1}}],["只能借助于随机性重新生成",{"2":{"312":1}}],["只能借助",{"2":{"217":1}}],["只不过在其基础上",{"2":{"196":1}}],["只不过在其基础上增加了",{"2":{"196":1}}],["只对那些真正需要更新的部分进行计算",{"2":{"153":1}}],["只捕捉对象",{"2":{"116":1}}],["这限制了其泛化能力和实用性",{"2":{"1006":1}}],["这限制了驾驶的安全性和鲁棒性",{"2":{"547":1}}],["这内在地限制了这些方法的效率",{"2":{"996":1}}],["这还不足以实现完全自监督的3d占用预测框架",{"2":{"941":1}}],["这项工作为从单张图像中理解",{"2":{"937":1}}],["这项工作部分由aia",{"2":{"467":1}}],["这证明了3d高斯表示的以物体为中心的特性",{"2":{"924":1}}],["这证明了3d高斯分布围绕前景物体聚集",{"2":{"842":1}}],["这通过几个数量级加速了路径规划查询",{"2":{"930":1}}],["这通过使用",{"2":{"917":1}}],["这通常会导致由于资源分配不合理而产生巨大的开销",{"2":{"693":1}}],["这形成了一个边界体积层次结构",{"2":{"905":1}}],["这迫使我们预测单个物体的运动",{"2":{"903":1}}],["这显著降低了数据注释的成本",{"2":{"932":1}}],["这显著缩短了算法部署时间并节省了计算资源",{"2":{"899":1}}],["这显著提高了预测效率并减少了内存消耗",{"2":{"808":1}}],["这展示了我们模型的效率和以目标为中心的特性",{"2":{"885":1}}],["这会增加每个epoch的样本数量",{"2":{"876":1}}],["这会导致不稳定的梯度",{"2":{"863":1}}],["这会导致特征错位",{"2":{"655":1}}],["这更具挑战性",{"2":{"841":1}}],["这需要想象被遮挡物体和场景的完整3d内容",{"2":{"841":1}}],["这需要大量的计算资源和内存",{"2":{"778":1}}],["这说明",{"2":{"824":1}}],["这带来了从2d视觉输入中获取完美3d特征的关键挑战",{"2":{"819":1}}],["这带来了两大挑战",{"2":{"535":1}}],["这既与激光雷达起源的",{"2":{"917":1}}],["这既耗时又昂贵",{"2":{"799":1}}],["这既能防止碰撞",{"2":{"503":1}}],["这不可避免地涉及3d卷积等操作",{"2":{"799":1}}],["这不仅产生了一致的结果",{"2":{"301":1}}],["这进一步验证了我们方法实现性能提升的有效性和合理性",{"2":{"800":1}}],["这进一步证明了我们提出的方法的有效性和效率",{"2":{"779":1}}],["这进一步减少了网格误差",{"2":{"709":1}}],["这突出了我们的方法能够从点云数据中挖掘更多信息的能力",{"2":{"779":1}}],["这将对",{"2":{"778":1}}],["这将给我们的局部空间占用预测模块带来额外的困难",{"2":{"705":1}}],["这归功于高斯的连续性属性",{"2":{"745":1}}],["这得益于激光雷达传感器",{"2":{"745":1}}],["这得益于高斯混合的通用逼近能力",{"2":{"532":1}}],["这花费了大约4",{"2":{"735":1}}],["这正是密集立体视觉最困难的地方",{"2":{"732":1}}],["这正是维护高斯记忆的本质",{"2":{"728":1}}],["这正是一个有潜力的具身智能体所应具备的能力",{"2":{"568":1}}],["这次收到的视觉信息仅仅是用来提炼这个记忆的",{"2":{"728":1}}],["这验证了多扫描激光雷达在为高斯提供占据空间准确几何信息方面的有效性",{"2":{"723":1}}],["这阻碍了每个高斯在后续细化中学习到达正确位置的路径",{"2":{"704":1}}],["这依赖于网络后续的细化以适应每个单独样本的分布",{"2":{"704":1}}],["这主要是因为这些小物体在数据集中较为稀疏",{"2":{"945":1}}],["这主要是因为bash后面多了",{"2":{"48":1}}],["这主要是由于室内场景的高变异性",{"2":{"992":1}}],["这主要是由于我们的非时间方法与基线方法相比实现了大幅提升",{"2":{"811":1}}],["这主要是由于",{"2":{"700":1}}],["这构成了挑战",{"2":{"700":1}}],["这只是向实际应用场景迈出的初始步骤",{"2":{"682":1}}],["这无疑会大幅限制其在大尺度模",{"2":{"863":1}}],["这无疑削弱了模型在实际中的理解能力",{"2":{"682":1}}],["这无法从全局视角进行表示学习",{"2":{"341":1}}],["这加剧了高斯之间的重叠",{"2":{"656":1}}],["这要求以激光雷达为中心的占用感知不仅要解决场景的稀疏到密集占用推理",{"2":{"910":1}}],["这要归功于imu",{"2":{"634":1}}],["这要困难得多",{"2":{"632":1}}],["这其实也为作者之后提出",{"2":{"631":1}}],["这实际上得益于高斯分布的物理意义和结构信息",{"2":{"600":1}}],["这确保了在融合和更新过程中的三维表示的一致性",{"2":{"600":1}}],["这确保了极其忠实的重建",{"2":{"552":1}}],["这促使我们在此算子的基础上开发基于",{"2":{"844":1}}],["这促使我们的工作将激光雷达数据与相机数据融合",{"2":{"596":1}}],["这促使了多种街景占用数据集的发展",{"2":{"759":1}}],["这促使研究人员将其他传感器模态整合进来",{"2":{"444":1}}],["这削弱了",{"2":{"567":1}}],["这削弱了它们的模型容量和效率",{"2":{"567":1}}],["这对实时决策提出更高要求",{"2":{"926":1}}],["这对实时或资源受限场景尤为关键",{"2":{"881":1}}],["这对自动驾驶系统至关重要",{"2":{"910":1}}],["这对应于相机视图中的岩石堆",{"2":{"899":1}}],["这对驾驶的安全性和可靠性构成了挑战",{"2":{"567":1}}],["这对于3d占用预测方法的训练或评估并不实用",{"2":{"997":1}}],["这对于自动驾驶车辆的安全运行至关重要",{"2":{"827":1}}],["这对于运动规划等下游任务非常有帮助",{"2":{"757":1}}],["这对于以视觉为中心的自动驾驶的鲁棒性至关重要",{"2":{"516":1}}],["这对于在人类居住环境中移动的机器人至关重要",{"2":{"116":1}}],["这对于机器人导航至关重要",{"2":{"116":1}}],["这对于保证安全运行也很重要",{"2":{"116":1}}],["这属于",{"2":{"525":1}}],["这忽略了占用的稀疏性和物体尺度的多样性",{"2":{"516":1}}],["这为它们提供了不公平的几何优势",{"2":{"870":1}}],["这为遮挡推理提供了足够的场景特征",{"2":{"691":1}}],["这为网络提供了全局感受野",{"2":{"684":1,"875":1}}],["这为更全面地理解环境铺平了道路",{"2":{"667":1}}],["这为探索数据驱动算法和大规模模型提供了便利",{"2":{"520":1}}],["这为未来的工作开辟了进一步的途径",{"2":{"467":1}}],["这为我们的聚类提供了强大的归纳偏置",{"2":{"153":1}}],["这激励了我们的任务感知聚类方法",{"2":{"462":1}}],["这激励了我们的观点",{"2":{"462":1}}],["这三个视图相互正交",{"2":{"858":1}}],["这三个目标相结合",{"2":{"715":1}}],["这三个数据集包括使用手持设备记录的rgb",{"2":{"605":1}}],["这三个步骤的输出是对象的3d姿态",{"2":{"449":1}}],["这三个线程允许创建图5",{"2":{"285":1}}],["这分为三个步骤",{"2":{"449":1}}],["这就是为什么尽管办公室场景比sidpac场景小",{"2":{"437":1}}],["这就是所谓的早期融合",{"2":{"96":1}}],["这表明它们尚未充分利用多模态融合的优势和输入数据的丰富性",{"2":{"1000":1}}],["这表明能够在dsg上运行语义有意义的路径规划查询",{"2":{"947":1}}],["这表明视锥比例损失确实能够为网络提供更精细的指导",{"2":{"928":1}}],["这表明我们的方法在仅使用图像的情况下就能很好地恢复几何结构",{"2":{"917":1}}],["这表明我们的方法有潜力实现更高效的通信",{"2":{"700":1}}],["这表明我们的网络在捕捉场景几何结构的同时",{"2":{"903":1}}],["这表明通过有效的特征增强",{"2":{"875":1}}],["这表明添加检测分支可以显著增强多模态特征的可区分性",{"2":{"800":1}}],["这表明概率高斯叠加在建模背景物体方面的优越性",{"2":{"792":1}}],["这表明",{"2":{"437":1,"833":1,"917":1,"928":2}}],["这创建了一个任务感知过程",{"2":{"436":1}}],["这仅相当于900×1600分辨率图像像素数量的2",{"2":{"421":1}}],["这有助于推断场景的语义占用",{"2":{"988":1}}],["这有助于根据外观区分人类",{"2":{"419":1}}],["这有助于为我们的研究重点",{"2":{"100":1}}],["这比从头开始重建网格或使用",{"2":{"390":1}}],["这四个值的意思是修正后的框在anchor的x和y方向上做出平移",{"2":{"375":1}}],["这可能并不总是成立",{"2":{"957":1}}],["这可能是由于雷达的特性所导致的",{"2":{"927":1}}],["这可能是由于3d语义高斯表示的不准确",{"2":{"878":1}}],["这可能是因为当前的3d语义高斯分布将",{"2":{"878":1}}],["这可能是因为multi",{"2":{"366":1}}],["这可能需要几分钟",{"2":{"816":1}}],["这可能导致系统的响应速度变慢",{"2":{"601":1}}],["这可能涉及将激光雷达信息整合到模型中以增强深度估计",{"2":{"564":1}}],["这可以表示为",{"2":{"730":1}}],["这可以充分发挥这种对比训练的潜力",{"2":{"184":1}}],["这可以被理解为每个原语的任务相关性",{"2":{"153":1}}],["这导致多对一的映射",{"2":{"950":1}}],["这导致语义对数无界",{"2":{"567":1}}],["这导致在远距离区域出现大量空体素网格",{"2":{"527":1}}],["这导致提案质量排名的错位",{"2":{"434":1}}],["这导致了在推理过程中",{"2":{"965":1}}],["这导致了大约3miou的提升",{"2":{"779":1}}],["这导致了一个全局一致的",{"2":{"408":1}}],["这导致了预训练数据集和微调数据集在数据分布上有较大的差距",{"2":{"313":1}}],["这导致vio和网格正则化之间的紧密耦合",{"2":{"336":1}}],["这9种初始anchor包含三种面积",{"2":{"321":1}}],["这篇综述有助于识别当前语义建图范式中的关键挑战",{"2":{"958":1}}],["这篇论文提出了一个新的",{"2":{"631":1}}],["这篇论文是直接基于ddpm的工作上展开的受控图像生成",{"2":{"264":1,"266":1}}],["这篇文章主要在探讨如何解决这个问题",{"2":{"343":1}}],["这篇工作略晚于以上两篇工作",{"2":{"312":1}}],["这样",{"2":{"705":1}}],["这样做可以减小数据的尺度差异",{"2":{"456":1}}],["这样做保证了结果与输入顺序无关",{"2":{"407":1}}],["这样做的目的是克服点云领域缺乏预定义词汇表和无序性的问题",{"2":{"340":1}}],["这样将保证无论输入任何长度的文本",{"2":{"373":1}}],["这样可以强迫网络关注局部形状特征",{"2":{"424":1}}],["这样可以节省内存和计算量",{"2":{"372":1}}],["这样可以避免不必要的计算",{"2":{"153":1}}],["这样就限制了能生成图像的大小",{"2":{"343":1}}],["这样的大型场景",{"2":{"816":1}}],["这样的网络能够轻松解决截断目标",{"2":{"658":1}}],["这样的假设保证每条边最多与两个面",{"2":{"325":1}}],["这样的设计使得能够在单次运行中端到端地训练模型",{"2":{"306":1}}],["这样的图表示方法可以帮助算法理解和学习对象之间的空间关系",{"2":{"271":1}}],["这样控制的方法可以让一个ddpm模型在无需额外模型或学习过程参与的情况下适用于multi",{"2":{"289":1}}],["这条边表示两个对象原语之间存在一定的空间关系",{"2":{"271":1}}],["这句话的意思是",{"2":{"271":1}}],["这句话是在描述信息瓶颈",{"2":{"271":1}}],["这指向一个样本而不是一个sample",{"2":{"254":1,"654":1}}],["这使我们可以通过拼接处理过的帧的掩码来获得已探索区域的空间占用真值",{"2":{"886":1}}],["这使我们能够准确推断目标在空间中的位置和方向",{"2":{"277":1}}],["这使我们能够以更少的伪影合成更精细的几何细节",{"2":{"247":1}}],["这使得整个训练过程更为稳定",{"2":{"863":1}}],["这使得",{"2":{"814":1}}],["这使得地图只能覆盖有限的对象类别",{"2":{"698":1}}],["这使得模型的结构更加复杂",{"2":{"601":1}}],["这使得模型难以有效地学习有意义的点云表示",{"2":{"549":1}}],["这使得大多数高斯在以目标为中心的公式中变得无用",{"2":{"567":1}}],["这使得网络能够非均匀地折叠某些对损失影响最小的区域",{"2":{"466":1}}],["这使得网络可以通过使用三维卷积来提取几何细节",{"2":{"363":1}}],["这使得激光雷达在3d语义占据预测方面具有特别的优势",{"2":{"444":1}}],["这使得统一bev特征对目标边界更加敏感",{"2":{"421":1}}],["这使得如果一个被接受的环路闭合后来被gnc视为异常值",{"2":{"380":1}}],["这使得实际应用相对更简单",{"2":{"369":1}}],["这使得卷积感受野变得模糊",{"2":{"325":1}}],["这使得clip模型还学习到了图像的各方面信息",{"2":{"204":1}}],["这使得能够在控制环境中将语义地图的高级推理能力与嘈杂传感器和现实世界观测的复杂性区分开来",{"2":{"90":1}}],["这也构建了一个世界模型",{"2":{"963":1}}],["这也不利于正确预测空间占用",{"2":{"833":1}}],["这也取决于场景的规模",{"2":{"816":1}}],["这也需要几分钟",{"2":{"816":1}}],["这也是为什么需要roi",{"2":{"272":1}}],["这也是sd的核心优势",{"2":{"205":1}}],["这也为我们关注的语义地图提供了语境",{"2":{"110":1}}],["这被选为在任何给定任务下原语不相关的余弦相似性的下限",{"2":{"153":1}}],["这意味着雷达数据有助于模型扩展其感知范围",{"2":{"952":1}}],["这意味着不同帧可能来自同一个室内场景",{"2":{"886":1}}],["这意味着在实现中",{"2":{"866":1}}],["这意味着如果点",{"2":{"681":1}}],["这意味着它们可以处理实时rgb",{"2":{"629":1}}],["这意味着它可以轻松地在dsg的顶部和底部添加更多层",{"2":{"262":1}}],["这意味着",{"2":{"153":1}}],["这允许机器人在映射环境时增量聚类",{"2":{"153":1}}],["这与度量坐标x",{"2":{"947":1}}],["这与在雨天场景中观察到的趋势相反",{"2":{"944":1}}],["这与我们的预期一致",{"2":{"928":1}}],["这与高斯分布的物理属性密切相关",{"2":{"833":1}}],["这与室内场景不同",{"2":{"759":1}}],["这与人类通过具身探索理解新场景的方式一致",{"2":{"568":1}}],["这与旋转激光雷达生成点云的方式更为一致",{"2":{"497":1}}],["这与实时操作相冲突",{"2":{"141":1}}],["这与今天机器人的能力形成了鲜明对比",{"2":{"116":1}}],["这类细粒度空间推理",{"2":{"913":1}}],["这类真实场景的",{"2":{"495":1}}],["这类似于在视觉跟踪中移除短特征轨迹",{"2":{"419":1}}],["这类模型",{"2":{"765":1}}],["这类模型能够隐式地推理障碍物",{"2":{"252":1}}],["这类模型直接从视觉观测中一次性输出离散动作",{"2":{"252":1}}],["这类方法常借助基于",{"2":{"252":1}}],["这类方法的代表作就是大名鼎鼎的mask",{"2":{"138":1}}],["这类任务要求智能体不仅要理解世界",{"2":{"110":1}}],["这代表一个任务不可知原语在",{"2":{"137":1}}],["这自然引出了信息瓶颈原理",{"2":{"137":1}}],["这极大地简化了任务描述问题",{"2":{"137":1}}],["这在真实的自动驾驶场景中更具实用性",{"2":{"975":1}}],["这在近年来通过深度学习方法得以实现",{"2":{"961":1}}],["这在大型环境中可能更难以存储",{"2":{"905":1}}],["这在第",{"2":{"903":2}}],["这在euroc的困难机器厅序列的ape增加中最为明显",{"2":{"836":1}}],["这在所有情况下都可能不是所期望的",{"2":{"836":1}}],["这在单个图像上需要大约33毫秒",{"2":{"816":1}}],["这在模拟场景中很常见",{"2":{"732":1}}],["这在3d语义占用预测中带来了独特的挑战",{"2":{"641":1}}],["这在不平坦路面或悬挂物体的场景中已得到验证",{"2":{"566":1}}],["这在预测后续点块时会引入不确定性",{"2":{"549":1}}],["这在室内往往无法依赖",{"2":{"435":1}}],["这在自动驾驶和机器人领域中极为关键",{"2":{"392":1}}],["这在",{"2":{"131":1}}],["这是从二维观测构建三维数据的基本单元",{"2":{"942":1}}],["这是意料之中的",{"2":{"936":1}}],["这是亟待突破的研究方向",{"2":{"897":1}}],["这是通过将",{"2":{"870":1}}],["这是通过一种新颖的同时姿态图和网格变形方法实现的",{"2":{"390":1}}],["这是移动机器人导航中的一个经典课题",{"2":{"759":1}}],["这是第一个用于周围语义占用感知的基准",{"2":{"757":1}}],["这是第一个从机器人收集的视觉",{"2":{"131":1}}],["这是最近引入的",{"2":{"736":1}}],["这是因为数据集提供的占用标签经过精心标注",{"2":{"1000":1}}],["这是因为预测某些语义类别的占用是具有挑战性的",{"2":{"1000":1}}],["这是因为在nuscenes中",{"2":{"934":1}}],["这是因为高斯分布的位置对噪声非常敏感",{"2":{"842":1}}],["这是因为3d高斯分布可以自适应地调整其位置和协方差以匹配图像中小物体的边界",{"2":{"842":1}}],["这是因为地板是所有重建中最可见的表面",{"2":{"709":1}}],["这是因为",{"2":{"691":1,"872":1}}],["这是由于其局部感受野的特性",{"2":{"916":1}}],["这是由于深度",{"2":{"853":1}}],["这是由于更多的高斯分布能够表示更细粒度的细节",{"2":{"842":1}}],["这是由于场景的性质",{"2":{"522":1}}],["这是由于收集3d数据的成本更高",{"2":{"265":1}}],["这是一种没有任何密集3d特征的稀疏占用网络",{"2":{"1004":1}}],["这是一种可操作的空间感知的统一表示",{"2":{"973":1}}],["这是一种新颖的多传感器框架",{"2":{"898":1}}],["这是一种新颖的多模态占据预测框架",{"2":{"421":1}}],["这是一种新颖的多模态occ框架",{"2":{"421":1}}],["这是一种结合了卷积神经网络表达能力和隐式表示优势的新型形状表示方法",{"2":{"665":1}}],["这是一种将gpt概念扩展到点云领域的新方法",{"2":{"643":1}}],["这是一种利用前向后向投影的先进基于相机的鸟瞰图感知设计",{"2":{"490":1}}],["这是一种基于多传感器融合的3d语义占据预测框架",{"2":{"438":1}}],["这是一个创新的框架",{"2":{"977":1}}],["这是一个从视觉",{"2":{"973":1}}],["这是一个更具挑战性的设置",{"2":{"793":1}}],["这是一个基于",{"2":{"767":1}}],["这是一个针对室内场景的大规模占用基准数据集",{"2":{"544":1}}],["这是一个实时空间感知系统",{"2":{"467":1}}],["这是一个用于自回归生成点块的模块",{"2":{"315":1}}],["这是一个用于学习潜在表示的模块",{"2":{"315":1}}],["这是一个巨大的进步",{"2":{"302":1}}],["这是一个完全自动的方法",{"2":{"105":1}}],["这是一套算法和实现",{"2":{"141":1}}],["这是一套算法",{"2":{"112":1}}],["这个中间表示不可避免地带来离散化误差",{"2":{"955":1}}],["这个简单的观察进一步实现了数据压缩",{"2":{"905":1}}],["这个人在房间a中拿起了哪个对象",{"2":{"905":1}}],["这个人在时间t在哪里",{"2":{"905":1}}],["这个范围适合我们模型对感知范围因素的消融研究",{"2":{"900":1}}],["这个主要是为了和deque",{"2":{"888":1}}],["这个问题更为严重",{"2":{"704":1}}],["这个问题可以自然地使用经典信息瓶颈",{"2":{"109":1}}],["这个挑战主要来自于两个方面",{"2":{"631":1}}],["这个红外模式使得图像不适合kimera",{"2":{"605":1}}],["这个函数",{"2":{"561":1}}],["这个策略能够帮助模型更好地处理点云数据",{"2":{"488":1}}],["这个划分操作的结果是一组不相连的2d",{"2":{"480":1}}],["这个2d截面为房间布局提供了清晰的特征",{"2":{"480":1}}],["这个网格包含多个属于同一类别的对象",{"2":{"449":1}}],["这个细粒度的text",{"2":{"373":1}}],["这个细化步骤有可能翻转sdf值的符号以细化局部类型学",{"2":{"372":1}}],["这个clip的text",{"2":{"373":1}}],["这个流程旨在通过自回归生成任务来学习点云数据的特征表示",{"2":{"368":1}}],["这个过程我们称之为位姿图修剪",{"2":{"419":1}}],["这个过程在每个关键帧重复",{"2":{"362":1}}],["这个过程可以被理解为迭代合并图中的邻近节点",{"2":{"153":1}}],["这个模块用于构建点块的有序序列",{"2":{"315":1}}],["这个框架不仅仅是基于实例",{"2":{"313":1}}],["这个数据集本身是经过了归一化",{"2":{"313":1}}],["这个数字是所有雷达传感器的总和",{"2":{"254":1,"654":1}}],["这个做法分别对应了未掩码区域没有考虑后向生成结果的问题和需要更多步骤生成的问题",{"2":{"312":1}}],["这个图的节点",{"2":{"271":1}}],["这个场景中的样本数量",{"2":{"254":1}}],["这个盒子里雷达点的数目",{"2":{"254":1,"654":1}}],["这个检测框里的激光雷达点的数量",{"2":{"254":1,"654":1}}],["这个注释是哪个对象实例",{"2":{"254":1,"654":1}}],["这个表是我们观察到的所有对象实例的枚举",{"2":{"254":1}}],["这个时候生成图像不再具有b的身份特性",{"2":{"181":1}}],["这个阈值",{"2":{"153":1}}],["这个分数度量用于决定是否执行合并操作",{"2":{"153":1}}],["这个分数度量是通过计算合并前后的互信息",{"2":{"153":1}}],["这个比例越小",{"2":{"153":1}}],["这个度量用于评估每次合并操作对保留任务相关信息的影响",{"2":{"153":1}}],["这个",{"2":{"133":1,"149":2,"571":1}}],["这个新模块概括了kimera",{"2":{"131":1}}],["这个点击在球拍上的new",{"2":{"117":1}}],["这两种结构的不同之处仅在于一个使用了w",{"2":{"659":1}}],["这两种方法都明确估计深度或在视觉特征中隐式编码深度信息",{"2":{"564":1}}],["这两种基本架构之间做出选择",{"2":{"231":1}}],["这两个数据集是目前最流行的数据集",{"2":{"1000":1}}],["这两个步骤都非常昂贵",{"2":{"932":1}}],["这两个输出结合为",{"2":{"712":1}}],["这两个表分别将输入和输出的tensor坐标映射到了序号",{"2":{"561":1}}],["这两个方法灵感来源于图像领域",{"2":{"424":1}}],["这两个领域的研究传统上是分开进行的",{"2":{"116":1}}],["这两篇文章的的探索方向相同",{"2":{"84":1}}],["这种新颖的miou与平均绝对速度误差",{"2":{"998":1}}],["这种结构需要每个尺度的监督信号",{"2":{"971":1}}],["这种子流形稀疏卷积适用于高维和空间稀疏数据的高效处理",{"2":{"962":1}}],["这种视角具有很强的时效性",{"2":{"958":1}}],["这种视角分解策略使得占用估计比直接从整个3d空间学习更高效和有效",{"2":{"908":1}}],["这种概率深度估计方法提供了更强的鲁棒性",{"2":{"950":1}}],["这种概念和语义结构提供了图像中各种对象的上下文和相互关系的保存",{"2":{"294":1}}],["这种基于深度分布的反向投影源自lss",{"2":{"950":1}}],["这种性能差异可能是由于",{"2":{"928":1}}],["这种性能需要大量的训练时间和渲染资源",{"2":{"860":1}}],["这种多尺度投影方式还能降低结果的方差",{"2":{"928":1}}],["这种简单直接的信息融合策略可以使三维占用感知的性能提高5",{"2":{"923":1}}],["这种融合策略涉及一种动态体素融合技术",{"2":{"923":1}}],["这种转换使得在三维分支中可以使用更高效的二维卷积",{"2":{"923":1}}],["这种两步过程有助于实现更准确和有效的场景占用预测",{"2":{"922":1}}],["这种二元方法未能捕捉到未占用区域中高斯与有意义位置的接近程度",{"2":{"916":1}}],["这种分组策略平衡了监督信号",{"2":{"875":1}}],["这种分类反映了影响地图可扩展性",{"2":{"90":1}}],["这种变窄被kimera误解释为房间之间的分隔",{"2":{"872":1}}],["这种使用方式不适用于需要从头开始训练的大尺度视觉基础模型",{"2":{"863":1}}],["这种机制使得2d",{"2":{"858":1}}],["这种适应允许将占用估计集成到现有的基于bev的框架中",{"2":{"839":1}}],["这种严重的类别不平衡对模型性能构成了挑战",{"2":{"828":1}}],["这种严格解耦导致信息碎片化",{"2":{"103":1}}],["这种紧凑的表示从自上而下的角度提供了空间布局的清晰直观描述",{"2":{"821":1}}],["这种增强操作产生了一个新的特征向量",{"2":{"789":1,"809":1}}],["这种体素化表示有两个主要优势",{"2":{"780":1}}],["这种统一地图表示可同时用于物体定位",{"2":{"765":1}}],["这种半自动方法生成了高质量的注释",{"2":{"735":1}}],["这种策略使模型能够学习整个数据集的占用先验分布",{"2":{"704":1}}],["这种策略特别有用",{"2":{"153":1}}],["这种表示涉及将连续的3d空间",{"2":{"780":1}}],["这种表示方法存在冗余",{"2":{"693":1}}],["这种表示缺乏对三维空间与几何的显式推理",{"2":{"252":1}}],["这种能力在夜间驾驶或阴影",{"2":{"691":1}}],["这种能力有助于基于实时感知执行下游任务",{"2":{"682":1}}],["这种稳定性对于确保驾驶安全至关重要",{"2":{"691":1}}],["这种设置为模型提供了充足的信息来进行推理",{"2":{"682":1}}],["这种设计限制了高斯仅从2d图像学习复杂的3d几何信息",{"2":{"563":1}}],["这种粗粒度的表示无法描绘细粒度的内部几何形状和背景区域",{"2":{"665":1}}],["这种现象在",{"2":{"631":1}}],["这种点云优化的方法更加灵活",{"2":{"618":1}}],["这种方式生成的真实标签是稀疏的",{"2":{"735":1}}],["这种方式有可能采样到测地距离远但空间距离近的点",{"2":{"589":1}}],["这种方法通常需要同时与多个智能体通信",{"2":{"969":1}}],["这种方法通常能够提供良好的数据对齐",{"2":{"211":1}}],["这种方法仍然有待进一步开发",{"2":{"958":1}}],["这种方法减少了建模所需的体素数量",{"2":{"922":1}}],["这种方法确保了对统一体积的准确估计",{"2":{"916":1}}],["这种方法的核心理念是将三维场景的表示与视角信息解耦",{"2":{"908":1}}],["这种方法的一个突出例子是采用u",{"2":{"875":1}}],["这种方法不仅增强了对场景的理解",{"2":{"875":1}}],["这种方法将2d特征提升到统一的3d特征图",{"2":{"875":1}}],["这种方法解决了激光雷达在雨天和雾天场景中遇到的反射问题",{"2":{"625":1}}],["这种方法并未从根本上解决部署和计算的挑战",{"2":{"535":1}}],["这种方法在低级语义方面存在问题",{"2":{"488":1}}],["这种方法极大地限制了顶级性能occ模型在边缘设备上的部署",{"2":{"421":1}}],["这种方法我们称之为动态掩蔽",{"2":{"419":1}}],["这种方法允许识别不符合预定义类别的物体",{"2":{"535":1}}],["这种方法允许我们以有限的计算量增量构建密集的3d模型",{"2":{"206":1}}],["这种方法允许算法在实时或近实时系统中高效运行",{"2":{"153":1}}],["这种辅助监督不仅增强了融合特征的可区分性",{"2":{"576":1}}],["这种取整操作",{"2":{"554":1}}],["这种离线生成的拓扑图依旧稀疏",{"2":{"525":1}}],["这种对齐方式能够保持几何一致性",{"2":{"497":1}}],["这种架构设计使得提取器能够更好地学习点云的语义信息",{"2":{"488":1}}],["这种依赖限制了网络结构设计的灵活性",{"2":{"482":1}}],["这种正则化仅利用了点云的距离真值",{"2":{"482":1}}],["这种加权方法降低了不在墙壁顶点附近和前面的地点的投票权重",{"2":{"480":1}}],["这种差异变得更加明显",{"2":{"944":1}}],["这种差异有时有助于性能指标",{"2":{"462":1}}],["这种差距部分是由于提供丰富的任务描述的困难",{"2":{"137":1}}],["这种形式的数据关联效果很好",{"2":{"419":1}}],["这种语义扩散对cams区域起到了很大的修正作用",{"2":{"410":1}}],["这种自下而上的方法的好处是",{"2":{"352":1}}],["这种",{"2":{"153":1}}],["这种计算是增量的",{"2":{"141":1}}],["这种理解在多个抽象层次上",{"2":{"116":1}}],["这种心理模型捕捉场景的几何和语义方面",{"2":{"105":1}}],["这让我们面临一个基本问题",{"2":{"98":1}}],["这让shell非常困惑",{"2":{"41":1}}],["这一设计方面可能会阻碍模型的收敛",{"2":{"971":1}}],["这一领域的工作侧重于将度量地图划分为语义有意义的地点",{"2":{"967":1}}],["这一领域的工作涉及在循环闭合发生后校正环境的密集表示",{"2":{"967":1}}],["这一领域的工作涉及从传感器数据中估计度量",{"2":{"967":1}}],["这一领域为研究提供了一个定义明确",{"2":{"90":1}}],["这一可视化结果表明",{"2":{"952":1}}],["这一问题可以通过加入激光雷达数据来解决",{"2":{"952":1}}],["这一问题得到了缓解",{"2":{"952":1}}],["这一问题已部分得到解决",{"2":{"952":1}}],["这一现象突显了传感器融合的优势",{"2":{"959":1}}],["这一现象可以归因于激光雷达传感器未能提供丰富的语义信息",{"2":{"952":1}}],["这一现象表明雷达传感器对纯视觉中心算法的增强作用",{"2":{"944":1}}],["这一现象促使我们探索一种标注高效的方法来训练高精度的视觉",{"2":{"455":1}}],["这一观点也得到了第",{"2":{"928":1}}],["这一观察结果表明",{"2":{"971":1}}],["这一观察结果验证了在更大bev范围内空间上下文信息的价值",{"2":{"800":1}}],["这一观察结果提示了一个新的研究方向",{"2":{"421":1}}],["这一假设在室内尚可成立",{"2":{"926":1}}],["这一指标量化了每个高斯与其他所有高斯之间的重叠程度",{"2":{"916":1}}],["这一指标提供了关于高斯用于表示场景的利用情况的见解",{"2":{"916":1}}],["这一点在",{"2":{"903":1}}],["这一点尤为明显",{"2":{"901":1}}],["这一点与图像中的max",{"2":{"589":1}}],["这一优势消除了训练多个模型以预测不同分辨率占据的需求",{"2":{"899":1}}],["这一提升与基线方法中观察到的时间增强一致",{"2":{"811":1}}],["这一转向尤为关键",{"2":{"806":1}}],["这一属性使得在某些区域以更高分辨率进行推理时能够实现更准确",{"2":{"745":1}}],["这一改进归功于高斯的通用近似能力",{"2":{"700":1}}],["这一新兴的感知技术旨在推断体素化世界中每个体素的占用状态",{"2":{"667":1}}],["这一过程随后通过",{"2":{"829":1}}],["这一过程增强了",{"2":{"660":1}}],["这一过程描述如下",{"2":{"621":1,"649":1,"699":1}}],["这一框架仍然无法克服传统点云模态的固有限制",{"2":{"629":1}}],["这一任务会变得更加容易",{"2":{"903":1}}],["这一任务几乎完全依赖于",{"2":{"632":1}}],["这一任务最近受到了越来越多的关注",{"2":{"603":1}}],["这一任务的复杂性不容小觑",{"2":{"570":1}}],["这一关注源于以下动机",{"2":{"520":1}}],["这一进步与环视雷达的速度测量功能有关",{"2":{"936":1}}],["这一进步进一步增强了自动驾驶车辆对三维世界的建模能力",{"2":{"503":1}}],["这一进程得益于多个研究方向的发展",{"2":{"123":1}}],["这一研究方向变得越来越受欢迎",{"2":{"438":1}}],["这一步产生了许多错误的假定匹配",{"2":{"449":1}}],["这一步消除了量化误差",{"2":{"400":1}}],["这一步将3d场景图的一个子图转换为一个因子图",{"2":{"380":1}}],["这一步是算法有效的关键",{"2":{"339":1}}],["这一层包括描述房间",{"2":{"218":1}}],["这一层包含两种类型的节点",{"2":{"178":1,"197":1}}],["这一层的节点是3d点",{"2":{"162":1}}],["这一趋势同时受到传统3d重建和slam技术的成熟",{"2":{"172":1}}],["这一分歧的动机源于真实世界机器人在可扩展性和可重复性方面面临的挑战",{"2":{"139":1}}],["这一视角既及时又必要",{"2":{"90":1}}],["这些挑战可能会激发未来几年的研究方向",{"2":{"1007":1}}],["这些挑战共同揭示了关键空白",{"2":{"846":1}}],["这些表根据输入模态和监督学习类型对占用方法进行了分类",{"2":{"1000":1}}],["这些表示必须是持久的",{"2":{"125":1}}],["这些表示必须实时构建以支持即时决策制定",{"2":{"125":1}}],["这些表示保留了关于某些任务的兴趣信息",{"2":{"121":1}}],["这些表示本身并不是分层的",{"2":{"116":1}}],["这些城市街道更宽",{"2":{"995":1}}],["这些语义点云是通过将反投影的点云与使用",{"2":{"978":1}}],["这些bev视觉特征通过与bev点云特征的拼接进一步增强",{"2":{"976":1}}],["这些类别在数据集中的比例很小",{"2":{"1000":1}}],["这些类别涵盖了广泛的未定义语义",{"2":{"975":1}}],["这些类别的性能分别提升了17",{"2":{"800":1}}],["这些概率基于多个时间序列观测和运动先验优化为3d关节",{"2":{"967":1}}],["这些概念对任务y具有最大的信息量",{"2":{"137":1}}],["这些因素导致该领域的性能稳步提高",{"2":{"962":1}}],["这些结构用于描述3d环境",{"2":{"961":1}}],["这些结果表明",{"2":{"899":1}}],["这些结果进一步验证了我们提出的通道到高度范式的泛化性",{"2":{"811":1}}],["这些结果进一步凸显了我们提出的通道到高度范式的高效部署兼容性",{"2":{"811":1}}],["这些结果证明了我们提出的flashocc方法的有效性和泛化性",{"2":{"791":1}}],["这些都构成了重大挑战",{"2":{"958":1}}],["这些地图在具身智能任务中具有潜力",{"2":{"958":1}}],["这些头部包括卷积头部",{"2":{"957":1}}],["这些混合矩阵从当前帧的查询特征",{"2":{"957":1}}],["这些2d地图由分割的lidar点云生成的标签进行监督",{"2":{"941":1}}],["这些尺度对应于",{"2":{"928":1}}],["这些实验结果证实了利用多传感器融合大幅提高",{"2":{"927":1}}],["这些实验共同强调了clio适用于实际机器人平台",{"2":{"522":1}}],["这些体素分布在3d体积",{"2":{"910":1}}],["这些通常存储成本较低",{"2":{"905":1}}],["这些技术在最近的工作中被证明可以增强3d占用预测的计算效率",{"2":{"892":1}}],["这些技术均可移植到具身场景",{"2":{"826":1}}],["这些错误检测可以通过微调有效检测的最小对象大小",{"2":{"872":1}}],["这些问题亟需持续的研究与创新",{"2":{"864":1}}],["这些问题在没有指定表示必须支持的任务之前都是未定义的",{"2":{"109":1}}],["这些物体通常具有与正常类别不同的形状和外观",{"2":{"842":1}}],["这些物体即成为拓扑图的节点",{"2":{"765":1}}],["这些观察结果证明了3d高斯分布对于语义占用预测的宝贵应用",{"2":{"842":1}}],["这些优势在以往的方法中大多被忽视",{"2":{"820":1}}],["这些指标分别是位置和重叠",{"2":{"812":1}}],["这些指标定义如下",{"2":{"437":1}}],["这些帧被标记了12种语义",{"2":{"793":1}}],["这些对象类别包括",{"2":{"775":1}}],["这些是异常结果",{"2":{"775":1}}],["这些是使用numpy以二进制格式存储的uint8的numpy数组",{"2":{"254":1,"534":1}}],["这些损失函数遵循retinanet",{"2":{"750":1}}],["这些损失函数用于衡量生成结果与真实结果之间的差异",{"2":{"582":1}}],["这些隐式特征既可以从零开始学习",{"2":{"743":1}}],["这些区域中的物体由激光雷达点检测到",{"2":{"723":1}}],["这些查询在前面的自编码和图像交叉注意力模块中已经聚合了足够的3d信息",{"2":{"716":1}}],["这些聚合了信息的高维特征向量将用于获得对应高斯分布属性的更新量",{"2":{"705":1}}],["这些聚类在正确的粒度下根据任务要求将3d片段组合成对象",{"2":{"137":1}}],["这些过程描述如下",{"2":{"676":1,"699":1}}],["这些过程需要被组织起来",{"2":{"408":1}}],["这些限制源于当前对高斯的解释",{"2":{"656":1}}],["这些限制促使近期对更统一端到端架构的兴趣",{"2":{"283":1}}],["这些标注被划分为",{"2":{"652":1}}],["这些序列是通过",{"2":{"652":1}}],["这些值在dbow2中使用",{"2":{"634":1}}],["这些输入作为强大的几何线索",{"2":{"632":1}}],["这些输出帮助解释感知系统所见或意图",{"2":{"260":1}}],["这些输出格式说明vla4ad系统不断演进的雄心",{"2":{"216":1}}],["这些高斯未能描述有意义的结构",{"2":{"916":1}}],["这些高斯分布的标记被设置为0",{"2":{"728":1}}],["这些高斯分布将按照3",{"2":{"728":1}}],["这些高斯分布最终通过精心设计的高斯到体素的溅射模块转换为局部三维空间占用预测",{"2":{"629":1}}],["这些高斯通过2d可变形注意力机制进行细化",{"2":{"444":1}}],["这些深度bin将深度范围",{"2":{"621":1}}],["这些平面进一步通过共享的2d编码器",{"2":{"621":1}}],["这些研究使用了显式",{"2":{"603":1}}],["这些整合良好的特征用于更新视锥体内的高斯分布",{"2":{"600":1}}],["这些智能体所需的三维感知能力多种多样",{"2":{"600":1}}],["这些模块共同构成了daocc的基本网络架构",{"2":{"576":1}}],["这些模型不仅在精度和时间消耗之间实现了最佳平衡",{"2":{"535":1}}],["这些模型可解释场景",{"2":{"82":1}}],["这些任务并未促进对环境的密集理解",{"2":{"714":1}}],["这些任务与多任务损失联合训练",{"2":{"574":1}}],["这些任务要求代理不仅要通过视觉",{"2":{"100":1}}],["这些传感器通常比普通相机更昂贵",{"2":{"570":1}}],["这些传感器简化了",{"2":{"570":1}}],["这些传统的自动评估措施与人类感知的相关性不佳",{"2":{"382":1}}],["这些发现共同强调了我们的flashocc在准确捕捉复杂形状方面的卓越能力",{"2":{"791":1}}],["这些发现促使我们利用bev级特征进行高效的占据预测",{"2":{"566":1}}],["这些发现表明",{"2":{"114":1}}],["这些边缘通过网格反池化层展开回原始输入网格分辨率",{"2":{"557":1}}],["这些向量被重新组织成预测的点块",{"2":{"549":1}}],["这些数据集也作为3d占用感知算法的元数据集",{"2":{"997":1}}],["这些数据集是3d占用感知算法流行之前广泛采用的2d感知算法基准",{"2":{"997":1}}],["这些数据集是基于其他大型数据集",{"2":{"997":1}}],["这些数据集是使用我们自制的传感装置",{"2":{"855":1}}],["这些数据集是我们收集的",{"2":{"605":1}}],["这些数据集包括真实和模拟场景",{"2":{"541":1}}],["这些数据是从研究平台上收集的",{"2":{"173":1}}],["这些在芯片部署和计算能力需求方面带来了重大挑战",{"2":{"535":1}}],["这些房间用",{"2":{"522":1}}],["这些方案在激光雷达监督下预测深度值",{"2":{"704":1}}],["这些方案可通过修改适配3d占据预测任务",{"2":{"520":1}}],["这些方法可以大致分为逐点mlp方法",{"2":{"974":1}}],["这些方法可以有效地捕捉和利用完整的空间信息",{"2":{"875":1}}],["这些方法直接从像素信息中推断网格",{"2":{"967":1}}],["这些方法直接预测类概率",{"2":{"857":1}}],["这些方法拟合3d网格到2d图像关键点",{"2":{"967":1}}],["这些方法专注于静态环境",{"2":{"967":1}}],["这些方法没有充分利用底层的几何和结构信息",{"2":{"955":1}}],["这些方法没有捕捉到这样一个直觉",{"2":{"109":1}}],["这些方法绕过了对lidar点云深度或语义标签的需求",{"2":{"949":1}}],["这些方法的一个关键优势是能够直接从原始3d空间中学习",{"2":{"875":1}}],["这些方法的计算成本通常很高",{"2":{"777":1}}],["这些方法是目前开源的最优方法之一",{"2":{"870":1}}],["这些方法不使用占用标签",{"2":{"988":1}}],["这些方法不需要区域建议生成和后处理",{"2":{"857":1}}],["这些方法不关心估计更高层次的语义",{"2":{"172":1}}],["这些方法实现了更高的对象召回率",{"2":{"798":1}}],["这些方法首先利用现有的2d对象检测器生成对象的2d候选区域",{"2":{"818":1}}],["这些方法首先利用现有的语义分割技术去除大部分背景点",{"2":{"798":1}}],["这些方法首先提出几个可能包含对象的区域",{"2":{"756":1}}],["这些方法融合了来自不同视图地图的建议性特征",{"2":{"777":1}}],["这些方法面临着相当大的计算和存储开销",{"2":{"612":1}}],["这些方法使用密集网格表示",{"2":{"599":1}}],["这些方法使用类无关的分割网络",{"2":{"109":1}}],["这些方法大多按场景优化",{"2":{"588":1}}],["这些方法定义了空间域中的操作",{"2":{"574":1}}],["这些方法通常将点云转换为密集",{"2":{"962":1}}],["这些方法通常将",{"2":{"955":1}}],["这些方法通常涉及从高维特征中解码每个体素的语义",{"2":{"693":1}}],["这些方法通常依赖计算昂贵的bev特征",{"2":{"114":1}}],["这些方法通过粗到细的上采样",{"2":{"547":1}}],["这些方法能够有效捕捉复杂的结构",{"2":{"808":1}}],["这些方法能够更详细地表示场景",{"2":{"535":1}}],["这些方法能够提高模型对点云数据的理解能力",{"2":{"488":1}}],["这些方法主要针对仅使用摄像头的自动驾驶设计",{"2":{"474":1}}],["这些方法未能有效保留细粒度细节",{"2":{"438":1}}],["这些方法无法很好地扩展到密集的三维数据",{"2":{"363":1}}],["这些方法将卷积定义为谱滤波",{"2":{"607":1}}],["这些方法将3d点云投影到多个视图当中",{"2":{"337":1}}],["这些方法将三维点云投影到不同的表示方式",{"2":{"311":1}}],["这些方法显著缩小语言指令与车辆动作间语义鸿沟",{"2":{"283":1}}],["这些方法在规则网格上定义卷积核",{"2":{"511":1}}],["这些方法在连续空间上定义卷积核",{"2":{"481":1}}],["这些方法在slam流程中被广泛采用",{"2":{"190":1}}],["这些方法在统一框架内集成感知",{"2":{"114":1}}],["这些方法在查询大型视觉",{"2":{"109":1}}],["这些方法留给用户一个困难的任务",{"2":{"109":1}}],["这些设计和优化在nuscenes数据集上实现了54",{"2":{"490":1}}],["这些基准的出现进一步推动了三维占据预测的发展",{"2":{"482":1}}],["这些流程难以处理超长或不规则形状的物体",{"2":{"455":1}}],["这些差异源于为kimera设置适当的高度以尝试分割房间的困难",{"2":{"437":1}}],["这些网络是基于不同的数据索引结构",{"2":{"636":1}}],["这些网络可以实现三维无序点云的置换不变性",{"2":{"420":1}}],["这些网格可以被优化以反映真实的地面模型",{"2":{"285":1}}],["这些节点很可能是错误的",{"2":{"419":1}}],["这些形状参数包括",{"2":{"419":1}}],["这些参数编码了网格的各种形状属性",{"2":{"419":1}}],["这些包括算法",{"2":{"408":1}}],["这些误差在经典方法中是固定的",{"2":{"400":1}}],["这些与标准姿态图优化相同",{"2":{"390":1}}],["这些变换描述了网格上的局部变形",{"2":{"390":1}}],["这些特征体通过特征融合模块进行中期融合",{"2":{"527":1}}],["这些特征应能充分表征地图中的物体",{"2":{"435":1}}],["这些特征通过加权求和的方式合并",{"2":{"623":1}}],["这些特征通过flexible",{"2":{"384":1}}],["这些特征通常来自预训练编码器",{"2":{"406":1}}],["这些特征之间相互关联",{"2":{"149":1}}],["这些层的目标",{"2":{"437":1}}],["这些层通过前端添加的层间边形成一个连接的子图",{"2":{"380":1}}],["这些层是基于当前里程计估计构建的",{"2":{"326":1}}],["这些点在一个固定的深度范围内",{"2":{"704":1}}],["这些点与物理空间中的",{"2":{"378":1}}],["这些点击区域相当于有ground",{"2":{"84":1}}],["这些id用于几何验证",{"2":{"352":1}}],["这些非直接方法有两个缺点",{"2":{"349":1}}],["这些系统不再仅对传感器输入反应",{"2":{"334":1}}],["这些系统可",{"2":{"82":1}}],["这些核心通过一个基于transformer的解码器进行训练",{"2":{"306":1}}],["这些见解激发了我们检测房间的方法",{"2":{"301":1}}],["这些假设不容易扩展到任意",{"2":{"301":1}}],["这些提升效率",{"2":{"260":1}}],["这些端到端模型都需重新训练",{"2":{"252":1}}],["这些轨迹常以bev或自车坐标表达",{"2":{"216":1}}],["这些动作常被建模为连续输出或离散动作token",{"2":{"216":1}}],["这些被提取的特征通过一个支持向量机",{"2":{"169":1}}],["这些场景中的模型性能分别如表",{"2":{"936":1}}],["这些场景中累积的ate是明显的",{"2":{"754":1}}],["这些场景更难从单个图像视点重建",{"2":{"917":1}}],["这些场景特别具有挑战性",{"2":{"437":1}}],["这些场景由专业标注人员进行仔细标注",{"2":{"157":1}}],["这些场景图在图像空间中定义",{"2":{"116":1}}],["这些顶点之间相互可达",{"2":{"153":1}}],["这些进展标志着从以感知为中心的vlm流水线向具备行动感知",{"2":{"145":1}}],["这些进展催生了从解释性叠加到具备思维链",{"2":{"82":1}}],["这些算法中用于视图变换的两种主要方法是经典的",{"2":{"564":1}}],["这些算法处理整个esdf",{"2":{"141":1}}],["这些算法在机器人当前位置周围构建局部欧几里得有符号距离函数",{"2":{"112":1}}],["这些工作在高质量长期预测方面仍然表现不佳",{"2":{"1003":1}}],["这些工作大多依赖于gpu处理",{"2":{"967":1}}],["这些工作与具身智能体的核心要求本质上不一致",{"2":{"600":1}}],["这些工作将动态目标建模为一个点或3d姿态",{"2":{"419":1}}],["这些工作都不涉及同时校正多个层次化表示",{"2":{"190":1}}],["这些工作使用整个环境的欧几里得有符号距离函数",{"2":{"141":1}}],["这些工作是在",{"2":{"116":1}}],["这些为我们想要保留在地图中的提供了一个概念的超集",{"2":{"137":1}}],["这些关联是特定任务标签常缺失的",{"2":{"128":1}}],["这些时长为",{"2":{"126":1}}],["这些范式在极端场景处理与分布外",{"2":{"114":1}}],["这些可以是机器人在其生命周期中或在其当前部署期间被设想要执行的任务",{"2":{"109":1}}],["这些规范都沿用至今",{"2":{"54":1}}],["这行命令与arm还是x86",{"2":{"76":1}}],["这里使用的是ckc",{"2":{"814":1}}],["这里使用的全局空间占用是每个场景的30个帧对应的视锥体的并集",{"2":{"793":1}}],["这里使用了",{"2":{"456":1}}],["这里将tensor的坐标与序号进行对应",{"2":{"530":1}}],["这里dmax是到k+1个最近节点的距离",{"2":{"390":1}}],["这里的tokenizer最大长度为77",{"2":{"373":1}}],["这里的几个关键概念包括",{"2":{"153":1}}],["这里vq的codebook采样较高的维度",{"2":{"345":1}}],["这里额外提一下",{"2":{"313":1}}],["这里我们展示dvio",{"2":{"709":1}}],["这里我们在3d体素上而不是2d像素上计算精度和召回率",{"2":{"437":1}}],["这里我们逐层描述kimera",{"2":{"285":1}}],["这里我们按线程描述架构",{"2":{"285":1}}],["这里我们首先根据dsg设计的任务和运动规划查询来激励我们选择的节点",{"2":{"262":1}}],["这里我仍然使用清华源",{"2":{"76":1}}],["这里做一步扩散的计算量就很大",{"2":{"205":1}}],["这里style是指人脸的风格",{"2":{"133":1}}],["这里",{"2":{"121":1,"437":1,"532":1,"693":1,"752":1}}],["这里开始就很骚了",{"2":{"66":1}}],["没有任何特征放大操作",{"2":{"971":1}}],["没有任何无效的点滤波",{"2":{"254":1,"654":1}}],["没有包括密集的",{"2":{"961":1}}],["没有处理动态场景",{"2":{"961":1}}],["没有",{"2":{"938":2}}],["没有经过人工校准",{"2":{"893":1}}],["没有标准化的内在指标",{"2":{"864":1}}],["没有深度信息的帮助",{"2":{"833":1}}],["没有现有的多模态占据预测工作使用rayiou指标来报告模型性能",{"2":{"779":1}}],["没有专门用于",{"2":{"653":1}}],["没有对3d模型进行推理",{"2":{"961":1}}],["没有对3d场景图进行后处理",{"2":{"522":1}}],["没有对称性",{"2":{"328":1}}],["没有对",{"2":{"196":1}}],["没有则返回map",{"2":{"177":1}}],["没有解决transformer训练所需数据量大的缺点",{"2":{"167":1}}],["没有适当的表征",{"2":{"116":1}}],["没有密码外部无法登陆",{"2":{"78":1}}],["没有见过的实例",{"2":{"54":1}}],["没有那个文件或目录",{"0":{"48":1},"2":{"48":1}}],["没有考虑真实数据与生成数据的具体差异",{"2":{"13":1}}],["7b",{"2":{"903":1}}],["7a",{"2":{"903":1}}],["7公里的驾驶距离",{"2":{"781":1}}],["7的nms算法排除掉重叠的proposal",{"2":{"493":1}}],["7和γ",{"2":{"431":1}}],["7以上",{"2":{"347":1}}],["704×256",{"2":{"823":1}}],["700",{"2":{"652":1,"739":1,"749":1}}],["700个场景用于火车",{"2":{"534":1}}],["70",{"2":{"172":1,"173":1,"195":1,"277":2,"481":1,"522":1,"534":2,"603":1,"607":1,"652":1,"700":4,"709":1,"803":1,"808":1,"860":1,"875":1,"893":2,"917":1}}],["76",{"2":{"145":1,"522":1,"603":1,"607":1,"803":1,"808":1,"875":1,"893":1,"942":3,"950":3,"957":2,"985":1,"997":1,"998":1,"1000":1}}],["7节中提到的",{"2":{"930":1}}],["7节评估了将地点分割成房间的准确性",{"2":{"541":1}}],["7节",{"0":{"480":1},"2":{"131":1,"285":1,"796":1}}],["795",{"2":{"853":1}}],["798",{"2":{"739":1}}],["79",{"2":{"128":1,"277":2,"522":2,"534":2,"603":1,"636":1,"808":2,"875":1,"910":5,"923":1,"971":1}}],["75miou",{"2":{"800":1}}],["75",{"2":{"128":1,"570":1,"603":1,"607":1,"808":1,"875":1,"893":1,"910":4,"923":1,"985":2,"1000":1,"1001":1}}],["787",{"2":{"277":1,"534":1}}],["78",{"2":{"125":1,"128":1,"277":1,"522":2,"534":1,"545":1,"603":1,"636":1,"875":1,"910":1,"965":1,"971":1,"985":1,"997":1}}],["78832947",{"2":{"48":1}}],["728个姿态节点和1031个网格节点",{"2":{"816":1}}],["720461546",{"2":{"663":1}}],["727",{"2":{"277":1,"534":1}}],["723",{"2":{"277":1,"534":1}}],["72",{"2":{"114":1,"437":2,"522":2,"603":1,"607":1,"860":1,"875":1,"893":1,"928":1}}],["7223",{"2":{"51":1}}],["7399",{"2":{"652":1,"828":1}}],["730",{"2":{"277":1,"534":1,"947":1}}],["736",{"2":{"277":1,"534":1}}],["73",{"2":{"103":1,"277":1,"522":1,"534":1,"607":1,"808":1,"860":1,"875":1}}],["74",{"2":{"82":1,"128":1,"195":1,"517":1,"607":1,"686":1,"860":1,"870":1,"875":1,"978":1}}],["710",{"2":{"635":1}}],["71m",{"2":{"545":2,"965":2}}],["713",{"2":{"277":2,"534":2}}],["718",{"2":{"277":1,"534":1}}],["71",{"2":{"67":1,"114":1,"172":1,"190":1,"522":1,"603":2,"607":2,"632":1,"684":2,"794":1,"860":1,"875":1}}],["715754",{"2":{"31":1}}],["775",{"2":{"947":1}}],["771",{"2":{"947":1}}],["77是token的数量",{"2":{"373":1}}],["77ghz",{"2":{"173":1}}],["77",{"2":{"66":2,"114":1,"277":1,"522":1,"534":1,"603":2,"607":1,"808":1,"875":1,"928":1}}],["7",{"0":{"478":1,"796":1,"864":1,"876":1,"954":1,"961":1,"967":1},"1":{"961":1,"967":1},"2":{"43":1,"51":1,"66":1,"82":1,"90":1,"109":1,"126":2,"228":1,"277":2,"360":4,"366":1,"380":1,"390":1,"421":1,"435":1,"495":1,"503":1,"517":1,"522":5,"525":1,"534":1,"545":1,"563":1,"585":1,"595":1,"603":1,"627":1,"632":1,"641":1,"652":1,"665":1,"667":1,"676":2,"749":1,"752":1,"790":4,"792":1,"811":3,"828":2,"832":1,"840":1,"846":1,"893":6,"900":1,"902":1,"903":1,"914":1,"931":1,"936":2,"947":1,"951":1,"957":1,"959":1,"965":1,"971":1,"982":1,"989":2,"992":1,"1003":2}}],["原则",{"2":{"585":1}}],["原来是这么一回事",{"2":{"292":1}}],["原始颜色和语义图也被渲染",{"2":{"949":1}}],["原始pcm旨在多机器人情况",{"2":{"390":1}}],["原始图像",{"2":{"410":1}}],["原始图像与传感器数据通过大型自监督骨干网络",{"2":{"195":1}}],["原始图像可直接处理或转换为结构化中间表示",{"2":{"176":1}}],["原始传感器数据等",{"2":{"126":1}}],["原因在于erase",{"2":{"115":1}}],["原文",{"2":{"62":1}}],["原文链接",{"2":{"41":1,"48":1,"220":1,"351":1}}],["原项目使用",{"2":{"27":1}}],["转移构造",{"2":{"604":1}}],["转化到rulebook",{"2":{"561":1}}],["转换过程与图6a中描述的过程略有不同",{"2":{"950":1}}],["转换脚本",{"0":{"850":1}}],["转换到当前帧",{"2":{"550":1}}],["转换成风格",{"2":{"149":1}}],["转换得到的仿射变换",{"2":{"133":1}}],["转换为柱坐标系",{"2":{"621":1}}],["转换为点云信息",{"2":{"424":1}}],["转换为潜在表示",{"2":{"195":1}}],["转换为",{"2":{"31":1}}],["转载请附上原文出处链接及本声明",{"2":{"41":1,"48":1,"220":1,"351":1}}],["版权声明",{"2":{"41":1,"48":1,"220":1,"351":1}}],["版本j采用vit",{"2":{"805":1}}],["版本i使用vovnet",{"2":{"805":1}}],["版本h为版本g的测试时增强结果",{"2":{"785":1}}],["版本g通过添加dice损失和3d变换对齐不同时间步体素特征优化损失函数",{"2":{"785":1}}],["版本f采用联合深度",{"2":{"785":1}}],["版本e利用前16帧时序信息",{"2":{"785":1}}],["版本d修复了版本c的主要错误",{"2":{"785":1}}],["版本c训练时忽略相机不可见体素",{"2":{"785":1}}],["版本b使用bevdepth的深度监督",{"2":{"785":1}}],["版本a为基线",{"2":{"785":1}}],["版本为",{"2":{"107":1}}],["版本中默认opencv",{"2":{"107":1}}],["版本",{"2":{"40":1,"47":1,"761":1}}],["我让给你",{"2":{"507":1}}],["我的新文本就是a",{"2":{"204":1}}],["我的大概理解为文件在windows上编辑过",{"2":{"41":1}}],["我想判断这个图片是不是狗",{"2":{"204":1}}],["我们描述了一些开放的挑战",{"2":{"1007":1}}],["我们描述了我们的方法",{"2":{"419":1}}],["我们探讨了3d占用感知在自动驾驶中的挑战和机遇",{"2":{"1002":1}}],["我们探索在多相机3d感知任务中使用10亿参数主干internimage",{"2":{"617":1}}],["我们探索利用多模态数据",{"2":{"474":1}}],["我们整理了3d占用方法的推理速度",{"2":{"1001":1}}],["我们再次使用",{"2":{"978":1}}],["我们考察了包括相机",{"2":{"977":1}}],["我们考虑体素之间的四种关系",{"2":{"707":1}}],["我们考虑体素",{"2":{"707":1}}],["我们考虑使用",{"2":{"437":1}}],["我们考虑并扩展了聚合ib方法",{"2":{"153":1}}],["我们考虑了",{"2":{"143":1,"870":1}}],["我们感谢dan",{"2":{"973":1}}],["我们之前概述的类别中仍存在一些需要进一步关注的挑战",{"2":{"969":1}}],["我们操作网格模型",{"2":{"967":1}}],["我们特别感兴趣的是环境被表示为网格",{"2":{"967":1}}],["我们广泛回顾了语义建图的多种方法",{"2":{"958":1}}],["我们省略了值后面的",{"2":{"931":1,"979":1}}],["我们推测",{"2":{"928":1}}],["我们推断关系矩阵",{"2":{"752":1}}],["我们检查它是否位于至少一个高斯的",{"2":{"916":1}}],["我们检查当前检测的beta参数与时间t",{"2":{"419":1}}],["我们生成一系列初始体素并提取其特征",{"2":{"910":1}}],["我们模型中的",{"2":{"901":1}}],["我们仍然在",{"2":{"917":1}}],["我们仍然在当前视锥体中均匀初始化一定数量的高斯分布",{"2":{"705":1}}],["我们仍然观察到一些错误的对象检测",{"2":{"889":1}}],["我们研究了多级监督和多尺度粗到细特征细化结构对整体性能的影响",{"2":{"971":1}}],["我们研究了在",{"2":{"928":1}}],["我们研究了深度估计模块中每个组件对整体性能的影响",{"2":{"882":1}}],["我们研究了将这些稀疏雷达特征与相机和激光雷达数据合并时对模型性能的影响",{"2":{"653":1}}],["我们深入讨论若干最具前景的未来方向",{"2":{"881":1}}],["我们深入比较训练范式",{"2":{"538":1}}],["我们调整了主要基线",{"2":{"870":1}}],["我们无法判断下游任务提升究竟源于更优的语义理解",{"2":{"864":1}}],["我们显著降低了训练成本并提升了可用性",{"2":{"862":1}}],["我们定性评估kimera从真实生活数据集中生成dsg的能力",{"2":{"855":1}}],["我们定义了一个互补的软性测量方法",{"2":{"916":1}}],["我们定义了˜",{"2":{"390":1}}],["我们定义高斯处于正确位置的百分比",{"2":{"916":1}}],["我们定义",{"2":{"794":1}}],["我们定义预测的",{"2":{"787":1}}],["我们定义超体素为",{"2":{"730":1}}],["我们定义osp为至少有90",{"2":{"402":1}}],["我们定义ti为姿态或网格顶点的变换",{"2":{"390":1}}],["我们能够实现实时操作的合适性能",{"2":{"836":1}}],["我们确定了两个候选参数",{"2":{"836":1}}],["我们分析了它对效率和性能的影响",{"2":{"842":1}}],["我们分析了各种参数设置对kimera",{"2":{"836":1}}],["我们分别观察到约",{"2":{"936":1}}],["我们分别在它们的",{"2":{"870":1}}],["我们分别实现了93",{"2":{"796":1}}],["我们分别获得了99",{"2":{"796":1}}],["我们分别使用不同比例的数据来训练融合网络和视觉网络",{"2":{"782":1}}],["我们分别使用单独的卷积层来预测每个参数",{"2":{"666":1}}],["我们分别使用二维图像编码器和三维稀疏卷积",{"2":{"421":1}}],["我们分别为这两组特征建立重建目标",{"2":{"640":1}}],["我们分别存储由kimera",{"2":{"390":1}}],["我们冻结了前两个优化层",{"2":{"833":1}}],["我们验证了我们的embodiedocc达到了我们的预期",{"2":{"833":1}}],["我们让模型回到第一帧",{"2":{"833":1}}],["我们期望embodiedocc在遇到之前探索过的部分时能够表现出更好的性能",{"2":{"833":1}}],["我们期待更多公司与社区共享数据",{"2":{"302":1}}],["我们把从我们的局部空间占用预测模块获得的局部空间占用拼接起来",{"2":{"833":1}}],["我们把这个",{"2":{"561":1}}],["我们是首个将子像素范式",{"2":{"831":1}}],["我们是首个将子像素范式应用于占据任务并完全避免计算密集型3d卷积的研究者",{"2":{"566":1}}],["我们过滤掉了",{"2":{"828":1}}],["我们列出可用于评估地图的各个维度",{"2":{"826":1}}],["我们集成七个模型",{"2":{"825":1}}],["我们训练模型20个周期",{"2":{"822":1}}],["我们训练的模型就可以解决",{"2":{"384":1}}],["我们局部空间占用预测模块的其他部分遵循gaussianformer",{"2":{"813":1}}],["我们注意到",{"2":{"872":1,"885":1,"886":1,"989":1}}],["我们注意到dsg足够通用",{"2":{"796":1}}],["我们注意到我们选择的关联策略在办公室和建筑场景中优于hydra",{"2":{"522":1}}],["我们优化语义",{"2":{"794":1}}],["我们优化类别级可微的",{"2":{"794":1}}],["我们优化加权多标签二元交叉熵损失",{"2":{"752":1}}],["我们相信",{"2":{"852":1}}],["我们相信daocc具有实际应用潜力",{"2":{"820":1}}],["我们相信知识蒸馏有助于提升仅视觉",{"2":{"455":1}}],["我们相应地从occ",{"2":{"793":1}}],["我们必须确保训练集中的场景与评估集中的场景不同",{"2":{"793":1}}],["我们必须创建一个类似于二维图像中的rgb通道的输入特征表示",{"2":{"379":1}}],["我们数据集中的大多数已知对象都是在运行初期可视化的",{"2":{"775":1}}],["我们都以显著的",{"2":{"903":1}}],["我们都可以正确地定位对象",{"2":{"775":1}}],["我们都使用kimera",{"2":{"437":1}}],["我们聚合多帧激光雷达点云",{"2":{"761":1}}],["我们聚合并体素化前",{"2":{"677":1}}],["我们随机丢弃80",{"2":{"758":1}}],["我们随机初始化一组查询和属性",{"2":{"716":1}}],["我们随机初始化一组查询来实例化3d高斯分布",{"2":{"547":1}}],["我们方法中的高斯在尺度和形状上更具适应性",{"2":{"745":1}}],["我们方法的整体流程",{"2":{"681":1}}],["我们额外报告一个语义分割指标",{"2":{"736":1}}],["我们预测哪些mmm关系存在",{"2":{"730":1}}],["我们预计地图将随着时间的推移而增长",{"2":{"153":1}}],["我们会先四处走动以探索周围环境",{"2":{"728":1}}],["我们担心由于对协方差和语义对数几率应用的sigmoid和softmax激活函数可能导致梯度消失",{"2":{"716":1}}],["我们如图3中的",{"2":{"716":1}}],["我们如方程",{"2":{"271":1}}],["我们应该考虑生成实心真实标签或在特定范围内匹配占用的体素",{"2":{"778":1}}],["我们应该利用什么好的信号来从没有注释的点云中学习特征",{"2":{"715":1}}],["我们应用",{"2":{"746":1}}],["我们应用2d主干网络",{"2":{"621":1}}],["我们应用三维稀疏卷积",{"2":{"609":1}}],["我们应用一个鲁棒的开源注册技术",{"2":{"449":1}}],["我们应用一个具有残差结构的全卷积bev编码器来进一步融合统一的bev特征",{"2":{"421":1}}],["我们系统地回顾了自动驾驶领域3d占用感知的最新研究",{"2":{"714":1}}],["我们系统地将相关研究分为无注释方法和无lidar方法",{"2":{"665":1}}],["我们编码它们的语义类别是否相似或不同",{"2":{"707":1}}],["我们编码是否两个体素都被占用",{"2":{"707":1}}],["我们合并了相似的类",{"2":{"702":1}}],["我们经验性地设置",{"2":{"694":1}}],["我们框架的总损失可以定义为",{"2":{"690":1}}],["我们常用的sgi",{"2":{"685":1}}],["我们受",{"2":{"684":1}}],["我们受光学原理启发",{"2":{"570":1}}],["我们有",{"2":{"682":1,"728":1}}],["我们有一个原始信号",{"2":{"137":1}}],["我们人类能够轻松地处理双眼收集到的视觉信息",{"2":{"682":1}}],["我们简单地将它们结合起来生成最终的语义占用预测",{"2":{"681":1}}],["我们简单地对四个最近的深度假设进行概率和来衡量估计质量",{"2":{"622":1}}],["我们移除了其他组件",{"2":{"928":1}}],["我们移除了",{"2":{"670":1}}],["我们移除对应于vio时间范围之外观察到的旧特征的顶点和三元组",{"2":{"336":1}}],["我们解释如何有效地将图像输入中的信息转换为3d高斯分布",{"2":{"669":1}}],["我们解决了从",{"2":{"539":1}}],["我们全面回顾了用于自动驾驶应用的基于视觉的3d占用预测方法",{"2":{"665":1}}],["我们主张这使得",{"2":{"660":1}}],["我们沿着",{"2":{"660":1}}],["我们沿着多头轴平均注意力张量以减少到",{"2":{"278":1}}],["我们沿每个视觉特征网格的射线预定义了一组深度bin",{"2":{"649":1}}],["我们开发了depthnet",{"2":{"649":1}}],["我们开发了pcm的实现",{"2":{"390":1}}],["我们已看到先前工作将地图结构化为空间网格",{"2":{"648":1}}],["我们已经展示了这个问题可以用经典的信息瓶颈来表达",{"2":{"586":1}}],["我们扩展点云范围以提供更多的三维空间上下文",{"2":{"638":1}}],["我们扩展了点云的处理范围",{"2":{"421":1}}],["我们总结了在这些数据集上训练和测试的各种3d占用方法的性能",{"2":{"1000":1}}],["我们总结了当前趋势",{"2":{"956":1}}],["我们总结了当前的研究趋势",{"2":{"637":1}}],["我们总结了通用的网络流程",{"2":{"610":1}}],["我们评估了框架中实施的每种传感器融合策略的效率",{"2":{"965":1}}],["我们评估了各种传感器融合策略在具有挑战性的夜间和雨天场景中的性能",{"2":{"936":1}}],["我们评估了处理所有帧",{"2":{"833":1}}],["我们评估从地面真实点云到估计点云最近邻的距离",{"2":{"686":1}}],["我们评估kimera",{"2":{"634":1}}],["我们评估并分析了最先进方法在流行数据集上的占用感知性能",{"2":{"610":1}}],["我们依赖于它们各自论文中报告的运行时间作为基准",{"2":{"859":1}}],["我们依赖于连续的",{"2":{"632":1}}],["我们依然可以使用之前ddpm的方式继续训练一个无条件生成模型",{"2":{"338":1}}],["我们详细回顾和讨论了最先进的以激光雷达为中心",{"2":{"1007":1}}],["我们详细阐述对应于",{"2":{"916":1}}],["我们详细描述了高斯到体素的溅射模块",{"2":{"669":1}}],["我们详细介绍了基于分布的初始化模块",{"2":{"628":1}}],["我们详述开放挑战",{"2":{"72":1}}],["我们联合训练深度估计和语义分割任务",{"2":{"617":1}}],["我们校准了imu",{"2":{"605":1}}],["我们请读者参考hu和carlone",{"2":{"605":1}}],["我们收集了现有方法在occ3d",{"2":{"757":1}}],["我们收集了现有方法在semantickitti数据集上的评估结果",{"2":{"757":1}}],["我们收集了uhumans2数据集",{"2":{"605":1}}],["我们收集了四个数据集",{"2":{"374":1}}],["我们说",{"2":{"592":1}}],["我们说如果估计对象的边界框包含真值边界框的质心",{"2":{"402":1}}],["我们维护一个明确的全局三维高斯分布记忆",{"2":{"568":1,"600":1}}],["我们维护一个场景图的版本",{"2":{"380":1}}],["我们基于",{"2":{"794":1}}],["我们基于这种表示设计了我们的局部和具身空间占用预测模块",{"2":{"705":1}}],["我们基于局部标注的occ",{"2":{"600":1,"793":1}}],["我们基于局部标注重新组织了一个embodiedoccscannet基准测试",{"2":{"568":1}}],["我们基于ib理论构建",{"2":{"121":1}}],["我们针对这一实际场景",{"2":{"568":1}}],["我们成功的建立了输入和输出的哈希表",{"2":{"561":1}}],["我们目前考虑的是相对简单的单步任务",{"2":{"553":1}}],["我们目前平均clip向量时合并两个原语",{"2":{"553":1}}],["我们讨论了3d占用的现有和潜在应用",{"2":{"1002":1}}],["我们讨论了不同clip模型对性能的影响",{"2":{"553":1}}],["我们讨论可以更好地利用我们问题的结构的算法",{"2":{"137":1}}],["我们表明",{"2":{"552":1}}],["我们迭代优化3d高斯分布的属性",{"2":{"547":1}}],["我们追溯vla4ad通过四个连续浪潮的演进",{"2":{"538":1}}],["我们追溯四个连续阶段",{"2":{"238":1}}],["我们直接建模3d体素表示以捕获更详细的3d空间信息",{"2":{"585":1}}],["我们直接将当代方法中的3d卷积替换为2d卷积",{"2":{"535":1}}],["我们直接使用这个图来提取地点及其拓扑结构",{"2":{"480":1}}],["我们直观地利用通道到高度变换将扁平化的bev特征重塑为三维体素级占据逻辑",{"2":{"535":1}}],["我们旨在通过将其应用于流行的基于3d卷积的占据模型",{"2":{"811":1}}],["我们旨在激励未来工作",{"2":{"538":1}}],["我们旨在高效实现通道到高度的特征变换",{"2":{"535":1}}],["我们旨在统一不同的研究方向",{"2":{"90":1}}],["我们远程操作spot观察场景中的所有对象",{"2":{"522":1}}],["我们选择相机前方的一个特定区域作为局部空间占用的范围",{"2":{"886":1}}],["我们选择了",{"2":{"886":1}}],["我们选择使用",{"2":{"867":1}}],["我们选择不带时间模块的bevdetocc",{"2":{"811":1}}],["我们选择当前输入语义片段中与提示嵌入余弦相似度最高的像素质心作为输入到spot",{"2":{"522":1}}],["我们选择gvd的一个子集作为地点节点",{"2":{"276":1}}],["我们没有应用任何测试时增强技术",{"2":{"866":1}}],["我们没有使用任何检测网络的预训练权重",{"2":{"782":1}}],["我们没有分析隔间或replica",{"2":{"522":1}}],["我们没有关于人类何时进入画面以及何时离开的信息",{"2":{"419":1}}],["我们强调模型规模和预训练技术的重要性",{"2":{"520":1}}],["我们强调需要标准化基准与开源工具包以促进可重复性并加速跨模型比较",{"2":{"82":1}}],["我们突出五大有前景线索",{"2":{"507":1}}],["我们认为使用llms和lvlms是实现广义3d占用感知的挑战和机遇",{"2":{"1006":1}}],["我们认为关于鲁棒bev感知的相关工作",{"2":{"1005":1}}],["我们认为3d占用在自动驾驶中具有更广泛的应用机会",{"2":{"1003":1}}],["我们认为dsg也补充了自然语言接地的工作",{"2":{"905":1}}],["我们认为当使用",{"2":{"903":1}}],["我们认为这可能是因为occ3d",{"2":{"1000":1}}],["我们认为这是由于地面真实情况中对运动物体的聚合",{"2":{"903":1}}],["我们认为这是由于我们初始化模块中耗时的最远点采样",{"2":{"812":1}}],["我们认为这样的选择本质上是任务依赖的",{"2":{"98":1}}],["我们认为现在是时候加大对内部指标的关注",{"2":{"806":1}}],["我们认为",{"2":{"786":1,"943":1}}],["我们认为社区必须汇聚共享评估协议与开源工具包",{"2":{"538":1}}],["我们认为理想的框架应该对多样化芯片部署友好",{"2":{"505":1}}],["我们重建相应surfel的法向量",{"2":{"640":1}}],["我们重复多数投票",{"2":{"480":1}}],["我们重新训练了所有基线方法",{"2":{"853":1}}],["我们重新划分了场景",{"2":{"793":1}}],["我们重新组织了embodiedocc",{"2":{"793":1}}],["我们重新初始化高斯记忆",{"2":{"750":1}}],["我们重新识别",{"2":{"372":1}}],["我们重新将去噪后的拼合结果xt−1x",{"2":{"312":1}}],["我们查询在法线方向上最近的地点节点",{"2":{"480":1}}],["我们类似地初始化查询",{"2":{"471":1}}],["我们仅应用了光度失真增强",{"2":{"866":1}}],["我们仅评估对相机可见的体素",{"2":{"803":1}}],["我们仅使用",{"2":{"782":1}}],["我们仅使用单张",{"2":{"603":1}}],["我们仅通过邻近的3d高斯分布进行局部聚合来高效近似占用预测",{"2":{"738":1}}],["我们仅考虑每个体素位置的邻近3d高斯分布以提高效率",{"2":{"738":1}}],["我们仅随机选择一半的初始化查询",{"2":{"471":1}}],["我们仅在tsdf截断距离内沿射线传播此信息",{"2":{"362":1}}],["我们需要以场景为最小单元进行高效学习",{"2":{"455":1}}],["我们证明了我们方法的有效性和鲁棒性",{"2":{"438":1}}],["我们仔细研究了层次环路闭合检测方法提出的环路闭合候选者的质量",{"2":{"437":1}}],["我们仔细设计边缘的输入描述符",{"2":{"325":1}}],["我们测试了不同的损失函数",{"2":{"823":1}}],["我们测试了不同传感器融合策略在不同感知范围内的性能变化",{"2":{"503":1}}],["我们测试它是否与之前的回路闭合成对一致",{"2":{"390":1}}],["我们测量估计地点节点到地面真实gvd中最近体素的平均距离",{"2":{"437":1}}],["我们测绘学生公寓以及在两层都复制的休息室和厨房区域",{"2":{"437":1}}],["我们穿过研究生住所的一楼的公共休息室",{"2":{"437":1}}],["我们包括了clio",{"2":{"431":1}}],["我们运行a在建筑物",{"2":{"947":1}}],["我们运行conceptgraphs",{"2":{"431":1}}],["我们运行fastsam",{"2":{"206":1}}],["我们根据文献中提到的监督训练类型对网络训练技术进行分类",{"2":{"981":1}}],["我们根据给定的内参和外参将其3d位置",{"2":{"950":1}}],["我们根据气候和光照条件对",{"2":{"914":1}}],["我们根据euroc数据集中的地面真实点云评估kimera",{"2":{"754":1}}],["我们根据其尺度属性",{"2":{"738":1}}],["我们根据体素索引对列表进行排序",{"2":{"738":2}}],["我们根据它们的标记",{"2":{"728":1}}],["我们根据它们是否使用固定滞后平滑或循环闭合进行分组",{"2":{"634":1}}],["我们根据高斯分布的协方差来计算偏移量",{"2":{"716":1}}],["我们根据经验发现",{"2":{"429":1}}],["我们根据kimera",{"2":{"419":1}}],["我们设计的体素到高斯",{"2":{"899":1}}],["我们设计的蒸馏策略更关注前景体素",{"2":{"694":1}}],["我们设计了gaussianformer模型",{"2":{"861":1}}],["我们设计了一种多阶段蒸馏策略",{"2":{"862":1}}],["我们设计了一种基于交叉注意力的通用调节机制",{"2":{"552":1}}],["我们设计了一种高效的高斯到体素的",{"2":{"516":1}}],["我们设计了一种轻量级融合网络",{"2":{"455":1}}],["我们设计了一个简单而有效的深度感知层",{"2":{"705":1}}],["我们设计了一个简单而高效的多模态三维语义占据预测基线",{"2":{"421":1}}],["我们设计了一个深度感知分支",{"2":{"705":1}}],["我们设计了一个",{"2":{"570":1}}],["我们设计了一个基于分布的初始化模块",{"2":{"536":1}}],["我们设计了一个高效的高斯到体素的溅射模块",{"2":{"486":1,"547":1,"738":1}}],["我们设计了一个体素到高斯初始化模块",{"2":{"444":1}}],["我们设计了一个分数分支来估计预测的超点mask和gt",{"2":{"434":1}}],["我们设置了一个大的vio范围",{"2":{"686":1}}],["我们设置所有权重",{"2":{"670":1}}],["我们设置α",{"2":{"522":1}}],["我们设置k",{"2":{"390":1}}],["我们设置",{"2":{"271":1,"766":1}}],["我们观察到多模态方法",{"2":{"1000":1}}],["我们观察到不同的传感器融合策略不仅影响框架的最终性能",{"2":{"959":1}}],["我们观察到随着高斯分布数量的增加",{"2":{"934":1}}],["我们观察到加入雷达信息会导致性能显著下降",{"2":{"927":1}}],["我们观察到当存在车辆时",{"2":{"924":1}}],["我们观察到高分辨率预测在某些区域实现了更准确和平滑的占据结果",{"2":{"899":1}}],["我们观察到遮挡体素倾向于被预测为遮挡它们的物体的一部分",{"2":{"814":1}}],["我们观察到了总体2",{"2":{"811":1}}],["我们观察到了6",{"2":{"811":1}}],["我们观察到kimera",{"2":{"754":1}}],["我们观察到这些测量值对深度图过滤没有显着改善",{"2":{"622":1}}],["我们观察到clio可以在几分之一秒内运行",{"2":{"462":1}}],["我们观察到任务感知基线khronos",{"2":{"462":1}}],["我们观察到任务感知方法",{"2":{"462":1}}],["我们观察到",{"2":{"421":1,"723":1,"754":1,"812":1,"901":1,"947":1}}],["我们观察到见",{"2":{"334":1}}],["我们初始化一个新的位姿图",{"2":{"419":1}}],["我们实验中为0",{"2":{"419":1}}],["我们实现了最佳的语义",{"2":{"803":1}}],["我们实现了57",{"2":{"522":1}}],["我们实现了比kimera更高的精度和召回率",{"2":{"437":1}}],["我们实现了高度准确的标注",{"2":{"277":1}}],["我们实现中为0",{"2":{"380":1}}],["我们实现中为3个",{"2":{"276":1}}],["我们实现中为8米",{"2":{"253":1}}],["我们假设不同高斯使点被占用的概率是相互独立的",{"2":{"681":1}}],["我们假设给定了机器人的cad模型",{"2":{"419":1}}],["我们假设机器人映射一个单一建筑物",{"2":{"210":1}}],["我们假设机器人能够在环境中感知到任务不可知的原语",{"2":{"109":1}}],["我们修改后的",{"2":{"405":1}}],["我们报告了场景补全",{"2":{"853":1}}],["我们报告了从三维目标检测监督中受益最多的四个类别",{"2":{"800":1}}],["我们报告了六种",{"2":{"782":1}}],["我们报告了所有类别的平均交并比",{"2":{"770":1}}],["我们报告了我们增量算法的伪代码在附录b中",{"2":{"153":1}}],["我们报告准确性作为类别平均召回率",{"2":{"492":1}}],["我们报告两个指标",{"2":{"437":1}}],["我们报告两个标准的f1分数",{"2":{"402":1}}],["我们引入了基于几何特征重建的点云表示学习框架",{"2":{"715":1}}],["我们引入了surfel重建的概念",{"2":{"640":1}}],["我们引入了新的互补损失函数",{"2":{"632":1}}],["我们引入了occ",{"2":{"544":1}}],["我们引入了bevfusion",{"2":{"512":1}}],["我们引入了bev视野范围扩展策略",{"2":{"421":1,"576":1}}],["我们引入了一种新的深度估计模块",{"2":{"438":1}}],["我们引入了一种体素到高斯初始化策略",{"2":{"415":1,"767":1}}],["我们引入了一个概率高斯叠加模型",{"2":{"567":1}}],["我们引入了一个简单而高效的多模态占据预测网络",{"2":{"482":1}}],["我们引入了一个潜在的形状作为过渡内核的条件",{"2":{"314":1}}],["我们引入了一个新的回路闭合机制",{"2":{"131":1}}],["我们引入了两个新指标",{"2":{"402":1}}],["我们引入了鸟瞰图视野范围扩展策略",{"2":{"392":1}}],["我们只执行特征跟踪",{"2":{"816":1}}],["我们只关注基于点的网络",{"2":{"688":1}}],["我们只剩下一个类似于文献中的姿态图优化问题",{"2":{"390":1}}],["我们只需要修剪相应的节点以及较低层",{"2":{"905":1}}],["我们只需要根据从当前图像中提取的语义和结构特征对其进行轻微的优化",{"2":{"728":1}}],["我们只需要更少的3d高斯分布来建模场景",{"2":{"693":1}}],["我们只需要将我们想判断的类别跟",{"2":{"204":1}}],["我们只需将任务陈述为机器人在其生命周期或当前部署期间预期执行的语言指令列表",{"2":{"137":1}}],["我们展示方程",{"2":{"390":1}}],["我们展示了kimera",{"2":{"973":1}}],["我们展示了夜间场景的预测结果",{"2":{"952":1}}],["我们展示了雨天场景的预测结果",{"2":{"952":1}}],["我们展示了白天场景的预测结果",{"2":{"952":1}}],["我们展示了从二维观测构建三维数据的技术",{"2":{"942":1}}],["我们展示了我们给机器人的语义查询示例",{"2":{"939":1}}],["我们展示了nuscenes验证集上各种方法的多视图3d语义占用预测的全面定量比较",{"2":{"842":1}}],["我们展示了机器人如何使用dsg理解和执行高级指令",{"2":{"131":1}}],["我们展示了hydra",{"2":{"112":1}}],["我们展示了3d场景图允许定义层次化的环路闭合检测描述符",{"2":{"112":1}}],["我们展示了如何使用clip嵌入来获得算法",{"2":{"109":1}}],["我们展示了这个问题可以使用信息瓶颈",{"2":{"98":1}}],["我们创建了一个包括简化网格和机器人姿态图的姿态图的统一变形图",{"2":{"390":1}}],["我们向变形图中添加了两种类型的顶点",{"2":{"390":1}}],["我们向矩阵a添加一行和一列",{"2":{"390":1}}],["我们向稀疏图添加识别的边",{"2":{"276":1}}],["我们标记为异常值的回路",{"2":{"390":1}}],["我们反而使后端对异常值具有鲁棒性",{"2":{"390":1}}],["我们回顾了机器人学和计算机视觉中使用的环境表示",{"2":{"954":1}}],["我们回顾了关于3d占用感知的最新研究",{"2":{"610":1}}],["我们回顾并分析了基于特征增强",{"2":{"665":1}}],["我们回顾各个组件",{"2":{"390":1}}],["我们回顾若干关键数据集与评估套件",{"2":{"360":1}}],["我们参考",{"2":{"380":1,"967":1}}],["我们手动注释了与给定任务集相关联的对象的3d边界框",{"2":{"374":1}}],["我们手动挑选了",{"2":{"157":1}}],["我们进行了消融实验以证明我们插件替换中每个组件的有效性",{"2":{"811":1}}],["我们进行了两个任务来评估我们的embodiedocc框架",{"2":{"793":1}}],["我们进行了一些针对性的测试来验证我们模型的能力",{"2":{"750":1}}],["我们进行了一种朴素蒸馏",{"2":{"694":1}}],["我们进行了7次移动操作实验",{"2":{"522":1}}],["我们进行了全面的研究",{"2":{"503":1}}],["我们进行了广泛的消融研究",{"2":{"503":1}}],["我们进行了广泛的实验",{"2":{"421":1}}],["我们进行体积细分步骤",{"2":{"372":1}}],["我们进一步尝试了不同的初始化策略",{"2":{"934":1}}],["我们进一步提取相关的地方图",{"2":{"930":1}}],["我们进一步提出了gaussianformer模型",{"2":{"716":1}}],["我们进一步将",{"2":{"928":1}}],["我们进一步将深度转换为",{"2":{"870":1}}],["我们进一步将esdf截面截断到0",{"2":{"480":1}}],["我们进一步比较了带和不带时间模块的flashocc变体",{"2":{"811":1}}],["我们进一步扩大图像",{"2":{"803":1}}],["我们进一步评估了在uhumans和uhumans2数据集中变形网格对度量",{"2":{"754":1}}],["我们进一步评估了我们的方法在三个真实数据集上的性能",{"2":{"605":1}}],["我们进一步沿三个轴对柱坐标体积",{"2":{"676":1}}],["我们进一步总结了基于鸟瞰图",{"2":{"665":1}}],["我们进一步把稠密几何语义地图划分为两大类",{"2":{"556":1}}],["我们进一步研究了针对3d占据预测任务的新设计和优化",{"2":{"490":1}}],["我们进一步根据它们所属的房间对墙壁进行分割",{"2":{"480":1}}],["我们进一步包括了基线的的任务感知版本",{"2":{"431":1}}],["我们进一步添加一个空任务",{"2":{"153":1}}],["我们进一步探讨了不同方法的优缺点",{"2":{"80":1}}],["我们节省了更新",{"2":{"362":1}}],["我们尝试了在离线3d",{"2":{"934":1}}],["我们尝试将训练计划延长至",{"2":{"803":1}}],["我们尝试使用",{"2":{"352":1}}],["我们尝试注册框架i和j",{"2":{"352":1}}],["我们尝试通过执行自下而上的几何验证来计算两个之间的相对姿态",{"2":{"352":1}}],["我们执行特征检测",{"2":{"816":1}}],["我们执行全平滑",{"2":{"686":1}}],["我们执行几何验证",{"2":{"352":1}}],["我们执行单目",{"2":{"310":1}}],["我们继续比较对象描述符",{"2":{"352":1}}],["我们比较了不同方法的运行时间",{"2":{"859":1}}],["我们比较了模型的复杂性",{"2":{"779":1}}],["我们比较了两种不同粒度的任务",{"2":{"522":1}}],["我们比较地点描述符",{"2":{"352":1}}],["我们比较当前",{"2":{"352":1}}],["我们构建了一个描述节点周围环境的统计信息的层次化描述符",{"2":{"352":1}}],["我们构建一个图",{"2":{"271":1}}],["我们现在深入研究",{"2":{"928":1}}],["我们现在介绍新的损失函数",{"2":{"773":1}}],["我们现在只需要额外训练一个新的基于噪声输入的分类器就可以了",{"2":{"338":1}}],["我们现在可以构建包含大量对象和无数语义变体的地图",{"2":{"98":1}}],["我们循环遍历其顶点和三元组",{"2":{"336":1}}],["我们采取两项措施来解决这个问题",{"2":{"325":1}}],["我们采用蒙特卡洛方法",{"2":{"916":1}}],["我们采用的深度感知分支比直接从预测深度图恢复的伪点云中初始化部分高斯分布的简单方法更为合理",{"2":{"833":1}}],["我们采用分而治之的策略",{"2":{"812":1}}],["我们采用adamw优化器",{"2":{"758":1}}],["我们采用",{"2":{"707":1,"749":1,"789":1}}],["我们采用swin",{"2":{"699":1}}],["我们采用由均值",{"2":{"681":1}}],["我们采用原始不透明度属性",{"2":{"681":1}}],["我们采用第3",{"2":{"680":1}}],["我们采用空间分组池化而不是最大池化",{"2":{"676":1}}],["我们采用简单的基于",{"2":{"670":1}}],["我们采用一个可分离的辅助检测头来进一步监督特征融合过程",{"2":{"666":1}}],["我们采用一种直接的融合策略",{"2":{"421":1}}],["我们采用坐标变换和插值",{"2":{"638":1}}],["我们采用特征金字塔网络",{"2":{"609":1}}],["我们采用概率的乘法定理来聚合独立的概率分布",{"2":{"567":1}}],["我们采用精确的高斯混合模型进行语义计算",{"2":{"536":1}}],["我们采用三种传感器融合策略",{"2":{"503":1}}],["我们采用了",{"2":{"982":1}}],["我们采用了交并比",{"2":{"848":1}}],["我们采用了一种简单而有效的投影和采样方法",{"2":{"609":1}}],["我们采用了一种类似于harley等人的简单方法",{"2":{"421":1}}],["我们采用了最简单直接的方法",{"2":{"421":1}}],["我们采用了oleynikova等人",{"2":{"362":1}}],["我们采用kimera",{"2":{"285":1}}],["我们采用穷举法对静态物体的补偿范围率进行最小化处理",{"2":{"191":1}}],["我们介绍我们开发的两个特定应用",{"2":{"919":1}}],["我们介绍我们的概率高斯建模以及我们如何根据概率的乘法定理和高斯混合模型推导出几何和语义预测",{"2":{"628":1}}],["我们介绍了3d动态场景图",{"2":{"973":1}}],["我们介绍了一种即插即用的方法flashocc",{"2":{"831":1}}],["我们介绍了一些常用于3d占用预测的开源大规模数据集",{"2":{"757":1}}],["我们介绍了用于高效",{"2":{"628":1}}],["我们介绍用于3d语义占用预测的3d高斯溅射方法",{"2":{"669":1}}],["我们介绍什么是语义地图",{"2":{"324":1}}],["我们介绍如何构建第1",{"2":{"210":1}}],["我们默认使用2点",{"2":{"310":1}}],["我们用deque作为单调队列的底层数据结构",{"2":{"938":1}}],["我们用0",{"2":{"813":1}}],["我们用从",{"2":{"704":1}}],["我们用线性投影预测每个点的光度值",{"2":{"640":1}}],["我们用均匀的三维语义高斯分布初始化待探索的场景",{"2":{"568":1}}],["我们用均匀的三维语义高斯分布初始化全局场景",{"2":{"568":1,"600":1}}],["我们用它来训练类条件",{"2":{"552":1}}],["我们用32个可能的语义标签之一注释它",{"2":{"534":1}}],["我们用于基准测试",{"2":{"437":1}}],["我们用基于对象的描述符和基于地点的描述符来增强外观描述符",{"2":{"352":1}}],["我们用imu估计的旋转光流向lukas",{"2":{"310":1}}],["我们用符号",{"2":{"137":1}}],["我们通常自动标注整个连续场景",{"2":{"455":1}}],["我们通常使用后者以限制估计时间",{"2":{"310":1}}],["我们通过生成可视化结果并将其与最新",{"2":{"952":1}}],["我们通过插值和卷积将",{"2":{"928":1}}],["我们通过提供它启用的查询示例来突出3d动态场景图的可操作性",{"2":{"905":1}}],["我们通过与最新算法",{"2":{"827":1}}],["我们通过与其他sota算法在3d语义占据预测任务中的比较",{"2":{"438":1}}],["我们通过注册估计的网格与地面真实网格来评估度量重建",{"2":{"732":1}}],["我们通过注意力机制从图像中聚合信息",{"2":{"516":1}}],["我们通过进行三种不同的实验来评估每个组件的影响",{"2":{"732":1}}],["我们通过相机的内参",{"2":{"705":1}}],["我们通过相机1拍照",{"2":{"355":1}}],["我们通过笛卡尔到极坐标转换以及双线性插值",{"2":{"699":1}}],["我们通过以103点",{"2":{"686":1}}],["我们通过以下方式形成变形图",{"2":{"380":1}}],["我们通过三个resnet18",{"2":{"609":1}}],["我们通过三线插值为一个网格顶点v∈r3v∈",{"2":{"318":1}}],["我们通过",{"2":{"595":1,"632":1}}],["我们通过代理封闭集任务评估clio的区域性能",{"2":{"522":1}}],["我们通过融合三种模态特征体积来进行3d语义占据预测",{"2":{"503":1}}],["我们通过融合三种模态的特征体积来进行",{"2":{"503":1}}],["我们通过n",{"2":{"480":1}}],["我们通过手动调整的姿态图优化和额外的高度先验获得了两个sidpac数据集的地面真实轨迹的代理",{"2":{"437":1}}],["我们通过在位姿图上运行优化来缓解节点误差",{"2":{"419":1}}],["我们通过在gvd体素上插入一个新节点来分割假定边",{"2":{"276":1}}],["我们通过实验结果确定",{"2":{"419":1}}],["我们通过为每个遇到的人类维护一个姿态图并使用简单但鲁棒的数据关联更新姿态图来实现这些结果",{"2":{"419":1}}],["我们通过仅在标记为人类的像素上使用自由空间信息进行深度投影来实现这一点",{"2":{"419":1}}],["我们通过将预测的深度图",{"2":{"978":1}}],["我们通过将3d高斯分布视为以高斯均值为中心的椭球体",{"2":{"842":1}}],["我们通过将网格的顶点存储在八叉树数据结构中来简化网格",{"2":{"390":1}}],["我们通过将校准目标的平面进行对齐",{"2":{"191":1}}],["我们通过增量构建矩阵a来实现在线操作",{"2":{"390":1}}],["我们通过增加距离δ",{"2":{"301":1}}],["我们通过找到一致回路闭合的最大集合来选择内点",{"2":{"390":1}}],["我们通过使用场景图中的多个层来增强视觉环路闭合检测和几何验证",{"2":{"352":1}}],["我们通过归一化流",{"2":{"314":1}}],["我们通过部分种子聚类技术对这些未标记的节点进行分配",{"2":{"301":1}}],["我们通过丢弃距离小于δ的节点",{"2":{"301":1}}],["我们通过修改",{"2":{"276":1}}],["我们通过向先前的对象节点添加新的网格顶点将它们合并在一起",{"2":{"253":1}}],["我们通过对3d度量语义网格顶点进行欧几里得聚类来分割对象",{"2":{"253":1}}],["我们通过双线性插值调整",{"2":{"143":1}}],["我们通过广泛的文献综述",{"2":{"131":1}}],["我们看到其他一些激光雷达分割数据集也相继出现",{"2":{"302":1}}],["我们计划探索我们的多模态",{"2":{"767":1}}],["我们计划围绕这些任务组织各种公开挑战",{"2":{"302":1}}],["我们计算lfpl",{"2":{"814":1}}],["我们计算pkp",{"2":{"814":1}}],["我们计算这些",{"2":{"809":1}}],["我们计算同一体素网格内这些",{"2":{"789":1}}],["我们计算了平均交并比",{"2":{"732":1}}],["我们计算期望",{"2":{"681":1}}],["我们计算重建的颜色和原始颜色之间的均方误差",{"2":{"640":1}}],["我们计算到关键视图的点的对应映射",{"2":{"579":1}}],["我们计算一个质心",{"2":{"480":1}}],["我们计算整个网格相对于相机的位置和方向",{"2":{"419":1}}],["我们计算gp",{"2":{"301":1}}],["我们计算其与所有任务嵌入的余弦相似性分数",{"2":{"153":1}}],["我们称之为2d",{"2":{"480":1}}],["我们称之为网格控制点",{"2":{"380":1}}],["我们称这个在天花板下方0",{"2":{"480":1}}],["我们称这种方法为",{"2":{"421":1}}],["我们称这些姿态为代理节点",{"2":{"352":1}}],["我们称这些体素为",{"2":{"253":1}}],["我们称修剪后的子图为gp",{"2":{"301":1}}],["我们也讨论了如何通过将语义信息与点云",{"2":{"958":1}}],["我们也可以指定vector为栈的底层实现",{"2":{"685":1}}],["我们也可以用更通俗的方式来理解",{"2":{"184":1}}],["我们也请读者参考第二个视频附件",{"2":{"480":1}}],["我们也在两个房间",{"2":{"480":1}}],["我们也传播语义标签",{"2":{"362":1}}],["我们也同样调控了生成与原图之间的相似程度",{"2":{"287":1}}],["我们以车辆中心为原点",{"2":{"944":1}}],["我们以这种方式划分这些场景",{"2":{"886":1}}],["我们以与对象相同的方式计算任务和地点节点之间的p",{"2":{"295":1}}],["我们以",{"2":{"277":1}}],["我们以城市或机场为单位进行推理",{"2":{"116":1}}],["我们交替进行两个阶段",{"2":{"276":1}}],["我们遍历每个新的gvd体素成员",{"2":{"276":1}}],["我们按照",{"2":{"276":1,"886":1}}],["我们则实现了一种增量提取地点子图的方法",{"2":{"276":1}}],["我们独立地对每个语义类别的顶点进行聚类",{"2":{"253":1}}],["我们利用",{"2":{"866":1}}],["我们利用surroundocc",{"2":{"781":1}}],["我们利用3d稀疏卷积来实现3d高斯分布之间的交互",{"2":{"716":1}}],["我们利用3d网格顶点法线的方向性",{"2":{"480":1}}],["我们利用多尺度监督对四尺度3d特征体积进行模型训练",{"2":{"699":1}}],["我们利用两个卷积层从bev视角生成一个关键点热图",{"2":{"666":1}}],["我们利用两个关键见解",{"2":{"137":1}}],["我们利用比赛允许使用额外公开数据的优势",{"2":{"617":1}}],["我们利用关节和躯干运动不能任意快速的事实",{"2":{"419":1}}],["我们利用目标检测器的输出结果",{"2":{"233":1}}],["我们力求实现高召回率",{"2":{"233":1}}],["我们力求涵盖多样的地点",{"2":{"157":1}}],["我们递增地计算场景的广义voronoi图generalized",{"2":{"228":1}}],["我们遵循相同的类别选择策略",{"2":{"828":1}}],["我们遵循",{"2":{"803":1,"834":1}}],["我们遵循lift",{"2":{"585":1}}],["我们遵循hydra",{"2":{"228":1}}],["我们遵循khronos",{"2":{"206":1}}],["我们就认为它们具有更准确的物理属性并且已经被",{"2":{"728":1}}],["我们就得到了上图里语义一致的输出结果",{"2":{"312":1}}],["我们就可以影响后向过程的生成结果",{"2":{"264":1,"266":1}}],["我们就可以计算出摄像头到车辆自身坐标系的变换以及相应的外参",{"2":{"191":1}}],["我们就能生成图片",{"2":{"224":1}}],["我们知道内积越大",{"2":{"184":1}}],["我们专注于以通用和即插即用的方式增强现有模型",{"2":{"535":1}}],["我们专注于室内环境",{"2":{"210":1}}],["我们专注于两类",{"2":{"178":1}}],["我们专注于具身人工智能",{"2":{"90":1}}],["我们使用所提出的框架在",{"2":{"927":1}}],["我们使用视频演示来展示",{"2":{"902":1}}],["我们使用更多样化的单目样本",{"2":{"902":1}}],["我们使用稀疏的3d高斯分布来描述驾驶场景",{"2":{"861":1}}],["我们使用官方的",{"2":{"853":1}}],["我们使用尺寸为",{"2":{"853":1}}],["我们使用nvpmodel使用maxn性能模式",{"2":{"836":1}}],["我们使用文献",{"2":{"827":1}}],["我们使用全部标注数据对视觉模型进行了",{"2":{"823":1}}],["我们使用adamw",{"2":{"822":1}}],["我们使用adamw优化器",{"2":{"813":1}}],["我们使用特征金字塔网络",{"2":{"822":1}}],["我们使用resnet101",{"2":{"822":1}}],["我们使用预训练的",{"2":{"870":1,"978":1}}],["我们使用预训练的resnet50",{"2":{"822":1}}],["我们使用预训练的efficientnet",{"2":{"813":1}}],["我们使用预积分imu模型和无结构视觉模型",{"2":{"310":1}}],["我们使用当前场景的全局空间占用来计算miou和iou",{"2":{"793":1}}],["我们使用当前的单目输入实时更新我们的高斯记忆",{"2":{"750":1}}],["我们使用盒子内的空间占用",{"2":{"793":1}}],["我们使用miou和iou作为评估指标",{"2":{"793":1}}],["我们使用mask",{"2":{"362":1}}],["我们使用左相机的rgb图像作为模型的输入",{"2":{"781":1}}],["我们使用sscbench",{"2":{"781":1}}],["我们使用spot的前置左和前置右rgb",{"2":{"522":1}}],["我们使用与",{"2":{"771":1}}],["我们使用指数移动平均",{"2":{"761":1}}],["我们使用单目视锥体内的空间占用",{"2":{"750":1}}],["我们使用单目5点ransac",{"2":{"390":1}}],["我们使用自车左相机的图像作为模型的输入",{"2":{"749":1}}],["我们使用交叉熵损失",{"2":{"738":1}}],["我们使用交并比",{"2":{"677":1,"807":1,"915":1}}],["我们使用平均交并比",{"2":{"736":1,"802":1}}],["我们使用包括密集立体视觉在内的完整kimera",{"2":{"732":1}}],["我们使用具有地面真实",{"2":{"732":1}}],["我们使用残差连接来细化高斯分布的均值",{"2":{"716":1}}],["我们使用细化模块",{"2":{"716":1}}],["我们使用加权和更新高斯查询",{"2":{"716":1}}],["我们使用高质量的深度相机",{"2":{"889":1}}],["我们使用高效的高斯到体素的溅射模块",{"2":{"716":1}}],["我们使用高斯到体素的溅射技术从更新后的三维高斯分布中获得全局三维空间占用",{"2":{"568":1}}],["我们使用深度感知分支为每个高斯分布的更新提供局部结构信息",{"2":{"705":1}}],["我们使用gaussianformer中提出的高斯到体素溅射技术来获得视锥体内的最终空间占用",{"2":{"705":1}}],["我们使用整合后的特征三次优化高斯分布",{"2":{"705":1}}],["我们使用iou和miou报告语义分割性能",{"2":{"736":1}}],["我们使用icp",{"2":{"686":1}}],["我们使用intel提供的脚本校准了每个realsense设备的imu",{"2":{"605":1}}],["我们使用这些高斯仅对占据空间进行建模",{"2":{"677":1}}],["我们使用在nuimages",{"2":{"758":1}}],["我们使用在",{"2":{"677":1}}],["我们使用在线难例挖掘",{"2":{"670":1}}],["我们使用在coco数据集",{"2":{"605":1}}],["我们使用先前工作中的损失函数",{"2":{"670":1}}],["我们使用轻量级",{"2":{"670":1}}],["我们使用图像编码器",{"2":{"670":1}}],["我们使用均值特征编码作为体素特征编码",{"2":{"670":1}}],["我们使用cuda编程语言实现",{"2":{"738":1}}],["我们使用centerpoint",{"2":{"666":1}}],["我们使用clip模型vit",{"2":{"431":1}}],["我们使用clip",{"2":{"153":1}}],["我们使用地面真实的2d语义分割",{"2":{"605":1}}],["我们使用我们引入的uhumans模拟数据集",{"2":{"605":1}}],["我们使用受m2bev",{"2":{"585":1}}],["我们使用前向投影生成初始3d体素表示",{"2":{"585":1}}],["我们使用euroc",{"2":{"686":1}}],["我们使用euroc来分析kimera",{"2":{"572":1}}],["我们使用euroc数据集再次描述了kimera",{"2":{"836":1}}],["我们使用euroc数据集",{"2":{"572":1}}],["我们使用装有手臂和夹持器的波士顿动力spot四足机器人进行了移动操作实验",{"2":{"522":1}}],["我们使用术语",{"2":{"500":1}}],["我们使用了",{"2":{"978":4}}],["我们使用了occ",{"2":{"793":1}}],["我们使用了azure",{"2":{"605":1}}],["我们使用了一个自制的传感装置",{"2":{"605":1}}],["我们使用了一个装有amd",{"2":{"437":1}}],["我们使用了gtsam",{"2":{"380":1}}],["我们使用提供的深度和分割",{"2":{"437":1}}],["我们使用hrnet",{"2":{"437":1}}],["我们使用两个数据集进行实验",{"2":{"437":1}}],["我们使用两个独立的",{"2":{"434":1}}],["我们使用两辆雷诺",{"2":{"173":1}}],["我们使用仅",{"2":{"425":1}}],["我们使用位姿图的大小作为节点误差的代理",{"2":{"419":1}}],["我们使用保守的3mon最大允许的关节位移来限制不规则的关节运动",{"2":{"419":1}}],["我们使用保守的3m",{"2":{"419":1}}],["我们使用简化的数据关联模型",{"2":{"419":1}}],["我们使用kalibr扩展的imu到imu外参校准",{"2":{"605":1}}],["我们使用kinect的深度重建",{"2":{"437":1}}],["我们使用kinect",{"2":{"437":1}}],["我们使用kimera",{"2":{"285":2,"732":1}}],["我们使用kolotouros等人",{"2":{"419":1,"967":1}}],["我们使用fps初始采样n个中心点c",{"2":{"396":1}}],["我们使用一定的间隔重新采样该场景在",{"2":{"886":1}}],["我们使用一组三维语义高斯分布来表示室内场景",{"2":{"705":1}}],["我们使用一组",{"2":{"693":1}}],["我们使用一组3d语义高斯分布来表示自动驾驶场景",{"2":{"693":1}}],["我们使用一组3d语义高斯分布来稀疏地描述3d场景",{"2":{"547":1}}],["我们使用一个坐标系转换掩码从高斯记忆中获取当前视锥体内的所有高斯分布",{"2":{"728":1}}],["我们使用一个自编码模块和一个图像交叉注意力模块",{"2":{"705":1}}],["我们使用一个卷积块融合不同尺度的特征",{"2":{"609":1}}],["我们使用一个带有已知图案的校准目标板",{"2":{"191":1}}],["我们使用一系列随机数据增强",{"2":{"579":1}}],["我们使用一种现代的异常值拒绝方法",{"2":{"390":1}}],["我们使用第iii节中描述的方法",{"2":{"380":1}}],["我们使用贝叶斯更新来估计每个体素的后验标签概率",{"2":{"362":1}}],["我们使用密集立体视觉",{"2":{"362":1}}],["我们使用标准的基于ransac的几何验证",{"2":{"352":1}}],["我们使用voxblox",{"2":{"362":1}}],["我们使用voxblox的marching",{"2":{"253":1}}],["我们使用vio后端的3d点估计进行反投影",{"2":{"336":1}}],["我们使用",{"2":{"301":1,"390":1,"444":1,"480":1,"522":1,"677":1,"686":1,"704":1,"732":1,"749":1,"761":1,"770":1,"771":1,"853":3,"867":1,"886":1,"916":1,"928":1}}],["我们使用它来忽略在训练过程中出现的大量共享自行车",{"2":{"277":1}}],["我们使用父体素将每个地点与3d网格中最近的顶点关联起来",{"2":{"253":1}}],["我们使用最先进的目标检测技术来检测车牌和人脸",{"2":{"233":1}}],["我们使用激光线标尺精确测量激光雷达相对于车辆自身坐标系的相对位置",{"2":{"191":1}}],["我们增加了稀有类别",{"2":{"157":1}}],["我们对gaussianformer的组件进行了全面分析",{"2":{"842":1}}],["我们对局部空间占用预测模块的定性可视化结果",{"2":{"833":1}}],["我们对使用",{"2":{"823":1}}],["我们对模型在具有挑战性的雨天和夜间场景下的性能进行了深入分析",{"2":{"787":1}}],["我们对输入图像进行了随机翻转和光度畸变增强",{"2":{"771":1}}],["我们对该领域的信息融合技术进行了深入分析",{"2":{"714":1}}],["我们对所有独立结果进行加权求和",{"2":{"697":1}}],["我们对",{"2":{"694":2}}],["我们对ff2进行双线性上采样",{"2":{"609":1}}],["我们对来自两个相应摄像头的图像特征进行平均",{"2":{"609":1}}],["我们对数据集与基准的回顾强调了丰富",{"2":{"538":1}}],["我们对实时方法的准确性和运行时间进行了广泛的评估",{"2":{"437":1}}],["我们对点云进行体素化",{"2":{"412":1}}],["我们对其表面的点进行采样",{"2":{"318":1}}],["我们对具有与空任务最高相似性的原语执行预修剪步骤",{"2":{"153":1}}],["我们对机器人学和具身人工智能中探索的具身任务进行了简要概述",{"2":{"100":1}}],["我们希望这篇综述能够为社区带来益处",{"2":{"1007":1}}],["我们希望这篇综述中提供的见解能够为研究界进一步推动该领域的进步提供指导和启发",{"2":{"958":1}}],["我们希望这个数据集能够让世界各地的研究人员在开发安全自动驾驶技术的道路上走得更远",{"2":{"302":1}}],["我们希望这个数据集能够让世界各地的研究人员开发出更安全的自动驾驶技术",{"2":{"126":1}}],["我们希望明确地让网络了解全局",{"2":{"794":1}}],["我们希望我们的embodiedocc能够在持续探索过程中不断改进预测结果",{"2":{"750":1}}],["我们希望本文能够激发社区的兴趣",{"2":{"610":1}}],["我们希望用最少的场景训练",{"2":{"455":1}}],["我们希望找到一个压缩表示",{"2":{"153":1}}],["我们可能想要在设置餐桌时区分叉子和刀子",{"2":{"553":1}}],["我们可能想要合并附近的片段",{"2":{"153":1}}],["我们可以改为以层次方式计算路径",{"2":{"930":1}}],["我们可以观察到0",{"2":{"876":1}}],["我们可以观察到",{"2":{"833":1}}],["我们可以实现1",{"2":{"800":1}}],["我们可以实时重建大型真实环境的3d场景图",{"2":{"141":1}}],["我们可以发现体素大小对模型性能有很大的影响",{"2":{"800":1}}],["我们可以轻松获得当前场景中已探索部分的空间占用真值",{"2":{"793":1}}],["我们可以轻松地将环境分割成大量无障碍的地方",{"2":{"137":1}}],["我们可以使用仅邻近的高斯分布来高效近似公式",{"2":{"738":1}}],["我们可以直接用新的视角进行更新",{"2":{"728":1}}],["我们可以从深度图恢复的伪点云中随机采样一些点",{"2":{"705":1}}],["我们可以看到rulebook中第一列为上一步记录的卷积核权重位置",{"2":{"561":1}}],["我们可以看到现有误差大大减少",{"2":{"419":1}}],["我们可以专注于特征图中感兴趣的区域",{"2":{"464":1}}],["我们可以每一步都计算现在的图像表征和文本表征的距离",{"2":{"422":1}}],["我们可以将分类器重新写成方程",{"2":{"422":1}}],["我们可以将其重新投影到3d",{"2":{"137":1}}],["我们可以进一步应用可学习的表面细分",{"2":{"400":1}}],["我们可以用贝叶斯定理将基于条件生成的梯度拆解成一个基于显式分类器的梯度和一个常规的无条件生成的梯度",{"2":{"338":1}}],["我们可以通过计算周围高斯分布的贡献总和来获得特定点的空间占用预测结果",{"2":{"705":1}}],["我们可以通过高斯到体素的溅射模块获得当前的三维空间占用预测",{"2":{"568":1}}],["我们可以通过用",{"2":{"279":1}}],["我们可以通过控制降维再升维的倍数来控制信息的留存比例",{"2":{"264":1}}],["我们可以在顶部添加进一步的抽象或层",{"2":{"262":1}}],["我们可以在",{"2":{"262":1}}],["我们可以很容易地推断",{"2":{"116":1}}],["我们将从三个方面比较感知准确性",{"2":{"1000":1}}],["我们将从三个方面比较和分析各种3d占用感知方法的性能准确性和推理速度",{"2":{"999":1}}],["我们将occnerf的miou",{"2":{"1000":1}}],["我们将使用最流行的数据集对最先进的3d占用感知方法进行详细的性能比较和讨论",{"2":{"991":1}}],["我们将提供3d占用感知的性能评估",{"2":{"991":1}}],["我们将提出的空间感知系统实现到一个高度并行化的架构中",{"2":{"112":1}}],["我们将可变形注意力函数重新定义为",{"2":{"957":1}}],["我们将办公室场景的3d",{"2":{"947":1}}],["我们将uhumans数据集中的",{"2":{"947":1}}],["我们将占用感知方法分为三类",{"2":{"877":1}}],["我们将占用预测分解为几何预测和语义预测",{"2":{"681":1}}],["我们将分析限于kimera",{"2":{"836":1}}],["我们将探索将flashocc集成到自动驾驶的感知流程中",{"2":{"831":1}}],["我们将nuscenes的高斯分布数量设置为144000",{"2":{"822":1}}],["我们将nuscenes",{"2":{"822":1}}],["我们将输入图像划分为ℓ×ℓ",{"2":{"814":1}}],["我们将这种性能差距归因于surroundocc数据集是自动生成的",{"2":{"893":1}}],["我们将这两个组件分类为待检查的独立模块",{"2":{"811":1}}],["我们将这些模型中的3d卷积替换为2d卷积",{"2":{"811":1}}],["我们将这些更新后的高斯分布放回记忆中",{"2":{"568":1}}],["我们将这些图标记为错误",{"2":{"419":1}}],["我们将lss沿z轴的网格大小减小为1",{"2":{"811":1}}],["我们将非空体素网格输入到",{"2":{"809":1}}],["我们将围绕这三个分支对当前方法进行全面概述",{"2":{"799":1}}],["我们将详细描述这些损失函数",{"2":{"985":1}}],["我们将详细讨论这两类评估指标",{"2":{"786":1}}],["我们将详细阐述我们如何维护和更新最终具身空间占用预测框架中使用的高斯记忆",{"2":{"728":1}}],["我们将详细阐述这些子模块的职能及常见设计选择",{"2":{"274":1}}],["我们将第",{"2":{"780":1}}],["我们将我们提出的daocc与occ3d",{"2":{"779":1}}],["我们将我们的方法与其他",{"2":{"503":1}}],["我们将我们的方法与使用dbow2进行地点识别和orb特征匹配的基于视觉的环路闭合检测进行了比较",{"2":{"437":1}}],["我们将我们的模型应用于点云生成",{"2":{"314":1}}],["我们将来自10个相邻时间戳的激光雷达扫描聚合为输入",{"2":{"758":1}}],["我们将它们的置信度值设置为0",{"2":{"728":2}}],["我们将它们的置信度值设置为0到1之间的某个值",{"2":{"728":1}}],["我们将它们视为位于高斯均值处的点云",{"2":{"547":1}}],["我们将中间均值",{"2":{"716":1}}],["我们将3d参考点投影到图像特征图上",{"2":{"716":1}}],["我们将3d体素表示压缩为bev表示",{"2":{"585":1}}],["我们将在本小节中首先解释我们的局部空间占用预测模块",{"2":{"705":1}}],["我们将在第",{"2":{"378":1,"435":1}}],["我们将教师模型预测的前景",{"2":{"694":1}}],["我们将具身空间占用预测模型的功能表述如下",{"2":{"682":1}}],["我们将高斯基元",{"2":{"681":1}}],["我们将高斯混合模型整合到我们的概率高斯表示中",{"2":{"567":1}}],["我们将柱坐标体积",{"2":{"676":1}}],["我们将利用这一重要属性来完成室内场景的具身空间占用预测",{"2":{"629":1}}],["我们将深度估计的质量定义为地面真实深度在估计附近的一个小范围内的概率",{"2":{"622":1}}],["我们将得到的算法集成到了一个实时系统中",{"2":{"586":1}}],["我们将更新后的查询解码为3d语义高斯分布的属性",{"2":{"547":1}}],["我们将spot移动到规划阶段的起始位置",{"2":{"522":1}}],["我们将sreals",{"2":{"429":1}}],["我们将其称为",{"2":{"870":1}}],["我们将其置信度值设置为介于0和1之间的某个值",{"2":{"728":1}}],["我们将其与替代策略clio",{"2":{"522":1}}],["我们将其定制为单机器人和在线设置",{"2":{"390":1}}],["我们将flashocc应用于具有挑战性的occ3d",{"2":{"505":1}}],["我们将三维目标检测作为辅助监督",{"2":{"576":2,"800":1}}],["我们将三维目标检测作为辅助监督添加到融合特征上",{"2":{"482":1}}],["我们将三个不同的功能块分组概念化为",{"2":{"408":1}}],["我们将所有落在2d",{"2":{"480":1}}],["我们将此操作称为动态特征获取",{"2":{"464":1}}],["我们将cad模型上的每个关键点与网格模型上的任何关键点匹配",{"2":{"449":1}}],["我们将一组预定义的三维点投影到二维图像特征平面上",{"2":{"421":1}}],["我们将人类边界框接近图像边界或太小",{"2":{"419":1}}],["我们将新节点添加到具有最近最终节点的位姿图中",{"2":{"419":1}}],["我们将左侧相机图像裁剪到每个检测到的人类周围的边界框",{"2":{"419":1}}],["我们将空间感知系统实现为一个高度并行化的架构",{"2":{"408":1}}],["我们将每个高斯解释为其邻域被占用的概率分布",{"2":{"851":1}}],["我们将每个高斯分布的索引和邻域内每个体素的索引作为元组",{"2":{"738":1}}],["我们将每个高斯分布视为位于其均值",{"2":{"716":1}}],["我们将每个模块替换为轻量级版本而不损失精度",{"2":{"670":1}}],["我们将每个笛卡尔深度bin坐标转换为柱坐标",{"2":{"649":1}}],["我们将每个对象和代理姿态与最近的地点关联",{"2":{"480":1}}],["我们将每个",{"2":{"405":1}}],["我们将机器人的姿态图节点添加到变形图中作为姿态顶点",{"2":{"390":1}}],["我们将未细分的四面体从完整的四面体网格中删除",{"2":{"372":1}}],["我们将未被掩码的区域从前向的记录里抽取出来",{"2":{"312":1}}],["我们将标签附加到由密集立体视觉产生的每个3d点",{"2":{"362":1}}],["我们将四个",{"2":{"325":1}}],["我们将训练目标制定为最大化以潜在形状为条件的点云似然的变分下界",{"2":{"314":1}}],["我们将初始社区设置为gp",{"2":{"301":1}}],["我们将以上述具身式",{"2":{"209":1}}],["我们将雷达水平安装",{"2":{"191":1}}],["我们将外参坐标相对于车辆自身坐标系",{"2":{"191":1}}],["我们将不在前k个最相似任务中的所有任务相似性设置为0",{"2":{"153":1}}],["我们将",{"2":{"153":1,"660":2,"677":1,"681":1}}],["我们将定义任务相关聚类",{"2":{"137":1}}],["我们将任务感知3d场景理解表述为将任务不可知原语",{"2":{"137":1}}],["我们将任务不可知的3d片段和地方称为任务不可知原语",{"2":{"137":1}}],["我们提取一个平滑的无碰撞路径",{"2":{"930":1}}],["我们提取它们的房间层",{"2":{"930":1}}],["我们提取并优化3d场景图的子图",{"2":{"380":1}}],["我们提供了现有占用方法的详细性能比较",{"2":{"1007":1}}],["我们提供了我们的方法与surroundocc",{"2":{"924":1}}],["我们提供了每种方法的fps",{"2":{"811":1}}],["我们提供了几种融合模型的变体",{"2":{"803":1}}],["我们提供了3d占用感知的评估",{"2":{"714":1}}],["我们提供了3d占用感知的分类",{"2":{"714":1}}],["我们提供了jupyter",{"2":{"510":1}}],["我们提供了以下类别的标注",{"2":{"277":2}}],["我们提供了更全面的评估",{"2":{"131":1}}],["我们提供两个版本的clio",{"2":{"271":1}}],["我们提出激光雷达引导的3d可变形注意力机制",{"2":{"595":1}}],["我们提出基于激光雷达的体素到高斯初始化策略",{"2":{"563":1}}],["我们提出的方法利用深度估计模块以及激光雷达的3d点云监督",{"2":{"898":1}}],["我们提出的daocc在保持最快运行速度的同时",{"2":{"859":1}}],["我们提出的daocc的参数数量仅约为其一半",{"2":{"779":1}}],["我们提出的daocc的概述",{"2":{"576":1}}],["我们提出的以物体为中心的3d高斯表示可以适应灵活的兴趣区域",{"2":{"693":1}}],["我们提出的3d高斯表示使用稀疏且自适应的特征集来描述3d场景",{"2":{"547":1}}],["我们提出的fb",{"2":{"490":1}}],["我们提出从融合教师模型向仅视觉学生模型蒸馏占据知识",{"2":{"455":1}}],["我们提出了视锥比例损失",{"2":{"814":1}}],["我们提出了用于室内具身空间占用预测的embodiedocc模型的训练框架",{"2":{"750":1}}],["我们提出了更轻量的超体素",{"2":{"707":1}}],["我们提出了概率高斯叠加作为一种高效且有效的",{"2":{"681":1}}],["我们提出了概率高斯表示",{"2":{"567":1}}],["我们提出了新的",{"2":{"570":1}}],["我们提出了通道到高度变换作为占据预测的高效方法",{"2":{"566":1}}],["我们提出了gaussianformer模型",{"2":{"547":1}}],["我们提出了首个以物体为中心的3d语义占用预测表示方法",{"2":{"547":1}}],["我们提出了名为occfusion的框架",{"2":{"503":1}}],["我们提出了",{"2":{"444":1,"455":1,"570":1,"767":1,"800":1}}],["我们提出了tpv",{"2":{"438":1,"898":1}}],["我们提出了occcylindrical",{"2":{"438":2}}],["我们提出了daocc",{"2":{"392":1,"421":2}}],["我们提出了一个新颖的多模态占据预测框架daocc",{"2":{"820":1}}],["我们提出了一个新颖的基于多模态高斯的语义占据预测框架",{"2":{"444":1}}],["我们提出了一个基于分布的初始化模块",{"2":{"704":1}}],["我们提出了一个基于激光雷达",{"2":{"444":1}}],["我们提出了一个",{"2":{"603":1,"684":1}}],["我们提出了一个具身三维空间占用预测任务",{"2":{"600":1,"852":1}}],["我们提出了一个任务驱动的3d度量",{"2":{"586":1}}],["我们提出了一个概率高斯叠加模型",{"2":{"536":1,"851":1}}],["我们提出了一个gaussianformer模型",{"2":{"486":1}}],["我们提出了一个利用3d可变形注意力的多模态基于高斯的语义占据预测框架",{"2":{"415":1}}],["我们提出了一个增量版本的算法",{"2":{"153":1}}],["我们提出了一个高度并行化的实现",{"2":{"141":1}}],["我们提出了一种高效的高斯到体素的溅射方法",{"2":{"861":1}}],["我们提出了一种高效的以物体为中心的3d高斯表示方法",{"2":{"861":1}}],["我们提出了一种3d语义高斯表示方法",{"2":{"760":1}}],["我们提出了一种名为iso的新方法",{"2":{"544":1}}],["我们提出了一种以物体为中心的3d表示方法",{"2":{"693":1}}],["我们提出了一种以物体为中心的3d语义高斯表示方法",{"2":{"486":1}}],["我们提出了一种以物体为中心的表示方法",{"2":{"516":1}}],["我们提出了一种即插即用的范式",{"2":{"505":1}}],["我们提出了一种计算高效的基于融合的",{"2":{"455":1}}],["我们提出了一种多阶段占据导向的蒸馏方法",{"2":{"425":1}}],["我们提出了一种直接从地点稀疏子图分割房间的新方法来构建3d场景图的第4层",{"2":{"301":1}}],["我们提出了一种不依赖于任何额外神经网络的运动监督损失",{"2":{"143":1}}],["我们提出了一种新颖的层次化环路闭合检测方法",{"2":{"141":1}}],["我们提出了第一个算法",{"2":{"141":1}}],["我们提出clio",{"2":{"109":1}}],["我们估计他们的3d姿态随时间变化",{"2":{"131":1}}],["我们dsg中的每个节点都包括空间坐标和形状或边界框信息作为属性",{"2":{"131":1,"147":1}}],["我们建议您通过发送电子邮件至",{"2":{"126":1,"302":1}}],["我们为高斯记忆中的所有高斯分布引入一个额外的标记",{"2":{"728":1}}],["我们为用于vio的一个realsense相机禁用了红外模式发射器",{"2":{"605":1}}],["我们为用户提供了灵活性",{"2":{"449":1}}],["我们为每次更新提出了一个局部预测模块",{"2":{"600":1}}],["我们为每个帧维护一个全局掩码",{"2":{"793":1}}],["我们为每个检测到的对象分配",{"2":{"492":1}}],["我们为每个房间手动定义一组边界框",{"2":{"437":1}}],["我们为每个人类构建一个姿态图",{"2":{"419":1}}],["我们为每个任务查询n个最佳对象",{"2":{"402":1}}],["我们为每个代理节点存储了一个关键帧",{"2":{"352":1}}],["我们为clio包括了",{"2":{"492":1}}],["我们为激光雷达",{"2":{"455":1}}],["我们为激光雷达点云中的每个点标注了语义标签",{"2":{"277":1,"534":1}}],["我们为提供给clio的每个输入图像计算clip嵌入向量",{"2":{"228":1}}],["我们为",{"2":{"126":1,"277":1}}],["我们发布了nuscenes",{"2":{"534":1}}],["我们发布了以下传感器的数据",{"2":{"173":1}}],["我们发布了来自波士顿海港和新加坡的",{"2":{"157":1}}],["我们发布了uhumans2数据集",{"2":{"131":1}}],["我们发布了",{"2":{"126":1}}],["我们发布了完整的",{"2":{"126":1}}],["我们发现即使仅加入雷达数据",{"2":{"952":1}}],["我们发现初始化对性能至关重要",{"2":{"934":1}}],["我们发现",{"2":{"117":1,"455":1,"552":1,"823":1,"832":1,"833":1,"936":1,"977":1}}],["我们发现列出走廊",{"2":{"116":1}}],["我们发现该领域正朝着开放词汇",{"2":{"80":1}}],["我们不总结使用该指标的占用性能",{"2":{"1000":1}}],["我们不依赖于曼哈顿世界假设",{"2":{"967":1}}],["我们不使用任何测试时增强技术",{"2":{"761":1}}],["我们不使用它来评估网格的语义精度或对动态场景的鲁棒性",{"2":{"572":1}}],["我们不是直接解决尺度问题",{"2":{"660":1}}],["我们不是关注视觉显著性",{"2":{"121":1}}],["我们不能使用相机到相机的外参校准",{"2":{"605":1}}],["我们不需要对球员的区域进行重新预测和更改",{"2":{"117":1}}],["我们不费吹灰之力地执行所有这些操作",{"2":{"116":1}}],["我们理解高级指令",{"2":{"116":1}}],["我们还讨论了占用感知在边缘设备上的部署效率",{"2":{"1002":1}}],["我们还讨论了在执行路径规划查询时房间过度分割的影响",{"2":{"796":1}}],["我们还探讨了感知范围如何影响不同感知范围下每种传感器融合策略的性能趋势",{"2":{"977":1}}],["我们还要感谢",{"2":{"958":1}}],["我们还显示了路径中的节点和边的数量",{"2":{"947":1}}],["我们还显着降低了推理成本",{"2":{"552":1}}],["我们还采用",{"2":{"915":1}}],["我们还采用高斯混合模型公式来计算归一化的语义预测",{"2":{"851":1}}],["我们还评估了这个辅助分支的性能",{"2":{"893":1}}],["我们还评估了kimera在许多机器人应用中常见的低swap处理器上的性能",{"2":{"836":1}}],["我们还为每个帧维护一个全局分辨率的掩码",{"2":{"886":1}}],["我们还设计了一个基于分布的初始化策略",{"2":{"851":1}}],["我们还设计了一个基于分布的初始化模块",{"2":{"567":1}}],["我们还发现",{"2":{"833":1}}],["我们还从embodiedocc",{"2":{"793":1}}],["我们还从nuscenes验证集中手动选取雨天和夜间场景构建了两个具有挑战性的子集",{"2":{"503":1}}],["我们还沿局部",{"2":{"789":1}}],["我们还报告了使用esdf和使用层次路径规划方法时估计轨迹的长度",{"2":{"947":1}}],["我们还报告了使用地面真实姿态",{"2":{"709":1}}],["我们还报告了与kimera",{"2":{"732":1}}],["我们还注意到",{"2":{"723":1}}],["我们还需要为语义预测实现相同的目标",{"2":{"681":1}}],["我们还观察到占据预测精度随距离显著下降",{"2":{"673":1}}],["我们还比较了kimera",{"2":{"634":1}}],["我们还通过展示clio可以实时在spot机器人上执行并支持捡取和放置移动操作任务",{"2":{"586":1}}],["我们还提出了新的全局场景和局部视锥损失函数",{"2":{"539":1}}],["我们还提供了更多的定性结果",{"2":{"989":1}}],["我们还提供了一个测试集",{"2":{"534":1}}],["我们还提供将结果网格进行语义标记的选项",{"2":{"336":1}}],["我们还使用icp对地面真实3d网格与估计的3d网格进行对齐",{"2":{"709":1}}],["我们还使用kalibr校准了相机和imu的外参和内参",{"2":{"605":1}}],["我们还使用",{"2":{"480":1}}],["我们还开发了一种增强的",{"2":{"444":1}}],["我们还在sscbench",{"2":{"1000":1}}],["我们还在本地与",{"2":{"870":1}}],["我们还在bev空间中执行随机翻转",{"2":{"758":1}}],["我们还在图8中可视化了每个细化层的输出3d语义高斯分布",{"2":{"924":1}}],["我们还在图6中进行了定性可视化",{"2":{"833":1}}],["我们还在图5中进行了可视化",{"2":{"833":1}}],["我们还在图",{"2":{"745":1}}],["我们还在表6中尝试了额外的光度损失来重建输入图像",{"2":{"934":1}}],["我们还在表",{"2":{"700":1,"989":1}}],["我们还在nvidia",{"2":{"437":1}}],["我们还在携带机械臂的波士顿动力spot四足机器人上展示了clio的实时机载映射",{"2":{"109":1}}],["我们还包括",{"2":{"437":1}}],["我们还测试了",{"2":{"431":1,"823":1}}],["我们还持久保存人类的smpl参数和关节位置的历史记录",{"2":{"419":1}}],["我们还将人类检测反馈给kimera",{"2":{"419":1}}],["我们还跟踪了代理节点周围对象和地点的id",{"2":{"352":1}}],["我们还跟踪哪个父体素最接近体素",{"2":{"253":1}}],["我们还展示了在scannet",{"2":{"306":1}}],["我们还增加了",{"2":{"277":1,"302":1,"534":1}}],["我们还合并附近的节点",{"2":{"276":1}}],["我们还修改了marching",{"2":{"253":1}}],["我们还计算了将地点分类为房间的平均精度和召回率",{"2":{"796":1}}],["我们还计算",{"2":{"153":1}}],["我们还演示了dsg允许在利用dsg的层次性质的情况下",{"2":{"131":1}}],["我们还没有找到很好的达到纳什均衡的方法",{"2":{"129":1}}],["我们还组织了",{"2":{"126":1}}],["我们还标注了目标级别的属性",{"2":{"126":1}}],["我们还汇总了现有数据集与基准",{"2":{"72":1}}],["我们在照片级逼真的模拟和真实数据中展示了kimera",{"2":{"973":1}}],["我们在投影的2d位置",{"2":{"950":1}}],["我们在不同相机设置的数据集上进行了实验",{"2":{"945":1}}],["我们在不同场景下研究了不同感知范围下不同传感器融合策略的特性",{"2":{"944":1}}],["我们在主文中使用可学习的属性作为初始化",{"2":{"934":1}}],["我们在小运动物体类别",{"2":{"903":1}}],["我们在正文中仅选择了少数帧来展示我们局部空间占用预测模块的性能",{"2":{"902":1}}],["我们在验证集上评估了我们的",{"2":{"900":1}}],["我们在训练集上训练我们的模型",{"2":{"900":1}}],["我们在训练集上训练模型",{"2":{"787":1}}],["我们在所有体素上使用更严格的评估指标",{"2":{"853":1}}],["我们在流行的室内",{"2":{"853":1}}],["我们在开源存储库中提供了两组额外的参数",{"2":{"836":1}}],["我们在鸟瞰图",{"2":{"823":1}}],["我们在ckc",{"2":{"814":1}}],["我们在embodiedocc",{"2":{"813":1}}],["我们在附录中提供了这些指标的详细信息",{"2":{"812":1}}],["我们在附录中报告了这次评估中使用的参数",{"2":{"437":1}}],["我们在占据头的输出处应用通道到高度操作",{"2":{"811":1}}],["我们在daocc中采用了设置",{"2":{"800":1}}],["我们在dsg上实现并测试了一个语义层次路径规划算法",{"2":{"131":1}}],["我们在dsg中选择的节点和边也捕捉到了地点及其连通性",{"2":{"131":1}}],["我们在该数据集上训练和评估我们的局部空间占用预测模块",{"2":{"793":1}}],["我们在该射线上等间隔地采样",{"2":{"704":1}}],["我们在道路",{"2":{"792":1}}],["我们在道路和非道路数据集上进行了广泛的实验",{"2":{"415":1}}],["我们在bevdetocc",{"2":{"791":1}}],["我们在评估对象定位误差之前使用icp对3d地面真实网格与估计的3d网格进行对齐",{"2":{"775":1}}],["我们在评估误差之前对估计和地面真实轨迹进行se",{"2":{"634":1}}],["我们在uhumans数据集上评估了人类跟踪和对象定位的准确性",{"2":{"775":1}}],["我们在三个部分详细解释了我们的基准测试",{"2":{"793":1}}],["我们在三个流行的占据基准测试上验证模型",{"2":{"739":1}}],["我们在三个数据集",{"2":{"522":1}}],["我们在每个局部视锥上应用该损失",{"2":{"814":1}}],["我们在每个细化模块的输出上应用监督",{"2":{"738":1}}],["我们在每个地点",{"2":{"480":1}}],["我们在本文中提出的具身空间占用预测框架的操作方式与之相似",{"2":{"728":1}}],["我们在本文中提出了一个具身三维空间占用预测任务",{"2":{"682":1}}],["我们在gaussianformer中引入了两组特征",{"2":{"716":1}}],["我们在gaussianformer的",{"2":{"716":1}}],["我们在相机坐标系中初始化一组三维语义高斯分布",{"2":{"705":1}}],["我们在相应位置查询真实占用",{"2":{"704":1}}],["我们在表6中进行了关于高斯分布数量",{"2":{"934":1}}],["我们在表3中提供了不同场景表示方法的效率比较",{"2":{"842":1}}],["我们在表4中分析了不同的高斯参数和深度感知分支的影响",{"2":{"833":1}}],["我们在表4",{"2":{"754":1}}],["我们在表",{"2":{"700":1,"723":1,"792":2,"812":3,"823":1,"827":1,"865":1,"914":1,"917":1,"989":1}}],["我们在高斯的中心处分配",{"2":{"681":1}}],["我们在第一次更新之前初始化一个场景的高斯记忆",{"2":{"750":1}}],["我们在第4",{"2":{"748":1}}],["我们在第6节中探讨了研究趋势",{"2":{"665":1}}],["我们在第2节中介绍了基于视觉的3d占用预测的问题定义",{"2":{"665":1}}],["我们在第vi",{"2":{"228":1}}],["我们在深度预测任务中同时预测2d语义分割标签",{"2":{"617":1}}],["我们在occ",{"2":{"793":1,"813":1,"833":1}}],["我们在occ3d",{"2":{"421":1,"770":1}}],["我们在object365数据集",{"2":{"617":1}}],["我们在各种数据集上评估kimera",{"2":{"605":1}}],["我们在室内和室外场景上广泛测试了",{"2":{"570":1}}],["我们在多项任务",{"2":{"552":1}}],["我们在iso中引入了双特征视线投影",{"2":{"544":1}}],["我们在图5中提供了定性可视化结果",{"2":{"842":1}}],["我们在图5中可视化hydra",{"2":{"408":1}}],["我们在图",{"2":{"745":2,"803":1,"832":3,"843":1,"899":4,"901":1,"903":1,"992":1}}],["我们在图4中展示了如何根据它们的置信度值维护高斯记忆并优化高斯分布",{"2":{"728":1}}],["我们在图3中展示了深度感知分支的引导作用",{"2":{"705":1}}],["我们在图6中展示了21次试验的分解",{"2":{"522":1}}],["我们在一台可以安装在机器人上的笔记本电脑上运行clio",{"2":{"522":1}}],["我们在广泛采用的nuscenes和kitti",{"2":{"516":1}}],["我们在灵活池化后使用骨干特征初始化查询",{"2":{"471":1}}],["我们在两个道路数据集",{"2":{"444":1}}],["我们在柱坐标系下进行这些操作",{"2":{"438":1}}],["我们在柱坐标系下进行不同模态的特征融合",{"2":{"409":1}}],["我们在同一位置计算出预测表面网格",{"2":{"429":1}}],["我们在从生成器预测的最终表面上应用一个三维判别器",{"2":{"429":1}}],["我们在基线模型的统一bev特征上增加了三维目标检测监督",{"2":{"421":1}}],["我们在时间t",{"2":{"419":1}}],["我们在时间窗口",{"2":{"206":1}}],["我们在将位姿添加到位姿图之前",{"2":{"419":1}}],["我们在nuscenes上进行了这些实验",{"2":{"842":1}}],["我们在nuscenes",{"2":{"760":1}}],["我们在nuscenes和kitti",{"2":{"547":1}}],["我们在nuscenes数据集",{"2":{"503":1}}],["我们在nuscenes数据集上进行了广泛的实验",{"2":{"409":1}}],["我们在nvidia",{"2":{"131":1}}],["我们在提取的网格上建立一个新的图形",{"2":{"400":1}}],["我们在",{"2":{"390":1,"536":1,"567":1,"677":1,"694":1,"700":1,"771":2,"900":1,"927":1,"928":1,"944":1}}],["我们在距离阈值内",{"2":{"380":1}}],["我们在后向去噪时",{"2":{"312":1}}],["我们在活动窗口内添加额外的边以连接断开的组件",{"2":{"276":1}}],["我们在实现",{"2":{"253":1}}],["我们在摄像头和激光雷达传感器前方放置一个立方体校准目标",{"2":{"191":1}}],["我们在波士顿和新加坡收集了大约",{"2":{"157":1}}],["我们在波士顿和新加坡这两个以交通密集和驾驶情况极具挑战性而闻名的城市中收集了",{"2":{"126":1}}],["我们在此单独讨论同步定位与建图",{"2":{"155":1}}],["我们在下面讨论每个层次及其相应的节点和边",{"2":{"147":1}}],["我们在下面讨论每个方面的重要性",{"2":{"116":1}}],["我们在几个异构环境中评估hydra",{"2":{"141":1}}],["我们在公寓和办公室空间收集的真实数据集上定性评估kimera",{"2":{"131":1}}],["我们在真实和模拟数据集上测试kimera",{"2":{"131":1}}],["我们在整个数据集中以",{"2":{"126":1}}],["我们在模拟和真实数据上评估hydra",{"2":{"112":1}}],["我们在https",{"2":{"109":1,"637":1}}],["我们在replica数据集",{"2":{"109":1}}],["我们在包含46个场景的测试拆分上测试我们的模型",{"2":{"32":1}}],["我们最后的贡獻是开发实时架构和实现",{"2":{"141":1}}],["我们最后的贡獻是展示如何使用dsg进行实时分层语义路径规划",{"2":{"105":1}}],["我们最后的贡獻是通过广泛的实验活动表明",{"2":{"98":1}}],["我们的研究结果表明",{"2":{"977":1}}],["我们的研究是首次检验融合雷达信息对",{"2":{"653":1}}],["我们的几何结构如预期一样更好",{"2":{"917":1}}],["我们的动态场景图通过",{"2":{"905":1}}],["我们的动机源于激光雷达点云天然适合几何重建",{"2":{"455":1}}],["我们的预测结果与真实标注高度相似",{"2":{"899":1}}],["我们的消融研究表明",{"2":{"861":1}}],["我们的算法仅基于两种模态",{"2":{"847":1}}],["我们的算法是唯一一个成功检测到远处部分遮挡行人的方法",{"2":{"847":1}}],["我们的算法成功检测到了远处的移动车辆和行人",{"2":{"847":1}}],["我们的算法还使用受社区检测启发的快速且可扩展的房间分割方法",{"2":{"141":1}}],["我们的蒸馏模型比基线",{"2":{"823":1}}],["我们的蒸馏方法非常高效",{"2":{"782":1}}],["我们的m0方法尽管仅导致0",{"2":{"811":1}}],["我们的纯激光雷达模型与基于",{"2":{"803":1}}],["我们的损失lscall",{"2":{"794":1}}],["我们的flashocc中的时间提升不如基线方法显著",{"2":{"811":1}}],["我们的flashocc在带和不带时间模块的配置中均实现了显著提升或可比性能",{"2":{"811":1}}],["我们的flashocc在引入时间信息时展示了显著的提升",{"2":{"811":1}}],["我们的flashocc在非时间和时间方法上分别实现了2",{"2":{"811":1}}],["我们的flashocc在非时间方法上实现了0",{"2":{"811":1}}],["我们的flashocc在bevdetocc的非时间和时间变体上分别实现了0",{"2":{"811":1}}],["我们的flashocc在bevdetocc上实现了1",{"2":{"811":1}}],["我们的flashocc基于当代体素级占据预测方法进行了两项改进",{"2":{"505":1}}],["我们的fo",{"2":{"791":1}}],["我们的即插即用flashocc实现在bevdetocc上展示了1",{"2":{"791":1}}],["我们的dsg中的代理",{"2":{"905":1}}],["我们的daocc实现了48",{"2":{"779":1}}],["我们的daocc建立了一个新的最先进性能",{"2":{"779":1}}],["我们的dmtet自动学习细分四面体",{"2":{"372":1}}],["我们的代码基于",{"2":{"761":1}}],["我们的代码和预训练模型可在",{"2":{"539":1}}],["我们的高斯记忆和置信度优化的说明",{"2":{"728":1}}],["我们的具身空间占用预测框架接收一个带姿态的视觉输入",{"2":{"728":1}}],["我们的综述专门针对自动驾驶场景",{"2":{"714":1}}],["我们的综述侧重于3d占用感知",{"2":{"714":1}}],["我们的基于分布的初始化模块初始化了高斯",{"2":{"704":1}}],["我们的单帧图像输入方法在",{"2":{"700":1}}],["我们的初始化方案从占用注释中学习像素对齐的占用分布",{"2":{"681":1}}],["我们的轻量级设计将体素特征替换为bev特征",{"2":{"670":1}}],["我们的网络与体素级密集融合方法的对比如图",{"2":{"670":1}}],["我们的设计目标是以尽可能少的网络参数实现相似的精度",{"2":{"670":1}}],["我们的过程如图",{"2":{"660":1}}],["我们的策略显著更好",{"2":{"660":1}}],["我们的组件通过将多尺度",{"2":{"660":1}}],["我们的投影机制将",{"2":{"660":1}}],["我们的直觉是",{"2":{"660":1}}],["我们的大规模模型在各种下游任务上取得了sota的性能",{"2":{"643":1}}],["我们的3d高斯表示是以在线方式学习的",{"2":{"641":1}}],["我们的3d高斯表示类似于体素表示",{"2":{"612":1}}],["我们的流程如图",{"2":{"632":1}}],["我们的场景类别亲和力损失",{"2":{"632":1}}],["我们的场景图优化方法与姿态图优化之间的联系提供了通过利用最近的姿态图稀疏化进展来提高优化效率的机会",{"2":{"467":1}}],["我们的场景图前端",{"2":{"437":1}}],["我们的概率和公式可以更好地控制异常值过滤的阈值参数",{"2":{"622":1}}],["我们的局部预测模块采用一个简单而有效的深度感知分支",{"2":{"600":1}}],["我们的对比学习框架直接对点云数据进行操作",{"2":{"579":1}}],["我们的目标不仅是估计人体的3d姿态",{"2":{"967":1}}],["我们的目标是通过适用于",{"2":{"471":1}}],["我们的目标是找到一个更紧凑的信号",{"2":{"137":1}}],["我们的目标是为视觉",{"2":{"82":1}}],["我们的目的是在多模态占据预测框架内充分利用点云特征中固有的几何和结构信息",{"2":{"576":1}}],["我们的主要贡献总结如下",{"2":{"570":1}}],["我们的主要贡献如下",{"2":{"444":1}}],["我们的embodiedocc为使主动智能体能够进行准确且灵活的具身空间占用预测铺平了道路",{"2":{"852":1}}],["我们的embodiedocc维护当前场景的一个明确的高斯记忆",{"2":{"852":1}}],["我们的embodiedocc通过整合不同视角的预测",{"2":{"833":1}}],["我们的embodiedocc能够有效地执行具身空间占用预测任务",{"2":{"750":1}}],["我们的embodiedocc能够实时接受单目rgb输入",{"2":{"568":1}}],["我们的embodiedocc在局部空间占用预测方面优于现有方法",{"2":{"600":1,"852":1}}],["我们的embodiedocc在局部预测方法上优于现有方法",{"2":{"568":1}}],["我们的embodiedocc框架用于具身三维空间占用预测",{"2":{"568":1}}],["我们的embodiedocc假设环境是未知的",{"2":{"568":1}}],["我们的工作做出了以下贡献",{"2":{"552":1}}],["我们的框架通过动态融合",{"2":{"977":1}}],["我们的框架变得更加复杂",{"2":{"965":1}}],["我们的框架使用",{"2":{"867":1}}],["我们的框架适用于任何视图变换方法",{"2":{"867":1}}],["我们的框架从单张",{"2":{"570":1}}],["我们的框架依赖于连续的",{"2":{"539":1}}],["我们的框架提高了占据预测的准确性和鲁棒性",{"2":{"475":1}}],["我们的定性可视化结果表明",{"2":{"516":1,"547":1}}],["我们的任务列表是每个replica场景中出现的每个对象标签",{"2":{"492":1}}],["我们的gaussianformer甚至成功预测了在图像中几乎不可见的物体",{"2":{"842":1}}],["我们的gaussianformer能够生成既整体又逼真的场景感知结果",{"2":{"842":1}}],["我们的gaussianformer不仅能够合理分配资源",{"2":{"842":1}}],["我们的gaussianformer在性能上与最先进的方法相当",{"2":{"842":1}}],["我们的gaussianformer在性能相当的情况下",{"2":{"486":1}}],["我们的gaussianformer基于以物体为中心的表示",{"2":{"612":1}}],["我们的gaussianformer3d在预测精度上达到了与基于多模态融合的最先进方法相当的高水平",{"2":{"415":1}}],["我们的贡献如下",{"2":{"455":1}}],["我们的贡献总结如下",{"2":{"421":1}}],["我们的",{"2":{"405":1,"536":1,"567":1,"787":1,"851":1,"900":1,"901":1,"928":1}}],["我们的测试中为1到4米",{"2":{"390":1}}],["我们的层次化描述符包括标准的dbow2外观描述符",{"2":{"352":1}}],["我们的方差也在逐渐减小",{"2":{"312":1}}],["我们的方法首次同时优化姿态图和网格",{"2":{"967":1}}],["我们的方法实现了细粒度的语义占据预测",{"2":{"899":1}}],["我们的方法实现了最先进的性能",{"2":{"792":1}}],["我们的方法准确地重建了大面积连续表面",{"2":{"899":1}}],["我们的方法成功预测了碎石区域",{"2":{"899":1}}],["我们的方法也比octreeocc",{"2":{"842":1}}],["我们的方法预测的",{"2":{"832":1}}],["我们的方法仍然表现良好",{"2":{"928":1}}],["我们的方法仍然排名第一",{"2":{"827":1}}],["我们的方法仍然在基准测试中排名第一",{"2":{"827":1}}],["我们的方法以显著更少的高斯数量",{"2":{"792":1}}],["我们的方法相比其他方法实现了最先进的性能",{"2":{"792":1}}],["我们的方法能够预测对非道路自动驾驶至关重要的类别的语义占据",{"2":{"745":1}}],["我们的方法能够准确预测周围环境的语义和细粒度几何结构",{"2":{"745":1}}],["我们的方法使用每个数据样本的",{"2":{"744":1}}],["我们的方法使用柱坐标系",{"2":{"497":1}}],["我们的方法重新审视图像和点云之间的差异",{"2":{"715":1}}],["我们的方法学习整体的占用分布",{"2":{"704":1}}],["我们的方法的延迟高于",{"2":{"812":1}}],["我们的方法的延迟高于基于视觉的流程",{"2":{"700":1}}],["我们的方法的房间分割方法仍然能够为vio+sg",{"2":{"437":1}}],["我们的方法仅使用",{"2":{"700":1}}],["我们的方法节省了大约",{"2":{"700":1}}],["我们的方法利用一个可分离的三维目标检测分支作为辅助监督",{"2":{"690":1}}],["我们的方法从概率角度出发",{"2":{"656":1}}],["我们的方法则致力于密集地估计室内外场景的语义和几何信息",{"2":{"603":1}}],["我们的方法不需要对重建和生成能力进行微妙的加权",{"2":{"552":1}}],["我们的方法可以在没有额外训练成本的情况下预测多分辨率语义占据",{"2":{"745":1}}],["我们的方法可以更优雅地扩展到更高维的数据",{"2":{"552":1}}],["我们的方法可以根据更新的点位置动态地从图像的不同区域获取特征",{"2":{"464":1}}],["我们的方法达到了最先进的性能",{"2":{"544":1}}],["我们的方法在包括具有挑战性的雨天和夜间场景在内的多种场景下均展现出有效性和鲁棒性",{"2":{"898":1}}],["我们的方法在性能上与最先进的方法相当",{"2":{"842":1}}],["我们的方法在性能上与基于密集网格的最先进方法相当",{"2":{"444":1}}],["我们的方法在",{"2":{"827":1}}],["我们的方法在基准测试中排名第一",{"2":{"827":1}}],["我们的方法在所有天气条件下均显示出性能提升",{"2":{"914":1}}],["我们的方法在所有这些指标上均优于",{"2":{"812":1}}],["我们的方法在所有类别上都显著优于",{"2":{"700":1}}],["我们的方法在更大的感知范围和更细的网格分辨率下也表现出同样良好的性能",{"2":{"803":1}}],["我们的方法在处理复杂建筑",{"2":{"796":1}}],["我们的方法在测试集上比",{"2":{"700":1}}],["我们的方法在总体性能上与基于激光雷达",{"2":{"700":1}}],["我们的方法在柱坐标系下处理来自环视摄像头和激光雷达的伪3d点云和真实3d点云",{"2":{"527":1}}],["我们的方法在类似内存使用量的情况下显著优于仅使用摄像头的基线",{"2":{"444":1}}],["我们的方法估计了一个房间分割",{"2":{"437":1}}],["我们的方法基于两个关键见解",{"2":{"301":1}}],["我们的方法依靠定义哪些标签被认为是2d图像语义分割中的动态标签来跟踪动态代理",{"2":{"178":1}}],["我们的方法依赖于嵌入式变形图",{"2":{"112":1,"141":1}}],["我们的方法生成的房间解析",{"2":{"162":1}}],["我们的imu前端执行流形预积分",{"2":{"310":1}}],["我们的oneformer3d在scannet测试排行榜中获得了第一名",{"2":{"306":1}}],["我们的房间检测只对环境的拓扑进行推理",{"2":{"301":1}}],["我们的新房间检测方法提供了两个优势",{"2":{"301":1}}],["我们的地点子图中的每个节点都存储了到最近障碍物的距离",{"2":{"301":1}}],["我们的模型经历了显著的",{"2":{"971":1}}],["我们的模型仅通过特征通道连接来实现特征融合",{"2":{"971":1}}],["我们的模型通过整合所有三种传感器的信息实现了最佳性能",{"2":{"936":1}}],["我们的模型也能够学习语义占据",{"2":{"899":1}}],["我们的模型有效地捕捉到了场景中的障碍物结构",{"2":{"899":1}}],["我们的模型能够预测出合理的高斯分布和全面的占用结果",{"2":{"832":1}}],["我们的模型在长距离处的性能显著提升",{"2":{"944":1}}],["我们的模型在检测小型动态目标",{"2":{"827":1}}],["我们的模型在实现基于多模态融合的预测性能的同时",{"2":{"700":1}}],["我们的模型相比",{"2":{"812":1}}],["我们的模型比其他模型更轻量级",{"2":{"803":1}}],["我们的模型是一个高度计算高效的占用网络",{"2":{"803":1}}],["我们的模型采用两组3d高斯特征",{"2":{"563":1}}],["我们的模型可以以卷积方式应用",{"2":{"552":1}}],["我们的模型可以合成具有任意拓扑结构的形状",{"2":{"247":1}}],["我们的模型的目标其实就是在生成噪音",{"2":{"279":1}}],["我们的前向和后向是一个等长的过程",{"2":{"264":1,"266":1}}],["我们的实验总体上展示了",{"2":{"977":1}}],["我们的实验表明",{"2":{"141":1,"320":1}}],["我们的实践表明",{"2":{"803":1}}],["我们的实现基于voxblox",{"2":{"362":1}}],["我们的实时系统",{"2":{"168":1}}],["我们的度量",{"2":{"162":1}}],["我们的关键观察是",{"2":{"153":1}}],["我们的环路闭合检测方法在检测到的环路闭合的数量和质量方面优于基于词袋和视觉特征匹配的标准方法",{"2":{"141":1}}],["我们的在线算法在精度上与批量离线方法相当",{"2":{"141":1}}],["我们的最后贡献",{"2":{"131":1}}],["我们的空间感知引擎",{"2":{"131":1,"285":1}}],["我们的描述符捕获跨场景图层次的统计数据",{"2":{"112":1}}],["我们的评估表明",{"2":{"105":1}}],["我们的第三项贡献",{"2":{"131":1}}],["我们的第三项贡献是对kimera在真实生活数据集和照片级逼真模拟中的全面评估",{"2":{"105":1}}],["我们的第三个贡献",{"2":{"109":1}}],["我们的第二个贡献是研究3d场景图中的环路闭合检测和优化",{"2":{"112":1,"141":1}}],["我们的第二个贡献",{"2":{"109":1}}],["我们的第二项贡献是kimera",{"2":{"105":1}}],["我们的第一个贡献是开发实时算法",{"2":{"112":1,"141":1}}],["我们的第一个贡献",{"2":{"109":1}}],["我们从它开始构建一个大规模的cnn",{"2":{"824":1}}],["我们从unity的3d资产商店获得",{"2":{"775":1}}],["我们从detr",{"2":{"716":1}}],["我们从",{"2":{"670":1,"900":1}}],["我们从数据",{"2":{"665":1}}],["我们从视角分解和从粗到细的范式两个角度进行了深入分析",{"2":{"665":1}}],["我们从尺度s=",{"2":{"660":1}}],["我们从多个尺度",{"2":{"660":1}}],["我们从3d高斯表示生成3d语义占用预测",{"2":{"641":1}}],["我们从特征增强",{"2":{"637":1}}],["我们从单张",{"2":{"632":1}}],["我们从记忆中提取当前视锥体内的高斯分布",{"2":{"568":1,"728":1}}],["我们从观察到的图像中提取语义和结构特征",{"2":{"568":1}}],["我们从观察到的标签的频率中构建一个标签概率向量",{"2":{"362":1}}],["我们从教师模型向仅视觉学生模型进行了",{"2":{"455":1}}],["我们从融合教师模型向仅视觉学生模型蒸馏占据知识",{"2":{"455":1}}],["我们从摄像头分支生成伪3d点云",{"2":{"438":1}}],["我们从每个估计的房间中包含的地点派生出自由空间体素",{"2":{"437":1}}],["我们从环境的地面真实重建中手动标记地面真实房间rg",{"2":{"437":1}}],["我们从地点描述符走到对象描述符",{"2":{"352":1}}],["我们从地图表示的结构出发",{"2":{"90":1}}],["我们从上一次esdf集成产生的标签开始",{"2":{"276":1}}],["我们从经典的信息瓶颈原理中汲取灵感",{"2":{"109":1}}],["我们从两大维度对这些方法进行分类",{"2":{"80":1}}],["我们首先对雷达",{"2":{"809":1}}],["我们首先对点云进行体素化",{"2":{"609":1}}],["我们首先采用",{"2":{"768":1}}],["我们首先加载多视角图像及其相机参数",{"2":{"761":1}}],["我们首先根据它们的均值",{"2":{"738":1}}],["我们首先根据3d高斯分布的均值将它们嵌入目标体素网格",{"2":{"738":1}}],["我们首先根据相机标定数据确定每条图像特征对应的射线的原点",{"2":{"704":1}}],["我们首先通过将均值",{"2":{"716":1}}],["我们首先使用",{"2":{"886":1}}],["我们首先使用焦点损失",{"2":{"750":1}}],["我们首先使用多层感知器",{"2":{"716":1}}],["我们首先使用图像主干网络提取多尺度",{"2":{"716":1}}],["我们首先使用一个微调的深度预测网络从输入",{"2":{"705":1}}],["我们首先使用resnet50",{"2":{"609":1}}],["我们首先从高斯的语义属性",{"2":{"681":1}}],["我们首先从目标网格中随机选择一个高曲率的顶点",{"2":{"429":1}}],["我们首先介绍一种以物体为中心的3d场景表示方法",{"2":{"669":1}}],["我们首先回顾原始的",{"2":{"628":1}}],["我们首先预定义一个形状为",{"2":{"609":1}}],["我们首先引入",{"2":{"576":1}}],["我们首先在建筑物层面上计算可行的最短路径",{"2":{"930":1}}],["我们首先在没有蒸馏的情况下训练",{"2":{"823":1}}],["我们首先在小规模下验证不同模型效果",{"2":{"785":1}}],["我们首先在第4",{"2":{"541":1,"748":1}}],["我们首先在当前关键帧中成功跟踪的2d特征",{"2":{"336":1}}],["我们首先将",{"2":{"789":1}}],["我们首先将3d高斯分布的属性及其对应的高维查询初始化为可学习的向量",{"2":{"716":1}}],["我们首先将激光雷达点云体素化",{"2":{"502":1}}],["我们首先将教师模型的占据结果分解为三个子区域",{"2":{"455":1}}],["我们首先提出了一种基于高效融合的",{"2":{"425":1}}],["我们首先提供有关聚合ib的相关背景",{"2":{"153":1}}],["我们首先确保两个骨架集之间的质心运动速率是合理的",{"2":{"419":1}}],["我们首先定义",{"2":{"153":1}}],["我们首先澄清关键术语",{"2":{"82":1}}],["我们首次呈现vla4ad综合综述",{"2":{"82":1}}],["我们",{"2":{"72":1,"352":1}}],["二元交叉熵",{"2":{"985":1}}],["二元亲和力损失",{"2":{"794":1}}],["二维到三维转换",{"2":{"942":1}}],["二维图像特征通过投影和插值转换到三维体素空间",{"2":{"576":1}}],["二是与该体素类别iou相关的特定类别权重",{"2":{"697":1}}],["二是把语义与几何线索融入运动恢复结构",{"2":{"209":1}}],["二者耦合",{"2":{"447":1}}],["二",{"2":{"41":1,"196":1,"292":1}}],["今天我在执行shell脚本",{"2":{"41":1}}],["今日工作",{"2":{"0":1}}],["则查询射线被视为真正例",{"2":{"998":1}}],["则记录为占用",{"2":{"988":1}}],["则变形一个密集的surfels地图",{"2":{"967":1}}],["则允许",{"2":{"928":1}}],["则提出了双路径transformer来编码不同方向的3d体素",{"2":{"875":1}}],["则提出一种多层次场景图",{"2":{"648":1}}],["则纯激光雷达模型的性能比融合模型高出",{"2":{"803":1}}],["则通过零填充达到",{"2":{"789":1}}],["则通过聚合函数",{"2":{"435":1}}],["则更新该节点的特征",{"2":{"765":1}}],["则取平均",{"2":{"765":1}}],["则构建",{"2":{"765":1}}],["则构建紧凑的环境模型",{"2":{"648":1}}],["则存在s3s^3s3对关系",{"2":{"730":1}}],["则还需要在预定义类别中预测其语义类别",{"2":{"712":1}}],["则对局部视锥中的类别分布进行优化",{"2":{"632":1}}],["则该点深度判断的准确概率越高",{"2":{"622":1}}],["则利用高斯泼溅在",{"2":{"588":1}}],["则利用全局地图完成定位任务",{"2":{"252":1}}],["则把语义与高斯表征融合",{"2":{"588":1}}],["则点",{"2":{"579":1}}],["则随机选择",{"2":{"563":1}}],["则视为同一节点",{"2":{"525":1}}],["则映射到同一节点",{"2":{"525":1}}],["则需合并成一张大图",{"2":{"525":1}}],["则建立一条边",{"2":{"525":1}}],["则有望提升自动驾驶车辆3d占据预测模型的准确性",{"2":{"503":1}}],["则用",{"2":{"525":1}}],["则用启发式",{"2":{"495":1}}],["则用聚合函数",{"2":{"495":1}}],["则返回",{"2":{"479":1}}],["则返回一个指向容器中最后一个键值对之后位置的迭代器",{"2":{"196":1}}],["则返回一个指向该键值对的正向迭代器",{"2":{"196":1}}],["则不进行roi边框修正的参数训练",{"2":{"463":1}}],["则输入可以表示为p∈rn×6p",{"2":{"412":1}}],["则得到",{"2":{"406":2}}],["则检测是宽松的",{"2":{"402":1}}],["则检测是严格的",{"2":{"402":1}}],["则姿态顶点",{"2":{"390":1}}],["则合并节点",{"2":{"380":1}}],["则在图中新增一个节点",{"2":{"525":1}}],["则在当前节点与上一节点之间添加边",{"2":{"525":1}}],["则在",{"2":{"378":1}}],["则在构建时可能会造成问题",{"2":{"27":1}}],["则从rgb",{"2":{"362":1}}],["则体素被视为节点",{"2":{"276":1}}],["则创建节点或边",{"2":{"276":1}}],["则使用离线",{"2":{"274":1}}],["则进一步细分为",{"2":{"274":1}}],["则语义差别越大",{"2":{"264":1}}],["则为true",{"2":{"254":1}}],["则为空",{"2":{"254":2,"654":2}}],["则这是图像高度",{"2":{"254":1}}],["则这是图像宽度",{"2":{"254":1}}],["则token为空字符串",{"2":{"254":1,"654":1}}],["则作为新节点添加",{"2":{"253":1}}],["则两个房间通过边连接",{"2":{"218":1}}],["则聚类可以在每个连通分量上独立执行",{"2":{"153":1}}],["则停止合并操作",{"2":{"153":1}}],["则训练完成后",{"2":{"129":1}}],["则会出现指针指向错误",{"2":{"115":1}}],["则以锚点车道的形式定义",{"2":{"644":1}}],["则以unix结束",{"2":{"41":1}}],["则以dos",{"2":{"41":1}}],["结论或建议仅代表作者的观点",{"2":{"973":1}}],["结论与讨论",{"0":{"861":1},"1":{"878":1}}],["结论",{"0":{"467":1,"538":1,"586":1,"643":1,"767":1,"820":1,"831":1,"845":1,"851":1,"852":1,"862":1,"898":1,"958":1,"973":1,"977":1,"1007":1}}],["结合语义和几何的损失",{"2":{"985":1}}],["结合学习的运动模型和粒子滤波来预测3d人体姿态",{"2":{"967":1}}],["结合新的特征投影模块",{"2":{"937":1}}],["结合密集的度量",{"2":{"905":1}}],["结合动态掩蔽",{"2":{"709":1}}],["结合两种方法优势",{"2":{"585":1}}],["结合insert函数",{"2":{"571":1}}],["结合了l1损失和可选的结构相似性",{"2":{"988":1}}],["结合了三种模态",{"2":{"975":1}}],["结合了场景的复杂性和大小",{"2":{"437":1}}],["结合了在封闭集上训练的图神经网络来映射对象及其关系",{"2":{"121":1}}],["结合稀疏",{"2":{"308":1}}],["结合隐式和显式3d呈现方法",{"2":{"247":1}}],["结合的方式分为以下几种",{"2":{"220":1}}],["结合多视图立体和曼哈顿世界假设从图像中重建楼层平面",{"2":{"172":1}}],["结合",{"2":{"149":1,"998":1}}],["结合文本与轨迹输出",{"2":{"145":1}}],["结合起来",{"2":{"121":1,"467":1}}],["结构更好地捕获空间信息",{"2":{"765":1}}],["结构和大小具有不变性",{"2":{"664":1}}],["结构和房间",{"2":{"480":1}}],["结构来处理变长输入",{"2":{"405":1}}],["结构捕获感知压缩",{"2":{"270":1}}],["结构层面",{"2":{"209":1,"864":1}}],["结构也可能与第3层的对象有边",{"2":{"197":1}}],["结构可能与它们包围的房间有边",{"2":{"197":1}}],["结构节点的属性是",{"2":{"197":1}}],["结构的概念捕捉了通常在相关工作中被称为",{"2":{"197":1}}],["结构",{"0":{"531":1},"1":{"562":1,"594":1,"623":1,"651":1},"2":{"116":1,"147":1,"162":1,"197":3,"209":1,"274":1,"285":1,"480":1,"648":1,"935":1}}],["结构表示",{"2":{"80":1}}],["结构相似性",{"2":{"8":1}}],["结果虽然仍然具有一致性",{"2":{"945":1}}],["结果总结在表",{"2":{"882":1}}],["结果与分析",{"0":{"833":1,"842":1}}],["结果最好不使用任何提出的技术",{"2":{"775":1}}],["结果中的失真现象逐渐增加",{"2":{"995":1}}],["结果中",{"2":{"561":1}}],["结果区域反映了这种粒度差异",{"2":{"522":1}}],["结果比较在表iii中展示",{"2":{"522":1}}],["结果证实了我们的即插即用范式在精度",{"2":{"505":1}}],["结果证明了我们方法的有效性和先进性",{"2":{"409":1}}],["结果和消融研究",{"2":{"437":1}}],["结果如表i所示",{"2":{"431":1}}],["结果表明我们的局部空间占用预测模块优于iso",{"2":{"833":1}}],["结果表明我们的模型在点云生成和自动编码方面取得了有竞争力的性能",{"2":{"314":1}}],["结果表明",{"2":{"415":1,"421":1,"444":1,"536":1,"859":1,"875":1,"909":1,"928":2,"945":1}}],["结果回路闭合仍可能包含异常值",{"2":{"390":1}}],["结果网格比第3",{"2":{"362":1}}],["结果是跨越当前vio时间范围内关键帧的最新3d网格",{"2":{"336":1}}],["结果",{"0":{"226":1,"353":1,"366":1,"454":1,"462":1},"2":{"43":1,"51":1}}],["结束",{"2":{"41":1}}],["还具有比毫米波雷达更高的垂直分辨率",{"2":{"1005":1}}],["还具有空间的自适应聚合能力以实现构建像素级别的关系",{"2":{"824":1}}],["还考虑了推理速度",{"2":{"1001":1}}],["还引入了一个名为",{"2":{"962":1}}],["还加快了其在训练过程中的收敛速度",{"2":{"959":1}}],["还显著影响其整体训练时长",{"2":{"959":1}}],["还增强了模型捕捉",{"2":{"952":1}}],["还增加了感知损失",{"2":{"345":1}}],["还将讨论网络训练策略和相应的损失函数",{"2":{"877":1}}],["还能够在3d空间中进行准确的重建和占用预测",{"2":{"875":1}}],["还能捕捉物体形状的细节",{"2":{"842":1}}],["还可以直接使用数组来初始化向量",{"2":{"888":1}}],["还可以阻止mask",{"2":{"872":1}}],["还可以把每个点扩展为一个带有协方差矩阵的",{"2":{"588":1}}],["还以相同的方式生成前视图和侧视图的特征",{"2":{"858":1}}],["还必须对地图进行内在评估",{"2":{"786":1}}],["还讨论了当前的局限性和未来的研究方向",{"2":{"714":1}}],["还讨论了挑战和未来的研究方向",{"2":{"610":1}}],["还促进了其他维度的优化",{"2":{"705":1}}],["还避免了高斯之间的不必要重叠",{"2":{"681":1}}],["还提供了摄像头可见性掩码",{"2":{"652":1}}],["还提出了许多其他方案",{"2":{"664":1}}],["还提出了几个带有密集占据标签的基准测试",{"2":{"566":1}}],["还提出了基于径向基函数的用于",{"2":{"481":1}}],["还提出了其他几种方法",{"2":{"337":1}}],["还有两种专门的语义损失",{"2":{"985":1}}],["还有两种其他几何损失",{"2":{"985":1}}],["还有一些混合转换方法结合了多种2d到3d转换技术",{"2":{"950":1}}],["还有一些方法直接对3d体素表示进行操作",{"2":{"875":1}}],["还有一些仍然是随机的",{"2":{"728":1}}],["还有研究进一步融合网格",{"2":{"648":1}}],["还有大量研究将",{"2":{"209":1}}],["还使我们提出的框架的整体训练损失",{"2":{"576":1}}],["还包括背景元素的不平衡",{"2":{"548":1}}],["还包括纹理细节上的人脸肤色",{"2":{"133":1}}],["还展示了出色的部署兼容性",{"2":{"535":1}}],["还自动评估kimera",{"2":{"510":1}}],["还需存储物体语义类别",{"2":{"698":1}}],["还需增加一步",{"2":{"435":1}}],["还需要全面理解环境的上下文",{"2":{"421":1}}],["还会将当前帧与历史帧进行时间空间对齐",{"2":{"942":1}}],["还会合并重叠的节点",{"2":{"380":1}}],["还会给出乱码错误消息",{"2":{"41":1}}],["还原原图像",{"2":{"371":1}}],["还赋予其意义与上下文",{"2":{"350":1}}],["还要实现物体的部分到完整估计",{"2":{"910":1}}],["还要能够在其中采取有意义的行动",{"2":{"110":1}}],["还要在其中采取有意义的行动",{"2":{"100":1}}],["还编码环境的高层语义",{"2":{"90":1}}],["还比较训练范式并总结同时评估控制性能与语言保真度的协议",{"2":{"82":1}}],["还是模拟",{"2":{"889":1}}],["还是更优的控制策略",{"2":{"864":1}}],["还是一张狗的素描",{"2":{"204":1}}],["还是作为一系列对象的集合",{"2":{"105":1}}],["还是存在一定的偏差",{"2":{"75":1}}],["还是会提醒的",{"2":{"66":1}}],["还是有输出",{"2":{"66":1}}],["还用了",{"2":{"54":1}}],["还未开源",{"2":{"30":1}}],["导航场景尤为不利",{"2":{"913":1}}],["导航",{"2":{"786":1}}],["导航历史",{"2":{"765":1}}],["导航以及更广泛的",{"2":{"556":1}}],["导航任务",{"2":{"139":1,"806":1}}],["导致栈内数据在内存中不是连续分布",{"2":{"938":1}}],["导致计算与内存开销巨大",{"2":{"897":1}}],["导致计算复杂性高",{"2":{"567":1}}],["导致走廊的过度分割",{"2":{"872":1}}],["导致3d网格嘈杂和不完整",{"2":{"872":1}}],["导致规划时对错误地图条目过度自信",{"2":{"864":1}}],["导致无法可靠衡量地图的语义准确性",{"2":{"846":1}}],["导致无界占用预测",{"2":{"656":1}}],["导致存储和计算成本高昂",{"2":{"808":1}}],["导致几何和语义误差增加",{"2":{"732":1}}],["导致尽管某些特征仍然可用",{"2":{"665":1}}],["导致在户外场景中由于空旷空间的巨大比例",{"2":{"656":1}}],["导致在推理的早期",{"2":{"267":1}}],["导致",{"2":{"622":1}}],["导致严重过拟合",{"2":{"617":1}}],["导致整个模型的参数量大幅增加",{"2":{"601":1}}],["导致物体类别识别不准确",{"2":{"596":1}}],["导致不同3d高斯投影到相同2d位置时可能聚合相同特征",{"2":{"595":1}}],["导致空间建模不准确",{"2":{"563":1}}],["导致空间偏差很大",{"2":{"96":1}}],["导致欠分割和比hydra",{"2":{"522":1}}],["导致模型在这些场景下表现不稳定",{"2":{"503":1}}],["导致模型很难弄清楚它们之间的关联",{"2":{"149":1}}],["导致占据预测结果稀疏",{"2":{"482":1}}],["导致开放集精确度提高",{"2":{"462":1}}],["导致随着esdf增长",{"2":{"437":1}}],["导致kinect的部分深度估计",{"2":{"437":1}}],["导致任务失败",{"2":{"435":1}}],["导致细节信息丢失和性能下降",{"2":{"409":1}}],["导致采样的特征超出物体区域",{"2":{"341":1}}],["导致了小的性能下降",{"2":{"732":1}}],["导致了语义的不一致性",{"2":{"312":1}}],["导致了众多探索它们在3d场景理解",{"2":{"121":1}}],["导致我们很难控制模型生成带有我们想要的语义信息的图片",{"2":{"264":1,"266":1}}],["导致现有的视觉和机器人学中的任务驱动表示框架要么太狭窄",{"2":{"137":1}}],["导致命令找不到错误",{"2":{"41":1}}],["导入自定义模块的方法",{"2":{"17":1}}],["您到底是如何复制脚本的",{"2":{"41":1}}],["您可以通过打印脚本文件来检查",{"2":{"41":1}}],["您的文件副本有dos",{"2":{"41":1}}],["您将获得几个新文件夹",{"2":{"38":1}}],["您将获得一个名为3rscan",{"2":{"32":1}}],["页面下载",{"2":{"40":1}}],["从具有完整点云的教师模型中蒸馏知识到具有不完美输入的学生模型",{"2":{"1005":1}}],["从表6可以看出",{"2":{"1001":1}}],["从表4可以看出",{"2":{"1000":1}}],["从表中可以看出",{"2":{"782":1}}],["从累积的激光雷达点云生成的真实体素标签并不完美",{"2":{"998":1}}],["从不平衡的数据集中学习仍然是点云分割中的一个具有挑战性的问题",{"2":{"996":1}}],["从消融研究中得出的另一个关键发现是多尺度粗到细结构与多级监督机制之间存在强烈的关联",{"2":{"971":1}}],["从前视到鸟瞰图的转换可以通过交叉注意力",{"2":{"950":1}}],["从粗到细的方法由于信息丢失较少",{"2":{"922":1}}],["从粗到细的方法",{"0":{"922":1}}],["从全局角度提供了高斯表示中冗余程度的视角",{"2":{"916":1}}],["从验证集和测试集中各选取了两个具有代表性的样本进行展示",{"2":{"899":1}}],["从语义和占用感知的种子体素向整个场景传播语义",{"2":{"875":1}}],["从语言查询抽取物体名称",{"2":{"765":1}}],["从0到k之间变化",{"2":{"863":1}}],["从方程中我们可以看出",{"2":{"844":1}}],["从任务内容的角度来看",{"2":{"841":1}}],["从fcos3d",{"2":{"822":1}}],["从tsdf构建esdf",{"2":{"816":1}}],["从单个图像中进行人体姿态和形状估计是一个日益增长的研究领域",{"2":{"967":1}}],["从单个图像",{"2":{"967":1}}],["从单个视点消除遮挡是无法实现的",{"2":{"814":1}}],["从单张图像中联合理解",{"2":{"953":1}}],["从单目图像中提取语义特征",{"2":{"600":1}}],["从398",{"2":{"811":1}}],["从7",{"2":{"811":1}}],["从直观角度来看",{"2":{"811":1}}],["从直观上看",{"2":{"390":1}}],["从检测检查点进行预训练",{"2":{"803":1}}],["从2d视觉输入中获取完美的3d特征很困难",{"2":{"799":1}}],["从2d占用网格计算voronoi图",{"2":{"172":1}}],["从输入图像中提取候选物体掩码",{"2":{"765":1}}],["从输入图上的roi到特征图上的roi",{"2":{"554":1}}],["从零学习",{"2":{"743":1}}],["从r",{"2":{"741":1}}],["从高斯查询",{"2":{"716":1}}],["从高层次的任务规划到运动规划和轨迹优化",{"2":{"116":1}}],["从图像到高斯分布",{"0":{"716":1}}],["从图像中收集信息",{"2":{"875":1}}],["从图像中估计",{"2":{"570":1}}],["从图像中提取并匹配几何特征",{"2":{"189":1}}],["从颈部获得的用于占据的bev特征被输入到占据头",{"2":{"703":1}}],["从向量构造对角矩阵的函数",{"2":{"693":1}}],["从同一场景和视点",{"2":{"686":1}}],["从同一传感器采样数据",{"2":{"254":1}}],["从下图中可以看出",{"2":{"685":1}}],["从工业角度来看",{"2":{"667":1}}],["从复杂的输入格式",{"2":{"667":1}}],["从学术角度来看",{"2":{"667":1}}],["从计算友好性出发",{"2":{"665":1}}],["从多视图中提取的高层次全局特征通过嵌入网络投影到点云的子空间中",{"2":{"664":1}}],["从多视角图像构建类似于nerf的3d体积表示",{"2":{"941":1}}],["从多视角图像中提取2d特征",{"2":{"550":1}}],["从多视角环视图像中预测车道段",{"2":{"123":1}}],["从世界系转到自车坐标系",{"2":{"654":1}}],["从标注中取",{"2":{"654":1}}],["从雷达传感器获得的速度信息可以增强检测性能",{"2":{"653":1}}],["从所有摄像头的多尺度特征图中采样得到的特征",{"2":{"623":1}}],["从辅助cam",{"2":{"591":1}}],["从getoffset",{"2":{"561":1}}],["从教师模型",{"2":{"548":1}}],["从大规模预训练与模态对齐到针对性极端案例数据增广与高效压缩技术",{"2":{"538":1}}],["从大到小",{"2":{"291":1}}],["从激光雷达和雷达数据中提取特征",{"2":{"527":1}}],["从我们方法的高精确度但低召回率中可以看出",{"2":{"522":1}}],["从esdf中获得拓扑图",{"2":{"480":1}}],["从esdf中提取地点的拓扑图",{"2":{"112":1}}],["从kimera的3d网格中解析地点",{"2":{"480":1}}],["从成对协调扩展至密集交通",{"2":{"478":1}}],["从orion语言总结长历史",{"2":{"478":1}}],["从融合教师模型蒸馏出实时仅视觉占据网络",{"2":{"455":1}}],["从其中也可以轻松提取与轴对齐的边界框",{"2":{"449":1}}],["从分割的簇中",{"2":{"449":1}}],["从一个大的感受野聚集相邻的信息",{"2":{"440":1}}],["从地面真实姿态构建的批量场景图作为地面真实场景图",{"2":{"437":1}}],["从相机中心出发",{"2":{"435":1}}],["从理论上证明了实现置换不变性的关键是总结所有表示并应用非线性变换",{"2":{"420":1}}],["从深度图像中恢复平移",{"2":{"419":1}}],["从最小标签中学习高效占据网络用于自动驾驶",{"0":{"395":1},"1":{"425":1,"455":1,"487":1,"517":1,"548":1,"581":1,"613":1,"642":1,"670":1,"694":1,"717":1,"739":1,"761":1,"782":1,"803":1,"823":1,"843":1,"862":1,"879":1}}],["从头开始构建邻接矩阵a",{"2":{"390":1}}],["从合并的地点重新检测房间",{"2":{"380":1}}],["从长远来看",{"2":{"380":1}}],["从每个对象或代理节点到活动窗口中最近的地点节点填充层间边",{"2":{"380":1}}],["从中我们提取最可能的标签",{"2":{"362":1}}],["从中使用游行立方体",{"2":{"362":1}}],["从中可以提取外观信息",{"2":{"352":1}}],["从代理节点周围半径内的对象和地点计算得出",{"2":{"352":1}}],["从两个不同的相机视角生成两个视角下的点云x1和x2",{"2":{"339":1}}],["从解释性感知",{"2":{"334":1}}],["从贝叶斯观点出发",{"2":{"292":1}}],["从视觉",{"2":{"285":1}}],["从记忆库检索相似历史驾驶案例",{"2":{"283":1}}],["从未探索前沿",{"2":{"274":1}}],["从餐厅的桌子上拿起红色杯子",{"2":{"262":1}}],["从自车坐标系转到",{"2":{"654":1}}],["从自顶向下视图存储为二进制语义掩码的地图数据",{"2":{"254":1}}],["从自动驾驶汽车到工厂地板上的协作机器人",{"2":{"116":1}}],["从静态指令到对话驱动",{"2":{"176":1}}],["从几何到动力学的演进推动了更复杂传感器融合框架研究",{"2":{"176":1}}],["从原始分辨率裁剪出",{"2":{"173":1}}],["从数学上看",{"2":{"171":1}}],["从低到高抽象层次",{"2":{"147":1}}],["从低层次的外观到对象语义和地点几何",{"2":{"352":1}}],["从低层次的几何形状到对象",{"2":{"125":1}}],["从低层次的几何形状到包括对象",{"2":{"112":1}}],["从低层次的视觉外观到关于对象和地点的汇总统计数据",{"2":{"112":1}}],["从vlm到自动驾驶vla",{"0":{"145":1}}],["从而监督网络训练",{"2":{"988":1}}],["从而细化最高层的特征",{"2":{"971":1}}],["从而带来了",{"2":{"959":1}}],["从而大大减少了计算量",{"2":{"950":1}}],["从而大大简化了从场景表示到占用预测的转换过程",{"2":{"842":1}}],["从而引入了2d和3d之间对应关系的模糊性",{"2":{"950":1}}],["从而表示3d场景",{"2":{"950":1}}],["从而为复杂推理提供更全面",{"2":{"935":1}}],["从而为诸如端到端自动驾驶",{"2":{"547":1}}],["从而保留了完整的三维场景",{"2":{"923":1}}],["从而保留图像全部信息",{"2":{"189":1}}],["从而显著节省计算资源",{"2":{"922":1}}],["从而反映了模型容量的更高效利用",{"2":{"916":1}}],["从而高效地获取完整的3d体素信息",{"2":{"908":1}}],["从而减少了计算需求",{"2":{"923":1}}],["从而减少特征学习过程中需要考虑的变量数量",{"2":{"908":1}}],["从而减少令牌数量",{"2":{"567":1}}],["从而对模型收敛产生负面影响",{"2":{"893":1}}],["从而对整体性能做出了贡献",{"2":{"842":1}}],["从而更深入地理解3d空间中的几何关系",{"2":{"941":1}}],["从而更好地捕捉局部和全局上下文信息",{"2":{"875":1}}],["从而更精确和全面地理解占用情况",{"2":{"875":1}}],["从而更精准地建模三维世界",{"2":{"503":1}}],["从而缓解信息丢失",{"2":{"875":1}}],["从而消除了所有基于",{"2":{"865":1}}],["从而消除任何顺序模糊性",{"2":{"325":1}}],["从而同时检测和重建场景中的3d占用",{"2":{"839":1}}],["从而使路径规划在大规模场景中以交互速度运行",{"2":{"947":1}}],["从而使关键特征占据主导地位",{"2":{"829":1}}],["从而使其更适合",{"2":{"599":1}}],["从而展示了高度信息的保留",{"2":{"791":1}}],["从而产生三个级别的多尺度图像特征",{"2":{"867":1}}],["从而产生最终的局部",{"2":{"789":1}}],["从而产生一个紧凑的全局描述符",{"2":{"337":1}}],["从而便于通过卷积",{"2":{"780":1}}],["从而获得更好的模型性能",{"2":{"882":1}}],["从而获得更密集的点云",{"2":{"735":1}}],["从而获得可开放词汇",{"2":{"721":1}}],["从而避免在这些区域进行不必要的预测",{"2":{"800":1}}],["从而避免了由于平面表示中的维度降低而导致的潜在细节丢失",{"2":{"693":1}}],["从而避免无界对数并防止高斯之间不必要的重叠",{"2":{"567":1}}],["从而防止了高斯之间的不必要重叠",{"2":{"681":1}}],["从而防止任何高斯描述空区域",{"2":{"681":1}}],["从而生成相对密集的体素注释",{"2":{"735":1}}],["从而生成更详细的3d表示",{"2":{"680":1}}],["从而生成尽可能真实的数据并让",{"2":{"129":1}}],["从而能像卷积神经网络一样把",{"2":{"659":1}}],["从而能够更有效地捕捉3d场景的几何结构",{"2":{"649":1}}],["从而能够使用高效的2d卷积层进行特征提取",{"2":{"505":1}}],["从而能够开展跨越多种传感器模态的广泛研究",{"2":{"302":1}}],["从而让他们可以在特别大的分辨率上去预训练模型",{"2":{"631":1}}],["从而变相的达到了一种全局建模的能力",{"2":{"631":1}}],["从而充分利用具有多样化粒度的语义信息",{"2":{"627":1}}],["从而构建开放词汇",{"2":{"619":1}}],["从而达到稀疏的场景表示",{"2":{"603":1}}],["从而达到更好的分割效果",{"2":{"84":1}}],["从而进一步强制从cam中激活更多的对象区域",{"2":{"591":1}}],["从而可用文本查询场景中的物理属性",{"2":{"588":1}}],["从而得到",{"2":{"707":1}}],["从而得到一个大小为",{"2":{"609":1}}],["从而得到深度感知上下文特征",{"2":{"578":1}}],["从而得到可用于占据预测的最终三维体素空间表示",{"2":{"576":1}}],["从而得到更灵活和有用的场景表示",{"2":{"462":1}}],["从而将几何结构与语义内容紧密结合",{"2":{"588":1}}],["从而将",{"2":{"570":1}}],["从而增强语义的空间一致性",{"2":{"985":1}}],["从而增强模型对复杂场景的理解",{"2":{"875":1}}],["从而增强融合特征中关于目标边界和场景结构的信息",{"2":{"666":1}}],["从而增强信息流并实现",{"2":{"632":1}}],["从而增强了提取器学习到的潜在表示的语义水平",{"2":{"488":1}}],["从而增强了统一bev特征的可区分性",{"2":{"421":1}}],["从而增加了下游任务的复杂性",{"2":{"547":1}}],["从而限制了观察到的自由空间",{"2":{"872":1}}],["从而限制了这些区域特征表示的有效性",{"2":{"527":1}}],["从而限制了整体模型性能",{"2":{"438":1}}],["从而导致表示和计算冗余",{"2":{"693":1}}],["从而导致无法被检测出来",{"2":{"630":1}}],["从而导致固有的冗余",{"2":{"599":1}}],["从而导致资源分配不平衡",{"2":{"516":1}}],["从而导致信息丢失",{"2":{"337":1}}],["从而估计当前位姿",{"2":{"495":1}}],["从而支持避障",{"2":{"698":1}}],["从而支持多层次的推理",{"2":{"648":1}}],["从而支持零样本传输",{"2":{"469":1}}],["从而支持梯度回传",{"2":{"252":1}}],["从而在渲染过程中无需进行动态对象过滤",{"2":{"941":1}}],["从而在每个层级产生最终的",{"2":{"746":1}}],["从而在每个池化操作之后控制网格的期望分辨率",{"2":{"466":1}}],["从而在聚合时用最新时间步更新该信息",{"2":{"698":1}}],["从而在同时实现所有三个分割任务的最佳性能",{"2":{"306":1}}],["从而允许网络选择网格的哪些部分要简化",{"2":{"436":1}}],["从而纠正累积误差",{"2":{"435":1}}],["从而提供了对3d场景的更完整描述",{"2":{"821":1}}],["从而提供更细粒度的感知结果",{"2":{"482":1}}],["从而提升任务表现",{"2":{"525":1}}],["从而提升性能",{"2":{"409":1,"527":1}}],["从而提高了鲁棒性和准确性",{"2":{"950":1}}],["从而提高了算法的实时性能和计算效率",{"2":{"153":1}}],["从而提高模型的效率和鲁棒性",{"2":{"356":1}}],["从而实现快速收敛并捕获",{"2":{"971":1}}],["从而实现3d场景感知",{"2":{"942":1}}],["从而实现自适应和高效的计算而不牺牲准确性",{"2":{"922":1}}],["从而实现有效的3d占用预测",{"2":{"875":1}}],["从而实现有效的避障",{"2":{"665":1}}],["从而实现了真正的自监督3d占用预测框架",{"2":{"949":1}}],["从而实现了只需要一次前向过程",{"2":{"751":1}}],["从而实现了细致的室内重建",{"2":{"588":1}}],["从而实现了通道到空间的特征变换",{"2":{"535":1}}],["从而实现更好的资源分配和效率",{"2":{"612":1}}],["从而实现更有效的特征融合和中间特征细化",{"2":{"497":1}}],["从而实现更准确",{"2":{"474":1}}],["从而实现跨表示的点云分割",{"2":{"356":1}}],["从而实现对点云的理解和分析",{"2":{"331":1}}],["从而加速网络",{"2":{"349":1}}],["从而解决点云分割的问题",{"2":{"331":1}}],["从而通过想象动作结果实现规划",{"2":{"308":1}}],["从而强制语言命令与结果轨迹紧密耦合",{"2":{"308":1}}],["从而节省计算资源并提高效率",{"2":{"153":1}}],["从而以贪婪的方式解决",{"2":{"153":1}}],["从点云中提取一个三维特征体fvol",{"2":{"318":1}}],["从点云",{"2":{"125":1}}],["从基础导航与避障",{"2":{"123":1}}],["从桌子上拿起玻璃杯",{"2":{"116":1}}],["从运动中恢复结构",{"2":{"116":1}}],["从官网https",{"2":{"47":1}}],["从",{"2":{"40":1,"120":1,"125":1,"328":1,"619":1,"660":1,"816":1,"917":1,"978":1}}],["到最近表面带符号距离",{"2":{"619":1}}],["到24",{"2":{"516":1,"547":1,"842":1}}],["到82",{"2":{"486":1}}],["到局部子集中点之间的高级关系",{"2":{"481":1}}],["到rag",{"2":{"478":1}}],["到模块化vla规划",{"2":{"334":1}}],["到来时",{"2":{"153":1}}],["到达房间y中的任何对象x",{"2":{"939":1}}],["到达目标但未发信号的",{"2":{"806":1}}],["到达目标对象后",{"2":{"522":1}}],["到达对应深度",{"2":{"435":1}}],["到达靠近沙发的人",{"2":{"131":1}}],["到达坐标xyz",{"2":{"116":1}}],["到涉及感知",{"2":{"123":1}}],["到",{"2":{"38":1,"285":1,"369":1,"539":1,"724":1}}],["最佳性能以粗体显示",{"2":{"1000":1}}],["最佳结果用粗体表示",{"2":{"1000":1}}],["最佳结果以粗体显示",{"2":{"736":3}}],["最佳结果以粗体标出",{"2":{"700":1}}],["最佳结果",{"2":{"662":1}}],["最右列",{"2":{"903":1}}],["最左列",{"2":{"903":1}}],["最高级别没有应用跳跃连接",{"2":{"867":1}}],["最高的候选轨迹",{"2":{"206":1}}],["最多需要180毫秒来寻找循环闭合候选者并执行几何验证和计算相对变换",{"2":{"816":1}}],["最强版本k使用internimage",{"2":{"805":1}}],["最典型的是占用",{"2":{"698":1}}],["最低误差",{"2":{"662":1}}],["最优匹配索引",{"2":{"651":1}}],["最优化算法",{"2":{"179":1}}],["最常见的类型是强监督学习",{"2":{"981":1}}],["最常见的做法是",{"2":{"495":1}}],["最常用的两种传感器是激光雷达和相机",{"2":{"599":1}}],["最常用的是stoll和stod这两个函数",{"2":{"63":1}}],["最先进的3d占用模型可能容易受到分布外场景和数据的影响",{"2":{"1005":1}}],["最先进的以视觉为中心的占用方法在iou和miou方面仍落后于以激光雷达为中心的方法",{"2":{"1000":1}}],["最先进的",{"2":{"471":1}}],["最本质来说",{"2":{"459":1,"552":1}}],["最小高度和最大高度",{"2":{"910":1}}],["最小化总损失",{"2":{"712":1}}],["最小化匹配的点对之间的距离",{"2":{"339":1}}],["最小范数",{"2":{"436":1}}],["最突出的假设包括",{"2":{"435":1}}],["最简单的方式莫过于余弦距离",{"2":{"422":1}}],["最远点采样",{"2":{"396":1}}],["最初被提出用于预测室内场景中所有体素的占据和语义状态",{"2":{"808":1}}],["最初的研究主要集中在单个三维物体的重建上",{"2":{"603":1}}],["最初的工作",{"2":{"121":1}}],["最初提出的",{"2":{"390":1}}],["最重要的是",{"2":{"285":1}}],["最大限度地减少信息丢失",{"2":{"875":1}}],["最大200个特征和4",{"2":{"836":1}}],["最大250个特征和5秒的时间范围",{"2":{"836":1}}],["最大学习率为",{"2":{"771":1}}],["最大的性能下降是由于使用密集立体视觉",{"2":{"732":1}}],["最大主干如vit",{"2":{"617":1}}],["最大化探索面积",{"2":{"698":1}}],["最大化全局class",{"2":{"591":1}}],["最大化覆盖面积",{"2":{"274":1}}],["最大值等",{"2":{"435":1}}],["最大池仅保留特定视图中的最大元素",{"2":{"337":1}}],["最大测量距离",{"2":{"173":1}}],["最早尝试以被动描述角色集成语言以增强可解释性",{"2":{"260":1}}],["最新语义建图方法日益依赖视觉",{"2":{"864":1}}],["最新趋势则是把多种结构融合成单一表征",{"2":{"648":1}}],["最新研究将多模态与语言监督融入点云理解",{"2":{"588":1}}],["最新的网格",{"2":{"380":1}}],["最新代理节点",{"2":{"352":1}}],["最新vla4ad浪潮超越解释与计划条件",{"2":{"334":1}}],["最新工作开始引入口语作为更自然",{"2":{"176":1}}],["最新努力推进至多轮对话",{"2":{"176":1}}],["最近关于3d占用感知的研究",{"2":{"1001":1}}],["最近提出了一系列基于点的网络",{"2":{"974":1}}],["最近在基于视觉的占据预测方面的进展已经在大规模数据集上展现出令人印象深刻的性能",{"2":{"444":1}}],["最近的",{"2":{"765":1}}],["最近的方法转向更具挑战性的以视觉为中心的3d占用预测",{"2":{"759":1}}],["最近的方法研究了使用图像序列",{"2":{"190":1}}],["最近的一些研究",{"2":{"735":1}}],["最近的对象查询依次与历史查询和当前图像特征交互",{"2":{"695":1}}],["最近的3d高斯溅射",{"2":{"641":1}}],["最近的多模态三维目标检测方法",{"2":{"512":1}}],["最近的工作调查了与rgb",{"2":{"967":1}}],["最近的工作集中在3d数据上",{"2":{"172":1}}],["最近的工作将基础模型与神经辐射场",{"2":{"121":1}}],["最近的工作还探索了直接的类无关3d分割",{"2":{"121":1}}],["最近的工作",{"2":{"116":1}}],["最近",{"2":{"172":1,"274":1,"444":1,"522":5,"535":1,"588":1,"603":1,"665":1,"759":1,"860":1,"932":1,"967":1,"975":1,"1005":1,"1006":1}}],["最近作为一种强大的3d环境高级表示形式出现",{"2":{"125":1}}],["最近视觉",{"2":{"121":1}}],["最近回顾了室内机器人中的语义地图构建",{"2":{"90":1}}],["最贴心",{"2":{"63":1}}],["最后两行",{"2":{"899":1}}],["最后两个子网络前去预测每个query的bounding",{"2":{"562":1}}],["最后一列",{"2":{"754":1}}],["最后一个线程包括kimera",{"2":{"285":1}}],["最后把这些部分加在一起",{"2":{"659":1}}],["最后对于分类网络",{"2":{"659":1}}],["最后过滤掉概率小于0",{"2":{"622":1}}],["最后体素化并沿高度求和投影到",{"2":{"495":1}}],["最后通过高斯到体素绘制模块预测语义占据",{"2":{"444":1}}],["最后回到起点",{"2":{"437":1}}],["最后蒸馏结果用于车载部署",{"2":{"417":1}}],["最后将ib表述适应于使用开放集视觉",{"2":{"153":1}}],["最后概述开放挑战并描绘未来方向",{"2":{"82":1}}],["最后",{"2":{"72":1,"116":1,"131":2,"141":1,"176":1,"206":1,"276":1,"296":1,"301":1,"310":1,"314":1,"336":1,"377":1,"380":2,"390":1,"408":1,"419":2,"421":1,"427":1,"437":2,"438":1,"449":1,"462":1,"467":1,"480":1,"503":2,"527":1,"541":1,"550":1,"552":1,"553":1,"568":1,"570":1,"576":1,"605":2,"609":1,"621":1,"623":1,"628":1,"637":1,"649":1,"664":1,"665":2,"669":1,"681":1,"699":1,"714":1,"716":1,"732":2,"735":2,"738":2,"746":1,"775":1,"796":1,"816":2,"850":1,"858":1,"875":4,"905":1,"928":1,"930":1,"942":1,"962":1,"973":1,"976":1,"1007":1}}],["最后输入",{"2":{"41":1}}],["最后执行以下命令删除",{"2":{"33":1}}],["最终目标可能是实现一个结合特征增强",{"2":{"969":1}}],["最终目录结构",{"2":{"38":1}}],["最终通过多帧光度一致性进行监督",{"2":{"949":1}}],["最终通过占用头推断环境的3d占用",{"2":{"942":1}}],["最终基于三个投影视角的特征表示完成3d占用预测",{"2":{"858":1}}],["最终基于bev特征表示完成3d占用预测",{"2":{"839":1}}],["最终获得了",{"2":{"828":1}}],["最终提交中",{"2":{"825":1}}],["最终损失函数如下",{"2":{"766":1}}],["最终输出的三维占据网格的形状为200×200×16",{"2":{"736":1}}],["最终蒸馏损失",{"2":{"694":1}}],["最终预测为所有结果的平均值",{"2":{"673":1}}],["最终采样点集为",{"2":{"595":1}}],["最终的occscore计算为",{"2":{"998":1}}],["最终的激光雷达",{"2":{"976":1}}],["最终的占用预测通过计算这两个嵌入的点积获得",{"2":{"957":1}}],["最终的三维占用推断涉及在增强特征上应用卷积",{"2":{"910":1}}],["最终的损失公式如下",{"2":{"884":1}}],["最终的损失表达式为",{"2":{"750":1}}],["最终的",{"2":{"660":2,"724":1}}],["最终的3d语义占据预测结果表示为",{"2":{"590":1}}],["最终的生成表达式中依赖神经网络对噪声的预测可以生成图像",{"2":{"224":1}}],["最终得到融合后的3d特征表示",{"2":{"527":1}}],["最终得到的地图与轨迹能够最大程度地与全部带噪传感器数据保持一致",{"2":{"171":1}}],["最终",{"2":{"233":1,"502":1,"705":1,"910":1}}],["最终生成的结果不受控制",{"2":{"224":1}}],["最终至全环视系统",{"2":{"176":1}}],["最终文件结构",{"2":{"32":1}}],["删除函数",{"2":{"904":1}}],["删除set1的所有元素",{"2":{"633":1}}],["删除操作",{"2":{"633":2}}],["删除元素",{"2":{"633":1}}],["删除最后一个元素是返回end",{"2":{"115":1}}],["删除一个元素时会返回下一个元素的迭代器",{"2":{"115":1}}],["删除容器内",{"2":{"115":1}}],["删除容器最后一个元素",{"2":{"115":1}}],["删除iter位置的元素",{"2":{"115":1}}],["删除不需要的",{"0":{"99":1}}],["删除以前安装的文件",{"2":{"66":1}}],["删除文字",{"2":{"57":1}}],["删除",{"0":{"33":1},"2":{"904":1}}],["└──",{"2":{"32":11,"38":14,"327":5}}],["│",{"2":{"32":49,"38":58,"327":12}}],["├──",{"2":{"32":42,"38":39,"327":7}}],["如物体运动",{"2":{"997":1}}],["如物体类别",{"2":{"90":1}}],["如knn",{"2":{"996":1}}],["如kd",{"2":{"877":1}}],["如主文中所述",{"2":{"989":1}}],["如上所述",{"2":{"978":1}}],["如零样本占用分割和基于文本的3d检索",{"2":{"975":1}}],["如对遮挡的敏感性",{"2":{"969":1}}],["如添加树木或替换汽车",{"2":{"963":1}}],["如空间网格",{"2":{"958":1}}],["如植被和人造结构",{"2":{"952":1}}],["如第6",{"2":{"947":1}}],["如第4",{"2":{"686":1,"732":1,"855":1}}],["如基于卷积的resnet",{"2":{"942":1}}],["如基于激光雷达或融合的检测器",{"2":{"548":1}}],["如3d目标检测",{"2":{"1003":1}}],["如3d卷积或mlp",{"2":{"942":1,"970":1}}],["如3d检测",{"2":{"667":1}}],["如投影",{"2":{"942":1}}],["如交叉熵损失",{"2":{"988":1}}],["如交通标志和车道线",{"2":{"942":1}}],["如交互式可视化和问题回答",{"2":{"905":1}}],["如绕开行人",{"2":{"926":1}}],["如桌子腿和靠垫",{"2":{"903":1}}],["如红色框中所示",{"2":{"899":1}}],["如灌木和泥泞",{"2":{"899":1}}],["如ln",{"2":{"880":1}}],["如llama",{"2":{"417":1}}],["如llama2",{"2":{"195":1}}],["如aff",{"2":{"877":1}}],["如bce",{"2":{"877":1}}],["如bev或tpv",{"2":{"875":1}}],["如bevdetocc",{"2":{"811":1}}],["如bev",{"2":{"693":1}}],["如bench2drive",{"2":{"478":1}}],["如遮挡和透视误差",{"2":{"875":1}}],["如整栋楼宇",{"2":{"864":1}}],["如紫色和深红色框所示",{"2":{"847":1}}],["如其他车辆",{"2":{"842":1}}],["如摩托车",{"2":{"842":1}}],["如测试时增强模型集成",{"2":{"839":1}}],["如拓扑图",{"2":{"826":1}}],["如像素准确率",{"2":{"826":1}}],["如先前研究广泛讨论的",{"2":{"811":1}}],["如uhumans2中的",{"2":{"796":1}}],["如定位",{"2":{"786":1}}],["如panoptic",{"2":{"779":1}}],["如pointvla",{"2":{"195":1}}],["如表3和表4所示",{"2":{"1000":1}}],["如表3所示",{"2":{"833":1}}],["如表9所示",{"2":{"893":1}}],["如表",{"2":{"882":1}}],["如表7所示",{"2":{"859":1}}],["如表4的第三行所示",{"2":{"833":1}}],["如表4所示",{"2":{"779":1}}],["如表6所示",{"2":{"800":1,"1001":1}}],["如表5所示",{"2":{"800":1,"811":2,"1000":1}}],["如表1所示",{"2":{"779":1,"791":1,"833":1}}],["如表2所示",{"2":{"757":2,"779":1,"805":1}}],["如汽车",{"2":{"778":1}}],["如检测",{"2":{"759":1}}],["如缩放",{"2":{"758":1}}],["如运动规划和控制",{"2":{"738":1}}],["如vdbfusion",{"2":{"735":1}}],["如nuscenes",{"2":{"735":1,"997":1}}],["如nas",{"2":{"627":1}}],["如墙壁",{"2":{"732":1}}],["如可行驶表面",{"2":{"723":1}}],["如自行车",{"2":{"723":1,"827":1}}],["如人造结构",{"2":{"723":1}}],["如行人",{"2":{"723":1}}],["如高斯分布c",{"2":{"705":1}}],["如高斯分布b",{"2":{"705":1}}],["如高斯分布a",{"2":{"705":1}}],["如泥泞",{"2":{"700":1}}],["如草地和树木",{"2":{"899":1}}],["如草地",{"2":{"700":1}}],["如道路和植被",{"2":{"693":1}}],["如公交车和行人",{"2":{"693":1}}],["如挖掘机和拖车等可变形障碍物",{"2":{"665":1}}],["如操作物体",{"2":{"648":1}}],["如网格",{"2":{"641":1}}],["如2",{"2":{"636":1}}],["如三维空间占用预测和目标检测",{"2":{"629":1}}],["如路面",{"2":{"617":1}}],["如路径规划",{"2":{"285":1}}],["如目标检测",{"2":{"601":1}}],["如视图变换或3d",{"2":{"598":1}}],["如视觉指令调优",{"2":{"195":1}}],["如语义分割",{"2":{"588":1}}],["如语义图",{"2":{"114":1}}],["如mlp",{"2":{"574":1}}],["如matlab时可能需要让",{"2":{"60":1}}],["如卷积和池",{"2":{"574":1}}],["如办公室中的场景",{"2":{"522":1}}],["如本工作所述",{"2":{"520":1}}],["如体素",{"2":{"516":1}}],["如识别警察手势或行人挥手",{"2":{"507":1}}],["如夜间和雨天场景",{"2":{"503":1}}],["如此生成的地图可能含噪",{"2":{"495":1}}],["如激光雷达和环视雷达",{"2":{"475":1}}],["如占据",{"2":{"455":1}}],["如搜救",{"2":{"435":1}}],["如取最大值",{"2":{"435":1}}],["如平均",{"2":{"435":1}}],["如前所述",{"2":{"419":2}}],["如sc",{"2":{"877":1}}],["如swintransformer",{"2":{"627":1}}],["如simlingo过滤琐碎场景强调罕见案例",{"2":{"507":1}}],["如simlingo",{"2":{"478":1}}],["如simlingo极端案例片段",{"2":{"417":1}}],["如safeauto插入逻辑交通检查",{"2":{"507":1}}],["如safeauto",{"2":{"417":1}}],["如切入",{"2":{"417":1}}],["如有语言提示",{"2":{"417":1}}],["如八叉树和kd树",{"2":{"636":1}}],["如八叉树",{"2":{"363":1}}],["如坐到沙发上",{"2":{"350":1}}],["如厨房",{"2":{"350":1}}],["如区域",{"2":{"337":1}}],["如稀疏体素",{"2":{"331":1}}],["如机器人导航",{"2":{"331":1}}],["如多视图",{"2":{"311":1}}],["如宽",{"2":{"254":1,"654":1}}],["如ce",{"2":{"877":1}}],["如center",{"2":{"254":1,"654":1}}],["如covla",{"2":{"417":1}}],["如clip",{"2":{"109":1,"260":1,"417":1}}],["如分类",{"2":{"220":1}}],["如需更全面",{"2":{"209":1}}],["如orion",{"2":{"195":1}}],["如dynamicfusion",{"2":{"967":1}}],["如drivemoe",{"2":{"417":1}}],["如drivemonkey在nuinteract",{"2":{"417":1}}],["如drivecot与cot",{"2":{"145":1}}],["如dinov2",{"2":{"195":1}}],["如思维链提示",{"2":{"176":1}}],["如解释交通规则",{"2":{"176":1}}],["如指令",{"2":{"176":1}}],["如转向角",{"2":{"176":1}}],["如鸟瞰图",{"2":{"176":1}}],["如轮速里程计或",{"2":{"171":1}}],["如图6c所示",{"2":{"957":1}}],["如图6b所示",{"2":{"957":1}}],["如图6所示",{"2":{"285":1}}],["如图所示",{"2":{"947":1}}],["如图8",{"2":{"798":1}}],["如图7",{"2":{"777":1,"818":1}}],["如图4所示",{"2":{"738":1,"811":1}}],["如图3中的",{"2":{"716":1}}],["如图3所示",{"2":{"238":1,"420":1,"617":1,"638":1,"780":1}}],["如图",{"2":{"436":1,"444":1,"656":1,"659":1,"681":1,"704":1,"730":1,"745":1,"814":1,"828":1,"899":1,"928":2,"945":1,"952":3,"959":1}}],["如图5所示",{"2":{"285":1,"466":1}}],["如图20所示",{"2":{"836":1,"969":1}}],["如图2中紫色部分所示",{"2":{"638":1}}],["如图2",{"2":{"518":1}}],["如图2a所示",{"2":{"276":1}}],["如图2所示",{"2":{"160":1,"598":1,"680":1,"693":1,"703":1,"726":1,"735":1}}],["如图像",{"2":{"254":1,"406":1,"450":1}}],["如图19所示",{"2":{"963":1}}],["如图18所示",{"2":{"949":1}}],["如图11所示",{"2":{"948":1}}],["如图17所示",{"2":{"941":1}}],["如图15所示",{"2":{"922":1}}],["如图14所示",{"2":{"922":1}}],["如图16所示",{"2":{"922":1}}],["如图16",{"2":{"709":1}}],["如图13所示",{"2":{"605":1,"908":1}}],["如图1中重建的",{"2":{"605":1}}],["如图1所示",{"2":{"128":1,"141":1,"421":1,"547":1,"735":1}}],["如图1",{"2":{"114":1,"145":1,"535":1}}],["如新的rgb",{"2":{"153":1}}],["如何让机器人智能决策何时",{"2":{"935":1}}],["如何充分利用图像中的纹理信息仍是一个有待解决的问题",{"2":{"931":1}}],["如何建立标准化的评估框架",{"2":{"864":1}}],["如何支持终身学习的地图更新机制",{"2":{"864":1}}],["如何打造可靠且灵活的多模态地图",{"2":{"864":1}}],["如何构建高效的动态地图",{"2":{"926":1}}],["如何构建高效",{"2":{"864":1}}],["如何构建特征",{"2":{"351":1}}],["如何在不牺牲各自质量的前提下高效融合两种表示",{"2":{"935":1}}],["如何在实时约束下实现高效",{"2":{"864":1}}],["如何在多模态occ框架内有效利用点云数据仍有待进一步探索",{"2":{"421":1}}],["如何得到一个6×6的全连接层的输入呢",{"2":{"554":1}}],["如何利用来自其他模态的数据",{"2":{"444":1}}],["如何更好地在多模态occ任务中利用点云数据的独特优势",{"2":{"421":1}}],["如何将多个基于视图的特征聚合到一个可区分的全局表示中是一个关键挑战",{"2":{"337":1}}],["如何提高点云分割的鲁棒性和精度",{"2":{"331":1}}],["如何有效地处理点云的数据结构",{"2":{"331":1}}],["如何设计一个通用的模型",{"2":{"331":1}}],["如何使用",{"0":{"327":1}}],["如何处理多头注意力",{"2":{"278":1}}],["如何监督",{"2":{"143":1}}],["如何对齐vlm输出与动作空间仍待解决",{"2":{"128":1}}],["如何取β的值",{"2":{"111":1,"236":1}}],["如警笛→让行",{"2":{"128":1}}],["如在学校",{"2":{"126":1,"302":1}}],["如下所示",{"2":{"676":1}}],["如下所述",{"2":{"390":1,"419":1}}],["如下表所示",{"2":{"345":1}}],["如下缺点所写",{"2":{"125":1}}],["如下图所示",{"2":{"204":1,"554":1}}],["如下图的椅子",{"2":{"165":1}}],["如下图",{"2":{"54":1,"117":1}}],["如计算关节角度与轨迹以执行这些动作",{"2":{"123":1}}],["如车辆在路口抛锚",{"2":{"114":1}}],["如类无关图像分割",{"2":{"98":1}}],["如导航或物体操作",{"2":{"110":1}}],["如导航",{"2":{"80":1}}],["如",{"2":{"31":1,"82":1,"109":1,"123":1,"139":2,"145":1,"176":1,"209":1,"252":1,"254":1,"274":2,"283":4,"336":1,"352":1,"360":1,"380":2,"390":4,"435":1,"437":1,"478":1,"495":1,"507":1,"525":1,"564":1,"567":1,"588":1,"605":1,"619":1,"622":1,"634":1,"754":1,"765":2,"796":2,"864":2,"975":1}}],["如果满足以下两个条件",{"2":{"998":1}}],["如果多摄像头图像中的对应像素具有错误的深度值并映射到3d空间中的同一体素",{"2":{"950":1}}],["如果想从大到小排序",{"2":{"929":1}}],["如果机器人检测到n个已知对象",{"2":{"905":1}}],["如果模型在",{"2":{"803":1}}],["如果模型预测成功了狗",{"2":{"204":1}}],["如果在训练期间未使用相机可见掩码",{"2":{"758":1}}],["如果需要栈顶元素",{"2":{"753":1}}],["如果可用",{"2":{"732":1}}],["如果可以预测到",{"2":{"279":1}}],["如果体素被预测为占用",{"2":{"712":1}}],["如果某个像素的深度不明确",{"2":{"950":1}}],["如果某个体素投影到图像外",{"2":{"660":1}}],["如果某些连通分量没有受到新数据的影响",{"2":{"153":1}}],["如果要以像素点作为基本单位的话",{"2":{"631":1}}],["如果要添加一个字符串",{"2":{"52":1}}],["如果重投影坐标",{"2":{"592":1}}],["如果元素被插入",{"2":{"571":1}}],["如果位置正确会减少插入时间",{"2":{"571":1}}],["如果提供了形状",{"2":{"449":1}}],["如果略有过分割",{"2":{"437":1}}],["如果质心运动和关节运动在时间步之间在界限内",{"2":{"419":1}}],["如果至少满足这两个条件中的一个",{"2":{"402":1}}],["如果网格顶点",{"2":{"390":1}}],["如果网格中检测到平面表面",{"2":{"336":1}}],["如果当前时间t检测到的回路通过里程计检查",{"2":{"390":1}}],["如果相应的对象具有相同的语义标签",{"2":{"380":1}}],["如果不使用监督",{"2":{"928":1}}],["如果不足则进行paddings",{"2":{"373":1}}],["如果不需要优化的3d度量",{"2":{"285":1}}],["如果对一张图片上每个像素点",{"2":{"355":1}}],["如果失败",{"2":{"352":1}}],["如果任何描述符比较返回一个假定的匹配项",{"2":{"352":1}}],["如果描述符距离低于阈值",{"2":{"352":1}}],["如果两个原语单独对同一个任务有类似的余弦相似度",{"2":{"553":1}}],["如果两个地点之间有边连接",{"2":{"480":1}}],["如果两个对象在3d空间中相互接触或接近到一定的程度",{"2":{"271":1}}],["如果两个房间相邻",{"2":{"218":1}}],["如果这些类别的iou分数较低",{"2":{"1000":1}}],["如果这个anchor与ground",{"2":{"347":1}}],["如果这两个节点对应的对象原语的3d边界框",{"2":{"271":1}}],["如果这是该对象的第一个注释",{"2":{"254":1,"654":1}}],["如果这是该对象的最后一个注释",{"2":{"254":1,"654":1}}],["如果我们能从这些高斯分布中得出一个可接受的局部空间占用预测",{"2":{"728":1}}],["如果我们不考虑spot未能实际抓取正确识别对象的情况",{"2":{"522":1}}],["如果我们想要做引导生成",{"2":{"338":1}}],["如果我们想要生成一张",{"2":{"205":1}}],["如果我们通过距离δ膨胀地图",{"2":{"301":1}}],["如果我们膨胀障碍物",{"2":{"301":1}}],["如果我们记录下前向过程里每一步的噪声图像",{"2":{"264":1,"266":1}}],["如果sample",{"2":{"254":1}}],["如果样本数据是一张图像",{"2":{"254":2}}],["如果场景开始为空",{"2":{"254":2}}],["如果新的gvd体素要么有足够的基点",{"2":{"276":1}}],["如果新对象不对应现有的对象节点",{"2":{"253":1}}],["如果新帧中只出现了新的对象或场景的一部分",{"2":{"153":1}}],["如果一个体素网格中的点数少于",{"2":{"789":1}}],["如果一个anchor与ground",{"2":{"347":1}}],["如果一个假定的对象与场景图中相同语义类别的现有对象节点重叠",{"2":{"253":1}}],["如果一个track在",{"2":{"206":1}}],["如果处理不了形式复杂的函数",{"2":{"235":1}}],["如果没有这些监督信号",{"2":{"971":1}}],["如果没有在细化过程中对连贯性进行正则化",{"2":{"842":1}}],["如果没有指定底层实现的话",{"2":{"685":1}}],["如果没有被插入",{"2":{"571":1}}],["如果没有位姿图满足一致性标准",{"2":{"419":1}}],["如果没有标注可见性",{"2":{"254":1,"654":1}}],["如果没有关联",{"2":{"206":1}}],["如果没问就是",{"2":{"66":1}}],["如果找到",{"2":{"196":1}}],["如果找不到则返回string",{"2":{"52":1}}],["如果有足够的基点",{"2":{"276":1}}],["如果有",{"2":{"177":1}}],["如果输入算法的原语图有多个连通分量",{"2":{"153":1}}],["如果",{"2":{"153":1,"196":1,"579":1}}],["如果直接用",{"2":{"149":1}}],["如果超出范围会返回异常错误",{"2":{"130":1}}],["如果为对象类别提供了cad模型",{"2":{"449":1}}],["如果为",{"2":{"129":1}}],["如果用到图片生成上",{"2":{"129":1}}],["如果您打算将",{"2":{"126":1,"302":1}}],["如果您使用fastsam版本",{"2":{"38":1}}],["如果标注人员达到一定规模",{"2":{"117":1}}],["如果前面的车突然在人行横道附近停在路上",{"2":{"116":1}}],["如果你安装过驱动",{"2":{"66":1}}],["如果你从来没有安装过nvidia驱动",{"2":{"66":1}}],["如果只有一个参数则表示截取从该位置到末尾",{"2":{"52":1}}],["如果它们仅以$结束",{"2":{"41":1}}],["如果行以^m$",{"2":{"41":1}}],["如果系统上已经设置了cuda",{"2":{"27":1}}],["如果生成模型只能生成和训练集一模一样的数据无法检测",{"2":{"20":1}}],["通信标准与人机交互进展",{"2":{"507":1}}],["通信系统等多个领域都有应用",{"2":{"137":1}}],["通讯作者",{"2":{"395":1}}],["通俗易懂版",{"2":{"207":1}}],["通道到高度",{"2":{"831":1}}],["通道的",{"2":{"828":1}}],["通道数",{"2":{"703":1}}],["通道一部分",{"2":{"507":1}}],["通道",{"2":{"173":1}}],["通常优于单模态模型",{"2":{"1005":1}}],["通常需要处理和分析大量的点云数据或多视角视觉信息",{"2":{"1004":1}}],["通常需要深度信息及已知的相机参数",{"2":{"435":1}}],["通常用作评估指标",{"2":{"998":1}}],["通常用于游戏引擎",{"2":{"961":1}}],["通常用互信息表示",{"2":{"826":1}}],["通常通过投影",{"2":{"942":1}}],["通常还提供一个可见性掩码",{"2":{"712":1}}],["通常被选为骨干网络",{"2":{"627":1}}],["通常被检测为孤立的原语",{"2":{"462":1}}],["通常会导致误检和漏检",{"2":{"625":1}}],["通常会抽象掉精确定位与底层传感器噪声",{"2":{"155":1}}],["通常的做法是用一个神经网络",{"2":{"619":1}}],["通常称为查询选择",{"2":{"471":1}}],["通常由体素级的重型",{"2":{"425":1}}],["通常辅以强化学习或基于规则惩罚",{"2":{"417":1}}],["通常以覆盖奖励",{"2":{"274":1}}],["通常借助",{"2":{"189":1}}],["通常",{"2":{"178":1,"274":1,"922":1,"962":1,"1004":1}}],["通常在",{"2":{"31":1}}],["通用流程",{"0":{"910":1,"942":1,"970":1}}],["通用地图需同时存储高分辨率几何与丰富语义",{"2":{"897":1}}],["通用型",{"2":{"897":1}}],["通用型地图",{"0":{"897":1}}],["通用视觉编码器在非驾驶相关细节上浪费精力",{"2":{"260":1}}],["通用",{"2":{"123":1,"951":1}}],["通过分解其占用网络并使用二值化卷积对其进行二值化",{"2":{"1004":1}}],["通过同时训练这些任务来实现相互增强",{"2":{"1003":1}}],["通过同时优化描述机器人轨迹的姿态图和kimera",{"2":{"131":1}}],["通过tensorrt",{"2":{"1001":1}}],["通过投影将3d点的强度值与其对应的2d图像特征拼接",{"2":{"976":1}}],["通过投影和图像主干网络分别提取多尺度激光雷达深度图和摄像头特征图",{"2":{"502":1}}],["通过移除动态融合模块中的",{"2":{"971":1}}],["通过移除lrell",{"2":{"752":1}}],["通过语义和占用任务特征的混合融合以及车辆之间共享的压缩正交注意力特征",{"2":{"969":1}}],["通过语音驱动接口桥接感知与交互",{"2":{"176":1}}],["通过共享连接的自动驾驶车辆之间的特征",{"2":{"969":1}}],["通过掩蔽对应动态元素的场景部分",{"2":{"967":1}}],["通过掩码",{"2":{"517":1}}],["通过引入更多的摄像头视角",{"2":{"957":1}}],["通过引入两个额外的平面",{"2":{"547":1}}],["通过融合多帧的特征图",{"2":{"957":1}}],["通过卷积",{"2":{"942":1}}],["通过卷积神经网络提取特征",{"2":{"169":1}}],["通过占用头",{"2":{"942":1}}],["通过2d到3d的转换",{"2":{"942":1}}],["通过2d到3d网络从环绕视角中提取3d体积特征",{"2":{"566":1}}],["通过体素流",{"2":{"941":1}}],["通过体素内点语义标签的多数投票确定体素的语义",{"2":{"735":1}}],["通过合并多个任务来学习交叉模态表示以获得最新的检测性能",{"2":{"931":1}}],["通过关系损失",{"2":{"928":1}}],["通过改变公式",{"2":{"928":1}}],["通过二元真实占用图监督分类器的训练",{"2":{"922":1}}],["通过空间分组池化和2d动态融合实现",{"2":{"898":1}}],["通过设置不同的分组参数值",{"2":{"882":1}}],["通过设置不同的深度",{"2":{"882":1}}],["通过设计动态稀疏卷积算子",{"2":{"824":1}}],["通过矩阵乘法和卷积实现占用预测",{"2":{"875":1}}],["通过不同深度的卷积层",{"2":{"875":1}}],["通过不同的相机参数将这些坐标转换为",{"2":{"369":1}}],["通过不同的",{"2":{"273":1}}],["通过利用无监督域适应管道来解决域移位问题",{"2":{"955":1}}],["通过利用原始的3d体素数据",{"2":{"875":1}}],["通过利用移位窗口机制",{"2":{"627":1}}],["通过注意力机制和迭代细化从输入图像中有效地学习3d高斯分布",{"2":{"861":1}}],["通过注册假定匹配来尝试估计环路闭合姿态",{"2":{"141":1}}],["通过重新定义场景表示和渲染的范式",{"2":{"860":1}}],["通过圆柱坐标变换将其投影到每个三视角平面上以采样相应的特征",{"2":{"858":1}}],["通过结合历史特征和当前感知输入的相关信息",{"2":{"957":1}}],["通过结合tpv特征",{"2":{"858":1}}],["通过结合这些互补的数据源",{"2":{"421":1}}],["通过数据增强来增加训练数据的多样性",{"2":{"839":1}}],["通过优化我们的",{"2":{"834":1}}],["通过交叉注意力实现2d到3d的转换",{"2":{"950":1}}],["通过交叉注意力机制隐式建模深度",{"2":{"821":1}}],["通过交叉注意力学习",{"2":{"441":1}}],["通过更大主干和输入尺寸扩大模型规模",{"2":{"805":1}}],["通过添加辅助三维目标检测监督",{"2":{"800":1}}],["通过比较",{"2":{"800":1}}],["通过比较hydra的三种不同配置",{"2":{"437":1}}],["通过高效学习技术",{"2":{"782":1}}],["通过拼接所有处理过的帧的全局掩码",{"2":{"793":1}}],["通过拼接",{"2":{"752":1}}],["通过视图变换获得多尺度的全局",{"2":{"768":1}}],["通过视图变换获得每个尺度的全局",{"2":{"746":1}}],["通过视觉",{"2":{"110":1}}],["通过后处理步骤对前一步骤中获得的体素进行细化",{"2":{"735":1}}],["通过局部聚合将3d高斯分布转换为密集的3d占用预测",{"2":{"716":1}}],["通过存储原始图像并在查询时用",{"2":{"698":1}}],["通过存储器队列的循环更新",{"2":{"695":1}}],["通过首先将3d信息编码到2d特征图中以提高效率",{"2":{"693":1}}],["通过深度神经网络分类器的连续决策边界隐式表示3d表面",{"2":{"665":1}}],["通过深度特征提取与端到端优化进一步提升了",{"2":{"588":1}}],["通过采样",{"2":{"660":1}}],["通过加性聚合对整体占用预测做出贡献",{"2":{"656":1}}],["通过加权聚合多模态特征",{"2":{"595":1}}],["通过预测语义类别c=",{"2":{"632":1}}],["通过预测周围",{"2":{"567":1}}],["通过预测周围三维空间中每个体素的占用状态",{"2":{"547":1}}],["通过我们的特征视线投影模块",{"2":{"632":1}}],["通过我们的特征视线投影",{"2":{"632":1}}],["通过平均每个体素内所有点的特征来获得该体素的特征表示",{"2":{"609":1}}],["通过稀疏卷积和3d可变形注意力获取足够的3d几何与语义信息后",{"2":{"595":1}}],["通过学习3d场景的密度和颜色场",{"2":{"860":1}}],["通过学习强大的bev表示",{"2":{"839":1}}],["通过学习相对欧几里德距离和方向距离来实现对几何变换的不变性",{"2":{"607":1}}],["通过学习的偏移量",{"2":{"595":1}}],["通过学习低级关系",{"2":{"481":1}}],["通过激光雷达深度图",{"2":{"595":1}}],["通过单目深度估计将2d特征扩展至3d",{"2":{"595":1}}],["通过其深度",{"2":{"592":1}}],["通过其具身",{"2":{"100":1}}],["通过池化聚合了局部特征信息",{"2":{"589":1}}],["通过扩展bev特征结合二者",{"2":{"585":1}}],["通过扩散在给定动作条件下预测未来相机帧",{"2":{"308":1}}],["通过从多个互补视图中重建3d信息",{"2":{"875":1}}],["通过从多视角图像中提取的综合特征更新高斯分布",{"2":{"629":1}}],["通过从鸟瞰图",{"2":{"576":1,"800":1}}],["通过从环视摄像头生成高质量的伪3d点云来增强视觉特征上下文中的深度信息和位置嵌入",{"2":{"438":1}}],["通过叠加多个dpams构造一个分层学习结构",{"2":{"574":1}}],["通过叠加多个提取层",{"2":{"420":1}}],["通过3d稀疏卷积模块对高斯进行自编码",{"2":{"563":1}}],["通过聚合邻近的高斯分布来为特定的3d位置生成语义占用预测",{"2":{"547":1}}],["通过提炼当前成果并勾勒开放方向",{"2":{"538":1}}],["通过累加所有高斯在位置",{"2":{"532":1}}],["通过对",{"2":{"977":1}}],["通过对每个类别的预测概率求和得到",{"2":{"814":1}}],["通过对每个特征通道取平均值",{"2":{"466":1}}],["通过对房间检测参数进行仔细调整",{"2":{"796":1}}],["通过对深度分布特征和深度感知上下文特征进行外积操作",{"2":{"621":1}}],["通过对激光雷达生成的真实3d点云和摄像头生成的伪3d点云进行体素化",{"2":{"527":1}}],["通过为规划栈提供丰富信息",{"2":{"520":1}}],["通过为pointnet学习的输入空间和函数空间构建一个查找表",{"2":{"420":1}}],["通过循环查询点的每个环上的核大小的邻域数组来定义环形卷积",{"2":{"511":1}}],["通过简单地降低",{"2":{"778":1}}],["通过简单地将前一帧的3d坐标与当前帧对齐",{"2":{"583":1}}],["通过简单地平均超点中点的特征来获得superpoint",{"2":{"384":1}}],["通过简单的二维卷积进行特征融合",{"2":{"576":1}}],["通过简单的二值化方法将卷积变换为1d",{"2":{"511":1}}],["通过mlp实现",{"2":{"511":1}}],["通过rpn",{"2":{"493":1}}],["通过核化密度估计和",{"2":{"481":1}}],["通过连接多个max",{"2":{"664":1}}],["通过连接所有先前层的特征来学习特征",{"2":{"481":1}}],["通过连接图像和点云特征",{"2":{"421":1}}],["通过几何和语义感知融合模块获得多模态体素特征",{"2":{"474":1}}],["通过查询选择",{"2":{"471":1}}],["通过应用",{"2":{"456":1}}],["通过选择网格的顶点",{"2":{"449":1}}],["通过整合更多的传感器信息",{"2":{"965":1}}],["通过整合雷达信息与相机",{"2":{"952":1}}],["通过整合雷达和激光雷达数据",{"2":{"944":1}}],["通过整合环视摄像头和激光雷达数据来执行3d语义占据预测任务",{"2":{"898":1}}],["通过整合激光雷达和雷达的特征来提高占据网络的准确性和鲁棒性",{"2":{"482":1}}],["通过整合激光雷达和摄像头数据",{"2":{"444":1}}],["通过整合来自其他传感器",{"2":{"475":1}}],["通过整体优化整个流水线",{"2":{"252":1}}],["通过与nuscenes数据集上的其他最新",{"2":{"438":1}}],["通过像素",{"2":{"435":1}}],["通过相对位移定位",{"2":{"435":1}}],["通过五个一维卷积层",{"2":{"420":1}}],["通过使用稀疏卷积层和掩码引导的稀疏采样来最小化计算成本",{"2":{"1004":1}}],["通过使用连续的",{"2":{"937":1}}],["通过使用相机可见掩码",{"2":{"800":1}}],["通过使用pcm",{"2":{"634":1}}],["通过使用smpl模型的beta参数",{"2":{"419":1}}],["通过使用kimera",{"2":{"419":1}}],["通过使用运动先验的位姿图优化来减轻人类位置误差",{"2":{"419":1}}],["通过模仿训练小交叉注意力头",{"2":{"417":1}}],["通过参数高效方法压缩模型用于部署",{"2":{"417":1}}],["通过获取的每个像素位置与cam对应类标签的关联性合成像素级的分割标签",{"2":{"410":1}}],["通过affinitynet估计图中连通像素对的语义相似度",{"2":{"410":1}}],["通过在一组子图姿态上应用图优化来构建全局一致的体积地图",{"2":{"967":1}}],["通过在该任务中探索跨模态知识蒸馏来解决这一问题",{"2":{"941":1}}],["通过在该位置观测到的感官输入",{"2":{"406":1}}],["通过在特定位置评估语义高斯分布的值并将它们相加",{"2":{"693":1}}],["通过在场景范围内采样点作为后续细化过程中的查询点",{"2":{"599":1}}],["通过在体素级特征上操作",{"2":{"535":1}}],["通过在提升的",{"2":{"444":1}}],["通过在3d度量语义模型上执行区域增长来检测房间",{"2":{"172":1}}],["通过超点交叉注意力来解码可学习的查询向量",{"2":{"405":1}}],["通过这种2d渲染监督",{"2":{"941":1}}],["通过这种重新参数化",{"2":{"390":1}}],["通过这个三阶段的过程",{"2":{"340":1}}],["通过微调dbow2",{"2":{"390":1}}],["通过构造",{"2":{"380":1}}],["通过构造一个score",{"2":{"235":1}}],["通过主干网络中提取出来的2d",{"2":{"369":1}}],["通过专门化专家混合领先排行榜",{"2":{"360":1}}],["通过一系列全连接层从标准化的点到节点的坐标学习单个点的特征",{"2":{"636":1}}],["通过一系列仿射变换",{"2":{"149":1}}],["通过一种新颖的",{"2":{"539":1}}],["通过一个",{"2":{"696":1}}],["通过一个走廊连接",{"2":{"522":1}}],["通过一个x",{"2":{"511":1}}],["通过一个正确的单应矩阵h",{"2":{"355":1}}],["通过一致性指标评估整个推理链逻辑一致性",{"2":{"360":1}}],["通过基于八叉树的顶点聚类网格简化方法计算简化的网格",{"2":{"380":1}}],["通过基于",{"2":{"349":1}}],["通过",{"2":{"340":1,"405":1,"474":1,"481":1,"495":1,"502":1,"660":1,"844":1,"863":1}}],["通过调整输入分辨率",{"2":{"1004":1}}],["通过调整",{"2":{"944":1}}],["通过调节标量",{"2":{"304":1}}],["通过调控信息保留的多少",{"2":{"287":1}}],["通过包含",{"2":{"302":1}}],["通过膨胀距离δ",{"2":{"276":1}}],["通过洪水填充将gvd体素标记为最近的节点id",{"2":{"276":1}}],["通过原论文里的两张图可以看到",{"2":{"264":1}}],["通过最小化不同视角之间的光度差异来鼓励时空一致性",{"2":{"988":1}}],["通过最小化全局class",{"2":{"591":2}}],["通过最小化模型的对数密度梯度",{"2":{"235":1}}],["通过最小化原始信号",{"2":{"137":1}}],["通过降维我们可以过滤掉一些不太重要的信息",{"2":{"227":1}}],["通过郎之万动力学的迭代过程从任意一个分布走到目标分布",{"2":{"225":1}}],["通过内积值的大小来判断新文本和图像是否是匹配的",{"2":{"204":1}}],["通过噪声level",{"2":{"175":1}}],["通过全局优化",{"2":{"171":1}}],["通过统一感知与自然语言推理至共享嵌入空间",{"2":{"128":1}}],["通过向公众发布部分数据",{"2":{"126":1}}],["通过允许在紧凑的抽象上进行规划",{"2":{"125":1}}],["通过端到端学习模型将多视角传感器输入转换为统一的俯视图",{"2":{"123":1}}],["通过llm",{"2":{"121":1}}],["通过极坐标点编码进一步优化bev表示",{"2":{"114":1}}],["通过自注意力机制",{"2":{"603":1}}],["通过自回归的方式学习点块的潜在表示",{"2":{"315":1}}],["通过自身的传感器和执行器感知并与环境交互",{"2":{"110":1}}],["通过自然语言任务",{"2":{"109":1}}],["通过以这种方式组织方法",{"2":{"90":1}}],["通过将不同模态的3d特征体积沿特征通道拼接",{"2":{"976":1}}],["通过将雷达信息与相机合并",{"2":{"952":1}}],["通过将3d空间分解为这些单独的视图表示",{"2":{"908":1}}],["通过将视角信息从3d场景特征中分离或将其投影到统一的表示空间中",{"2":{"908":1}}],["通过将这个look",{"2":{"833":1}}],["通过将长程依赖",{"2":{"824":1}}],["通过将单个二维任务特征反向投影到三维空间来实现",{"2":{"603":1}}],["通过将聚矩阵和点矩阵相乘来实现",{"2":{"574":1}}],["通过将每个点与点云中所有其他点连接来构造图",{"2":{"607":1}}],["通过将每个高斯解释为其邻域被占用的概率分布",{"2":{"567":1}}],["通过将每个网格转换为点云",{"2":{"449":1}}],["通过将",{"2":{"564":1,"596":1}}],["通过将图像检索和图像集合中的联合分割相结合",{"2":{"469":1}}],["通过将多维数据转换成一维的比特串",{"2":{"340":1}}],["通过将点云分割成块状的子集",{"2":{"340":1}}],["通过将2d标签纹理到网格上",{"2":{"336":1}}],["通过将高维冗余数据从像素空间投影到潜在空间的超空间来实现这一点",{"2":{"270":1}}],["通过将原始数据编码到更小的空间中",{"2":{"205":1}}],["通过将地图分解为可以在环路闭合后刚性对齐的子图来校正体积表示中的漂移",{"2":{"190":1}}],["通过将控制器条件于语言token",{"2":{"82":1}}],["通过将像素与文本对齐",{"2":{"82":1}}],["通过vim编辑工具打开文件",{"2":{"41":1}}],["通过计算空间中每个点到最近物体表面的距离来构建",{"2":{"31":1}}],["它表明",{"2":{"1000":1}}],["它表明加入雷达信息显著增强了框架在长距离处感知物体的能力",{"2":{"944":1}}],["它整合了环视相机",{"2":{"977":1}}],["它促进了开放词汇任务",{"2":{"975":1}}],["它假设不同的2d视角对感知3d场景的贡献是等效的",{"2":{"957":1}}],["它建立了从特征体积到特征图的几何映射",{"2":{"950":1}}],["它仍然在预测细小物体",{"2":{"989":1}}],["它仍然能够建模细粒度结构",{"2":{"547":1}}],["它仍可显著提升模型的整体性能",{"2":{"936":1}}],["它首先从多摄像头图像中提取前视特征图",{"2":{"942":1}}],["它首先构建低分辨率查询以预测粗略占用",{"2":{"922":1}}],["它首先通过解析度量",{"2":{"285":1}}],["它衡量两个高斯分布之间的相似性",{"2":{"916":1}}],["它直接用2d卷积替换体素基占用方法中的3d卷积",{"2":{"908":1}}],["它直接替换体素级占据方法中的3d卷积为2d卷积",{"2":{"831":1}}],["它只需存储一个cad模型",{"2":{"905":1}}],["它只计算clio输入的3d对象原语集合",{"2":{"431":1}}],["它处理来自激光雷达的密集",{"2":{"867":1}}],["它要求系统能够同时应对",{"2":{"864":1}}],["它还会混淆语义相似的类别",{"2":{"992":1}}],["它还能推断出更精细的被遮挡的几何结构",{"2":{"903":1}}],["它还引入了3d",{"2":{"839":1}}],["它还解决了单目相机深度估计不佳的问题",{"2":{"625":1}}],["它与",{"2":{"824":1,"867":1}}],["它与现有文献不同",{"2":{"570":1}}],["它接受单目图像作为输入",{"2":{"793":1}}],["它接收场景的所有原语",{"2":{"431":1}}],["它接收立体图像和imu数据",{"2":{"285":1}}],["它为未来的工作提供了一个有前景的方向",{"2":{"958":1}}],["它为3d场景理解提供了灵活且可扩展的表示",{"2":{"780":1}}],["它为信号",{"2":{"137":1}}],["它仅使用最先进方法17",{"2":{"1004":1}}],["它仅使用相机输入",{"2":{"599":1}}],["它仅关注理解空间几何",{"2":{"998":1}}],["它仅关注占用的体素以细化结果",{"2":{"922":1}}],["它仅对整幅图像做全局匹配",{"2":{"765":1}}],["它从大量未标注的图像中学习占用感知",{"2":{"1006":1}}],["它从视觉视锥的角度提供线索以缓解遮挡模糊性",{"2":{"985":1}}],["它从单张图像中预测室内场景中所有体素的占用状态和语义信息",{"2":{"759":1}}],["它从图像输入中预测自动驾驶车辆周围3d体素网格的空间占用状态和语义信息",{"2":{"637":1}}],["它引入了辅助光线的概念",{"2":{"941":1}}],["它引入了语义引导的八叉树初始化模块和迭代细化模块",{"2":{"922":1}}],["它引入了一种称为2d特征视线投影",{"2":{"875":1}}],["它引入了一个动态的点云采样模块",{"2":{"356":1}}],["它引入了openoccupancy",{"2":{"757":1}}],["它包含大约",{"2":{"828":1}}],["它包含5504",{"2":{"793":1}}],["它包含64",{"2":{"793":1}}],["它包含850个序列",{"2":{"757":2}}],["它包含1",{"2":{"757":1}}],["它包括拥挤的室内和室外场景",{"2":{"131":1}}],["它甚至通过在缺乏语义标注的区域完成占据",{"2":{"745":1}}],["它基于nuscenes",{"2":{"736":1}}],["它捕捉了bev感知忽略的环境高度信息",{"2":{"714":1}}],["它捕获点云局部区域中不同区域之间的相关性",{"2":{"664":1}}],["它输出这些高斯分布的深度感知特征",{"2":{"705":1}}],["它由两个主要组件组成",{"2":{"726":1}}],["它由多层卷积网络",{"2":{"703":1}}],["它由视觉分支",{"2":{"670":1}}],["它由一个两层的多层感知机",{"2":{"549":1}}],["它以空间维度为h×w×dh",{"2":{"752":1}}],["它以相同的方式使用语义属性",{"2":{"656":1}}],["它以提取的令牌",{"2":{"549":1}}],["它较少被用于3d占用预测",{"2":{"612":1}}],["它采用tpv作为潜在的自我空间表示",{"2":{"858":1}}],["它采用2d到3d的反向投影来提升2d图像",{"2":{"841":1}}],["它采用",{"2":{"599":1}}],["它能够准确识别出隐藏在柱子后面的部分遮挡行人",{"2":{"847":1}}],["它能够将非结构化数据转换为体素体积",{"2":{"780":1}}],["它能够在下采样的时候",{"2":{"589":1}}],["它能够预测周围场景的精细几何形状和语义信息",{"2":{"536":1}}],["它指定了元素被插入的位置",{"2":{"571":1}}],["它可能可重复用于各种任务",{"2":{"552":1}}],["它可以帮助做出更安全的驾驶决策",{"2":{"1003":1}}],["它可以提高现有地点识别",{"2":{"1003":1}}],["它可以处理深度感知中的不确定性和模糊性",{"2":{"950":1}}],["它可以保留所有对象",{"2":{"905":1}}],["它可以很容易地转换为三维空间占用预测",{"2":{"750":1}}],["它可以被用来作为一个计算机视觉领域一个通用的骨干网络",{"2":{"631":1}}],["它可以通过",{"2":{"349":1}}],["它可以直接生成256x256和512x512甚至更高分辨率的图像",{"2":{"205":1}}],["它可以表示环境中每个点到最近障碍物的欧氏距离",{"2":{"31":1}}],["它利用一系列3d高斯函数来表示空间中的稀疏兴趣区域",{"2":{"1004":1}}],["它利用局部语义熵来鼓励更锐利的语义和几何梯度",{"2":{"985":1}}],["它利用3d卷积处理多个单模态表示以确定其融合权重",{"2":{"976":1}}],["它利用冻结的2d分割器和文本编码器获取开放词汇语义参考",{"2":{"975":1}}],["它利用骨干网络提取多尺度语义特征",{"2":{"627":1}}],["它利用多个关系先验",{"2":{"603":1}}],["它利用预训练的深度模型估计像素级深度图",{"2":{"544":1}}],["它利用迭代最近点",{"2":{"189":1}}],["它面临复杂形状缺失问题",{"2":{"535":1}}],["它面临长尾缺陷问题",{"2":{"535":1}}],["它断言代码的质量",{"2":{"510":1}}],["它计算一个与规范方向对齐的边界框",{"2":{"449":1}}],["它计算每个可能合并相邻聚类",{"2":{"153":1}}],["它实时接收原语以进行实时映射",{"2":{"431":1}}],["它执行",{"2":{"431":1}}],["它",{"2":{"390":1}}],["它也利用透视投影来建立2d和3d之间的对应关系",{"2":{"950":1}}],["它也是第一个使用掩码分类模型mask2former",{"2":{"875":1}}],["它也被用于",{"2":{"603":1}}],["它也接受可学习的语义和实例queries作为输入",{"2":{"384":1}}],["它也能够拒绝错误的环路闭合作为异常值",{"2":{"380":1}}],["它也可以提供很多信息",{"2":{"106":1}}],["它保持了原始",{"2":{"369":1}}],["它集成了点和网格的表示",{"2":{"363":1}}],["它提出了掩码引导的稀疏采样",{"2":{"922":1}}],["它提出了显式",{"2":{"875":1}}],["它提出了一个基于transformer的点云解码器",{"2":{"356":1}}],["它提供稀疏的",{"2":{"952":1}}],["它提供了几个基线模型",{"2":{"975":1}}],["它提供了对遮挡不敏感且包含一定深度几何信息的特征",{"2":{"839":1}}],["它提供了60×60×36体素网格的帧",{"2":{"793":1}}],["它提供了9个长序列的地面真实标签",{"2":{"781":1}}],["它提供",{"2":{"285":1}}],["它设计了一个通用的点云编码器",{"2":{"356":1}}],["它对环境中的物体与场所提供更丰富",{"2":{"350":1}}],["它对多尺度特征对齐同时融合不同层是有效的",{"2":{"96":1}}],["它有着广泛的应用",{"2":{"331":1}}],["它有以下几个主要优点",{"2":{"275":1}}],["它构成了我们的vio后端",{"2":{"310":1}}],["它构建了一个3d对象图",{"2":{"121":1}}],["它构建了一个可以渲染场景密集clip向量的辐射场",{"2":{"121":1}}],["它是一个多模态数据集",{"2":{"302":1}}],["它不仅继承了毫米波雷达在所有光照和天气条件下的鲁棒性",{"2":{"1005":1}}],["它不仅需要区分语义不同的点",{"2":{"983":1}}],["它不仅提升了最终框架的性能",{"2":{"959":1}}],["它不仅编码空间几何信息",{"2":{"90":1}}],["它不包含雷达",{"2":{"302":1}}],["它代表了当前场景中已探索的区域",{"2":{"793":1}}],["它代表",{"2":{"285":1}}],["它已经存储了到最近障碍物的距离",{"2":{"253":1}}],["它使场景观察更加密集",{"2":{"691":1}}],["它使用参数化占用场处理无界的室外场景",{"2":{"949":1}}],["它使用了相同的",{"2":{"928":1}}],["它使用了l层网络从2d",{"2":{"594":1}}],["它使用数百万个3d高斯函数以显式方式表示场景",{"2":{"860":1}}],["它使用矢量化的局部协方差矩阵和点坐标的级联作为输入",{"2":{"574":1}}],["它使用柱坐标系来更好地保留每种传感器模态的细粒度几何信息",{"2":{"438":1}}],["它使用标准的现成深度网络",{"2":{"408":1}}],["它使用修改版的成对一致测量集最大化",{"2":{"390":1}}],["它使用imu旋转来修剪特征轨迹中的异常对应关系",{"2":{"310":1}}],["它使用检测到的循环闭合",{"2":{"285":1}}],["它使用rgb",{"2":{"285":1}}],["它使用传感器数据填充dsg节点和边",{"2":{"285":1}}],["它使用任务驱动的度量",{"2":{"153":1}}],["它使得信息瓶颈算法能够更加高效地处理动态环境中的数据流",{"2":{"153":1}}],["它通过观察当前和历史数据来模拟和预测周围环境的未来状态",{"2":{"1003":1}}],["它通过引入占用稀疏模块探索3d空间的稀疏性",{"2":{"922":1}}],["它通过追踪光线检查汽车的每个姿势中哪些体素对传感器可见",{"2":{"757":1}}],["它通过叠加未来帧",{"2":{"757":1}}],["它通过局部优化区域高斯分布逐渐获得知识",{"2":{"568":1}}],["它通过一种新颖的3d场景图优化方法",{"2":{"467":1}}],["它通过迭代合并相邻原语来形成任务相关聚类",{"2":{"153":1}}],["它通过截断",{"2":{"31":1}}],["它被用来评估变量之间的依赖性",{"2":{"137":1}}],["它量化了一个随机变量包含关于另一个随机变量的信息量",{"2":{"137":1}}],["它的特征是通过一种叫做移动窗口的方式学来的",{"2":{"631":1}}],["它的编码器遵循pointnet的设计",{"2":{"420":1}}],["它的计算方式是精确率",{"2":{"263":1}}],["它的作用是生成图像",{"2":{"133":1}}],["它的输入参数是",{"2":{"129":1}}],["它将不同传感器输入整合为统一的占用表示",{"2":{"1003":1}}],["它将所有类别的iou分数总和除以类别数量",{"2":{"1000":1}}],["它将交叉熵分类损失和每个预测掩码段的二元掩码损失结合起来",{"2":{"985":1}}],["它将类别视为独立实体",{"2":{"985":1}}],["它将输入图像的视锥特征视为密度场",{"2":{"949":1}}],["它将3d空间中每个整个柱体的特征提取为相应bev网格的特征",{"2":{"821":1}}],["它将被预测为被占用",{"2":{"681":1}}],["它将被终止",{"2":{"206":1}}],["它将亲和点选择和紧凑的特征聚合结合到使用点积自关注的软对齐操作中",{"2":{"664":1}}],["它将2d感知视图特征映射到bev表示",{"2":{"655":1}}],["它将细粒度特征与直接上采样的粗粒度特征集成",{"2":{"627":1}}],["它将图像特征转换为鸟瞰图",{"2":{"599":1}}],["它将大尺度环境抽象为",{"2":{"525":1}}],["它将其他模块的结果收集到一个",{"2":{"408":1}}],["它将点云中的潜在特征分组为",{"2":{"349":1}}],["它将点云分割成不规则的点块",{"2":{"315":1}}],["它将多视图特征简单地聚合到一个全局描述符中",{"2":{"337":1}}],["它将无法分割在开放式平面图中语义上不同的房间",{"2":{"301":1}}],["它将密集的3d模型",{"2":{"162":1}}],["它将高层符号推理",{"2":{"123":1}}],["它将positive",{"2":{"54":1}}],["它在计算机图形中广泛用于碰撞检查",{"2":{"905":1}}],["它在多样化的车载平台上展现出更强的部署灵活性",{"2":{"598":1}}],["它在多个点云分割的数据集上进行了实验",{"2":{"356":1}}],["它在机器人探索环境时构建一个3d场景图",{"2":{"586":1}}],["它在所有可比基线方法上均表现出色",{"2":{"570":1}}],["它在所有特征中表现最好",{"2":{"143":1}}],["它在高度维度上减少了特征表示以提高计算效率",{"2":{"566":1}}],["它在分类中使用融合特征",{"2":{"512":1}}],["它在",{"2":{"304":1}}],["它在尽可能减少表示的复杂度的同时",{"2":{"153":1}}],["它在不同的抽象层次上捕捉场景的3d几何和语义",{"2":{"147":1}}],["它在lerf的基础上使用高斯溅射创建了一个3d场景语言地图",{"2":{"121":1}}],["它在线构建环境的层次化3d场景图",{"2":{"98":1}}],["它们利用体积渲染和光度一致性来获取自监督信号",{"2":{"1000":1}}],["它们利用图像数据或预训练模型来获取这些标签",{"2":{"949":1}}],["它们会显著影响整体miou值",{"2":{"1000":1}}],["它们仅生成稀疏特征",{"2":{"970":1}}],["它们仅保存稀疏地标",{"2":{"525":1}}],["它们计算每个体素的嵌入",{"2":{"957":1}}],["它们仍能实现相当的准确性",{"2":{"949":1}}],["它们仍能实现相当的性能",{"2":{"875":1}}],["它们仍然依赖于lidar点云提供深度或语义标签来监督渲染图",{"2":{"941":1}}],["它们使用",{"2":{"865":1}}],["它们可以高速运行",{"2":{"857":1}}],["它们实际上是模型的学习目标",{"2":{"716":1}}],["它们能产生紧凑",{"2":{"619":1}}],["它们将空间坐标",{"2":{"619":1}}],["它们在当前更新中只会被轻微调整",{"2":{"728":1}}],["它们在当前更新中将被轻微更新",{"2":{"728":1}}],["它们在自编码和图像交叉注意力模块中隐式地编码3d信息",{"2":{"716":1}}],["它们在建模环境时仍然会考虑空区域",{"2":{"567":1}}],["它们在复杂动态环境中展现出更强的鲁棒性与效率",{"2":{"252":1}}],["它们无法捕捉任意形状的障碍物",{"2":{"567":1}}],["它们通常被视为一般障碍物",{"2":{"975":1}}],["它们通常依赖非结构化的记忆机制",{"2":{"252":1}}],["它们通过把几何结构与语义内容耦合在一起",{"2":{"556":1}}],["它们取khronos和conceptgraphs的结果",{"2":{"431":1}}],["它们增量地构建",{"2":{"408":1}}],["它们要比直接采用一个从零训练好的模型要好",{"2":{"373":1}}],["它们指向实时口头证明行动的对话式自动驾驶车辆",{"2":{"334":1}}],["它们解释",{"2":{"334":1}}],["它们常依赖多阶段流水线",{"2":{"283":1}}],["它们是任务驱动聚类的基础",{"2":{"271":1}}],["它们被传递到场景图前端",{"2":{"253":1}}],["它们之间有一扇门连接",{"2":{"218":1}}],["它们的占用头部使用两个独立的mlp",{"2":{"957":1}}],["它们的信息可能无法整合",{"2":{"950":1}}],["它们的性能仍然有限",{"2":{"1000":1}}],["它们的性能受到了很大限制",{"2":{"949":1}}],["它们的性能差异是由于clio",{"2":{"462":1}}],["它们的标记被设置为1",{"2":{"728":1}}],["它们的概率分布是分散的并且不能集中到一个峰值",{"2":{"622":1}}],["它们的主要区别在于代理是时变实体",{"2":{"178":1}}],["它们的大小应该只随着它们建模的环境的大小增长",{"2":{"125":1}}],["它们应该允许机器人收集新证据时进行更正",{"2":{"125":1}}],["它们需要扩展到大型环境",{"2":{"125":1}}],["它们需要对场景的整体理解",{"2":{"116":1}}],["它们必须能够在长距离和长时间范围内规划和行动以支持终身运行",{"2":{"116":1}}],["它们推理场景",{"2":{"82":1}}],["它结合了快速的早期和中级感知过程",{"2":{"112":1,"141":1}}],["它允许开发者显式地定义他们的",{"2":{"57":1}}],["是排除",{"2":{"1000":1}}],["是cvpr",{"2":{"1000":1}}],["是两个基于占用的工作",{"2":{"1003":1}}],["是两个基于自监督学习的代表性占用工作",{"2":{"1000":1}}],["是两个新数据集",{"2":{"997":1}}],["是两个聚类的概率分布差异的度量",{"2":{"153":1}}],["是广泛用于2d语义感知方法的基准",{"2":{"997":1}}],["是广泛的实验评估和新照片级逼真数据集的发布",{"2":{"131":1}}],["是根据类别频率的倒数分配的特定类别",{"2":{"985":1}}],["是真实和预测的语义占用",{"2":{"985":1}}],["是真实的数据",{"2":{"129":1}}],["是占用体积",{"2":{"985":1}}],["是主要评价指标",{"2":{"979":1}}],["是不同的",{"2":{"1000":1}}],["是不可行的",{"2":{"974":1}}],["是不稳定的",{"2":{"129":1}}],["是其在特定2d视角上的投影位置",{"2":{"957":1}}],["是3d空间中的查询位置",{"2":{"957":1}}],["是摄像头的内参和外参矩阵",{"2":{"950":1}}],["是摄像头的数量",{"2":{"780":1}}],["是从2d到3d的转换",{"2":{"950":1}}],["是从有限观察中同时估计给定范围内3d环境的几何和语义的任务",{"2":{"841":1}}],["是像素坐标",{"2":{"942":1}}],["是特征提取器",{"2":{"910":1}}],["是长度",{"2":{"910":1}}],["是则抛出",{"2":{"904":1}}],["是缺乏一套统一",{"2":{"864":1}}],["是灵活的",{"2":{"844":1}}],["是对应的2d前视特征图",{"2":{"957":1}}],["是对应于第",{"2":{"844":1}}],["是对角矩阵构造函数",{"2":{"532":1}}],["是基于弱监督学习表现最好的方法",{"2":{"1000":1}}],["是基于",{"2":{"828":1}}],["是基于nuscenes",{"2":{"757":1}}],["是可学习的权重",{"2":{"950":1,"970":1}}],["是可变形卷积",{"2":{"824":1}}],["是可操作空间感知的统一表示",{"2":{"131":1}}],["是具有非常大的内核的深度卷积",{"2":{"824":1}}],["是具身空间占用预测模型",{"2":{"682":1}}],["是具身智能体迄今为止收集的rgb序列及其对应的外参",{"2":{"682":1}}],["是均值位于占用空间中的高斯数量的百分比",{"2":{"812":1}}],["是该场景在世界坐标系中的范围",{"2":{"793":1}}],["是该领域的开创性工作",{"2":{"599":1}}],["是使用密集占用标注进行监督的",{"2":{"842":1}}],["是使用激光雷达分割标签进行训练的",{"2":{"842":1}}],["是使用单目摄像头进行室外场景占用感知的开创性工作",{"2":{"759":1}}],["是使用在每次迭代中具有不同分割方向的多个k",{"2":{"636":1}}],["是这些高斯分布在世界坐标系中的均值和旋转四元数",{"2":{"728":1}}],["是这一能力的直接体现",{"2":{"629":1}}],["是高维特征向量",{"2":{"716":1}}],["是高斯分布的总数",{"2":{"705":1}}],["是我们在第3",{"2":{"716":1}}],["是采样函数",{"2":{"705":1}}],["是前景区域网格的总和",{"2":{"694":1}}],["是次优的",{"2":{"684":1}}],["是提出的单目预测模型",{"2":{"682":1}}],["是提出任务驱动的3d场景理解问题",{"2":{"109":1}}],["是各损失的加权和",{"2":{"670":1}}],["是有价值的",{"2":{"667":1}}],["是有一些挑战的",{"2":{"631":1}}],["是焦点损失",{"2":{"666":1}}],["是点云中的目标数量",{"2":{"666":1}}],["是另一个基于rnn的模型",{"2":{"664":1}}],["是透视投影",{"2":{"660":1}}],["是位置",{"2":{"656":1}}],["是构建更优表征的关键",{"2":{"648":1}}],["是离散拓扑文献",{"2":{"640":1}}],["是因为vit",{"2":{"631":1}}],["是双视图一致的",{"2":{"592":1}}],["是工业设施的内部",{"2":{"572":1}}],["是四元数到旋转矩阵的转换函数",{"2":{"532":1}}],["是表示场景的高斯总数",{"2":{"532":1}}],["是在德国中型城市卡尔斯鲁厄的住宅场景和狭窄街道上进行训练的",{"2":{"995":1}}],["是在",{"2":{"623":1}}],["是在正式任务前进行",{"2":{"525":1}}],["是在第k次合并操作前",{"2":{"153":1}}],["是在第k次合并操作后",{"2":{"153":1}}],["是自动驾驶车辆",{"2":{"520":1}}],["是自动驾驶领域中一个快速崛起且具有挑战性的感知任务",{"2":{"425":1}}],["是最常见的类型",{"2":{"1000":1}}],["是最常用的性能评估标准",{"2":{"263":1}}],["是最常用的性能标准",{"2":{"263":1}}],["是最常用的标准",{"2":{"263":1}}],["是最稠密的",{"2":{"465":1}}],["是首个采用基于高斯的对象中心场景表示的多模态语义占据网络",{"2":{"444":1}}],["是嵌入维数",{"2":{"405":1}}],["是局部平移",{"2":{"390":1}}],["是围绕顶点",{"2":{"390":1}}],["是顶点",{"2":{"390":1}}],["是某个网格顶点",{"2":{"390":1}}],["是否采用轻量化的网络设计",{"2":{"877":1}}],["是否使用多帧信息进行时间融合",{"2":{"877":1}}],["是否使用多相机输入",{"2":{"877":1}}],["是否使用激光雷达",{"2":{"547":1}}],["是否为空",{"0":{"795":1}}],["是否已被智能体探索",{"2":{"406":1}}],["是否与里程计",{"2":{"390":1}}],["是否继续安装",{"2":{"66":1}}],["是更新的每个顶点特征",{"2":{"372":1}}],["是输出后的",{"2":{"351":1}}],["是选择生成的维度",{"2":{"351":1}}],["是生成数据的维度大小",{"2":{"351":1}}],["是完成复杂任务的关键",{"2":{"350":1}}],["是站在巨人的肩膀上发展起来的",{"2":{"302":1}}],["是图像编码器对生成图和原图的编码向量差",{"2":{"268":1}}],["是评估场景完成和语义分割性能的两个不同指标",{"2":{"778":1}}],["是评估",{"2":{"263":1}}],["是步长",{"2":{"256":1}}],["是用于从复杂分布中获取随机样本的统计学算法",{"2":{"256":1}}],["是把特定降质下的图片还原成好看的图像",{"2":{"220":1}}],["是存储",{"2":{"196":1}}],["是迭代器",{"2":{"177":1}}],["是归一化常数",{"2":{"153":1}}],["是原始表示",{"2":{"153":1}}],["是杰森",{"2":{"153":1}}],["是符合均匀分布或者高斯分布的随机向量",{"2":{"149":1}}],["是",{"2":{"137":3,"149":1,"372":1,"694":2,"741":1}}],["是转换后的随机噪声",{"2":{"133":1}}],["是指每个高斯分布对应的两个像素坐标",{"2":{"705":1}}],["是指在深度估计模块中用于表示深度分布的离散化区间",{"2":{"621":1}}],["是指在信息瓶颈",{"2":{"153":1}}],["是指在将两个或多个对象原语",{"2":{"153":1}}],["是指数据集中人脸的主要属性",{"2":{"133":1}}],["是指最后一个元素再下一个位置",{"2":{"104":1}}],["是展示可以在dsg上实现的潜在查询",{"2":{"131":1}}],["是第一个为室外驾驶场景提供3d占用标签的数据集",{"2":{"1000":1}}],["是第一个基于视觉的协同语义占用预测框架",{"2":{"969":1}}],["是第一个从传感器数据构建场景图的引擎",{"2":{"131":1}}],["是第一个提供自动驾驶车辆整个传感器套件数据的大规模数据集",{"2":{"126":1}}],["是kimera",{"2":{"131":1}}],["是由一段一段的定量连续空间构成",{"2":{"871":1}}],["是由与姿态",{"2":{"390":1}}],["是由",{"2":{"126":1,"133":1}}],["是一类专门编码",{"2":{"619":1}}],["是一类连续函数",{"2":{"619":1}}],["是一样的",{"2":{"198":1}}],["是一系列时间戳的3d姿态",{"2":{"178":1}}],["是一个有前景的研究方向",{"2":{"975":1}}],["是一个有前景的解决方案",{"2":{"665":1}}],["是一个有趣的研究方向",{"2":{"969":1}}],["是一个大规模数据集",{"2":{"781":1}}],["是一个大规模的三维占据预测基准数据集",{"2":{"736":1}}],["是一个广泛用于3d占用预测的数据集",{"2":{"757":1}}],["是一个平衡因子",{"2":{"750":1}}],["是一个自然的方向",{"2":{"973":1}}],["是一个自动生成的占据预测数据集",{"2":{"736":1}}],["是一个自定义的浅层编码器",{"2":{"632":1}}],["是一个高度不平衡的任务",{"2":{"684":1}}],["是一个众所周知的病态问题",{"2":{"660":1}}],["是一个小常数",{"2":{"623":1}}],["是一个二进制掩码",{"2":{"623":1}}],["是一个可学习的过程吗",{"2":{"496":1}}],["是一个可操作的空间表示",{"2":{"147":1}}],["是一个基于encoder",{"2":{"345":1}}],["是一个实际的问题",{"2":{"331":1}}],["是一个核心的问题",{"2":{"331":1}}],["是一个关键的问题",{"2":{"331":1}}],["是一个开源库",{"2":{"285":1}}],["是一个低通滤波器加上一系列降维再升维保持图像维度不变的过程",{"2":{"264":1,"266":1}}],["是一个指标",{"2":{"221":1}}],["是一个随机过程",{"2":{"188":1}}],["是一个分层和层次化的表示",{"2":{"162":1}}],["是一个分层图",{"2":{"125":1}}],["是一个超参数权重",{"2":{"988":1}}],["是一个超参数",{"2":{"153":1}}],["是一个视觉",{"2":{"131":1}}],["是一个博弈问题",{"2":{"129":1}}],["是一个判别网络",{"2":{"129":1}}],["是一个生成网络",{"2":{"129":1}}],["是一种衡量两个点云之间距离的指标",{"2":{"582":1}}],["是一种给予近期数据更高权重的平均方法",{"2":{"528":1}}],["是一种度量地图",{"2":{"465":1}}],["是一种常用的点云处理网络",{"2":{"456":1}}],["是一种常见的中介表示",{"2":{"123":1}}],["是一种优化策略",{"2":{"153":1}}],["是一种欧几里得有符号距离场",{"2":{"31":1}}],["是一种带符号的距离函数",{"2":{"31":1}}],["是一种间接的对图片质量评估的方法",{"2":{"13":1}}],["是将第",{"2":{"957":1}}],["是将语义概念",{"2":{"116":1}}],["是将提出的任务驱动聚类算法集成到一个实时系统中",{"2":{"109":1}}],["是将",{"2":{"109":1}}],["是通过机器人使用地图来完成任务的能力来衡量的",{"2":{"109":1}}],["是体素化",{"2":{"950":1}}],["是体素体积的长度",{"2":{"780":1}}],["是体素",{"2":{"31":1}}],["是截断距离",{"2":{"31":1}}],["​i",{"2":{"988":1}}],["​if",{"2":{"666":1}}],["​evic​​",{"2":{"985":1}}],["​\\t多源输入包括来自多个传感器",{"2":{"780":1}}],["​\\t\\tx",{"2":{"188":1}}],["​∣si​∣wi​​x∑w​y∑l​z∑h​si",{"2":{"694":1}}],["​∣si​∣wi​​x∑w​y∑l​si",{"2":{"694":1}}],["​−f",{"2":{"694":2}}],["​×",{"2":{"694":2}}],["​1​​",{"2":{"647":1}}],["​p∈pvalid​∑​​dgt​",{"2":{"647":1}}],["​logqσ​",{"2":{"235":1}}],["​dx=f",{"2":{"208":1}}],["​xt​+1−αˉt​αˉt−1​​βt​​αˉt​​1​",{"2":{"140":1,"280":1}}],["​xt​+1−αˉt​αˉt−1​​βt​​x0​​​",{"2":{"140":1,"280":1}}],["​+1−αˉt​αˉt−1​​x0​βt​​=1−αˉt​αt​​",{"2":{"140":1,"280":1}}],["​∼n",{"2":{"140":1,"280":1}}],["​​+unconditional",{"2":{"513":1}}],["​​δt​ε​",{"2":{"273":1}}],["​​​​",{"2":{"513":1}}],["​​​",{"2":{"235":1}}],["​​∝exp",{"2":{"140":1,"280":1}}],["​​",{"2":{"140":2,"208":1,"273":1,"280":2,"342":1,"372":1,"916":1}}],["​=ψs​",{"2":{"957":1}}],["​=34​π",{"2":{"916":1}}],["​=∇logp",{"2":{"513":1}}],["​=vi​+δvi​",{"2":{"372":1}}],["​=p",{"2":{"208":1}}],["​=f",{"2":{"208":1}}],["​=1−αˉt​1−αˉt−1​​βt​​​",{"2":{"140":1,"280":1}}],["​=q",{"2":{"140":1,"280":1}}],["​=μx2​+μy2​+c1​2μx​μy​+c1​​=σx2​+σy2​+c2​2σx​σy​+c2​​=σx​σy​+c3​σxy​+c3​​​​​",{"2":{"8":1}}],["​",{"2":{"31":1,"137":1,"140":3,"153":5,"213":1,"235":6,"268":1,"269":1,"273":1,"280":3,"316":1,"342":1,"372":4,"400":1,"660":1,"752":1,"794":1,"814":1,"957":1}}],["而miou分数低于30",{"2":{"1000":1}}],["而miou评估了语义占用感知的性能",{"2":{"1000":1}}],["而meshcnn根据边进行上下采样",{"2":{"589":1}}],["而openscene包含约4m标注帧",{"2":{"997":1}}],["而waymo包含更多的场景",{"2":{"997":1}}],["而视野外的性能显著较低",{"2":{"989":1}}],["而视角分解方法通常表现出更好的实时性能和更低的内存使用",{"2":{"922":1}}],["而zheng和pronobis",{"2":{"967":1}}],["而更近期的工作集中在联合视觉",{"2":{"967":1}}],["而低分辨率会导致细节丢失",{"2":{"962":1}}],["而键和值来自2d特征图",{"2":{"950":1}}],["而体素的尺寸为",{"2":{"917":1}}],["而没有考虑它们与最近占用区域的接近程度",{"2":{"916":1}}],["而无需重新学习整个模型",{"2":{"908":1}}],["而无需每次都从零训练",{"2":{"274":1}}],["而全局路径处理折叠的bev特征以获得场景级理解",{"2":{"875":1}}],["而第二阶段采用类似于mae",{"2":{"875":1}}],["而第二种更细粒度且以对象为导向",{"2":{"522":1}}],["而语义一致性损失则模仿由视觉基础模型引导的段内相似性",{"2":{"941":1}}],["而语义信息为机器人理解和执行人类指令",{"2":{"116":1}}],["而语言",{"2":{"864":1}}],["而室外评估则在所有体素上进行",{"2":{"853":1}}],["而尺度过大的高斯分布会相互重叠",{"2":{"833":1}}],["而下部图表则展示了动态融合",{"2":{"829":1}}],["而图像是使用",{"2":{"828":1}}],["而难以克服卷积天然的归纳偏置",{"2":{"824":1}}],["而构建多帧网格平均需要15毫秒",{"2":{"816":1}}],["而个体重叠则是通过计算每个高斯与其他所有高斯之间的",{"2":{"812":1}}],["而其他两个数据集评估了可见和被遮挡区域",{"2":{"1000":1}}],["而其他方法则采用弱监督",{"2":{"981":1}}],["而其他模型使用",{"2":{"803":1}}],["而其余节点",{"2":{"285":1}}],["而腿部后方延伸的体素表示该人拖拽的行李箱",{"2":{"791":1}}],["而较低分辨率的特征则通过",{"2":{"789":1}}],["而使用全部标注训练的视觉网络的",{"2":{"782":1}}],["而内部是空的",{"2":{"778":1}}],["而cad模型的可用性进一步提高了准确性",{"2":{"775":1}}],["而clio则过度分割",{"2":{"522":1}}],["而clip模型在大规模数据集上完成的训练",{"2":{"204":1}}],["而fbocc仅训练20个周期",{"2":{"770":1}}],["而后续数据集通常使用多视角图像",{"2":{"757":1}}],["而后者将被高效更新",{"2":{"728":1}}],["而后向时信息逐渐从纯噪声中补全",{"2":{"264":1,"266":1}}],["而近期方法则改用大型视觉",{"2":{"721":1}}],["而近年来用于3d语义占据预测的模型已成功解决了描述具有不同形状和类别的真实世界物体的挑战",{"2":{"475":1}}],["而直接用其他中间属性",{"2":{"716":1}}],["而动态融合",{"2":{"829":1}}],["而动态掩蔽确保了高度准确的重建",{"2":{"709":1}}],["而动态对象的网格则存储在一个单独的结构中",{"2":{"162":1}}],["而那些分布在真实深度点之后但距离较远的高斯分布需要更多信息来指导它们的更新",{"2":{"705":1}}],["而被归类为container",{"2":{"685":1}}],["而被掩码的区域则由噪声填充",{"2":{"312":1}}],["而2点ransac的使用已经提高了性能",{"2":{"662":1}}],["而2d可变形注意力缺乏深度信息",{"2":{"595":1}}],["而雷达提供的是稀疏特征",{"2":{"653":1}}],["而走廊仅需拓扑保持全局一致性",{"2":{"648":1}}],["而分割查询",{"2":{"644":1}}],["而3d",{"2":{"641":2}}],["而过滤策略则忽略了被遮挡的区域",{"2":{"612":1}}],["而过大的fff其生成质量较差",{"2":{"345":1}}],["而可变形注意力会带来巨大的计算负担",{"2":{"609":1}}],["而另一个相机则启用了红外发射器以捕获高质量的深度数据",{"2":{"605":1}}],["而池则是通过聚合每个点邻域的信息来产生一个新的粗略图",{"2":{"574":1}}],["而它们的特点在下面详细说明",{"2":{"572":1}}],["而边表示两个节点之间的直线可通行性",{"2":{"480":1}}],["而轻量级视觉分支足以补充语义识别能力",{"2":{"455":1}}],["而基于深度的对应方案仅捕获物体的表面",{"2":{"681":1}}],["而基于查询的方法通常使用bev查询和可变形注意力从图像特征中聚合信息",{"2":{"612":1}}],["而基于摄像头的方法在这方面表现出色",{"2":{"444":1}}],["而基于latent的sd是在latent空间操作的",{"2":{"205":1}}],["而远处的物体则显得更小",{"2":{"438":1}}],["而罗盘也噪声大",{"2":{"435":1}}],["而非开发新的模型架构",{"2":{"535":1}}],["而非查询场景中的所有高斯",{"2":{"532":1}}],["而非具身系统可先收集全部观测再统一处理",{"2":{"435":1}}],["而非特定下游任务",{"2":{"90":1}}],["而对地图本身的品质关注不足",{"2":{"881":1}}],["而对于需要特定类型调味品的替代任务集",{"2":{"462":1}}],["而对于这些融合特征的监督形式的探索则相对不足",{"2":{"421":1}}],["而对象是静态的",{"2":{"178":1}}],["而摄像头则捕捉颜色和纹理等视觉细节",{"2":{"421":1}}],["而严格的检测可以排除与真值有实质性重叠的估计",{"2":{"402":1}}],["而kitti",{"2":{"997":1}}],["而kimera在低精度和高召回率估计",{"2":{"437":1}}],["而kimera",{"2":{"390":1}}],["而key和value则是text",{"2":{"401":1}}],["而这种流程对于用文本引导从零生成和以图生图的区别仅在于输入是随机噪声还是给定图像",{"2":{"399":1}}],["而在关键帧速率下",{"2":{"816":1}}],["而在回归中则仅使用点云特征",{"2":{"512":1}}],["而在回归基准上的表现稍差",{"2":{"382":1}}],["而在更远距离处则变得稀疏",{"2":{"438":1}}],["而在实践中",{"2":{"434":1}}],["而在不使用相机掩码的情况下",{"2":{"421":1}}],["而在得到了编解码器后采样生成的第二个步骤时",{"2":{"371":1}}],["而scs",{"2":{"794":1}}],["而sd则采用clip",{"2":{"373":1}}],["而stod可以兼容stof",{"2":{"63":1}}],["而不需要许多上述方法所必需的持久图像历史记录",{"2":{"967":1}}],["而不能耗尽机载存储或算力",{"2":{"864":1}}],["而不会丢失太多信息",{"2":{"858":1}}],["而不再受预定义类别限制",{"2":{"765":1}}],["而不依赖于对象检测或语义分割的结果",{"2":{"349":1}}],["而不是每个体素",{"2":{"998":1}}],["而不是场景图",{"2":{"967":1}}],["而不是多摄像头特征图",{"2":{"957":1}}],["而不是特征图中的所有特征",{"2":{"950":1}}],["而不是为每个像素估计特定深度",{"2":{"950":1}}],["而不是三维卷积",{"2":{"923":1}}],["而不是2d",{"2":{"821":1}}],["而不是ccc",{"2":{"814":1}}],["而不是在遇到之前探索过的部分时破坏之前的预测",{"2":{"750":1}}],["而不是回归v↔νv",{"2":{"730":1}}],["而不是直接处理整个3d空间",{"2":{"892":1}}],["而不是直接计算所有体素对之间的关系",{"2":{"707":1}}],["而不是直接掩码估计",{"2":{"96":1}}],["而不是仅学习场景的可见表面",{"2":{"704":1}}],["而不是仅在网络开始时融合特征",{"2":{"96":1}}],["而不是固定的网格",{"2":{"693":1}}],["而不是完整的长宽高信息",{"2":{"658":1}}],["而不是平方级增长",{"2":{"631":1}}],["而不是表面的深度值",{"2":{"567":1}}],["而不是表面的深度",{"2":{"536":1}}],["而不是统一对待它们",{"2":{"464":1}}],["而不是",{"2":{"380":1}}],["而不是shapenet那样的",{"2":{"313":1}}],["而不是整个",{"2":{"302":1}}],["而不是将其视为点云",{"2":{"275":1}}],["而不是另一组",{"2":{"262":1}}],["而不是实例表中",{"2":{"254":1,"654":1}}],["而不是风格转换中的图像风格",{"2":{"133":1}}],["而不是密集的低级几何形状",{"2":{"125":1}}],["而不是对模型进行",{"2":{"75":1}}],["而不是unix风格的行尾",{"2":{"41":1}}],["而unet参数大小为860m",{"2":{"319":1}}],["而提取器则利用学习到的潜在表示进行下游任务",{"2":{"315":1}}],["而作者具体的做法则是结合了以上两点洞见",{"2":{"312":1}}],["而掩码区域更新为后向去噪的结果",{"2":{"312":1}}],["而我们的m1模块展示了更优的性能",{"2":{"811":1}}],["而我们的方法采用了更轻量级的resnet50骨干网络和较低的输入分辨率256×704",{"2":{"779":1}}],["而我们甚至可以使用同一个模型同时表示两者",{"2":{"513":1}}],["而我们假设了",{"2":{"355":1}}],["而我们在中间帧上跟踪特征",{"2":{"310":1}}],["而我们通过影响混合时注入的前向信息的多少",{"2":{"264":1,"266":1}}],["而每个边的特征通常被赋予两个连接点之间的几何属性",{"2":{"574":1}}],["而每个anchor都有",{"2":{"321":1}}],["而每个anhcor要分positive和negative",{"2":{"321":1}}],["而每个模块的具体描述将在后面的各节中给出",{"2":{"285":1}}],["而每个模块的描述在以下各节中给出",{"2":{"285":1}}],["而每个代理由一个姿态图描述其轨迹",{"2":{"210":1}}],["而模块化系统则把任务拆分成若干可解释的子模块",{"2":{"231":1}}],["而激光雷达的运行频率为",{"2":{"211":1}}],["而激光雷达扫描的时间戳是当前激光雷达帧完成一次完整旋转的时间",{"2":{"211":1}}],["而结构捕捉不同空间之间的分隔符",{"2":{"197":1}}],["而映射值是一个对象",{"2":{"196":1}}],["而文本t1和图像i2是不匹配的图文对",{"2":{"184":1}}],["而具身式人工智能中的语义建图则更强调能够支撑高层推理与决策的表示形式",{"2":{"155":1}}],["而接下来我们讨论如何设置所需的分布",{"2":{"153":1}}],["而轨迹估计会随着环路闭合而不断变化",{"2":{"141":1}}],["而经典机器人学则聚焦于控制",{"2":{"139":1}}],["而通常不依赖实体硬件",{"2":{"139":1}}],["而输出为",{"2":{"129":1}}],["而且deque里元素并不是严格的连续分布的",{"2":{"938":1}}],["而且指针也是可以移动的",{"2":{"918":1}}],["而且只需要计算4个窗口",{"2":{"751":1}}],["而且",{"2":{"693":1,"704":1}}],["而且这两个结构是成对使用的",{"2":{"659":1}}],["而且由于缺乏语义信息",{"2":{"596":1}}],["而且没有使用多尺度特征",{"2":{"386":1}}],["而且可以在点级别捕获密集",{"2":{"313":1}}],["而且比相关技术",{"2":{"301":1}}],["而且生成的图像保持了多样性和高细节度",{"2":{"248":1}}],["而且下游推理同样费时费力",{"2":{"205":1,"428":1}}],["而且变得至关重要的是捕捉场景中的动态实体",{"2":{"116":1}}],["而且还需要区分语义相同的实例",{"2":{"983":1}}],["而且还要估计完整的smpl形状",{"2":{"967":1}}],["而且还通过限制地图仅包含相关对象和区域来提高任务执行的准确性",{"2":{"109":1}}],["而且还通过限制地图仅包含相关语义概念来提高任务执行的准确性",{"2":{"98":1}}],["而且还能够相应地忽略与任务无关的场景部分",{"2":{"109":1}}],["而再++iter",{"2":{"115":1}}],["而是将带有语义标签的激光雷达点云投影到摄像头平面上",{"2":{"988":1}}],["而是将三维目标检测作为辅助分支无缝集成到多模态占据预测框架中",{"2":{"779":1}}],["而是从其他标签中获取监督信号",{"2":{"988":1}}],["而是从光学角度出发",{"2":{"660":1}}],["而是校正与相机关键帧相关联的姿态图",{"2":{"967":1}}],["而是更关注场景的占用分布和语义理解",{"2":{"860":1}}],["而是与可微规划器共同学习",{"2":{"743":1}}],["而是与规划器一起端到端训练",{"2":{"495":1}}],["而是凭借机载传感器实时估计位姿",{"2":{"435":1}}],["而是聚合到3d",{"2":{"423":1}}],["而是加噪到中间过程使其保留一些低频信息",{"2":{"287":1}}],["而是学习",{"2":{"225":1}}],["而是直接存储数据的值",{"2":{"217":1}}],["而是直接输入",{"2":{"175":1}}],["而是在潜在空间中进行操作",{"2":{"205":1}}],["而是主动选择动作以同步改善地图与自身定位",{"2":{"189":1}}],["而是原图和",{"2":{"180":1}}],["而是取均匀分布",{"2":{"175":1}}],["而是希望创建任务驱动的场景地图",{"2":{"121":1}}],["而是可以通过将钢琴视为一个大对象来完成任务",{"2":{"109":1}}],["而是本质上是任务依赖的",{"2":{"109":1}}],["而ts",{"2":{"82":1}}],["而",{"2":{"31":2,"126":1,"131":1,"137":1,"184":1,"217":1,"252":1,"390":1,"517":1,"582":1,"652":1,"693":1,"700":2,"807":1,"915":1,"928":2,"938":3,"989":1,"995":1}}],["值表明存在更多的冗余",{"2":{"916":1}}],["值表明高斯之间的重叠体积更大",{"2":{"916":1}}],["值表示该体素与最近物体表面的距离",{"2":{"31":1}}],["值地图显然更强大",{"2":{"765":1}}],["值地图完成同类任务",{"2":{"765":1}}],["值地图的有效性",{"2":{"765":1}}],["值地图",{"2":{"765":2}}],["值为104以供可视化",{"2":{"732":1}}],["值为1返回完全合并的原语",{"2":{"153":1}}],["值得未来探索",{"2":{"826":1}}],["值得未来深入研究",{"2":{"826":1}}],["值得一提的是相关方法包括基于优化的方法",{"2":{"967":1}}],["值得一提的是",{"2":{"709":1,"824":1,"867":1}}],["值得注意的是",{"2":{"184":1,"349":1,"373":1,"421":1,"437":1,"482":1,"522":1,"603":1,"640":1,"682":1,"735":1,"775":1,"779":3,"793":1,"800":1,"821":1,"842":3,"859":1,"875":1,"889":1,"893":1,"899":1,"917":1,"950":1,"952":1,"985":1,"1000":1,"1001":1}}],["值来识别表面四面体tsurft",{"2":{"372":1}}],["值趋于正一或负一",{"2":{"31":1}}],["值接近于零",{"2":{"31":1}}],["值被填充为",{"2":{"31":2}}],["值用于生成重建表面",{"2":{"31":1}}],["−81​",{"2":{"916":1}}],["−f",{"2":{"694":2}}],["−f2",{"2":{"208":2}}],["−表示缺少数据",{"2":{"686":1}}],["−40m",{"2":{"652":4}}],["−5",{"2":{"749":2}}],["−50",{"2":{"749":4}}],["−50m",{"2":{"652":4}}],["−5m",{"2":{"652":2}}],["−d",{"2":{"647":2}}],["−γ∇logp",{"2":{"513":1}}],["−γ∇log⁡p",{"2":{"513":1}}],["−∇logp",{"2":{"513":1}}],["−∇log⁡p",{"2":{"513":1}}],["−∇x^",{"2":{"235":2}}],["−∇x​logpdata​",{"2":{"235":1}}],["−∇xlog⁡pdata",{"2":{"235":1}}],["−sθ​",{"2":{"235":1,"342":1}}],["−sθ",{"2":{"235":1,"342":1}}],["−2m",{"2":{"652":2,"828":2}}],["−20m",{"2":{"652":2,"828":2}}],["−2",{"2":{"316":1}}],["−2∇θ​∫sθ​",{"2":{"235":1}}],["−2∇θ∫sθ",{"2":{"235":1}}],["−2sθ​",{"2":{"235":1}}],["−2sθ",{"2":{"235":1}}],["−2g2",{"2":{"208":4}}],["−21​a",{"2":{"140":1,"280":1}}],["−21​",{"2":{"140":3,"280":3,"532":1,"656":1,"681":2,"693":2,"738":1,"916":1}}],["−21​σ2",{"2":{"140":1,"280":1}}],["−δt∂t∂​logp",{"2":{"208":3}}],["−δt∂∂tlog⁡p",{"2":{"208":3}}],["−logp",{"2":{"208":1}}],["−log⁡p",{"2":{"208":1}}],["−g2",{"2":{"208":12}}],["−i",{"2":{"153":4}}],["−h",{"2":{"137":4}}],["−βi",{"2":{"137":2}}],["−",{"2":{"57":2,"153":1,"171":2,"208":6,"316":1,"390":9,"435":1,"592":2,"985":2}}],["−18",{"2":{"916":1}}],["−10m",{"2":{"652":2,"828":2}}],["−1m",{"2":{"652":2}}],["−12g2",{"2":{"208":3}}],["−12a",{"2":{"140":1,"280":1}}],["−12",{"2":{"140":4,"280":4,"532":1,"656":1,"681":2,"693":2,"738":1,"916":1}}],["−1",{"2":{"31":4,"57":2,"844":9}}],["−k",{"2":{"5":2}}],["zanfir等人",{"2":{"967":1}}],["zaheer等人",{"2":{"420":1}}],["z^",{"2":{"950":1}}],["z∗",{"2":{"950":2}}],["z轴上",{"2":{"770":1}}],["zzl​−zr​​",{"2":{"712":1}}],["zzz轴上的范围",{"2":{"749":1}}],["zzz",{"2":{"676":1}}],["z估计",{"2":{"709":1}}],["z维度的数量",{"2":{"703":1}}],["zl−zrz",{"2":{"712":1}}],["zl−1​",{"2":{"405":1}}],["zl−1z",{"2":{"405":1}}],["zl​",{"2":{"712":1}}],["zl",{"2":{"712":1}}],["zli​​",{"2":{"699":2}}],["zli",{"2":{"699":2}}],["z表示局部三维场景的维度",{"2":{"682":1}}],["zroom​",{"2":{"682":1}}],["zroomz",{"2":{"682":1}}],["zr​",{"2":{"676":3,"699":1,"712":1}}],["zr",{"2":{"676":7,"699":4,"712":1}}],["zya3d",{"2":{"637":1}}],["z×8h​×8w​",{"2":{"609":1}}],["z×h8×w8z",{"2":{"609":1}}],["zj​",{"2":{"563":1}}],["zj",{"2":{"563":1}}],["zx",{"2":{"694":2,"712":2}}],["zx×y×z",{"2":{"532":1,"716":1,"738":1}}],["zxt​=αˉt​​x0​+1−αˉt​​z",{"2":{"175":1}}],["zxt​=αt​​xt−1​+1−αt​​z",{"2":{"140":1,"280":1}}],["zongdai",{"2":{"477":1}}],["zoe",{"2":{"173":1}}],["zi−zˉ",{"2":{"789":1,"809":1}}],["zi​−zˉ",{"2":{"789":1,"809":1}}],["zi​",{"2":{"532":1,"789":2,"809":2}}],["zi",{"2":{"532":1,"789":2,"809":2}}],["zichen",{"2":{"477":1}}],["zij||2",{"2":{"390":1}}],["zij||^2",{"2":{"390":1}}],["zij∈z",{"2":{"390":1}}],["zij",{"2":{"390":1}}],["z⎤ᵀ",{"2":{"435":1}}],["z41​",{"2":{"390":1}}],["z41z",{"2":{"390":1}}],["zn​​b1​bn​​​",{"2":{"357":1}}],["z1​",{"2":{"221":1}}],["z1",{"2":{"221":1}}],["z1z",{"2":{"181":1,"221":1}}],["zθ​​​=−∇x​fθ​",{"2":{"235":1}}],["zθ⏟=0=−∇xfθ",{"2":{"235":1}}],["zθz",{"2":{"213":1,"235":1}}],["zθ",{"2":{"213":1}}],["z2z",{"2":{"181":1}}],["z~=unet",{"2":{"175":4}}],["zᵢₜ",{"2":{"171":3}}],["z∼n",{"2":{"111":2,"236":2}}],["z",{"2":{"111":5,"132":1,"133":4,"140":6,"149":4,"171":2,"175":2,"213":1,"221":1,"225":1,"236":5,"254":6,"280":6,"314":1,"357":3,"377":1,"378":6,"390":1,"406":2,"412":1,"426":1,"434":4,"435":2,"532":2,"563":1,"590":1,"609":1,"619":1,"621":6,"654":2,"656":4,"676":13,"682":2,"693":7,"694":11,"699":2,"703":1,"705":3,"712":11,"724":1,"746":3,"780":5,"787":1,"789":5,"793":2,"809":4,"900":2,"910":4,"947":3,"950":9,"957":15}}],["zt​∼n",{"2":{"111":1,"236":1}}],["zt∼n",{"2":{"111":1,"236":1}}],["zh",{"2":{"712":2}}],["zhi",{"2":{"619":1}}],["zhiding",{"2":{"458":1}}],["zhiqi",{"2":{"458":1}}],["zhihu",{"2":{"73":1,"133":1,"179":1,"201":1,"223":1,"243":1,"258":1,"264":1,"266":1,"292":2,"325":1,"328":1,"382":2,"469":1,"500":1,"513":1,"528":1,"589":1,"663":1,"715":1,"763":1,"804":1,"824":1,"839":1}}],["zhou等人",{"2":{"510":1,"967":1}}],["zhouce",{"2":{"276":1}}],["zhou",{"2":{"274":1}}],["zhaoyang",{"2":{"914":1}}],["zhao等人",{"2":{"362":1,"664":1}}],["zhao",{"2":{"123":1,"387":1,"588":1}}],["zhao和zhu",{"2":{"116":1,"961":1,"967":1}}],["zhangyp15",{"2":{"733":1}}],["zhang等人",{"2":{"362":1,"511":1,"714":1,"905":1,"1004":1}}],["zhang",{"2":{"90":1,"274":1,"350":1,"525":1,"588":1,"698":1,"914":2}}],["zheng等人",{"2":{"116":1,"172":1,"190":1,"419":1,"967":2}}],["zheng",{"2":{"90":1,"588":1}}],["zhenzhongcao",{"2":{"30":1}}],["zhu等人",{"2":{"961":1}}],["zhuanlan",{"2":{"663":1,"839":1}}],["zhu",{"2":{"90":1,"619":1}}],["zender",{"2":{"648":1}}],["zender等人",{"2":{"116":1,"961":2}}],["zeng",{"2":{"123":1,"806":2,"914":1}}],["zebra",{"2":{"57":1}}],["zero",{"2":{"26":1,"159":1,"469":2}}],["📖",{"2":{"30":1}}],["重叠",{"2":{"916":1}}],["重定位",{"2":{"864":1}}],["重排",{"2":{"806":1}}],["重复这一过程",{"2":{"660":1}}],["重复上述过程",{"2":{"636":1}}],["重复的页脚定义",{"2":{"57":1}}],["重大挑战仍在",{"2":{"538":1}}],["重型模块仅在新场景激活",{"2":{"478":1}}],["重点是开发准确且高效的方法",{"2":{"892":1}}],["重点介绍了信息融合技术",{"2":{"610":1}}],["重点",{"2":{"351":1}}],["重点关注构建真正的层次化表示",{"2":{"125":1}}],["重点关注",{"0":{"30":1}}],["重建的3d网格嘈杂和不完整",{"2":{"947":1}}],["重建的3d网格的俯视图",{"2":{"947":2}}],["重建的边界可能过度平滑",{"2":{"470":1}}],["重建场景的准确和完整的3d网格",{"2":{"889":1}}],["重建场景中人类的密集网格",{"2":{"285":1}}],["重建点坐标会导致过拟合的表示",{"2":{"640":1}}],["重建学习",{"0":{"640":1}}],["重建和视图合成",{"2":{"619":1}}],["重建对齐",{"2":{"588":1}}],["重建伪影更少",{"2":{"495":1}}],["重建数据集",{"2":{"495":1}}],["重建效果越好",{"2":{"345":1}}],["重建用于避障的快速局部3d网格",{"2":{"131":1}}],["重建了对象及其关系的场景图",{"2":{"125":1}}],["重新组织采样策略",{"2":{"949":1}}],["重新投影回参考图像",{"2":{"592":1}}],["重新设计调整并提出",{"2":{"824":1}}],["重新设计了一个由粗到细的体素编码器以构建占据表示",{"2":{"566":1}}],["重新设置文件的格式",{"2":{"48":1}}],["重新定义合并特征的邻接关系",{"2":{"466":1}}],["重新摆放物体",{"2":{"350":1}}],["重新生成的结果往往在局部语义上是自洽的但是没有考虑到全局语义",{"2":{"312":1}}],["重新弄一遍",{"2":{"66":1}}],["重装ubuntu",{"0":{"55":1},"1":{"66":1}}],["重要的是",{"2":{"437":1,"903":1}}],["重要",{"2":{"31":1,"137":1,"153":2,"271":1,"341":1,"621":1,"670":4,"800":1}}],["重启后ctrl",{"2":{"66":1}}],["重启",{"2":{"24":1,"66":1,"74":1}}],["并部分得到香港特别行政区研究资助局的支持",{"2":{"1008":1}}],["并帮助非专业读者了解该领域",{"2":{"1007":1}}],["并实现了开放词汇的3d占用感知",{"2":{"1006":1}}],["并实现了大约",{"2":{"959":1}}],["并未超越单模态",{"2":{"1000":1}}],["并未考虑时间轴上周围对象的未来状态",{"2":{"975":1}}],["并包含",{"2":{"982":1}}],["并包括平均iou的顶部n个最相关估计对象",{"2":{"402":1}}],["并导致最终性能不佳",{"2":{"971":1}}],["并导致了干净的网格重建",{"2":{"709":1}}],["并缓解单模态感知的局限性",{"2":{"970":1}}],["并缓解了从常见对象到稀有对象的抑制",{"2":{"875":1}}],["并缓解了",{"2":{"832":1}}],["并重点介绍了该领域的信息融合技术",{"2":{"1007":1}}],["并重建和跟踪密集人类smpl网格的工作",{"2":{"967":1}}],["并重新处理这",{"2":{"833":1}}],["并依赖于激光雷达",{"2":{"967":1}}],["并依赖于激光雷达监督",{"2":{"681":1}}],["并描述了一个半自动算法来构建场景图",{"2":{"961":1}}],["并评估每个查询嵌入及其相关语义",{"2":{"957":1}}],["并评估每组对整体模型性能的影响",{"2":{"882":1}}],["并扩展了模型的感知范围",{"2":{"944":1}}],["并观察到与基线相比性能有所提升",{"2":{"934":1}}],["并报告了它们的运行平台",{"2":{"1001":1}}],["并报告了",{"2":{"928":1}}],["并报告正确检测的数量除以真值对象的数量",{"2":{"402":1}}],["并取场景中所有高斯的平均值",{"2":{"916":1}}],["并取得了一定的性能提升",{"2":{"949":1}}],["并取得了优异的性能",{"2":{"875":1}}],["并取得了新的最先进水平",{"2":{"306":1}}],["并成功保留了高度信息",{"2":{"908":1}}],["并回答有关可能的未来结果的查询",{"2":{"905":1}}],["并正确表示场景和层之间的连通性",{"2":{"889":1}}],["并研究其对模型性能的影响",{"2":{"882":1}}],["并抑制特征定位中的歧义",{"2":{"875":1}}],["并作为连接2d和3d",{"2":{"875":1}}],["并作为额外的输入位置嵌入",{"2":{"369":1}}],["并学习3d占用表示",{"2":{"875":1}}],["并准确将地点分割成房间",{"2":{"872":1}}],["并近似一个保守的边界框",{"2":{"872":1}}],["并代表一个灵活的兴趣区域",{"2":{"861":1}}],["并沿不同轴压缩3d空间信息",{"2":{"858":1}}],["并始终在全尺寸",{"2":{"853":1}}],["并相应地提出了一个基于高斯分布的embodiedocc框架",{"2":{"852":1}}],["并相互促进模型更好地推理点云的细粒度几何形状",{"2":{"715":1}}],["并尝试通过卷积神经网络来解决",{"2":{"841":1}}],["并加入了额外的损失函数以优化模型",{"2":{"839":1}}],["并结合通道到高度变换将扁平化的bev特征重塑为占用逻辑",{"2":{"908":1}}],["并结合通道到高度变换将扁平化的bev特征重塑为占据逻辑",{"2":{"831":1}}],["并结合密集立体视觉",{"2":{"732":1}}],["并集平均交集",{"2":{"979":1}}],["并集",{"2":{"826":1}}],["并指出当前空白与未来发展方向",{"2":{"826":1}}],["并指出了本研究与以往出版物的关键差异",{"2":{"438":1,"503":1}}],["并已在基于视觉",{"2":{"808":1}}],["并获得体素网格及其相关坐标",{"2":{"809":1}}],["并获得了occ",{"2":{"793":1}}],["并获得了最终的embodiedocc",{"2":{"793":1}}],["并获得相应相机视锥体内的空间占用预测",{"2":{"793":1}}],["并给出未来研究的潜在方向",{"2":{"881":1}}],["并给出占用体素的语义标签",{"2":{"778":1}}],["并给出人类可读的解释",{"2":{"82":1}}],["并支持自动驾驶中的各种任务",{"2":{"1003":1}}],["并支持额外的雷达输入",{"2":{"997":1}}],["并支持开放词汇的文本查询",{"2":{"765":1}}],["并支持多样化的环境推理",{"2":{"648":1}}],["并配备余弦退火学习率调度器",{"2":{"758":1}}],["并配合",{"2":{"274":1}}],["并由多视角图像序列生成的标签进行监督",{"2":{"949":1}}],["并由其真实值ama",{"2":{"752":1}}],["并由kimera",{"2":{"285":1}}],["并记录每个3d高斯分布影响的体素索引",{"2":{"738":1}}],["并记录相对位姿",{"2":{"525":1}}],["并识别点云特有的三个自监督学习目标",{"2":{"715":1}}],["并识别包围房间的结构",{"2":{"131":1}}],["并仅从掩模点云预测原始坐标或占用率的论文相比",{"2":{"715":1}}],["并仅保留同时位于图像特征平面和摄像头视野范围内的点",{"2":{"609":1}}],["并预测从粗到细的3d占用",{"2":{"922":1}}],["并预测这些超体素与单个体素之间的关系",{"2":{"707":1}}],["并预测他们的行为或意图",{"2":{"116":1}}],["并删除了罕见的类",{"2":{"702":1}}],["并面临更严重的语义分布不平衡",{"2":{"694":1}}],["并直接将",{"2":{"681":1}}],["并直接产生归一化的类别概率",{"2":{"681":1}}],["并存储信息",{"2":{"675":1}}],["并可以规划一条可行的路径到达那个地方",{"2":{"939":1}}],["并可以通过cuda高效实现",{"2":{"669":1}}],["并可能激发未来在多模态占据预测领域的研究",{"2":{"820":1}}],["并可用于探索任务",{"2":{"139":1}}],["并详细阐述了核心方法问题",{"2":{"714":1}}],["并详细说明模型设计",{"2":{"669":1}}],["并详细解释了每个模块的实现",{"2":{"438":1,"503":1}}],["并展望了基于视觉的3d占用预测的未来方向",{"2":{"665":1}}],["并展示它在嵌入式硬件上实时执行",{"2":{"131":1}}],["并展示了结果算法可以随着机器人探索环境而增量执行",{"2":{"109":1}}],["并允许我们基于smpl身体形状进行数据关联",{"2":{"967":1}}],["并允许",{"2":{"660":1}}],["并允许密码登录",{"2":{"78":1}}],["并随任务复杂度提升而持续演进",{"2":{"846":1}}],["并随着具身任务日益复杂和多样化而持续演进",{"2":{"806":1}}],["并随后沿相机射线方向产生误检",{"2":{"655":1}}],["并随时间将这些特征合并到同一张地图中",{"2":{"435":1}}],["并被自监督的occnerf",{"2":{"1000":1}}],["并被标记为",{"2":{"652":1,"749":1}}],["并被训练用来预测噪声向量",{"2":{"304":1}}],["并表示该体积被占据的概率",{"2":{"649":1}}],["并表明它能够在线重建3d场景图",{"2":{"112":1}}],["并计算点的rmse",{"2":{"732":1}}],["并计算估计值和surfel法向量之间的平均余弦相似性作为对比损失",{"2":{"640":1}}],["并计算一个与轴对齐的边界框",{"2":{"480":1}}],["并汇总了10帧的数据",{"2":{"638":1}}],["并深入分析了每类方法的潜力和挑战",{"2":{"637":1}}],["并鼓励更多关于3d占用感知的研究工作",{"2":{"610":1}}],["并讨论了由所提出的dsg表示启用的应用",{"2":{"973":1}}],["并讨论了该任务中的挑战",{"2":{"637":1}}],["并讨论了有效的网络训练",{"2":{"610":1}}],["并讨论了多种训练技术以实现最先进的性能",{"2":{"455":1}}],["并引入了4d占用预测任务",{"2":{"975":1}}],["并引入了一个",{"2":{"539":1}}],["并引入了一个专用内核来加速鸟瞰图池化操作",{"2":{"512":1}}],["并引入两种新颖的一致性标准来对齐教师和学生模型的渲染输出",{"2":{"941":1}}],["并引入混合引导和有效的体素聚合",{"2":{"875":1}}],["并引起了工业界和学术界的广泛关注",{"2":{"610":1}}],["并更新每个层中的图拉普拉斯矩阵",{"2":{"607":1}}],["并更容易从仿真迁移到真实机器人",{"2":{"274":1}}],["并伴随着一个高斯到体素的溅射模块",{"2":{"600":1}}],["并省略被视为为空的区域",{"2":{"599":1}}],["并开发了动态采样训练策略以过滤掉未对齐的光线",{"2":{"941":1}}],["并开发了一个增量版本的聚合信息瓶颈算法作为解决策略",{"2":{"586":1}}],["并开始在未知的非结构化动态环境中作业",{"2":{"209":1}}],["并基于三种",{"2":{"678":1}}],["并基于ward",{"2":{"574":1}}],["并基于每个点的领域为图生成有向边",{"2":{"542":1}}],["并能够合理地推测出图像视野范围之外的场景",{"2":{"570":1}}],["并逐步更新位于智能体视野内的高斯分布",{"2":{"600":1}}],["并逐步更新具身智能体观察到的局部区域",{"2":{"568":1}}],["并逐层提取局部特征",{"2":{"420":1}}],["并推导出几何预测",{"2":{"567":1}}],["并促进下游规划和导航任务",{"2":{"566":1}}],["并渲染其他视图的合成",{"2":{"949":1}}],["并渲染",{"2":{"552":1}}],["并输入到一个mlp层中以进行特征过滤",{"2":{"676":1}}],["并输入到另一个mlp层中以进行特征过滤",{"2":{"621":1}}],["并输入到特征引导的位置编码器",{"2":{"550":1,"583":1}}],["并输出三视图",{"2":{"621":1}}],["并输出三个tpv",{"2":{"578":1}}],["并输出对应特征",{"2":{"619":1}}],["并输出一组学习内核",{"2":{"384":1}}],["并输出一个行动",{"2":{"121":1}}],["并输出优化后的状态估计",{"2":{"285":1}}],["并输出特征轨迹和预积分的imu测量值",{"2":{"285":1}}],["并输出",{"2":{"285":1}}],["并生成用于后续预测头的点令牌",{"2":{"549":1}}],["并分别使用",{"2":{"803":1}}],["并分别采用概率乘法和高斯混合模型来处理它们",{"2":{"681":1}}],["并分别从概率角度采用概率的乘法定理和高斯混合模型来处理它们",{"2":{"681":1}}],["并分析了每个模块的运行时间",{"2":{"541":1}}],["并分配一个与世界框架对齐的规范方向",{"2":{"449":1}}],["并分配一个分数",{"2":{"153":1}}],["并追求持续",{"2":{"538":1}}],["并迭代优化3d高斯分布的属性",{"2":{"516":1}}],["并应用多尺度监督以提高模型的性能",{"2":{"746":1}}],["并应用高斯核",{"2":{"666":1}}],["并应用交叉注意力来获取每个目标查询的图像特征",{"2":{"512":1}}],["并应用于检测",{"2":{"394":1}}],["并利用2d",{"2":{"922":1}}],["并利用连续的2d和3d",{"2":{"841":1}}],["并利用从点云数据中导出的深度信息来监督图像的单目深度估计训练",{"2":{"779":1}}],["并利用现有的三维检测和三维语义分割标签生成密集的占据真值",{"2":{"736":1}}],["并利用3d稀疏卷积来处理它们",{"2":{"547":1}}],["并利用surroundocc",{"2":{"503":1}}],["并利用基于图的聚集来提取局部特征",{"2":{"420":1}}],["并没有充分利用其固有的几何信息",{"2":{"482":1}}],["并借助强大的预训练视觉语言模型",{"2":{"975":1}}],["并借助雷达特征提高深度估计的准确性",{"2":{"482":1}}],["并借助认知能力对所见物体与区域进行分类",{"2":{"350":1}}],["并限制搜索半径为保守的0",{"2":{"480":1}}],["并根据其底层地图结构",{"2":{"958":1}}],["并根据",{"2":{"957":1}}],["并根据成像原理和相机参数计",{"2":{"875":1}}],["并根据高斯协方差矩阵确定其半轴长度来进行可视化",{"2":{"842":1}}],["并根据深度对特征进行加权",{"2":{"839":1}}],["并根据余弦时间表逐渐降低",{"2":{"822":1}}],["并根据可见性识别体素类型",{"2":{"757":1}}],["并根据目标帧和目标id对齐动态前景的点云",{"2":{"735":1}}],["并根据定位信息进行运动补偿",{"2":{"735":1}}],["并根据它们的标签",{"2":{"728":1}}],["并根据从输入图像中提取的语义和结构特征更新基于高斯分布的表示",{"2":{"705":1}}],["并根据实时观测在线更新维护的高斯记忆",{"2":{"568":1}}],["并根据对象分数进行采样",{"2":{"471":1}}],["并根据最新的vio后端估计更新它们的3d位置",{"2":{"336":1}}],["并还原到深度加深区间",{"2":{"470":1}}],["并保留了更少的对象数量",{"2":{"462":1}}],["并保证网络内相似变换",{"2":{"325":1}}],["并以精细的细节准确地重现场景",{"2":{"909":1}}],["并以数据驱动的方式优化这种初始化",{"2":{"704":1}}],["并以",{"2":{"652":1,"749":1}}],["并以高准确性和强大的可扩展性完成了室内场景的具身空间占用预测",{"2":{"600":1}}],["并以高准确性和强大的可扩展性完成了具身空间占用预测任务",{"2":{"852":1}}],["并以高准确性和强大的可扩展性完成了具身空间占用预测",{"2":{"568":1}}],["并以更少的标注数据实现竞争性性能",{"2":{"455":1}}],["并以l2或交叉熵损失最小化复制专家控制或轨迹",{"2":{"417":1}}],["并尽可能达到高精度",{"2":{"455":1}}],["并解码多种信息",{"2":{"455":1}}],["并最终将各通道数压缩为1",{"2":{"440":1}}],["并需要超过40秒来生成中等场景大小的整个场景图",{"2":{"437":1}}],["并需要构建一个最小的地图表示",{"2":{"109":1}}],["并与停止准则",{"2":{"826":1}}],["并与输入特征结合",{"2":{"752":1}}],["并与其他模块联合训练",{"2":{"698":1}}],["并与基础模型深度融合",{"2":{"619":1}}],["并与transformer解码器中的多视角图像特征进行交互",{"2":{"550":1}}],["并与上一个节点连边",{"2":{"525":1}}],["并与传统基于视觉的方法在办公室场景上进行了比较",{"2":{"437":1}}],["并与",{"2":{"437":1}}],["并通常与定位一起在",{"2":{"435":1}}],["并通过体积渲染计算深度和语义图",{"2":{"988":1}}],["并通过体素特征编码器",{"2":{"677":1}}],["并通过线性投影获得可学习的权重",{"2":{"976":1}}],["并通过自适应混合进行聚合",{"2":{"957":1}}],["并通过自编码",{"2":{"716":1}}],["并通过组间一对多分配训练网络",{"2":{"875":1}}],["并通过实例查询的高效融合缓解几何歧义",{"2":{"875":1}}],["并通过关系发现机制增加了空间语义意识",{"2":{"875":1}}],["并通过关系发现机制增强了空间语义感知能力",{"2":{"684":1}}],["并通过迭代细化合理分配资源",{"2":{"842":1}}],["并通过消融实验证明了其管道中每个步骤的有效性",{"2":{"735":1}}],["并通过考虑更多传感器模态扩展了现有的3d占用综述",{"2":{"714":1}}],["并通过像素坐标获得相应的深度值",{"2":{"705":1}}],["并通过软注意力mask与点云特征融合",{"2":{"664":1}}],["并通过建模物体与智能体之间的时空关系",{"2":{"648":1}}],["并通过最大池进行聚合",{"2":{"636":1}}],["并通过可变形交叉注意力将它们整合起来",{"2":{"600":1}}],["并通过可变形交叉注意力高效地将它们整合起来",{"2":{"568":1}}],["并通过有向边将每个顶点连接到其所有领域",{"2":{"574":1}}],["并通过多次重复的细化模块迭代优化",{"2":{"563":1}}],["并通过概率乘法来推导整体几何形状",{"2":{"536":1}}],["并通过外积运算构建提升的",{"2":{"502":1}}],["并通过轻量级设计将其提升至最先进水平",{"2":{"455":1}}],["并通过调整",{"2":{"400":1}}],["并通过查询向量作为自上而下的管道提出实例",{"2":{"349":1}}],["并通过查询向量直接预测实例",{"2":{"349":1}}],["并通过在每对上应用简单的对称函数来生成新特征",{"2":{"325":1}}],["并通过进一步将第4层分割为建筑物生成第5层",{"2":{"285":1}}],["并通过平均计算最终的clip特征",{"2":{"206":1}}],["并通过回环检测",{"2":{"189":1}}],["并通过一个bounding",{"2":{"169":1}}],["并通过引入语义来增强定位精度",{"2":{"155":1}}],["并通过聚类场景到任务相关的语义区域",{"2":{"109":1}}],["并通过运行生成",{"2":{"32":1,"38":1}}],["并把时刻",{"2":{"435":1}}],["并减轻了降低图像分辨率带来的不利影响",{"2":{"421":2}}],["并使我们的方法避免了需要复杂的损失函数组合",{"2":{"421":1}}],["并使用对称池化函数学习全局特征",{"2":{"974":1}}],["并使用类似gpt的模块预测未来的3d占用数据",{"2":{"963":1}}],["并使用类别引导采样捕捉前景区域",{"2":{"875":1}}],["并使用2d激光雷达数据进行估计",{"2":{"961":1}}],["并使用2d像素级语义分割和3d贝叶斯更新对3d网格进行语义注释",{"2":{"131":1}}],["并使用体积渲染将占用场转换为多相机深度图",{"2":{"949":1}}],["并使用单级网络回归物体的三维包围盒",{"2":{"857":1}}],["并使用强大的图像骨干网络从输入数据中提取更多信息特征",{"2":{"839":1}}],["并使用特征金字塔网络",{"2":{"768":1}}],["并使用nuscenes基准提供的平均精度",{"2":{"893":1}}],["并使用nuscenes验证集进行评估",{"2":{"736":1}}],["并使用nerf监督预测每个体素的密度和标签",{"2":{"566":1}}],["并使用人工增强来净化标签",{"2":{"735":1}}],["并使用初始标签监督训练以获得粗略模型",{"2":{"735":1}}],["并使用投票机制确定体素的语义",{"2":{"735":1}}],["并使用这些坐标来初始化部分高斯分布的均值",{"2":{"705":1}}],["并使用二进制交叉熵损失与",{"2":{"704":1}}],["并使用下采样步幅为",{"2":{"670":1}}],["并使用局部2d高斯分布渲染图像块",{"2":{"641":1}}],["并使用标准的跳跃连接",{"2":{"632":1}}],["并使用高斯核对每个边进行加权",{"2":{"607":1}}],["并使用自制的传感装置进行记录",{"2":{"605":1}}],["并使用激光雷达点云中的深度信息对深度分布特征进行监督",{"2":{"578":1}}],["并使用从单目rgb输入中提取的语义和结构特征来更新它们",{"2":{"568":1}}],["并使用稀疏卷积算子",{"2":{"517":1}}],["并使用稀疏查询来预测掩码和标签",{"2":{"482":1}}],["并使用rtx",{"2":{"431":1}}],["并使用双线性插值来采样这些点对应的二维图像特征",{"2":{"421":1}}],["并使用adaptive",{"2":{"420":1}}],["并使用多个mlp层获得分类分数",{"2":{"420":1}}],["并使用由稀疏",{"2":{"412":1}}],["并使用gcn来预测每个顶点",{"2":{"400":1}}],["并使用orb描述符的词袋表示快速检测候选回路闭合",{"2":{"390":1}}],["并使用基于体素的",{"2":{"362":1}}],["并使用",{"2":{"285":1,"434":1,"481":1,"677":1,"853":1}}],["并使用五个线程来适应不同速率的输入和输出",{"2":{"285":1}}],["并使用视觉",{"2":{"137":1}}],["并使用teaser++",{"2":{"131":1}}],["并使用姿态图模型估计他们的轨迹",{"2":{"131":1,"285":1}}],["并从数据",{"2":{"956":1}}],["并从原始图像特征中插值集成的3d体素特征",{"2":{"908":1}}],["并从图像特征中提取bev特征",{"2":{"821":1}}],["并从图像特征金字塔中获取点特征",{"2":{"464":1}}],["并从头开始训练模型",{"2":{"803":1}}],["并从头开始训练",{"2":{"758":1}}],["并从",{"2":{"660":2}}],["并从整个后续过程中完全消除",{"2":{"599":1}}],["并从dsg中移除它们",{"2":{"419":1}}],["并从vio状态中解析消除相应的3d点",{"2":{"310":1}}],["并确保每对beta参数之间的平均差异不超过某个阈值",{"2":{"419":1}}],["并检查每个关节的运动是否在该时间间隔内是物理上合理的",{"2":{"419":1}}],["并具有允许小运动的宽容噪声模型",{"2":{"419":1}}],["并具有相关的变换xi=",{"2":{"390":1}}],["并具有相关的变换mk=",{"2":{"390":1}}],["并丢弃了有关人类的有用时间信息",{"2":{"419":1}}],["并设置初始大小为10且初始值都为1",{"2":{"888":1}}],["并设置初始大小为10",{"2":{"888":1}}],["并设置分辨率为δdδdδd",{"2":{"355":1}}],["并设计了一种激光雷达引导的",{"2":{"767":1}}],["并设计了一种激光雷达引导的3d可变形注意力机制",{"2":{"415":1}}],["并设计了gaussianformer模型以执行3d占用预测",{"2":{"760":1}}],["并执行跳跃连接",{"2":{"545":1,"746":1}}],["并执行可变形注意力",{"2":{"482":1}}],["并执行房间检测",{"2":{"408":1}}],["并执行几何验证",{"2":{"310":1}}],["并强制执行通过最小化连接网格顶点之间的相对平移来执行网格顶点之间的局部刚性",{"2":{"390":1}}],["并强调近期系统如何结合两者",{"2":{"388":1}}],["并强调当前方法的不足之处",{"2":{"116":1}}],["并强调其作为研究方向的不断发展",{"2":{"110":1}}],["并只检查机器人间的回路闭合是否一致",{"2":{"390":1}}],["并估计全局一致的轨迹",{"2":{"390":1}}],["并估计场景中最相似于查询的部分",{"2":{"121":1}}],["并找到所有唯一的哈希键标签对以消除冲突",{"2":{"385":1}}],["并注意到我们使用了",{"2":{"380":1}}],["并为驾驶行为提供3d可解释性",{"2":{"1003":1}}],["并为未来语义建图的研究提供有前景的方向",{"2":{"958":1}}],["并为每个点添加相对于平均值的相对偏移量",{"2":{"809":1}}],["并为每个点添加相对于中心位置的相对偏移量",{"2":{"789":1}}],["并为每个体素分配一个向量以表示其占据状态",{"2":{"535":1}}],["并为每个体素标记占据和语义信息",{"2":{"409":1}}],["并为细化模块中的校正提供指导",{"2":{"716":1}}],["并为城市驾驶场景建立了新的视角合成基准",{"2":{"648":1}}],["并为建图",{"2":{"619":1}}],["并为其分配语义标签",{"2":{"482":1}}],["并为后续任务提供更好的表示能力",{"2":{"368":1}}],["并为人类提供了易于理解的环境模型",{"2":{"116":1}}],["并产生一个tsdf",{"2":{"362":1}}],["并经过嵌入转换为模型可处理的表示形式",{"2":{"340":1}}],["并添加在每帧网格中但不在多帧网格中的顶点和三元组",{"2":{"336":1}}],["并概述其结构表示",{"2":{"324":1}}],["并按照余弦时间表逐渐降低",{"2":{"813":1}}],["并按照特定的维度进行排序",{"2":{"664":1}}],["并按照",{"2":{"315":1,"550":1}}],["并选择具有nr连通分量的最大gp",{"2":{"301":1}}],["并对点云和体素标签进行随机翻转以进行",{"2":{"761":1}}],["并对点的坐标进行归一化处理",{"2":{"456":1}}],["并对其进行",{"2":{"681":1}}],["并对不同类别的方法进行了深入分析和比较",{"2":{"665":1}}],["并对各种输入模态的方法进行了深入分析",{"2":{"610":1}}],["并对所有预训练参数进行微调以进行下游任务",{"2":{"488":1}}],["并对传播到其他语义类别的区域进行处罚",{"2":{"410":1}}],["并对",{"2":{"372":1}}],["并对四面体网格进行细分",{"2":{"372":1}}],["并对房间几何形状做出假设",{"2":{"301":1}}],["并对roi的包围框进行第一次修正",{"2":{"296":1}}],["并对环境进行高级推理",{"2":{"116":1}}],["并进入下一个场景的预测",{"2":{"750":1}}],["并进一步有利于资源分配",{"2":{"924":1}}],["并进一步将深度一致性引入后向投影",{"2":{"839":1}}],["并进一步扩展到室外环境",{"2":{"808":1}}],["并进一步增加了高斯之间的重叠",{"2":{"567":1}}],["并进一步被",{"2":{"285":1}}],["并进行时间信息融合",{"2":{"942":1}}],["并进行了广泛的实验以验证其有效性",{"2":{"505":1}}],["并进行l2归一化",{"2":{"184":1}}],["并移除与提供的任务列表中至少一个任务的余弦相似度不够高",{"2":{"431":1}}],["并移除任何断开连接的节点",{"2":{"276":1}}],["并移除那些与已知人物和车辆边界框的重投影不重叠的误检结果",{"2":{"233":1}}],["并跟踪相应的网格顶点",{"2":{"253":1}}],["并采用先进的体积渲染技术生成2d渲染图",{"2":{"941":1}}],["并采用概率的乘法定理来推导几何预测",{"2":{"851":1}}],["并采用随机翻转和光度失真增强",{"2":{"822":1}}],["并采用所有语义类别的平均",{"2":{"807":1}}],["并采用余弦退火计划进行衰减",{"2":{"677":1,"771":1}}],["并采用激光雷达笛卡尔坐标系",{"2":{"649":1}}],["并采用双重掩码策略",{"2":{"549":1}}],["并采用交叉注意力机制从多尺度图像特征中聚合信息",{"2":{"547":1}}],["并采用鸟瞰图作为场景表示",{"2":{"547":1}}],["并采用基于",{"2":{"474":1}}],["并采用稀疏卷积",{"2":{"421":1}}],["并采用",{"2":{"210":1,"670":1}}],["并向前端反馈回环验证结果",{"2":{"189":1}}],["并不一定反映国防研究与工程副部长办公室的观点",{"2":{"973":1}}],["并不会检查是否越界",{"2":{"904":1}}],["并不理想用于自动驾驶场景",{"2":{"757":1}}],["并不是所有的边都可以折叠",{"2":{"466":1}}],["并不是这样",{"2":{"149":1}}],["并不在这一层建模",{"2":{"178":1}}],["并不能代表",{"2":{"173":1}}],["并构建对象原语的图",{"2":{"168":1}}],["并模拟人类代理的潜在高级动作",{"2":{"905":1}}],["并模拟它们之间的时空关系",{"2":{"162":1}}],["并模拟对象",{"2":{"147":1}}],["并定义环境的拓扑结构",{"2":{"162":1}}],["并避免合并相距甚远的片段",{"2":{"153":1}}],["并增强潜在表示的语义水平",{"2":{"488":1}}],["并增强了它以捕获空间概念的层次结构及其关系",{"2":{"131":1}}],["并增量地将esdf转换为度量语义3d网格以及可以从中快速提取地点拓扑图的广义voronoi图",{"2":{"141":1}}],["并阐明如何在实践中计算",{"2":{"137":1}}],["并用上标表示",{"2":{"870":1}}],["并用可微",{"2":{"743":1}}],["并用可微光栅化进行监督",{"2":{"619":1}}],["并用边存储坐标系之间的变换关系",{"2":{"648":1}}],["并用边连接它们以形成地点图",{"2":{"276":1}}],["并用三维高斯分布维护一个明确的全局记忆",{"2":{"568":1}}],["并用广义快速傅立叶变换",{"2":{"481":1}}],["并用简单的算法对每个体素的特征向量进行索引",{"2":{"363":1}}],["并用于从所有相机视图中采样2d特征",{"2":{"341":1}}],["并用",{"2":{"137":1,"698":1,"826":1}}],["并提高了注释的质量",{"2":{"735":1}}],["并提高算法效率",{"2":{"444":1}}],["并提取3d",{"2":{"449":1}}],["并提取不同视图方向的特征",{"2":{"337":1}}],["并提供了详细的性能比较",{"2":{"714":1}}],["并提供了一个定期更新的github仓库",{"2":{"665":1}}],["并提供了一种生成细粒度的高度细节图像的方法",{"2":{"294":1}}],["并提供全局感受野",{"2":{"603":1}}],["并提供几项新贡献",{"2":{"131":1}}],["并提出可微分反投影层来联合融合学习到的",{"2":{"968":1}}],["并提出一种将建筑物解析为房间的方法",{"2":{"967":1}}],["并提出了在多相机设置中将体积渲染作为中间3d特征调制器",{"2":{"941":1}}],["并提出了时间跨视图混合注意力",{"2":{"858":1}}],["并提出了",{"2":{"648":1}}],["并提出了一些启发性的未来展望",{"2":{"637":1}}],["并提出了基于高斯分布的embodiedocc框架来完成这一新任务",{"2":{"600":1}}],["并提出了基于高斯分布的embodiedocc框架来完成这一任务",{"2":{"568":1}}],["并提出了基于隐式体绘制的正则化",{"2":{"482":1}}],["并提出了通道到高度的变换",{"2":{"482":1}}],["并提出了将度量语义3d网格解析为3d场景图的首批算法",{"2":{"125":1}}],["并提出未来研究方向",{"2":{"80":1}}],["并在场景中检测对象",{"2":{"967":1}}],["并在场景图中的n个节点中进行交叉引用",{"2":{"905":1}}],["并在没有细粒度注释或lidar点云参与的情况下训练占用网络",{"2":{"932":1}}],["并在该层面上再次规划",{"2":{"930":1}}],["并在该层面上重新规划",{"2":{"930":1}}],["并在表",{"2":{"927":1}}],["并在表1中对它们进行了比较",{"2":{"757":1}}],["并在上采样和下采样路径之间使用跳跃连接",{"2":{"875":1}}],["并在毫秒内规划安全轨迹",{"2":{"864":1}}],["并在整个过程中保持效率",{"2":{"864":1}}],["并在投影过程中使用空间分组池化以更好地保留3d结构信息",{"2":{"858":1}}],["并在测试集上进行评估",{"2":{"853":1}}],["并在探索该场景的过程中更新这个记忆",{"2":{"852":1}}],["并在最后一个优化层中平等地更新所有高斯分布",{"2":{"833":1}}],["并在gaussianformer中使用4个transformer块来细化高斯分布的属性",{"2":{"822":1}}],["并在括号中报告初始化模块的延迟",{"2":{"812":1}}],["并在embodiedocc",{"2":{"793":1}}],["并在线更新当前场景的空间占用预测",{"2":{"793":1}}],["并在验证集上评估其性能",{"2":{"787":1,"900":1}}],["并在后处理过程中利用未标记的中间帧和场景完成来增强体素密度",{"2":{"735":1}}],["并在后处理过程中使用泊松重建填充空洞",{"2":{"735":1}}],["并在网格中创建了伪影",{"2":{"709":1}}],["并在网络的每一层之后动态更新",{"2":{"574":1}}],["并在当前视锥体中推导出三维空间占用预测",{"2":{"682":1}}],["并在每个级别应用监督信号",{"2":{"875":1}}],["并在每个网格上定义卷积核",{"2":{"511":1}}],["并在每次更新后按照上述公式计算当前损失",{"2":{"750":1}}],["并在每一步更新",{"2":{"743":1}}],["并在每组中分别进行最大池化",{"2":{"676":1}}],["并在采样前对",{"2":{"660":1}}],["并在不同语义抽象层级上呈现环境",{"2":{"648":1}}],["并在bev",{"2":{"642":1}}],["并在超图上应用谱卷积建立了超边缘卷积层",{"2":{"607":1}}],["并在此论文中进一步发布了新的uhumans2数据集",{"2":{"605":1}}],["并在综述",{"2":{"603":1}}],["并在具身智能社区迅速流行",{"2":{"588":1}}],["并在具有挑战性的模拟和真实数据上演示结果的空间感知系统",{"2":{"141":1}}],["并在室内场景中进行具身空间占用预测",{"2":{"568":1}}],["并在激光雷达数据集上进行评估",{"2":{"566":1}}],["并在两个流之后执行特征融合",{"2":{"512":1}}],["并在预训练后被丢弃",{"2":{"488":1}}],["并在其各自提出的数据集上建立了基准",{"2":{"482":1}}],["并在合作协议号fa8750",{"2":{"467":1}}],["并在包括更大开放空间和更远离地点子图中的节点的地铁站数据集中更大",{"2":{"437":1}}],["并在小型到中型场景",{"2":{"437":1}}],["并在映射会话结束时只执行一次",{"2":{"431":1}}],["并在三个大规模基准测试",{"2":{"425":1}}],["并在卷积部分和网络的全连接部分之间放置一个全局平均池化层",{"2":{"407":1}}],["并在训练和评估过程中忽略不可见的体素",{"2":{"757":1}}],["并在训练",{"2":{"377":1}}],["并在所有数据集上取得了最先进的性能",{"2":{"356":1}}],["并在transformer解码器中与2d特征进行交互以生成预测",{"2":{"341":1}}],["并在图的相应节点之间添加一条边",{"2":{"271":1}}],["并在图1和图6中可视化",{"2":{"210":1}}],["并在相应的原语的3d边界框有非零重叠时添加边",{"2":{"271":1}}],["并在第6",{"2":{"919":1}}],["并在第",{"2":{"231":1,"853":1}}],["并在构建环境地图的同时",{"2":{"171":1}}],["并在",{"2":{"153":1,"429":1,"670":1}}],["并在kimera",{"2":{"131":1}}],["并在几分钟内构建一个复杂室内环境的dsg",{"2":{"105":1}}],["并显式建模不确定性",{"2":{"435":1}}],["并显式建模场景中的动态实体",{"2":{"131":1}}],["并显著提高了速度",{"2":{"121":1}}],["并专门针对驾驶场景",{"2":{"123":1}}],["并创建场景中对象的可供性3d地图",{"2":{"121":1}}],["并假设环境是静态的",{"2":{"116":1}}],["并阻止下游任务直接从原始传感器输入学习",{"2":{"114":1}}],["并嵌入开放集语义",{"2":{"109":1}}],["并返回当前位置",{"2":{"104":1}}],["并且需要高效的数据结构和算法设计",{"2":{"1004":1}}],["并且需要进行信息融合",{"2":{"610":1}}],["并且它们的形状较小",{"2":{"1000":1}}],["并且它被用作场景补全",{"2":{"736":1}}],["并且擅长通过精确的深度测量捕捉场景几何",{"2":{"970":1}}],["并且首次将这个问题形式化为姿态图优化",{"2":{"967":1}}],["并且循环闭合通过变形这个网格来实施的情况",{"2":{"967":1}}],["并且倾向于降低方差",{"2":{"928":2}}],["并且最高可达",{"2":{"928":1}}],["并且容易受到遮挡的影响",{"2":{"910":1}}],["并且偶尔甚至超过了真实标注",{"2":{"899":1}}],["并且有效地检测到了不规则物体和地形",{"2":{"899":1}}],["并且通过将柱坐标体积压缩成三个",{"2":{"865":1}}],["并且通常返回可能不直接适用于导航的密集模型",{"2":{"172":1}}],["并且相比",{"2":{"851":1}}],["并且与使用三种模态的",{"2":{"847":1}}],["并且与segment的3d",{"2":{"206":1}}],["并且明显优于基于深度的对应方案",{"2":{"812":1}}],["并且更适合对象高度遮挡和拥挤的复杂场景",{"2":{"798":1}}],["并且显著优于基于图像的方法",{"2":{"779":1}}],["并且接近架子和地板",{"2":{"732":1}}],["并且前k个非背景目标查询被推送到存储器队列中",{"2":{"695":1}}],["并且对于大规模模型来说足够有效",{"2":{"824":1}}],["并且对周围摄像头可见",{"2":{"723":1}}],["并且对循环闭合参数调整不太敏感",{"2":{"634":1}}],["并且对各种类型的场景都具有鲁棒性",{"2":{"603":1}}],["并且依赖于深度估计的质量",{"2":{"612":1}}],["并且为了扩展数据集以适应其他场景",{"2":{"605":1}}],["并且界面类似于",{"2":{"605":1}}],["并且大多数方法是为室内或室外场景专门设计的",{"2":{"570":1}}],["并且使得为每个roi取得的特征能够更好地对齐原图上的roi区域",{"2":{"554":1}}],["并且几乎不需要对潜在空间进行正则化",{"2":{"552":1}}],["并且全局结构对于点云的理解至关重要",{"2":{"549":1}}],["并且可以对网络训练施加强约束",{"2":{"1000":1}}],["并且可以渲染为具有6890个顶点和23个关节的网格",{"2":{"967":1}}],["并且可以根据需要灵活操纵数据多样性",{"2":{"963":1}}],["并且可以处理不同的采样密度",{"2":{"481":1}}],["并且可以由商业实体获得许可",{"2":{"302":1}}],["并且能够充分发挥每种传感器的独特优势",{"2":{"898":1}}],["并且能够高效地关注灵活的兴趣区域",{"2":{"612":1}}],["并且能够捕捉到物体之间更精细的几何关系",{"2":{"444":1}}],["并且能够表示距离的方向",{"2":{"31":1}}],["并且缺乏实际用途",{"2":{"916":1}}],["并且缺乏准确的深度估计",{"2":{"444":1}}],["并且缺乏场景信息",{"2":{"313":1}}],["并且精度与批量离线方法相当",{"2":{"437":1}}],["并且送入全连接层进行分类",{"2":{"432":1,"741":1}}],["并且beta参数检查通过",{"2":{"419":1}}],["并且真值对象的边界框包含估计边界框的质心",{"2":{"402":1}}],["并且给定",{"2":{"390":1}}],["并且随着时间的推移而漂移",{"2":{"390":1}}],["并且随着网格分辨率的提高",{"2":{"372":1}}],["并且一个节点包含在另一个节点的边界框内",{"2":{"380":1}}],["并且整个网格将根据变形图方法",{"2":{"380":1}}],["并且长宽各自放大一定的倍数",{"2":{"375":1}}],["并且因此能够很好地拟合输入间复杂的关系",{"2":{"343":1}}],["并且点云是一种稀疏结构",{"2":{"340":1}}],["并且进行目标包围框的第二次修正",{"2":{"296":1}}],["并且总是从高频信息开始到低频信息",{"2":{"287":1}}],["并且直观易懂",{"2":{"264":1}}],["并且取决于任务",{"2":{"262":1}}],["并且只需要一个简单的交叉熵损失lce用于占据预测",{"2":{"690":1}}],["并且只测试新回路与之前的回路",{"2":{"390":1}}],["并且只迭代未标记的节点",{"2":{"301":1}}],["并且只能保留原有图像的空间布局",{"2":{"264":1}}],["并且只在用户指定的半径内",{"2":{"253":1}}],["并且只关注那些真正变化的部分",{"2":{"153":1}}],["并且在occ3d",{"2":{"1000":1}}],["并且在推断非常复杂",{"2":{"989":1}}],["并且在推理过程中具有良好的可扩展性",{"2":{"962":1}}],["并且在",{"2":{"982":1}}],["并且在kitti",{"2":{"931":1}}],["并且在保持高预测精度的同时节省了相同的高斯",{"2":{"899":1}}],["并且在保证稀疏性的同时维护特征的空间不变性",{"2":{"332":1}}],["并且在雨天场景中保持了对小型动态目标的检测能力",{"2":{"827":1}}],["并且在多样化主流体素级占据方法",{"2":{"770":1}}],["并且在真实场景中我们将kimera",{"2":{"437":1}}],["并且在这些情况下预测质量较差",{"2":{"419":1}}],["并且在这些领域的交叉点上最近的研究越来越多",{"2":{"116":1}}],["并且在无监督表示学习方面取得了可比的结果",{"2":{"314":1}}],["并且在训练的时候",{"2":{"207":1}}],["并且",{"2":{"162":1,"320":1,"343":1,"380":1}}],["并且不呈正相关",{"2":{"1000":1}}],["并且不需要任何额外的模态作为监督",{"2":{"704":1}}],["并且不需要激光雷达分支的三维目标检测预训练",{"2":{"482":1}}],["并且不需要为不受影响的连通分量重新计算",{"2":{"153":1}}],["并且不能很好地处理自然语言的内在模糊性和多样性",{"2":{"109":1}}],["并且没有因果关系或高级推理的概念",{"2":{"116":1}}],["并且必须创建一个地图",{"2":{"586":1}}],["并且必须将它们聚类成一个任务相关的压缩表示",{"2":{"109":1}}],["并且必须选择粒度和保留在地图中的对象和场景结构的子集",{"2":{"98":1}}],["并且仅使用机载计算",{"2":{"98":1}}],["并且包含高级信息",{"2":{"96":1}}],["并将深度图转换为",{"2":{"978":1}}],["并将深度反投影为点云",{"2":{"870":1}}],["并将中间3d特征累积到2d平面上以进行额外的2d监督",{"2":{"941":1}}],["并将实验结果展示在表",{"2":{"882":1}}],["并将每个平面的多尺度特征聚合以解码高分辨率的三视角特征表示",{"2":{"858":1}}],["并将每个体积箱与一个可学习的加权矩阵相关联",{"2":{"511":1}}],["并将生成的网格体素化",{"2":{"850":1}}],["并将它们投影到2d图像平面上以生成密集的bev特征",{"2":{"839":1}}],["并将它们发送给我们的标注合作伙伴",{"2":{"277":1}}],["并将结果展示在表",{"2":{"827":1}}],["并将占据逻辑替换为通过2d卷积获得的bev级特征的通道到高度变换",{"2":{"811":1}}],["并将bevdetocc中的3d卷积替换为2d对应部分",{"2":{"811":1}}],["并将来自",{"2":{"808":1}}],["并将我们的插件替换与流行的现有方法",{"2":{"791":1}}],["并将初始学习率设置为2e",{"2":{"758":1}}],["并将输入图像分辨率调整为256×704",{"2":{"758":1}}],["并将lidar点云分割为静态背景和动态前景",{"2":{"735":1}}],["并将区域输入到",{"2":{"694":1}}],["并将空闲空间留给一个固定的大型高斯以提高效率",{"2":{"677":1}}],["并将复杂的由粗到精预测头替换为简单的conv2d头",{"2":{"670":1}}],["并将体素融合层替换为",{"2":{"670":1}}],["并将这些特征汇总为复合特征",{"2":{"858":1}}],["并将这些特征直接放置在世界中特定的",{"2":{"564":1}}],["并将这些序列从所有局部区域反馈到基于rnn的编解码结构中",{"2":{"664":1}}],["并将采样得到的特征进行聚合",{"2":{"660":1}}],["并将所有重投影深度的平均值作为像素的最终深度估计",{"2":{"650":1}}],["并将所有迭代过程中的深度预测图都考虑进去",{"2":{"647":1}}],["并将教师模型的占据结果作为感兴趣区域",{"2":{"642":1}}],["并将细化后的tpv",{"2":{"578":1}}],["并将dgcnn",{"2":{"574":1}}],["并将从3d卷积输出中获得的占据逻辑替换为通过2d卷积获得的bev级特征的通道到高度变换",{"2":{"535":1}}],["并将三维目标检测作为训练中的辅助分支",{"2":{"512":1}}],["并将其计时性能与直接在体积esdf表示上运行a进行比较",{"2":{"947":1}}],["并将其用作层次路径规划的输入",{"2":{"939":1}}],["并将其性能与其他",{"2":{"865":1}}],["并将其左侧裁剪为",{"2":{"853":1}}],["并将其与其他",{"2":{"965":1}}],["并将其与我们的方法进行比较",{"2":{"807":1}}],["并将其与旧均值",{"2":{"716":1}}],["并将其与ff0沿特征维度连接起来",{"2":{"609":1}}],["并将其作为位置嵌入与深度特征一起加入到原始视觉特征",{"2":{"649":1}}],["并将其输出到预测头以进行3d语义占据预测",{"2":{"621":1}}],["并将其整合到object",{"2":{"594":1}}],["并将其标记为一般物体",{"2":{"535":1}}],["并将其转换为柱坐标系",{"2":{"649":1}}],["并将其转换为柱坐标系以进行特征细化和融合",{"2":{"438":1}}],["并将其转换为",{"2":{"441":1}}],["并将其稀疏化为地点图",{"2":{"228":1}}],["并将落在每个房间内的独特",{"2":{"437":1}}],["并将intel",{"2":{"437":1}}],["并将该相似度以损失的形式传递给图像生成器",{"2":{"399":1}}],["并将优化重写为",{"2":{"390":1}}],["并将剩余的回路闭合传递给异常值拒绝和姿态求解器",{"2":{"390":1}}],["并将3d高斯分布的数量设置为51200",{"2":{"842":1}}],["并将3d",{"2":{"363":1}}],["并将维度置为定值",{"2":{"296":1}}],["并将前",{"2":{"153":1}}],["并将机器人学中的基础技术与具身人工智能中新兴范式联系起来",{"2":{"90":1}}],["并将场景重命名为",{"2":{"32":1}}],["并呈现语义地图构建的关键挑战和未来机遇",{"2":{"90":1}}],["并勾勒vla4ad的未来方向",{"2":{"72":1}}],["并",{"2":{"27":1}}],["9+max",{"2":{"998":1}}],["9+max⁡",{"2":{"998":1}}],["9节展示了kimera在嵌入式计算机上运行时的实时性能如何扩展",{"2":{"541":1}}],["9和γ",{"2":{"431":1}}],["98",{"2":{"195":1,"216":1,"522":1,"545":1,"965":1}}],["939",{"2":{"277":1}}],["93",{"2":{"176":1,"277":1,"360":3,"447":1,"522":1,"534":1,"563":1,"664":1,"677":1,"808":1,"823":1,"997":2,"998":1}}],["93842",{"2":{"136":1}}],["944",{"2":{"947":1}}],["942",{"2":{"277":1,"534":1}}],["94",{"2":{"145":1,"195":1,"425":1,"563":1,"595":1,"664":1,"732":1,"917":1,"971":1}}],["99m",{"2":{"971":1}}],["99主干",{"2":{"805":1}}],["993",{"2":{"277":1}}],["99677",{"2":{"136":1}}],["99",{"2":{"128":1,"176":1,"617":1,"931":1}}],["96",{"2":{"128":1,"145":1,"176":1,"216":1,"947":1}}],["91",{"2":{"128":1,"277":1,"534":1,"664":1,"808":1,"957":1,"975":1,"988":1,"1006":1}}],["900×1600900",{"2":{"771":1}}],["900×1600",{"2":{"677":1}}],["900",{"2":{"495":1}}],["907",{"2":{"277":1,"534":1}}],["90",{"2":{"128":1,"522":1,"552":1,"803":1,"812":1,"916":13,"957":1,"969":1,"971":2,"1000":1,"1004":1}}],["97m",{"2":{"545":1,"965":1,"971":2}}],["975",{"2":{"277":1}}],["97",{"2":{"128":1,"277":1,"534":1,"1000":1,"1005":1}}],["92​≈6",{"2":{"916":1}}],["92≈6",{"2":{"916":1}}],["92miou",{"2":{"779":1}}],["92",{"2":{"114":1,"277":1,"333":1,"534":1,"545":2,"664":1,"782":1,"965":2,"975":1,"997":1}}],["958",{"2":{"277":1,"534":1}}],["959",{"2":{"277":1,"534":1}}],["95",{"2":{"82":1,"808":1,"996":1}}],["9",{"0":{"538":1,"836":1,"909":1,"958":1},"2":{"27":1,"67":1,"90":1,"109":2,"114":1,"121":1,"172":1,"277":5,"302":1,"431":1,"437":1,"492":2,"517":1,"534":6,"535":1,"548":1,"564":1,"566":1,"603":3,"617":1,"627":1,"652":1,"655":1,"665":1,"667":1,"700":1,"765":1,"771":1,"790":1,"800":1,"803":1,"808":1,"822":1,"824":1,"834":1,"840":1,"853":2,"870":1,"893":2,"899":1,"901":1,"902":1,"916":4,"917":1,"928":1,"945":1,"947":1,"959":1,"978":1,"982":1,"988":1,"989":2,"992":2,"996":1,"998":1,"1006":2}}],["8hz",{"2":{"1001":1}}],["8子集中实现了76",{"2":{"996":1}}],["8b",{"2":{"928":1}}],["8a",{"2":{"928":1}}],["8ℓ×ℓ=8×8的视锥用于",{"2":{"853":1}}],["8毫秒",{"2":{"836":1}}],["8m×2",{"2":{"793":1}}],["8m×4",{"2":{"793":1}}],["8cm误差的3d网格",{"2":{"732":1}}],["8的点",{"2":{"622":1}}],["8np×cp×hp",{"2":{"609":1}}],["8np",{"2":{"609":1}}],["8​",{"2":{"609":1}}],["8fg",{"2":{"609":1}}],["8×wp",{"2":{"609":2}}],["8×w",{"2":{"609":2}}],["8×8",{"2":{"278":2}}],["82°",{"2":{"917":1}}],["82",{"2":{"522":2,"664":1,"808":1,"840":1,"870":1,"876":2,"941":1,"942":3,"950":2,"957":1,"978":1,"985":2,"1000":1,"1001":3,"1004":1}}],["82的miou",{"2":{"421":1,"779":1}}],["820",{"2":{"277":1,"534":1}}],["8节突出了kimera的实时性能",{"2":{"541":1}}],["8节",{"0":{"510":1},"2":{"362":1,"686":1}}],["8万30秒片段",{"2":{"360":1}}],["8x8",{"2":{"181":1}}],["8x11",{"2":{"136":1}}],["896×1600",{"2":{"803":1}}],["899",{"2":{"277":1,"534":1}}],["89",{"2":{"176":1,"947":1,"957":1,"963":1,"985":2}}],["859",{"2":{"277":1,"534":1}}],["85",{"2":{"145":1,"664":1,"893":2,"942":1,"950":2,"957":1,"963":1,"985":2,"998":1,"1000":2}}],["850",{"2":{"126":1}}],["88m的盒子",{"2":{"793":1}}],["880",{"2":{"421":1}}],["88",{"2":{"128":1,"176":1,"277":1,"437":1,"534":1,"664":1,"808":1,"942":1,"963":1,"985":1}}],["815",{"2":{"853":1}}],["81​",{"2":{"768":1}}],["8192",{"2":{"345":1}}],["817",{"2":{"277":1,"534":1}}],["81",{"2":{"128":1,"522":1,"603":2,"664":1,"893":1,"932":1,"942":3,"950":2,"957":1,"988":1,"1000":2}}],["877",{"2":{"277":1,"710":1}}],["87",{"2":{"128":1,"522":3,"664":1,"700":1,"903":1,"942":1,"957":1,"963":1,"988":1,"998":1,"1000":1,"1006":1}}],["8487",{"2":{"749":1}}],["841",{"2":{"277":1,"534":1}}],["84",{"2":{"128":1,"522":2,"664":1,"808":1,"942":1,"949":1,"957":2,"985":1,"998":1}}],["860",{"2":{"277":1,"534":1}}],["861",{"2":{"277":1,"534":1}}],["86",{"2":{"114":1,"128":1,"277":1,"534":1,"664":1,"808":1,"827":1,"963":1,"997":2}}],["83miou和5",{"2":{"800":1}}],["83",{"2":{"103":1,"603":1,"652":2,"664":1,"700":2,"828":2,"899":2,"928":1,"941":1,"942":1,"957":1,"988":1,"1000":1}}],["800",{"2":{"333":1}}],["809",{"2":{"277":1,"534":1}}],["80",{"2":{"76":1,"82":1,"173":1,"254":1,"360":1,"437":1,"522":1,"570":1,"603":1,"636":1,"700":1,"782":1,"803":1,"808":1,"922":1,"942":3,"950":4,"998":1}}],["8",{"0":{"507":1,"816":1,"881":1,"893":1,"897":1,"913":1,"926":1,"935":1,"943":1,"951":1,"973":1},"1":{"897":1,"913":1,"926":1,"935":1,"943":1,"951":1},"2":{"27":1,"40":1,"64":1,"90":1,"109":1,"121":1,"145":1,"173":3,"176":2,"277":4,"278":2,"301":1,"306":2,"390":2,"421":1,"486":1,"492":1,"516":2,"519":2,"534":4,"547":3,"548":1,"562":1,"585":1,"603":1,"609":13,"627":1,"660":6,"665":1,"667":1,"670":1,"675":1,"676":2,"677":1,"691":1,"693":1,"700":2,"738":1,"759":1,"761":1,"768":1,"770":1,"771":1,"790":1,"803":2,"811":3,"822":1,"832":2,"840":1,"842":2,"853":2,"885":1,"886":1,"893":5,"899":1,"916":1,"928":3,"942":3,"947":2,"979":2,"989":2,"992":2,"997":1,"1003":1,"1004":2}}],["目的",{"2":{"470":1}}],["目前限于小型桌面场景",{"2":{"967":1}}],["目前社区聚焦任务级外部评估",{"2":{"864":1}}],["目前社区多将建图视作解决高层推理任务的一个子模块",{"2":{"435":1}}],["目前缺乏一套可跨不同地图结构",{"2":{"846":1}}],["目前尚不存在一套被广泛认可的地图表征评估指标",{"2":{"826":1}}],["目前",{"2":{"629":1,"667":1,"759":1,"864":1,"881":1,"973":1,"1004":1}}],["目前大多数现有算法主要服务于",{"2":{"625":1}}],["目前的三维卷积网络可以分为连续卷积网络和离散卷积网络",{"2":{"450":1}}],["目前点云特征提取的框架仍在快速发展",{"2":{"265":1}}],["目前点云领域的自监督学习并没有取得很好的成果",{"2":{"265":1}}],["目前只有semantic",{"2":{"254":1}}],["目前面临以下几点问题",{"2":{"220":1}}],["目前已知的有",{"2":{"140":1,"280":1}}],["目前测试下来可以使用",{"2":{"27":1}}],["目标运动不可预测",{"2":{"926":1}}],["目标任务",{"2":{"877":1}}],["目标导航",{"2":{"698":1}}],["目标类别",{"0":{"679":1},"1":{"702":1}}],["目标是预测3d语义占用",{"2":{"693":1}}],["目标是根据输入图像",{"2":{"656":1}}],["目标是将场景表示压缩成相关对象和区域的聚类",{"2":{"121":1}}],["目标跟踪和目标未来轨迹预测任务",{"2":{"653":1}}],["目标查询",{"2":{"623":1}}],["目标搜索",{"2":{"525":1}}],["目标",{"2":{"302":1,"305":1,"355":1}}],["目标及交通模式",{"2":{"252":1}}],["目标函数",{"0":{"342":1},"2":{"235":1}}],["目标检测结果",{"2":{"596":1}}],["目标检测任务",{"2":{"564":1,"678":2}}],["目标检测的工作",{"2":{"414":1}}],["目标检测之选择性搜索",{"2":{"207":1}}],["目标检测",{"0":{"16":1,"734":1},"1":{"23":1,"30":1,"756":1,"777":1,"798":1,"818":1,"838":1,"857":1,"874":1,"891":1},"2":{"263":1,"625":1,"653":1,"808":1,"824":1}}],["|i",{"2":{"988":1}}],["|m",{"2":{"916":2}}],["|m|n=∣m∣个大小为hwd×hwd",{"2":{"752":1}}],["|c",{"2":{"749":1,"802":1}}],["|c|d=10+∣c∣",{"2":{"693":1}}],["|c|",{"2":{"693":1}}],["|∣sf​∣",{"2":{"694":1}}],["|s",{"2":{"694":2}}],["|d=11+∣c∣",{"2":{"563":1}}],["|返回集合的基数",{"2":{"437":1}}],["|re",{"2":{"437":1}}],["|re|",{"2":{"437":2}}],["|rg|",{"2":{"437":2}}],["|rg",{"2":{"437":1}}],["|b",{"2":{"351":1}}],["|a",{"2":{"351":1}}],["|^2",{"2":{"208":3}}],["|x",{"2":{"137":3,"140":1,"208":4,"235":2,"280":1}}],["||vi",{"2":{"390":1}}],["||t−1",{"2":{"390":1}}],["||m−1",{"2":{"390":1}}],["||x−1",{"2":{"390":2}}],["||x^",{"2":{"390":1}}],["||rx",{"2":{"390":1}}],["||rm",{"2":{"390":1}}],["||s",{"2":{"235":6}}],["||",{"2":{"235":8,"390":2}}],["|||but||but|||||but|||||but||||but||||but||||||but||||",{"2":{"66":1}}],["|||||||||||||||||||||||||||||||||||||||||||||||||||||",{"2":{"66":1}}],["||p",{"2":{"13":1}}],["|",{"2":{"26":1,"40":1,"43":15,"45":1,"51":15,"66":2,"67":2,"78":1,"135":2,"148":1,"149":2,"183":1,"208":3,"235":1,"243":1,"268":5,"287":1,"290":1,"306":1,"312":1,"323":1,"342":2,"382":1,"394":1,"399":1,"422":1,"437":1,"452":1,"498":1,"513":2,"515":1,"532":2,"563":3,"593":2,"647":2,"666":1,"668":1,"681":1,"692":1,"693":4,"694":2,"705":1,"715":2,"716":3,"728":1,"746":1,"749":1,"802":1,"814":1,"848":2,"916":8,"988":1}}],["单模态语义占据预测",{"2":{"808":1}}],["单图像过滤",{"2":{"775":1}}],["单图像",{"2":{"775":1}}],["单步长稀疏transformer",{"2":{"715":1}}],["单个传感器的观察只能捕捉场景的一部分",{"2":{"691":1}}],["单元测试",{"2":{"510":1}}],["单元格边长",{"2":{"495":1}}],["单元格",{"2":{"406":1}}],["单位",{"2":{"584":1}}],["单位范数",{"2":{"480":1}}],["单位是",{"2":{"26":1}}],["单帧点云中的最大点数仅为34",{"2":{"421":1}}],["单一的语义",{"2":{"406":1}}],["单视角",{"2":{"394":1}}],["单视角+数据增强",{"2":{"366":1}}],["单视角设定下pointcontrast是否也可以发挥作用",{"2":{"366":1}}],["单应性变换简单来说",{"2":{"355":1}}],["单前向传递完成",{"2":{"308":1}}],["单目人体跟踪的常见方法是预测2d图像空间中的关节概率",{"2":{"967":1}}],["单目相机",{"2":{"967":1}}],["单目相机无法准确估计深度",{"2":{"564":1}}],["单目3d语义占用预测",{"2":{"842":1}}],["单目3d目标检测",{"2":{"23":1}}],["单目输入的分辨率设置为480×640",{"2":{"813":1}}],["单目设置",{"2":{"652":1}}],["单目深度估计本质上是一个病态问题",{"2":{"609":1}}],["单目图像的三维重建",{"2":{"603":1}}],["单目前视",{"2":{"334":5}}],["单目",{"2":{"310":1,"792":1}}],["单目标跟踪器的整体性能",{"2":{"263":1}}],["单层室内环境的dsg包括5个层次",{"2":{"147":1}}],["单独用",{"2":{"133":1}}],["单任务机器人向鲁棒",{"2":{"123":1}}],["因缺乏带详细语义的真值地图而极少被量化",{"2":{"826":1}}],["因输入bev查询已含语义先验",{"2":{"764":1}}],["因行人穿行减速",{"2":{"360":1}}],["因而开发可扩展",{"2":{"913":1}}],["因而极少作为评估指标被报告",{"2":{"826":1}}],["因而研究者更关注",{"2":{"435":1}}],["因而出现锥形",{"2":{"355":1}}],["因而更适用于需要长时规划与语义推理的复杂任务",{"2":{"299":1}}],["因子图",{"2":{"310":1}}],["因子图的节点表示机器人位姿",{"2":{"171":1}}],["因视觉编码器每帧处理数千token",{"2":{"260":1}}],["因果关系和被遮挡的对象",{"2":{"116":1}}],["因此与",{"2":{"995":1}}],["因此与两个或四个其他边相邻",{"2":{"325":1}}],["因此强监督学习中使用的损失函数",{"2":{"988":1}}],["因此具有一定的尺度不变性",{"2":{"985":1}}],["因此更有效的方法是预测沿光线的离散深度分布",{"2":{"950":1}}],["因此3d空间中的每个特征都可以表示为三个tpv特征的组合",{"2":{"950":1}}],["因此创建了一个更大场景",{"2":{"947":1}}],["因此必须进行2d到3d的转换",{"2":{"942":1}}],["因此纯视觉中心方法在这些场景中的表现较差",{"2":{"936":1}}],["因此使用光度损失无法提供进一步的结构信息",{"2":{"934":1}}],["因此使用时序tta缓解此问题",{"2":{"673":1}}],["因此位于正确占用区域内的高斯也可能具有非零距离",{"2":{"916":1}}],["因此为每个体素网格提供了可见性掩码",{"2":{"900":1}}],["因此为导航和规划提供了严格概括了拓扑地图的概念",{"2":{"131":1}}],["因此仍然可能存在冗余",{"2":{"878":1}}],["因此不论在尾部或头部安插元素都十分迅速",{"2":{"871":1}}],["因此体素大小可能仍需要调整以在其他情况下保持实时性能",{"2":{"836":1}}],["因此损失函数仅在yyy定义的地方进行计算",{"2":{"834":1}}],["因此进行了look",{"2":{"833":1}}],["因此几乎不存在漂移",{"2":{"826":1}}],["因此设计可靠的停止准仍是开放难题",{"2":{"826":1}}],["因此它们是无效的",{"2":{"916":1}}],["因此它们无法负担高级的语义理解",{"2":{"116":1}}],["因此它可以以imu速率",{"2":{"816":1}}],["因此这类算法应始终与其他手段相结合以确保安全",{"2":{"953":1}}],["因此这些方法也可以被视为在训练阶段的多模态",{"2":{"779":1}}],["因此这种比较允许评估clio中ib聚类的有效性",{"2":{"431":1}}],["因此一个好的模型应该在这两个指标上都表现良好",{"2":{"778":1}}],["因此训练细节严格遵循原始主流体素级占据方法",{"2":{"770":1}}],["因此当距离足够大时",{"2":{"738":1}}],["因此后续研究很少使用这种人工净化",{"2":{"735":1}}],["因此无法提供3d场景的完整表示",{"2":{"667":1}}],["因此无法捕获点之间的局部结构信息",{"2":{"420":1}}],["因此得到的表示对点云顺序",{"2":{"664":1}}],["因此点的选择基本只依赖于mesh本身的结构",{"2":{"589":1}}],["因此仅为占用网络训练提供部分监督",{"2":{"988":1}}],["因此仅使用单一平面无法描述场景的细粒度3d结构",{"2":{"858":1}}],["因此仅使用625个分割查询来预测最终的200×200",{"2":{"566":1}}],["因此仅靠马尔可夫链无法生成各种形状的点云",{"2":{"314":1}}],["因此基于网格的表示也更难以捕捉场景动态",{"2":{"547":1}}],["因此缺乏鲁棒性",{"2":{"482":1}}],["因此也被用于驾驶场景重建和仿真",{"2":{"474":1}}],["因此我们将训练限制在6个epoch",{"2":{"876":1}}],["因此我们的方法比其他",{"2":{"865":1}}],["因此我们在第",{"2":{"853":1}}],["因此我们在每次迭代后更新点位置",{"2":{"464":1}}],["因此我们没有报告结果",{"2":{"842":1}}],["因此我们主要与基于图像的方法进行比较",{"2":{"779":1}}],["因此我们可以根据概率的乘法定理进行聚合",{"2":{"681":1}}],["因此我们可以看到任务知识对这一数据集的影响较小",{"2":{"462":1}}],["因此我们进一步针对3d感知任务进行针对性预训练",{"2":{"617":1}}],["因此sidpac场景的计算成本高于其他场景",{"2":{"437":1}}],["因此synthesis",{"2":{"133":1}}],["因此ωgij和ω",{"2":{"390":1}}],["因此只能得出一些初步结论",{"2":{"922":1}}],["因此只通过各类指标评估智能体在下游任务中的表现",{"2":{"786":1}}],["因此只需要一个深度值变量",{"2":{"355":1}}],["因此只有一个建筑物节点",{"2":{"240":1}}],["因此可以直接用于执行下游任务",{"2":{"738":1}}],["因此可以",{"2":{"552":1}}],["因此可以提高分割的稳定性和效率",{"2":{"96":1}}],["因此可求",{"2":{"235":1}}],["因此并非所有激光雷达扫描都有对应的摄像头帧",{"2":{"211":1}}],["因此匹配的图文对的相似度",{"2":{"184":1}}],["因此没有潜在的合并",{"2":{"153":1}}],["因此至关重要的是要限制聚合ib的计算复杂度",{"2":{"153":1}}],["因此在每个体素内应用最大池化操作以聚合特征",{"2":{"676":1}}],["因此在优化过程中提供了多重正则化效果",{"2":{"666":1}}],["因此在fmiou方面性能优越",{"2":{"492":1}}],["因此在",{"2":{"149":1}}],["因此需要寻找到这些表面特征之下隐藏的深层次的关系",{"2":{"149":1}}],["因此简单的损失就足以监督运动",{"2":{"143":1}}],["因此交互特征会通过早期层被稀释",{"2":{"96":1}}],["因此主要聚焦于任务本身",{"2":{"90":1}}],["因此",{"2":{"90":1,"96":1,"114":1,"126":1,"128":1,"129":1,"141":1,"217":1,"301":2,"306":1,"333":1,"372":2,"384":1,"405":1,"408":1,"417":1,"419":2,"420":1,"421":1,"429":1,"432":2,"434":1,"447":1,"449":1,"455":1,"464":1,"466":1,"471":1,"480":1,"525":1,"532":1,"534":1,"535":1,"548":1,"554":1,"564":1,"567":1,"570":2,"590":1,"596":1,"599":1,"605":2,"625":1,"638":2,"648":1,"653":1,"678":1,"682":1,"691":1,"693":2,"702":1,"705":1,"724":1,"735":1,"741":2,"750":2,"765":1,"793":1,"814":1,"816":1,"824":1,"836":1,"864":4,"866":1,"867":1,"872":1,"892":1,"905":1,"910":1,"913":1,"916":2,"922":1,"926":1,"935":1,"952":1,"962":1,"965":1,"969":1,"996":1,"1000":5,"1005":1,"1006":2}}],["因此采用反向传播修正机制",{"2":{"75":1}}],["因此提出",{"2":{"75":1}}],["因此来衡量生成图片和真实图片的距离",{"2":{"20":1}}],["因为miou计算不考虑类别频率",{"2":{"1000":1}}],["因为一个体素的偏差会将薄物体的iou值降低到零",{"2":{"998":1}}],["因为一旦用交互式分割工具打一个点",{"2":{"117":1}}],["因为邻域搜索机制既需要较高的计算成本",{"2":{"996":1}}],["因为图像并未观察到该部分",{"2":{"989":1}}],["因为图像的latent空间要比图像pixel空间要小",{"2":{"205":1}}],["因为验证集和测试集之间的差距更小",{"2":{"989":1}}],["因为重要特征未被放大",{"2":{"971":1}}],["因为非零值的数量只占很小的百分比",{"2":{"962":1}}],["因为投影步骤不可避免地会引入信息丢失",{"2":{"955":1}}],["因为每个查询必须关注特征图中的所有特征",{"2":{"950":1}}],["因为每个地点都与至少一个房间标签相关",{"2":{"522":1}}],["因为每个地点都连接到附近的对象",{"2":{"218":1}}],["因为操作员需要向机器人提供度量坐标",{"2":{"939":1}}],["因为高斯之间存在大量重叠",{"2":{"916":1}}],["因为高斯仅用于建模占用区域",{"2":{"704":1}}],["因为必须移动其它元素",{"2":{"871":1}}],["因为通过降低语义标签的准确性",{"2":{"853":1}}],["因为用于协方差的sigmoid激活函数容易出现梯度消失问题",{"2":{"842":1}}],["因为3d高斯表示更好地利用了驾驶场景的稀疏性和物体尺度的多样性",{"2":{"842":1}}],["因为有限的训练数据可能会阻碍对这些代表性不足的类别的准确预测",{"2":{"828":1}}],["因为uniocc中的渲染监督需要细粒度体积表示",{"2":{"791":1}}],["因为检测网络是使用全部数据进行训练的",{"2":{"782":1}}],["因为kimera",{"2":{"754":1}}],["因为我们只使用了",{"2":{"917":1}}],["因为我们使用",{"2":{"803":1}}],["因为我们的vio的漂移很小",{"2":{"732":1}}],["因为我们观察到clio通常在所有数据集和所有指标上都优于基线",{"2":{"462":1}}],["因为同一场景由多个视角观察",{"2":{"691":1}}],["因为对于每一帧",{"2":{"816":1}}],["因为对于任何高斯",{"2":{"681":1}}],["因为对每个roi取得的特征并没有与roi对齐",{"2":{"554":1}}],["因为单视点存在尺度歧义",{"2":{"660":1}}],["因为成对使用",{"2":{"659":1}}],["因为直接人工标注的难度较大",{"2":{"658":1}}],["因为数据的生成与优化很大程度上影响occ模型的检测性能",{"2":{"658":1}}],["因为聚合过程独立地将每个高斯的贡献相加",{"2":{"656":1}}],["因为掩蔽点只是从3d物体表面而不是连续表面本身采样的",{"2":{"640":1}}],["因为跟之前的工作一样",{"2":{"631":1}}],["因为比如说现在有一张街景的图片",{"2":{"631":1}}],["因为深度相机发射的红外模式会在图像中可见",{"2":{"605":1}}],["因为从这个视角来看",{"2":{"599":1}}],["因为具有细粒度3d结构的体素级表示天生非常适合3d语义占据预测",{"2":{"566":1}}],["因为占据预测存在更严重的类别不平衡",{"2":{"548":1}}],["因为现有检测方法无法充分捕捉多样化物体的复杂几何形状",{"2":{"535":1}}],["因为不同模态可以相互补充",{"2":{"474":1}}],["因为两者都使用任务感知来过滤掉不相关的对象",{"2":{"462":1}}],["因为场景的规模",{"2":{"437":1}}],["因为在图像空间中像素点间的邻近信息不能很好地反应三维欧几里得空间中的邻近关系",{"2":{"524":1}}],["因为在",{"2":{"431":1}}],["因为其计算需求过高",{"2":{"421":1}}],["因为其简单性和很强的表示能力",{"2":{"420":1}}],["因为前面性能最好的算法是pointcontrast",{"2":{"394":1}}],["因为detr是没法使用高分辨率的图片的",{"2":{"386":1}}],["因为多个src都是要变换到这个参考图下的",{"2":{"383":1}}],["因为合成细节和参考细节并不完全一致",{"2":{"382":1}}],["因为tsurft",{"2":{"372":1}}],["因为当单应矩阵对应的真实深度不同时",{"2":{"355":1}}],["因为注释是在样本级别上完成的",{"2":{"254":1,"654":1}}],["因为代理从一个地方移动到另一个地方",{"2":{"197":1}}],["因为这已经在几何预测中被考虑过了",{"2":{"681":1}}],["因为这些系统需要快速响应环境变化",{"2":{"153":1}}],["因为这类方法可扩展应用于操作任务的地图构建",{"2":{"139":1}}],["因为这比以笛卡尔坐标系推理更为",{"2":{"116":1}}],["因为",{"2":{"129":1,"140":1,"280":1,"631":1,"857":1,"928":2}}],["因为机器人探索环境",{"2":{"112":1}}],["因为它仅考虑了可见表面",{"2":{"989":1}}],["因为它需要对点进行更精确",{"2":{"983":1}}],["因为它需要更宽的感知范围",{"2":{"739":1}}],["因为它不会产生采集成本",{"2":{"963":1}}],["因为它不要求绝对位姿",{"2":{"435":1}}],["因为它显著提高了语义",{"2":{"928":1}}],["因为它负责3d高斯分布之间的交互",{"2":{"842":1}}],["因为它与bevdetocc具有相似的模型结构",{"2":{"811":1}}],["因为它更适合vio",{"2":{"634":1}}],["因为它提供了比intel",{"2":{"605":1}}],["因为它没有空间范围",{"2":{"599":1}}],["因为它会导致高度信息丢失",{"2":{"599":1}}],["因为它以全面的方式描述驾驶场景",{"2":{"599":1}}],["因为它们在计算过程中不会遭受显著的信息丢失",{"2":{"875":1}}],["因为它们在这个维度上非常相似",{"2":{"278":1}}],["因为它们只包含一个房间",{"2":{"522":1}}],["因为它的有效维数低于它所在的空间",{"2":{"500":1}}],["因为它结合了激光雷达精确的深度和几何感知以及摄像头强大的语义感知能力",{"2":{"474":1}}],["因为它违反了四个卷积邻居的假设",{"2":{"466":1}}],["因为它能够实现对环境语义和几何信息的细粒度理解",{"2":{"444":1}}],["因为它优化了一个更大的图",{"2":{"390":1}}],["因为它允许研究人员使用点级语义来研究和量化诸如激光雷达点云分割",{"2":{"302":1}}],["因为它将不再在自由空间中",{"2":{"301":1}}],["因为它决定了地图如何构建",{"2":{"231":1}}],["因为它减少了需要处理的数据量",{"2":{"153":1}}],["因为它常常与具身任务结合研究",{"2":{"110":1}}],["因为它认为回车符是命令的一部分",{"2":{"41":1}}],["因为end",{"2":{"104":1}}],["因为语义地图构建通常与这些具身任务一起研究",{"2":{"100":1}}],["因为基础模型的进展和对通用",{"2":{"90":1}}],["因为要分配硬盘空间",{"2":{"26":1}}],["用点云表示环境",{"2":{"967":1}}],["用来改变排序方式",{"2":{"929":1}}],["用来构建后续层",{"2":{"285":1}}],["用新颖的残差风格架构替换耗时的3d卷积网络",{"2":{"908":1}}],["用红色框标出",{"2":{"899":1}}],["用法",{"2":{"871":1}}],["用若干",{"2":{"743":1}}],["用作",{"2":{"660":1}}],["用到",{"2":{"631":1}}],["用多头注意力描述object之间的相互作用",{"2":{"594":1}}],["用这些体素特征初始化高斯的位置和透明度",{"2":{"563":1}}],["用这种方式构建的以自我为中心的地图可同时提升",{"2":{"252":1}}],["用激光雷达数据提供的几何先验初始化高斯的均值和透明度",{"2":{"563":1}}],["用神经网络将场景表示为连续函数",{"2":{"556":1}}],["用神经网络的连续潜向量表示语义信息",{"2":{"209":1}}],["用预训练网络",{"2":{"525":1}}],["用交叉熵损失判断两张图像是否来自同一区域",{"2":{"525":1}}],["用概率模型更新此图",{"2":{"525":1}}],["用稀疏卷积替换",{"2":{"517":1}}],["用均匀划分的",{"2":{"517":1}}],["用可学习的去噪网络",{"2":{"495":1}}],["用卷积实现与上一步",{"2":{"495":1}}],["用深度和相机内参把",{"2":{"495":1}}],["用图结构表示环境",{"2":{"465":1}}],["用逻辑否决检查规则合规",{"2":{"447":1}}],["用途",{"2":{"423":1}}],["用max",{"2":{"420":1}}],["用8个浮点参数表示",{"2":{"419":1}}],["用rl细化v2v协调",{"2":{"417":1}}],["用一个多模态的编码器来计算文和图的编码向量的余弦相似度",{"2":{"399":1}}],["用一种特定的噪声分布来扰动原始数据",{"2":{"235":1}}],["用其他方式衡量相似的",{"2":{"328":1}}],["用同一网络提取特征",{"2":{"305":1}}],["用自动编码器",{"2":{"270":1}}],["用score",{"2":{"235":1}}],["用训练过程中相邻时间节点上的两个生成图像的距离来表示",{"2":{"221":1}}],["用gan可缓解",{"2":{"220":1}}],["用它们的向量表示建立一个相似度矩阵",{"2":{"184":1}}],["用户可以使用自然语言",{"2":{"939":1}}],["用户可以根据计算考虑和对一致地图的需求选择求解器",{"2":{"390":1}}],["用户贡献真实世界基准",{"2":{"360":1}}],["用户每一次点击",{"2":{"106":1}}],["用户施加的",{"2":{"84":1}}],["用户名",{"2":{"24":1}}],["用vim打开sh脚本文件",{"2":{"48":1}}],["用",{"0":{"188":1},"2":{"48":1,"177":1,"235":1,"481":1,"495":1,"525":1,"698":2,"743":1,"765":1,"826":1,"916":1}}],["用于研究鲁棒的3d占用感知",{"2":{"1005":1}}],["用于支持3d占用感知的基准测试",{"2":{"997":1}}],["用于计算变形图像",{"2":{"988":1}}],["用于计算iou和miou的真值是视锥体的并集",{"2":{"833":1}}],["用于量化一个概率分布与参考分布的偏差",{"2":{"985":1}}],["用于区分空体素和占用体素",{"2":{"985":1}}],["用于鼓励整体一致性",{"2":{"985":1}}],["用于鼓励更好的语义和几何精度",{"2":{"985":1}}],["用于达到输出尺寸",{"2":{"982":1}}],["用于收集多尺度特征",{"2":{"982":2}}],["用于收集相关论文",{"2":{"665":1}}],["用于融合多模态",{"2":{"971":2}}],["用于描述",{"2":{"961":1}}],["用于场景感知",{"2":{"957":1}}],["用于整合来自二维和三维分支的信息",{"2":{"923":1}}],["用于整体3d场景理解的占用感知具有重要意义",{"2":{"667":1}}],["用于增强语义预测",{"2":{"985":1}}],["用于增强特征",{"2":{"910":1}}],["用于增强网络的上下文感知能力",{"2":{"570":1}}],["用于模拟代理和场景之间的合理交互",{"2":{"905":1}}],["用于模拟长程依赖关系",{"2":{"824":1}}],["用于占据预测",{"2":{"893":1}}],["用于lgeo",{"2":{"834":1}}],["用于l2级高速公路导航和智能召唤",{"2":{"821":1}}],["用于具有14914条边和1759个节点的姿态图",{"2":{"816":1}}],["用于具有734条边和728个节点的姿态图",{"2":{"816":1}}],["用于具身三维空间占用预测任务",{"2":{"600":1}}],["用于进行局部预测的高斯分布数量为16200",{"2":{"813":1}}],["用于训练和评估我们的embodiedocc框架",{"2":{"793":1}}],["用于提取体素的神经特征",{"2":{"910":1}}],["用于提取",{"2":{"789":1}}],["用于平衡损失权重",{"2":{"766":1}}],["用于高效的桌面机器人操作",{"2":{"765":1}}],["用于高效且有效地描述3d场景",{"2":{"760":1}}],["用于评分该栅格空间被障碍物占据的概率",{"2":{"759":1}}],["用于评估预测质量",{"2":{"806":1}}],["用于评估先进的3d占用预测方法",{"2":{"757":1}}],["用于评估我们的模型在非道路场景上的性能",{"2":{"652":1}}],["用于评估的数据集概览",{"2":{"605":1}}],["用于评估生成的点块与真实点块之间的差异",{"2":{"582":1}}],["用于权重参数和测试时增强",{"2":{"758":1}}],["用于大规模3d占用预测",{"2":{"757":1}}],["用于后续处理",{"2":{"752":1}}],["用于后续的预训练和任务学习",{"2":{"340":1}}],["用于定位任务",{"2":{"743":1}}],["用于定位和避障",{"2":{"90":1}}],["用于生成密集的3d占用注释",{"2":{"735":1}}],["用于生成密集的3d占用预测",{"2":{"516":1}}],["用于我们的基于视觉的方法",{"2":{"716":1}}],["用于校正3d高斯分布的属性",{"2":{"716":1}}],["用于聚合视觉信息",{"2":{"716":1}}],["用于实现3d高斯分布之间的交互",{"2":{"716":1}}],["用于实时度量",{"2":{"285":1}}],["用于实时从传感器数据构建3d场景图",{"2":{"112":1}}],["用于实时构建任务驱动的3d场景图",{"2":{"109":1}}],["用于获取深度值",{"2":{"705":1}}],["用于获得人类骨盆关节在图像中的近似3d位置",{"2":{"419":1}}],["用于预测体素是否被物体占用",{"2":{"665":1}}],["用于分层特征聚合",{"2":{"664":1}}],["用于将两个柱坐标体积压缩并融合为一组三视图",{"2":{"898":1}}],["用于将",{"2":{"649":1}}],["用于将相机",{"2":{"503":1}}],["用于表示由行驶车辆采集图像生成的大规模动态城市场景",{"2":{"648":1}}],["用于表明当前容器中键为",{"2":{"196":1}}],["用于追踪移动的物体与智能体",{"2":{"648":1}}],["用于避免除以零",{"2":{"623":1}}],["用于过滤那些投影到图像外的无效点",{"2":{"623":1}}],["用于处理局部图",{"2":{"607":1}}],["用于重建紧凑的3d占用表示",{"2":{"875":1}}],["用于重建",{"2":{"605":1}}],["用于跟踪的相机不受另一个相机发射的红外模式的影响",{"2":{"605":1}}],["用于三维语义占位预测",{"2":{"578":1}}],["用于优化几何精度",{"2":{"985":1}}],["用于优化全局场景类别亲和力",{"2":{"570":1}}],["用于优化一组体素的语义分布",{"2":{"570":1}}],["用于连接",{"2":{"570":1}}],["用于确定此次更新的程度",{"2":{"568":1}}],["用于利用单目图像预测室内场景的占用情况",{"2":{"544":1}}],["用于挑战",{"2":{"534":1}}],["用于可视化中间vio统计数据",{"2":{"510":1}}],["用于调试",{"2":{"510":1}}],["用于在提升的",{"2":{"767":1}}],["用于在提升的3d空间中用激光雷达",{"2":{"415":1}}],["用于在不使用密集网格的情况下描述3d场景的细粒度结构",{"2":{"486":1}}],["用于各种下游感知和规划任务",{"2":{"474":1}}],["用于各种应用",{"2":{"420":1}}],["用于采样",{"2":{"474":1}}],["用于3d注释",{"2":{"735":1}}],["用于3d语义占用预测",{"2":{"693":1,"861":1}}],["用于3d语义占据预测的多传感器融合框架",{"2":{"445":1}}],["用于3d场景图节点标记",{"2":{"467":1}}],["用于障碍物检测",{"2":{"421":1}}],["用于姿态分析",{"2":{"419":1}}],["用于",{"2":{"419":1,"678":1,"955":1,"962":1}}],["用于从教师模型向学生模型传递知识",{"2":{"985":1}}],["用于从多视图图像中学习有意义的3d高斯分布",{"2":{"716":1}}],["用于从各种三维形状中学习点的分布",{"2":{"363":1}}],["用于从传感器数据中实时构建分层的3d场景图",{"2":{"141":1}}],["用于从传感器数据中实时构建3d场景图",{"2":{"112":1}}],["用于体积细分阶段的表面细化",{"2":{"344":1}}],["用于特征学习和形状分类",{"2":{"311":1}}],["用于产生语义注释网格和基于voxblox的欧几里得符号距离函数",{"2":{"285":1}}],["用于判断生成器是否选择了最近的路线",{"2":{"221":1}}],["用于构建任务驱动的开放集3d场景图",{"2":{"168":1}}],["用于指导算法在压缩表示的同时",{"2":{"153":1}}],["用于控制压缩表示的粒度和信息保留量之间的平衡",{"2":{"153":1}}],["用于控制生成图像的风格",{"2":{"133":1}}],["用于解决ib问题",{"2":{"153":1}}],["用于解决内存容量不足的情况",{"2":{"18":1}}],["用于丰富生成图像的细节",{"2":{"133":1}}],["用于快速和局部准确的3d姿态估计",{"2":{"131":1}}],["用于简化对空间布局",{"2":{"123":1}}],["用于slam",{"2":{"121":1}}],["用于视觉",{"2":{"105":1}}],["用于路径规划的地图结构",{"2":{"31":1}}],["用于衡量分布",{"2":{"13":1}}],["h以2",{"2":{"824":1}}],["h取得了89",{"2":{"824":1}}],["h主干",{"2":{"805":1}}],["h主干使用6帧",{"2":{"764":1}}],["hhl​−hr​​",{"2":{"712":1}}],["hhh",{"2":{"355":1}}],["h×w×z",{"2":{"712":8}}],["hl−hrh",{"2":{"712":1}}],["hl​",{"2":{"712":1}}],["hl",{"2":{"712":1}}],["h和z分别表示批量大小",{"2":{"703":1}}],["hw",{"2":{"694":2,"752":1}}],["hwangbo等人",{"2":{"310":1,"967":1}}],["hm=pxyhm=p",{"2":{"666":1}}],["hm3d",{"2":{"495":2}}],["h检查点",{"2":{"617":1}}],["hgnn",{"2":{"607":1}}],["hz",{"2":{"437":1,"816":1}}],["hq",{"2":{"382":1}}],["hp",{"2":{"355":1,"609":2}}],["h为下采样率",{"2":{"345":1}}],["hf=h",{"2":{"345":2}}],["h=w",{"2":{"345":3}}],["hierarchical",{"2":{"631":1,"659":1,"692":2}}],["hint",{"2":{"571":1}}],["history",{"0":{"718":1},"2":{"496":1}}],["hirschmüller",{"2":{"362":1,"732":1}}],["hihihi",{"2":{"355":1}}],["hidden",{"2":{"333":15}}],["highlighted",{"2":{"616":3}}],["highlighter",{"2":{"57":1}}],["high",{"2":{"145":1,"205":1,"220":1,"247":1,"317":1,"589":1}}],["hr​",{"2":{"712":1}}],["hr",{"2":{"329":1,"712":1}}],["hrnet",{"2":{"96":1}}],["hk​",{"2":{"278":1}}],["hk",{"2":{"278":1}}],["hkp",{"2":{"76":1}}],["html",{"2":{"276":1}}],["http",{"2":{"36":2,"76":1,"87":1,"196":7}}],["https",{"2":{"12":1,"23":3,"30":8,"31":1,"36":1,"40":1,"41":1,"48":1,"58":1,"84":1,"98":1,"106":1,"107":1,"113":1,"120":2,"174":1,"220":1,"244":1,"256":1,"276":2,"351":1,"367":1,"369":2,"387":1,"409":1,"414":3,"445":2,"453":2,"490":1,"508":1,"514":2,"545":2,"577":2,"578":1,"584":2,"605":1,"610":1,"635":1,"663":2,"671":2,"687":1,"710":1,"733":1,"776":2,"839":1,"890":1,"906":1,"920":1}}],["hdl32e",{"2":{"173":1}}],["hungarian",{"2":{"651":1}}],["hughes",{"2":{"648":1}}],["huaiyuanxu",{"2":{"577":1,"610":1}}],["hua等人",{"2":{"511":1}}],["huang",{"2":{"155":1,"495":1,"765":3}}],["huang等人最近提出了gaussianformer",{"2":{"1004":1}}],["huang等人",{"2":{"116":1,"961":1,"962":1,"967":1}}],["hui",{"2":{"477":1}}],["human",{"2":{"254":1,"702":7,"790":7}}],["humans首先使用graphcmr",{"2":{"816":1}}],["humans中",{"2":{"419":1}}],["humans需要在相机图像中检测和估计人类的形状",{"2":{"419":1}}],["humans跟踪一个描述人类随时间变化的密集网格模型的形状",{"2":{"419":1}}],["humans",{"0":{"419":1},"2":{"131":2,"285":2}}],["hu等人",{"2":{"116":1,"362":1}}],["hao",{"2":{"914":1}}],["harley",{"2":{"609":1}}],["harris关键点",{"2":{"449":1}}],["hartley和zisserman",{"2":{"310":1}}],["hays",{"2":{"387":1}}],["hassc",{"2":{"985":1}}],["hassan等人",{"2":{"905":1}}],["hassani等人",{"2":{"574":1}}],["hash",{"2":{"530":1}}],["hashmap",{"2":{"196":1}}],["has",{"2":{"366":1,"500":1,"659":1}}],["hat",{"2":{"235":4,"304":1,"532":1,"632":2,"656":5,"666":2,"681":1,"693":1,"704":2,"705":2,"716":18,"738":1,"752":4,"794":16,"814":4,"870":7,"928":1,"985":4,"988":3}}],["hane",{"2":{"209":1}}],["handle",{"2":{"143":1,"158":1}}],["habitat",{"2":{"139":1,"495":1}}],["hackel等人",{"2":{"116":1,"732":1}}],["have",{"2":{"67":1,"120":1,"327":2,"496":1,"659":1}}],["hydro",{"0":{"102":1},"1":{"112":1,"125":1,"141":1,"156":1,"172":1,"190":1,"210":1,"232":1,"253":1,"276":1,"301":1,"326":1,"352":1,"380":1,"408":1,"437":1,"467":1},"2":{"95":1}}],["hydra得益于新颖的在线算法和高度并行化的感知架构",{"2":{"467":1}}],["hydra处理对象的时间为75",{"2":{"437":1}}],["hydra高级运行时间的显著峰值",{"2":{"437":1}}],["hydra高级的运行时间略有上升趋势",{"2":{"437":1}}],["hydra中级在图9中",{"2":{"437":1}}],["hydra的实时场景图与批量和离线方法相当",{"2":{"437":1}}],["hydra的性能接近地面真实场景图",{"2":{"437":1}}],["hydra的功能块图",{"2":{"408":1}}],["hydra的源代码在https",{"2":{"141":1}}],["hydra在多层环境中表现出色",{"2":{"437":1}}],["hydra在多核cpu上实时运行",{"2":{"408":1}}],["hydra在uh2办公室数据集中创建的3d场景图",{"2":{"210":1}}],["hydra从快速的早期感知过程",{"2":{"408":1}}],["hydra涉及一系列以传感器速率",{"2":{"408":1}}],["hydra架构",{"0":{"408":1}}],["hydra上公开可用",{"2":{"141":1}}],["hydra",{"2":{"30":1,"102":1,"437":1,"482":1,"522":3,"648":1,"976":1}}],["hybrid",{"0":{"648":1},"2":{"80":1,"247":1,"378":1,"465":1,"740":1}}],["h>",{"2":{"67":1}}],["hou等人",{"2":{"1004":1}}],["houdini",{"2":{"57":1}}],["hongyang",{"2":{"914":1}}],["hongxiaoy",{"2":{"890":1}}],["hops邻域内",{"2":{"607":1}}],["horizon",{"2":{"836":1}}],["horse",{"2":{"373":1}}],["horn",{"2":{"310":1,"390":1}}],["homography",{"0":{"355":1}}],["home",{"2":{"57":1,"66":1}}],["holland",{"2":{"157":2}}],["holger",{"2":{"126":1}}],["hot",{"2":{"153":1}}],["how",{"2":{"135":1}}],["host",{"2":{"78":1}}],["h2o",{"2":{"57":1}}],["hedau等人",{"2":{"967":1}}],["herath",{"2":{"958":1}}],["here",{"2":{"32":2,"67":1}}],["hemachandra",{"2":{"648":3}}],["henriques",{"2":{"252":1,"435":1,"495":3,"743":1}}],["he",{"2":{"189":1,"274":2,"350":1}}],["head由6个layers",{"2":{"562":1}}],["head=d",{"2":{"174":2}}],["head",{"0":{"434":1},"2":{"174":3,"549":1,"562":1,"839":1,"950":1}}],["heads=8",{"2":{"623":1}}],["heads=n",{"2":{"174":2}}],["heads",{"2":{"174":3,"550":1}}],["height",{"2":{"136":1,"254":1,"379":1}}],["he等人",{"2":{"116":1,"362":2,"605":1}}],["hello",{"2":{"52":1,"57":1}}],["hellopangolin",{"2":{"40":2}}],["h",{"0":{"882":1,"952":1},"2":{"24":1,"67":2,"126":1,"137":16,"171":2,"184":1,"278":1,"305":2,"321":1,"333":16,"345":1,"362":1,"383":2,"411":2,"431":1,"440":2,"470":5,"609":5,"617":1,"621":4,"622":3,"649":1,"659":4,"682":2,"693":4,"694":2,"712":10,"732":1,"746":1,"931":1}}],["编码平面表面",{"2":{"967":1}}],["编码为",{"2":{"853":1}}],["编码后的表示可以用现有的机器学习方法进行处理",{"2":{"664":1}}],["编码器包含",{"2":{"982":1}}],["编码器和解码器可以是各种模块",{"2":{"910":1}}],["编码器和解码器之间",{"2":{"632":1}}],["编码器",{"2":{"670":1,"928":1}}],["编码器是基于多尺度图构造的",{"2":{"574":1}}],["编码的查询视图应该与其关键视图相似",{"2":{"579":1}}],["编码到绿色",{"2":{"480":1}}],["编码转换成显式的mesh",{"2":{"247":1}}],["编码",{"2":{"247":1,"675":1,"743":1}}],["编码层面",{"2":{"209":1,"864":1}}],["编码方式",{"2":{"209":1}}],["编录20余个代表性模型及其支持数据集",{"2":{"82":1}}],["编辑",{"2":{"24":1}}],["编译",{"0":{"22":1,"36":1,"40":1,"47":1,"58":1},"1":{"29":1,"36":1,"40":1,"47":1,"58":1,"67":2},"2":{"36":1,"40":1,"58":1,"120":1,"510":1}}],["其目标是捕捉周围环境中的动态物体及其运动",{"2":{"1003":1}}],["其miou分数为28",{"2":{"1000":1}}],["其预测的类别标签与真实类别标签匹配",{"2":{"998":1}}],["其扩张率分别为",{"2":{"982":1}}],["其扩张率为",{"2":{"982":1}}],["其最近的视觉分支特征表示为",{"2":{"976":1}}],["其最新趋势日益依赖鸟瞰图",{"2":{"123":1}}],["其稀疏卷积还可以控制提取特征的稀疏性",{"2":{"962":1}}],["其常规数据格式还允许直接应用标准",{"2":{"962":1}}],["其过程可以看作是公式7的扩展",{"2":{"957":1}}],["其提取利用了预训练的图像骨干网络",{"2":{"942":1}}],["其提取层由三层组成",{"2":{"420":1}}],["其通用流程如图5所示",{"2":{"942":1}}],["其优势更加明显",{"2":{"928":1}}],["其优势在于绝对尺度和无遮挡的环境描述",{"2":{"667":1}}],["其定义为",{"2":{"916":1}}],["其半轴长度是从对应于高斯分布的",{"2":{"916":1}}],["其需求随环境规模与丰富度呈指数级增长",{"2":{"864":1}}],["其参数量与内存复杂度与采样点成线性关系",{"2":{"863":1}}],["其算子具有长距离依赖性",{"2":{"824":1}}],["其算法如下",{"2":{"264":1,"266":1}}],["其关键在于从图像空间到bev空间的有效特征转换",{"2":{"821":1}}],["其真值标签由",{"2":{"787":1}}],["其计算和内存成本在需要高分辨率输入的下游任务中非常昂贵",{"2":{"824":1}}],["其计算复杂度与可变形注意力相同",{"2":{"716":1}}],["其计算成本随着时间的推移而增加",{"2":{"141":1}}],["其值与单目设置不同",{"2":{"682":1}}],["其具体语义通常不可直接解读",{"2":{"675":1}}],["其分辨率为原始图像的1",{"2":{"649":1}}],["其x范围从",{"2":{"638":1}}],["其粒度和结构足以支持这些任务",{"2":{"586":1}}],["其旨在从图像中提取3d场景的详细结构信息",{"2":{"566":1}}],["其余组件",{"2":{"811":1}}],["其余支柱均为空",{"2":{"694":1}}],["其余行",{"2":{"662":1}}],["其余使用立体相机",{"2":{"634":1}}],["其余使用a的style",{"2":{"181":1}}],["其余位置均为零",{"2":{"561":1}}],["其对应的输出tensor中与p1有关的像素点为a1的六个位置那么将这些点视作作为p",{"2":{"530":1}}],["其对掩码区域所能做的调控依然非常有限",{"2":{"312":1}}],["其相邻点的权重以其相对于中心点的偏移量有关",{"2":{"511":1}}],["其特征向量被设置为",{"2":{"660":1}}],["其特征向量将被设置为零",{"2":{"660":1}}],["其特征处理在笛卡尔坐标系下进行",{"2":{"497":1}}],["其特征维度大小为77x768",{"2":{"373":1}}],["其内部数值的编码方式都可以归为两大类",{"2":{"675":1}}],["其内所有点的平均位置和强度",{"2":{"563":1}}],["其内存消耗可减少约64倍",{"2":{"481":1}}],["其内容与此键关联",{"2":{"196":1}}],["其维度与真实环境对齐",{"2":{"465":1}}],["其在当前层的特征被定义为给定点的特征与其在上一层的相邻边缘特征之和",{"2":{"511":1}}],["其在modelnet和shapenet数据集上的推理时间超过pointnet",{"2":{"420":1}}],["其在循环中累积的误差与测量噪声不一致",{"2":{"390":1}}],["其复杂度取决于地图大小",{"2":{"408":1}}],["其训练损失也和ddpm一样",{"2":{"401":1}}],["其训练过程的生成质量如下所示",{"2":{"345":1}}],["其使用了mutil",{"2":{"394":1}}],["其形式为zij",{"2":{"390":1}}],["其大小呈四次方而非三次方扩展",{"2":{"372":1}}],["其正确推理步骤已标注",{"2":{"334":1}}],["其autoencoder模型参数大小为84m",{"2":{"319":1}}],["其数据涵盖了新加坡和波士顿的城区和郊区场景",{"2":{"302":1}}],["其标注仅涵盖前置摄像头",{"2":{"302":1}}],["其不足之处在于可能出现误差传播以及模块间集成不够最优",{"2":{"299":1}}],["其细节信息的缺失会导致最终生成的结果与原图的语义差别加大",{"2":{"264":1}}],["其核心思想非常地简洁但精巧",{"2":{"264":1,"266":1}}],["其主要针对的痛点是ddpm的随机性太高无法确定性的生成",{"2":{"264":1,"266":1}}],["其score",{"2":{"235":1}}],["其包含",{"2":{"196":1}}],["其允许通过",{"2":{"196":1}}],["其语义类别",{"2":{"178":1}}],["其语言输出与低层控制耦合松散",{"2":{"82":1}}],["其传感器布局完全相同",{"2":{"173":1}}],["其观测模型由测量方程给出",{"2":{"171":1}}],["其催化剂是",{"2":{"139":1}}],["其模块现在已扩展并包含在kimera",{"2":{"131":1}}],["其输入为一个随机噪音",{"2":{"129":1}}],["其生成计划与闭环控制缺乏紧密集成",{"2":{"128":1}}],["其他平面",{"2":{"1000":2}}],["其他一些方法计算的是从源图像变形后的图像与目标图像之间的差异",{"2":{"988":1}}],["其他监督训练",{"0":{"988":1}}],["其他类别如",{"2":{"975":1}}],["其他函数",{"2":{"904":1}}],["其他操作",{"0":{"854":1}}],["其他方法同时使用对象和密集模型",{"2":{"967":1}}],["其他方法",{"0":{"838":1}}],["其他方法利用目标函数和规划动作先验优化轨迹",{"2":{"114":1}}],["其他设置与局部空间占用预测模块的训练相同",{"2":{"813":1}}],["其他模态",{"2":{"698":1}}],["其他模型",{"0":{"664":1}}],["其他的都会和",{"2":{"358":1}}],["其他创新方法包括使用生成视频模型",{"2":{"308":1}}],["其他",{"2":{"277":2,"534":2,"736":1,"785":1,"811":2,"828":1,"842":1,"1000":2}}],["其他部分都可以合在一起训练",{"2":{"272":1}}],["其他通过点云编码器",{"2":{"195":1}}],["其他传感器数据",{"2":{"176":1}}],["其他论文专注于重建对象及其关系的图",{"2":{"172":1}}],["其他功能",{"2":{"126":1}}],["其实在源码中patch",{"2":{"659":1}}],["其实是在通过概率体得到初始深度图的同时计算了一个概率图",{"2":{"622":1}}],["其实现方式是图上信号与图的拉普拉斯矩阵的特征向量相乘",{"2":{"607":1}}],["其实每一次点击都是有",{"2":{"117":1}}],["其实就是一个文件夹",{"2":{"24":1}}],["其次是深度分布特征和深度监督",{"2":{"882":1}}],["其次",{"2":{"82":1,"131":1,"137":1,"301":1,"325":1,"419":1,"437":1,"449":1,"467":1,"505":1,"535":1,"553":1,"561":1,"567":1,"632":1,"637":1,"656":1,"732":1,"833":1,"931":1,"973":1}}],["其中变形所需的深度通过体积渲染获得",{"2":{"988":1}}],["其中如果体素包含至少一个激光雷达点",{"2":{"988":1}}],["其中多个模块具有不一致的优化目标",{"2":{"975":1}}],["其中3d特征体积被替换为三个视角中特定视角的2d特征图",{"2":{"950":1}}],["其中3d空间被划分为体素单元",{"2":{"665":1}}],["其中查询与选定的参考特征进行交互",{"2":{"950":1}}],["其中x",{"2":{"947":1}}],["其中x轴为深度指数假设",{"2":{"622":1}}],["其中机器人可以在不同的抽象层次上规划以节省计算资源",{"2":{"930":1}}],["其中机器人被提供了自然语言任务列表",{"2":{"586":1}}],["其中机器人被赋予自然语言中的任务列表",{"2":{"98":1,"109":1}}],["其中高斯被二元地分类为处于正确或错误的位置",{"2":{"916":1}}],["其中ed表示编码器和解码器",{"2":{"910":1}}],["其中靠近激光雷达传感器的点比远处的点更密集",{"2":{"910":1}}],["其中主要关注点之一是推理人类指令的变异性",{"2":{"905":1}}],["其中碰撞检查通常是原语",{"2":{"905":1}}],["其中缺少物体",{"2":{"903":1}}],["其中位置嵌入的贡献最小",{"2":{"882":1}}],["其中合并后的特征被输入到挤压模块中",{"2":{"829":1}}],["其中计算esdf",{"2":{"816":1}}],["其中某些类别可能缺失",{"2":{"814":1}}],["其中2d特征直接重塑为3d占据逻辑",{"2":{"811":1}}],["其中大部分成本是不必要的",{"2":{"808":1}}],["其中pcp",{"2":{"794":1}}],["其中应用了梯度裁剪",{"2":{"770":1}}],["其中得分最高的图像",{"2":{"765":1}}],["其中一类表示未被占据的空体素",{"2":{"742":1}}],["其中一些已经被之前的帧很好地更新了",{"2":{"728":1}}],["其中一些只有少数几个样本",{"2":{"702":1}}],["其中b",{"2":{"703":1}}],["其中bev表示中的每个像素包含沿高度维度对应柱中所有物体的信息",{"2":{"535":1}}],["其中第一类是在bev特征上进行时序融合",{"2":{"695":1}}],["其中前向投影和后向投影是最主要的范式",{"2":{"839":1}}],["其中前向时原数据的信息逐渐丢失",{"2":{"264":1,"266":1}}],["其中前景区域掩码",{"2":{"694":1}}],["其中我们使用几何概率",{"2":{"681":1}}],["其中语义预测可以被表述为计算给定概率高斯混合模型的语义期望",{"2":{"681":1}}],["其中$p",{"2":{"647":1}}],["其中尺度是可观察的",{"2":{"634":1}}],["其中z表示沿z轴的体素数量",{"2":{"609":1}}],["其中z是变形图中所有里程计和回路闭合边的集合",{"2":{"390":1}}],["其中三维空间占用预测因其效率",{"2":{"600":1}}],["其中占据逻辑通过通道到高度变换直接从扁平化的bev级特征重塑而来",{"2":{"566":1}}],["其中8×8网格大小的分割表示由一个分割查询描述",{"2":{"566":1}}],["其中分为两个主要部分",{"2":{"561":1}}],["其中整个花瓶手柄已折叠为单个边缘",{"2":{"557":1}}],["其中输出通道的数量等于一个点块中的坐标总数",{"2":{"549":1}}],["其中图像上采样通过通道重排实现",{"2":{"535":1}}],["其中图的每个节点对应于人类骨盆在离散时间的位置",{"2":{"419":1}}],["其中图的边代表允许的合并",{"2":{"153":1}}],["其中spot在笔记本电脑机载操作",{"2":{"522":1}}],["其中c0c",{"2":{"632":1}}],["其中clio被提供场景的可能房间标签作为任务",{"2":{"522":1}}],["其中cnn负责作为编码器",{"2":{"371":1}}],["其中生成器更专注于生成任务",{"2":{"488":1}}],["其中相邻点的权重与相对于中心点的空间分布相关",{"2":{"481":1}}],["其中n是墙壁顶点处的法线",{"2":{"480":1}}],["其中n是与任务相关的真值对象的数量",{"2":{"402":1}}],["其中有两个合并操作",{"2":{"466":1}}],["其中邻接关系由拓扑结构决定",{"2":{"466":1}}],["其中re是估计房间的集合",{"2":{"437":1}}],["其中random",{"2":{"424":1}}],["其中网络学习确定对象部分相对于其任务的重要性",{"2":{"436":1}}],["其中包含537",{"2":{"793":1}}],["其中包含对应于当前检测的单个节点",{"2":{"419":1}}],["其中包含数十个对象和人类",{"2":{"105":1}}],["其中vi表示原始顶点位置",{"2":{"390":1}}],["其中vsurf",{"2":{"372":1}}],["其中ω的形式为ω",{"2":{"390":1}}],["其中l是检测到的回路闭合数量",{"2":{"390":1}}],["其中需要最小化的边缘势能",{"2":{"380":1}}],["其中f1",{"2":{"609":1}}],["其中f",{"2":{"354":1}}],["其中下采样率",{"2":{"345":1}}],["其中统一的实例和语义查询作为输入传递",{"2":{"306":1}}],["其中的激光雷达语义分割标注最初于",{"2":{"302":1}}],["其中的每个",{"2":{"193":1}}],["其中地点图中的每条边被视为潜在的合并对象",{"2":{"295":1}}],["其中t0就是前向加噪的比例",{"2":{"287":1}}],["其中直线边偏离连接两个节点的gvd体素太远",{"2":{"276":1}}],["其中仅对受最新测量影响的连通分量再次执行聚类",{"2":{"271":1}}],["其中节点稀疏地采样自由空间",{"2":{"480":1}}],["其中节点没有合并",{"2":{"380":1}}],["其中节点是对象原语",{"2":{"271":1}}],["其中节点代表空间概念",{"2":{"147":1}}],["其中节点代表",{"2":{"131":1}}],["其中节点代表场景中的实体",{"2":{"116":1}}],["其中节点代表多个抽象层次的空间概念",{"2":{"112":1,"125":1}}],["其中节点代表不同抽象层次的空间概念",{"2":{"105":1}}],["其中每个办公室被视为一个建筑物",{"2":{"947":1}}],["其中每个新",{"2":{"947":1}}],["其中每个体素都与类别估计相关联",{"2":{"841":1}}],["其中每个对象类别的实例分割是顺序进行的",{"2":{"816":1}}],["其中每个网格都被赋予了一个语义属性",{"2":{"724":1}}],["其中每个单元描述一个兴趣区域",{"2":{"693":1}}],["其中每个高斯分布代表一个灵活的兴趣区域",{"2":{"547":1}}],["其中每个高斯分布代表一个灵活的兴趣区域及其语义特征",{"2":{"516":1}}],["其中每个高斯",{"2":{"532":1}}],["其中每个标签被更改为",{"2":{"492":1}}],["其中每个边折叠将5条边转换为2条边",{"2":{"466":1}}],["其中每个像素都在一定半径内与其邻域相连",{"2":{"410":1}}],["其中每个组成单元捕捉到丰富的几何信息",{"2":{"340":1}}],["其中每个核心负责为实例或语义类别生成掩码",{"2":{"306":1}}],["其中每个地点是一个无障碍位置",{"2":{"210":1}}],["其中每个点都被分配了clip向量",{"2":{"121":1}}],["其中边模拟成对相对测量",{"2":{"178":1}}],["其中值为",{"2":{"153":1}}],["其中突出的框架是任务与运动规划",{"2":{"123":1}}],["其中表示只保留任务相关的对象和区域",{"2":{"109":1}}],["其中只包含相关对象和区域",{"2":{"109":1}}],["其中",{"2":{"31":1,"109":1,"137":3,"153":3,"171":4,"264":1,"266":1,"268":1,"325":1,"329":1,"345":1,"357":1,"372":1,"378":1,"390":3,"435":2,"464":2,"474":1,"495":1,"524":1,"532":2,"556":1,"563":1,"590":1,"595":1,"609":2,"621":1,"623":1,"638":1,"649":1,"656":3,"660":2,"666":2,"676":1,"681":3,"682":3,"693":3,"699":1,"705":2,"712":3,"716":1,"724":1,"728":1,"730":1,"738":3,"739":1,"741":1,"742":1,"746":1,"749":1,"750":1,"752":1,"766":1,"778":2,"780":1,"793":1,"794":2,"802":1,"807":1,"809":1,"841":1,"844":1,"848":1,"863":1,"884":1,"910":1,"915":1,"916":8,"949":1,"950":5,"957":4,"976":1,"985":2,"988":1,"998":2}}],["其中使用的图片类别分类器为inception",{"2":{"13":1}}],["其中maxi2max",{"2":{"5":1}}],["uuu",{"2":{"705":1}}],["uuid",{"2":{"24":1}}],["ui​",{"2":{"595":1}}],["ui",{"2":{"595":1}}],["uint8",{"2":{"504":1,"534":1}}],["uk",{"2":{"469":1}}],["uhumans",{"2":{"709":1,"947":1}}],["uhumans的问题在于每次运行的轨迹都不相同",{"2":{"605":1}}],["uhumans展示了一个大型办公空间",{"2":{"605":1}}],["uhumans和uhumans2是使用mit",{"2":{"605":1}}],["uhumans和uhumans2",{"0":{"605":1},"2":{"662":1}}],["uhumans2展示了室内场景",{"2":{"605":1}}],["uhumans2",{"2":{"131":1,"437":1,"709":1}}],["uh2数据集是一个基于unity的模拟数据集",{"2":{"437":1}}],["uh2",{"2":{"437":1}}],["umap",{"2":{"196":10}}],["uₜ",{"2":{"171":2}}],["upsampling",{"2":{"496":1}}],["upsampled",{"2":{"496":1}}],["upsample",{"2":{"496":1}}],["uparrowσt​↑",{"2":{"251":1}}],["up",{"2":{"138":1,"306":1}}],["update时国外的网站实在令人头疼",{"2":{"87":1}}],["update",{"2":{"36":2,"66":1,"69":1,"76":1,"87":1,"525":1}}],["udevadm",{"2":{"120":2}}],["udev",{"2":{"120":2}}],["utilizes",{"2":{"949":1}}],["utils",{"2":{"32":2,"38":2}}],["utm",{"2":{"106":3}}],["u",{"0":{"412":1},"2":{"66":1,"205":1,"377":1,"384":1,"412":1,"579":1,"595":2,"705":3,"875":3,"942":12,"950":9}}],["usa",{"2":{"387":1}}],["usage",{"2":{"333":1}}],["usual",{"2":{"327":1}}],["usb",{"2":{"120":1}}],["usleep",{"2":{"67":2}}],["using",{"0":{"312":1},"2":{"63":1,"93":1,"104":1,"115":1,"130":1,"146":1,"159":1,"161":1,"196":1,"201":1,"312":1,"439":1,"452":1,"616":1,"888":1}}],["usr",{"0":{"48":1},"2":{"36":1,"41":1,"48":2,"67":1,"107":1}}],["used",{"2":{"519":1}}],["useful",{"2":{"518":1}}],["uses",{"2":{"496":1}}],["usenko等人",{"2":{"390":1,"634":1}}],["username",{"2":{"66":1}}],["username是你自己的用户名",{"2":{"66":1}}],["users",{"2":{"57":1}}],["userwarning",{"2":{"43":1}}],["use",{"2":{"27":1,"500":1}}],["uno",{"2":{"1003":1}}],["unordered",{"0":{"196":1,"217":1,"448":1},"1":{"239":1,"261":1,"284":1,"309":1,"335":1,"361":1,"389":1,"418":1,"448":1,"479":2,"509":2,"540":2,"571":2,"604":2,"633":2,"661":2},"2":{"177":2,"196":14,"217":6,"239":1,"261":6,"284":1,"309":1,"335":1,"361":1,"389":1,"418":1,"571":1}}],["uncertainty",{"2":{"826":1}}],["uncompressing",{"2":{"496":1}}],["unconditional~score",{"2":{"513":1}}],["unconditional",{"0":{"224":1}}],["unpooled",{"2":{"496":2}}],["unpooling",{"0":{"496":1},"2":{"496":7}}],["unreasonable",{"2":{"345":1}}],["under",{"2":{"365":1}}],["underbrace",{"2":{"208":2,"235":1,"513":2}}],["underset",{"2":{"208":2,"235":1,"513":2}}],["understanding",{"2":{"23":1,"149":1,"243":1,"537":1}}],["unet的瓶颈处",{"2":{"875":1}}],["unet进行语义场景补全",{"2":{"841":1}}],["unet",{"0":{"401":1},"2":{"175":2,"440":1,"539":1,"632":6,"660":2,"684":1,"839":1,"853":1,"928":1,"937":1,"982":1}}],["unsupervised",{"2":{"159":1,"243":1,"366":1,"498":1,"515":2}}],["unsupported",{"2":{"120":1}}],["unsqueezed",{"2":{"839":1}}],["unsqueeze",{"2":{"124":1,"257":1,"333":4,"623":2}}],["uniworld",{"2":{"963":1}}],["univision",{"2":{"875":1}}],["universal",{"2":{"405":1}}],["uniocc遵循一般的体积渲染",{"2":{"941":1}}],["uniocc中渲染监督的引入显著增加了训练时长",{"2":{"811":1}}],["uniocc上0",{"2":{"791":1}}],["uniocc",{"2":{"770":1,"941":2,"949":1}}],["units",{"2":{"616":3}}],["uniform",{"2":{"379":1}}],["unix时间戳",{"2":{"254":2}}],["unix即可",{"2":{"41":1}}],["unimate",{"2":{"123":1}}],["uniad",{"2":{"114":1}}],["unistd",{"2":{"67":1}}],["uninstall",{"2":{"66":1}}],["unaligned",{"2":{"32":1}}],["ubuntu挂载多个硬盘并赋予权限",{"0":{"24":1}}],["ubuntu",{"0":{"18":1},"1":{"26":1,"33":1},"2":{"15":1,"36":4,"60":4,"76":2,"99":2}}],["刷分不会导致生成图片的质量变差",{"2":{"20":1}}],["不考虑语义的占用预测被视为类别无关的感知",{"2":{"998":1}}],["不考虑其语义类别",{"2":{"853":1}}],["不带时间融合的方法",{"2":{"942":1}}],["不连续的",{"2":{"938":1}}],["不依赖于密集的3d特征或稀疏到密集的全局注意力操作",{"2":{"922":1}}],["不经常观察到的环境部分",{"2":{"905":1}}],["不利于实际部署应用",{"2":{"892":1}}],["不利于扩大模型",{"2":{"824":1}}],["不能通过索引访问队列中的元素",{"2":{"835":1}}],["不支持随机访问",{"2":{"835":1}}],["不提供迭代器访问元素",{"2":{"835":1}}],["不使用lidar点云提供深度和语义标签",{"2":{"949":1}}],["不使用cbgs",{"2":{"800":1}}],["不使用mmm",{"2":{"752":1}}],["不正确的地点分类通常发生在门附近",{"2":{"796":1}}],["不需要额外的人工注释",{"2":{"736":1}}],["不需要像先前的工作那样在中间步骤中增加损失项来监督八叉树层次结构的学习",{"2":{"372":1}}],["不规则数据的离散卷积网络和连续卷积网络应引起足够的重视",{"2":{"688":1}}],["不规则形状车辆和特殊道路结构的强大泛化能力",{"2":{"667":1}}],["不像是set",{"2":{"685":1}}],["不常见的物体类别没被标注",{"2":{"630":1}}],["不透明度",{"2":{"656":1,"705":1}}],["不透明度和语义来以稀疏的方式描述",{"2":{"567":1}}],["不透明推理",{"2":{"114":1}}],["不受任何特定基础模型的约束",{"2":{"553":1}}],["不可避免地导致高度信息的丢失",{"2":{"665":1}}],["不可避免地会受到空网格的计算冗余问题的影响",{"2":{"612":1}}],["不可避免地会受到空网格冗余的影响",{"2":{"547":1}}],["不可学习的高维高斯特征",{"2":{"563":1}}],["不可能给每个标注员配gpu",{"2":{"117":1}}],["不附带激光雷达语义分割标签",{"2":{"534":1}}],["不懂",{"2":{"469":1}}],["不应被解释为代表美国空军或美国政府的官方政策",{"2":{"467":1}}],["不允许产生非流形面的边缘折叠",{"2":{"466":1}}],["不断迭代直到收敛",{"2":{"399":1}}],["不断博弈",{"2":{"129":1}}],["不精确的边界框或不令人满意的语义预测限制了整个",{"2":{"349":1}}],["不过度区分语义",{"2":{"658":1}}],["不过",{"2":{"435":1}}],["不过vq层是在decoder模块中",{"2":{"345":1}}],["不过这里为了保证重建效果",{"2":{"345":1}}],["不包括测试集",{"2":{"277":2}}],["不变的输入特征和学习到的网格池化运算使meshcnn成为一个特别有趣的模型",{"2":{"275":1}}],["不会妨碍更快的过程",{"2":{"408":1}}],["不会存在重叠",{"2":{"358":1}}],["不会跨场景保存",{"2":{"254":1}}],["不会对内部存储的数据进行排序",{"2":{"217":1}}],["不是直接学习概率分布",{"2":{"225":1}}],["不是stylegan提到的",{"2":{"165":1}}],["不仅考虑了感知准确性",{"2":{"1001":1}}],["不仅带来了更大的效率",{"2":{"631":1}}],["不仅是前景物体之间的不平衡",{"2":{"548":1}}],["不仅安全驾驶",{"2":{"334":1}}],["不仅驾驶",{"2":{"216":1}}],["不仅用语言命令车辆",{"2":{"176":1}}],["不确定性的置信度与抗干扰能力",{"2":{"943":1}}],["不确定性感知建图",{"2":{"826":1}}],["不确定性",{"2":{"208":1}}],["不容易训练",{"2":{"203":1}}],["不匹配图文的内积尽可能小",{"2":{"184":1}}],["不再进行取整操作",{"2":{"554":1}}],["不再使用双重掩码策略",{"2":{"315":1}}],["不再使用",{"2":{"315":1}}],["不再以键值对的形式存储数据",{"2":{"217":1}}],["不再是原图",{"2":{"180":1}}],["不再输入t给unet",{"2":{"175":1}}],["不再直接取",{"2":{"175":1}}],["不再额外的借助分类器",{"2":{"20":1}}],["不标注直接爬取",{"2":{"167":1}}],["不幸的是",{"2":{"141":1}}],["不建议用鱼香ros的脚本一键安装ros",{"2":{"76":1}}],["不同天气条件下的模型性能",{"2":{"914":1}}],["不同高斯初始化策略的可视化比较",{"2":{"899":1}}],["不同于传统cnn常用的bottleneck",{"2":{"880":1}}],["不同于lss建模bev特征",{"2":{"585":1}}],["不同环境和不同地图表征之间进行公平比较",{"2":{"864":1}}],["不同方法的运行时间比较",{"2":{"840":1}}],["不同方法的模型效率比较",{"2":{"545":1,"965":1}}],["不同bev范围和体素大小之间的性能比较",{"2":{"800":1}}],["不同工作在步骤1",{"2":{"735":1}}],["不同地图结构各有优劣",{"2":{"648":1}}],["不同之处在于",{"2":{"652":1}}],["不同之处在于它捕捉了2d",{"2":{"610":1}}],["不同之处在于kimera",{"2":{"390":1}}],["不同点如下",{"2":{"550":1}}],["不同点在于本文使用8层的卷积网络从图像当中提取更深层的图像特征表示",{"2":{"305":1}}],["不同传感器组合的性能提升情况",{"2":{"503":1}}],["不同数据规模下蒸馏的益处如图",{"2":{"455":1}}],["不同数量的map进行复制",{"2":{"303":1}}],["不同噪声尺度的加权结果",{"2":{"342":1}}],["不同的下标可能对应相似的位置和视角",{"2":{"682":1}}],["不同的是对anchor进行聚类和平均",{"2":{"328":1}}],["不同的说明决定了需要保留的信息粒度",{"2":{"139":1}}],["不同大小的map使用双线性插值扩大",{"2":{"303":1}}],["不同抽象层次",{"2":{"216":1}}],["不同分量之间没有边",{"2":{"153":1}}],["不同房间中的3d对象片段",{"2":{"153":1}}],["不同语义实例",{"2":{"125":1}}],["不同",{"2":{"20":1,"109":1,"131":1,"147":1,"253":1,"511":1,"636":1,"967":2}}],["迹",{"2":{"20":1}}],["中代码获得的",{"2":{"978":1}}],["中各个子模块对最终模型性能的影响",{"2":{"971":1}}],["中共同资助",{"2":{"960":1}}],["中部所示",{"2":{"952":1}}],["中部署orbslam2",{"0":{"15":1},"1":{"22":1,"29":1,"36":1,"40":1,"47":1,"58":1,"67":1,"76":1,"87":1,"97":1,"107":1,"120":1,"136":1,"152":1}}],["中占比不到",{"2":{"945":1}}],["中等和困难类别的对象",{"2":{"931":1}}],["中进一步研究了不同数量的关系",{"2":{"928":1}}],["中进行了广泛的消融实验",{"2":{"723":1}}],["中进行了全面的回顾",{"2":{"603":1}}],["中已经证明",{"2":{"928":1}}],["中分别呈现最终的基准测试结果",{"2":{"927":1}}],["中还将",{"2":{"917":1}}],["中展示了更多的定性结果",{"2":{"992":1}}],["中展示了",{"2":{"914":1}}],["中展示了模型在",{"2":{"899":1}}],["中比较了我们的",{"2":{"903":1}}],["中比较了融合式基线模型和我们模型的参数数量和运行速度",{"2":{"803":1}}],["中被强调",{"2":{"903":1}}],["中被探索",{"2":{"808":1}}],["中具有最大尺度的各向同性球形高斯相比",{"2":{"901":1}}],["中红色框所示",{"2":{"899":1}}],["中报告",{"2":{"899":1}}],["中报告了完整的",{"2":{"989":1}}],["中报告了验证集上的性能",{"2":{"989":1}}],["中报告了高斯数量对我们的模型效率和性能的影响",{"2":{"812":1}}],["中报告了在",{"2":{"792":1}}],["中报告了",{"2":{"792":1}}],["中一个场景的流程如图",{"2":{"886":1}}],["中使用",{"2":{"1000":1}}],["中使用的数据集",{"2":{"1000":1}}],["中使用的数据格式重新组织了",{"2":{"886":1}}],["中使用了一个可选的反卷积层来达到输出尺寸",{"2":{"982":1}}],["中使用不同的",{"2":{"928":1}}],["中使用两个重要指标来比较",{"2":{"812":1}}],["中实现",{"2":{"978":1}}],["中实现的深度加权",{"2":{"866":1}}],["中实现了显著的改进",{"2":{"754":1}}],["中缺少对应语义占据标签",{"2":{"828":1}}],["中对我们的方法与其他",{"2":{"827":1}}],["中对不同的蒸馏方法进行了消融研究",{"2":{"823":1}}],["中对",{"2":{"812":1}}],["中取得成功后",{"2":{"808":1}}],["中取得了可比的性能",{"2":{"437":1}}],["中评估了我们提出的方法的效率",{"2":{"865":1}}],["中评估了kimera",{"2":{"754":1}}],["中评估并比较了我们方法与其他方法的延迟和内存消耗",{"2":{"700":1}}],["中将我们的方法与",{"2":{"745":1,"832":1}}],["中将分布",{"2":{"149":1}}],["中给出了我们的方法在非道路场景上的定性结果",{"2":{"745":1}}],["中可视化了一个单帧的融合式",{"2":{"843":1}}],["中可视化了",{"2":{"745":1,"832":1}}],["中像素的数量",{"2":{"741":1}}],["中随着马氏距离的平方呈指数衰减",{"2":{"738":1}}],["中随机选一个中间的交叉点",{"2":{"181":1}}],["中解码中间属性",{"2":{"716":1}}],["中解决因子图",{"2":{"310":1}}],["中获得一个相对准确的深度图",{"2":{"705":1}}],["中检查了高斯数量对模型性能的影响",{"2":{"700":1}}],["中栈是用什么容器实现的",{"2":{"685":1}}],["中心特征缺失",{"2":{"680":1}}],["中介绍的体素级密集融合方法开始",{"2":{"670":1}}],["中介绍的精确度和召回率指标来评估我们提出的clip嵌入向量关联策略clio",{"2":{"522":1}}],["中估计现实世界的密集3d占用是具有挑战性的",{"2":{"667":1}}],["中采样对应的特征",{"2":{"660":1}}],["中独立报告的值和各自作者的自我报告值",{"2":{"634":1}}],["中独立取得的",{"2":{"193":1}}],["中就没有",{"2":{"631":1}}],["中就是这两个特征的组合",{"2":{"149":1}}],["中记录",{"2":{"605":2}}],["中损失函数的多样性不足",{"2":{"603":1}}],["中不同层的分层特征连接起来",{"2":{"574":1}}],["中学习",{"2":{"548":1}}],["中包含11亿个注释点",{"2":{"534":1}}],["中提供了",{"2":{"901":1}}],["中提供了不同高斯初始化策略的可视化比较结果",{"2":{"899":1}}],["中提供了更多关于多分辨率语义占据预测的定性结果",{"2":{"899":1}}],["中提供了模型在",{"2":{"899":1}}],["中提供了高斯和占用的可视化结果",{"2":{"832":1}}],["中提到的",{"2":{"603":1,"853":1,"917":1}}],["中提出",{"2":{"566":1}}],["中提出的注释对模型进行评估",{"2":{"827":1}}],["中提出的全局",{"2":{"746":1}}],["中提出的2d动态融合模块分别应用于这两组中的每个2d平面",{"2":{"676":1}}],["中提出的方法",{"2":{"649":1,"787":1}}],["中提出的视图变换方法来聚合视觉特征",{"2":{"867":1}}],["中提出的视图变换方法",{"2":{"527":1}}],["中提出的一种视图变换方法生成额外的3d特征体",{"2":{"527":1}}],["中提取地点和房间的方法涉及批处理算法",{"2":{"141":1}}],["中找到最佳匹配",{"2":{"525":1}}],["中均得到广泛使用",{"2":{"525":1}}],["中交换意图",{"2":{"478":1}}],["中至关重要",{"2":{"475":1}}],["中定义的核相比",{"2":{"450":1}}],["中定义的精度和召回率指标",{"2":{"437":1}}],["中描述的聚类",{"2":{"431":1}}],["中显示clip对这些类型的查询具有类似的性能",{"2":{"431":1}}],["中显示了一个网格示例",{"2":{"419":1}}],["中是一项关键任务",{"2":{"421":1}}],["中级感知和高级感知",{"2":{"408":1}}],["中级感知还包括场景图前端",{"2":{"408":1}}],["中国",{"2":{"395":1,"608":1}}],["中引入的一阶段centerhead作为辅助检测头",{"2":{"666":1}}],["中引入的鲁棒姿态图优化器",{"2":{"390":1}}],["中引入的3d场景图模型",{"2":{"210":1}}],["中所示",{"2":{"659":1,"709":1}}],["中所定义",{"2":{"390":1}}],["中所述",{"2":{"352":1,"380":2,"437":1}}],["中所述计算",{"2":{"271":1}}],["中刚性变换的变形图重构",{"2":{"380":1}}],["中关于优化的详细信息",{"2":{"380":1}}],["中顶点的总数",{"2":{"372":1}}],["中需要整个环境的体积表示",{"2":{"301":1}}],["中那样带有语义标签",{"2":{"285":1}}],["中选取",{"2":{"274":1}}],["中间是真实的空间占用",{"2":{"833":1}}],["中间网格中的边缘使用最终分割预测进行着色",{"2":{"557":1}}],["中间的放大视图显示azure",{"2":{"686":1}}],["中间的3d柱坐标体进一步沿每个轴压缩",{"2":{"438":1}}],["中间的椅子是这两种椅子特征的线性组合",{"2":{"165":1}}],["中间隐藏变量",{"2":{"133":1}}],["中元素设置成当前向量元素",{"2":{"161":1}}],["中建议的",{"2":{"153":1}}],["中出现的分布和互信息项",{"2":{"137":1}}],["中属于聚类在",{"2":{"137":1}}],["中仅进行了讨论",{"2":{"131":1}}],["中",{"2":{"126":1,"152":1,"171":1,"181":1,"196":1,"234":1,"304":1,"310":1,"311":1,"408":1,"420":1,"435":1,"436":1,"437":2,"456":1,"481":5,"497":1,"505":1,"511":2,"527":2,"550":2,"574":2,"596":1,"607":1,"615":1,"621":1,"623":1,"634":1,"649":1,"664":1,"673":1,"678":3,"705":1,"728":1,"744":1,"827":1,"867":1,"875":1,"882":2,"899":2,"902":1,"903":2,"910":1,"917":3,"927":2,"928":3,"962":1,"989":1}}],["中抽象出",{"2":{"125":1}}],["中潜力的工作",{"2":{"121":1}}],["中安装",{"0":{"107":1}}],["中的体素数量",{"2":{"985":1}}],["中的空间层次结构已经类似于场景图",{"2":{"961":1}}],["中的稀疏几何结构",{"2":{"903":1}}],["中的噪声标签",{"2":{"903":1}}],["中的表现",{"2":{"903":1}}],["中的表面元素或表面体素的缩写",{"2":{"640":1}}],["中的拉伸效应",{"2":{"832":1}}],["中的各向同性球形高斯相比更具优势",{"2":{"832":1}}],["中的基线具有可比性",{"2":{"828":1}}],["中的模拟数据集",{"2":{"732":1}}],["中的注意力架构块",{"2":{"704":1}}],["中的非道路结果",{"2":{"700":1}}],["中的道路场景",{"2":{"700":1}}],["中的准确性和完整性度量来评估每个网格与地面真实的对比",{"2":{"686":1}}],["中的高斯混合模型对语义属性和不同高斯的贡献进行了归一化",{"2":{"681":1}}],["中的另一项研究发现",{"2":{"653":1}}],["中的一组多视角相机图像及其对应的标注占用标签",{"2":{"712":1}}],["中的一项研究表明",{"2":{"653":1}}],["中的一致性",{"2":{"125":1}}],["中的工作表明",{"2":{"653":1}}],["中的sgc",{"2":{"607":1}}],["中的固定图拉普拉斯矩阵计算出来的",{"2":{"607":1}}],["中的数据关联",{"2":{"525":1}}],["中的几何方法很容易分割",{"2":{"522":1}}],["中的风格混合方法生成图像的合成变体时",{"2":{"498":1}}],["中的密集clip特征的全局上下文clip向量",{"2":{"492":1}}],["中的卷积是基于球面互相关定义的",{"2":{"481":1}}],["中的红色边",{"2":{"480":1}}],["中的结果",{"2":{"449":1}}],["中的椅子",{"2":{"449":1}}],["中的大多数过程涉及处理整个esdf",{"2":{"437":1}}],["中的大值",{"2":{"153":1}}],["中的批量方法的运行时间",{"2":{"437":1}}],["中的批量离线场景图构建方法进行了比较",{"2":{"437":1}}],["中的两个",{"2":{"436":1}}],["中的检查进行了可视化",{"2":{"419":1}}],["中的graduated",{"2":{"380":1}}],["中的仿射变换",{"2":{"380":1}}],["中的贪婪模度基于社区检测方法",{"2":{"301":1}}],["中的多帧网格",{"2":{"285":1}}],["中的每帧网格",{"2":{"285":1}}],["中的dsg的第一层",{"2":{"285":1}}],["中的某些类别具有特殊属性",{"2":{"277":1}}],["中的",{"2":{"217":1,"277":1,"302":1,"534":1,"794":1,"928":2}}],["中的语义建图类似",{"2":{"209":1}}],["中的语义地图构建",{"2":{"90":1}}],["中的方法",{"2":{"276":1,"437":1}}],["中的方法设计为离线使用",{"2":{"172":1}}],["中的方法将需要在每次环路闭合后从头开始重建场景图",{"2":{"141":1}}],["中的变量",{"2":{"153":1}}],["中的参数",{"2":{"153":1}}],["中的概率",{"2":{"137":1}}],["中的左部分",{"2":{"133":1}}],["中的网格没有纳入回路闭合校正的结果",{"2":{"131":1}}],["中的优化器不常用",{"2":{"129":1}}],["中的关键帧的每个激光雷达点标注了",{"2":{"126":1}}],["中的聚合ib算法应用于任务驱动的3d场景理解问题",{"2":{"109":1}}],["中的定义错误",{"0":{"67":1}}],["中换成",{"2":{"40":1}}],["中添加",{"2":{"17":1,"107":1}}],["~training~object",{"2":{"235":1}}],["~~~g",{"2":{"273":1}}],["~~~",{"2":{"208":1,"273":1}}],["~~~~i=0",{"2":{"225":1}}],["~~~~",{"2":{"208":1}}],["~~~~x",{"2":{"111":1,"236":1,"273":1}}],["~~~~z",{"2":{"111":2,"236":2}}],["~~",{"2":{"208":1,"273":2}}],["~x",{"2":{"188":1}}],["~|z",{"2":{"132":1}}],["~and~|y",{"2":{"132":1}}],["~10^",{"2":{"111":1,"236":1}}],["~",{"2":{"17":1,"27":4,"34":1,"57":1,"87":3,"120":4,"132":1,"208":1,"235":4,"712":4,"780":1}}],["直到获得根节点",{"2":{"636":1}}],["直到所有地点都被标记",{"2":{"480":1}}],["直到步数t足够多之后",{"2":{"279":1}}],["直到结果可以满意",{"2":{"75":1}}],["直观地描述了节点附近地图的几何形状",{"2":{"352":1}}],["直观地描述了附近的对象集合",{"2":{"352":1}}],["直观地形成了环境的骨架",{"2":{"276":1}}],["直观地对比了端到端方法与模块化方法的区别",{"2":{"274":1}}],["直观地说",{"2":{"137":1,"197":1,"276":1,"301":1,"437":1}}],["直观上",{"2":{"137":2,"153":2,"402":1,"814":1}}],["直观感受",{"2":{"13":1}}],["直接从大规模3d空间中学习高分辨率细粒度全局体素特征既耗时又具有挑战性",{"2":{"922":1}}],["直接从3d空间学习占用表示具有很高的挑战性",{"2":{"892":1}}],["直接从传感器数据构建",{"2":{"125":1}}],["直接处理体素表示的方法通常能够实现较强的性能",{"2":{"875":1}}],["直接用作",{"2":{"870":1}}],["直接替换旧属性与新属性的",{"2":{"842":1}}],["直接替换其他属性的原因是",{"2":{"716":1}}],["直接影响路径规划与避障安全",{"2":{"826":1}}],["直接优化场景级和类别级指标",{"2":{"794":1}}],["直接优化重建表面",{"2":{"247":1}}],["直接评测任务性能已足够",{"2":{"786":1}}],["直接重建掩蔽点的坐标是不合理的",{"2":{"640":1}}],["直接将原始传感器数据映射到控制信号",{"2":{"975":1}}],["直接将原始传感器输入映射为驾驶动作带来挑战",{"2":{"114":1}}],["直接将每个高斯的贡献相加以产生占用预测",{"2":{"567":1}}],["直接投影法",{"2":{"495":1}}],["直接应用到点云数据的方法是利用基本的",{"2":{"488":1}}],["直接预测",{"2":{"473":1}}],["直接覆盖",{"2":{"435":1}}],["直接映射至轨迹或控制信号",{"2":{"308":1}}],["直接映射到控制输出或运动轨迹",{"2":{"252":1}}],["直接采用一个神经网络对全图提取特征",{"2":{"272":1}}],["直接在降质图像上fine",{"2":{"220":1}}],["直接在地图中存储可解释的高层概念",{"2":{"209":1}}],["直接队数据分布进行你和",{"2":{"203":1}}],["直接按的距离",{"2":{"20":1}}],["直接考虑生成数据和真实数据在feature层次的距离",{"2":{"20":1}}],["直接复制到",{"2":{"17":1}}],["在涉及自然因素的大多数损坏场景中",{"2":{"1005":1}}],["在恶劣天气条件下提供可靠的检测能力",{"2":{"1005":1}}],["在传感器模态方面",{"2":{"1005":1}}],["在网络架构和场景表示方面",{"2":{"1005":1}}],["在决策层面",{"2":{"1003":1}}],["在占用流预测中展示了潜力",{"2":{"1003":1}}],["在占据基准测试上的广泛实验表明",{"2":{"425":1}}],["在几何损失中",{"2":{"985":1}}],["在融合过程中加入2d前视特征可以进一步细化表示",{"2":{"970":1}}],["在人体跟踪文献中",{"2":{"967":1}}],["在人类在两个时间步之间的移动距离小于人类之间的距离的温和假设下",{"2":{"419":1}}],["在对3d占用进行修改",{"2":{"963":1}}],["在空间稀疏数据上应用密集卷积神经网络效率很低",{"2":{"962":1}}],["在空间粒度和内存消耗之间实现了最佳权衡",{"2":{"780":1}}],["在底部",{"2":{"952":1}}],["在中部",{"2":{"952":1}}],["在中间部分安插元素则比较费时",{"2":{"871":1}}],["在建筑物",{"2":{"947":1}}],["在建筑物z的房间y中的任何对象x附近",{"2":{"947":1}}],["在光照较弱的环境中表现不佳",{"2":{"936":1,"952":1}}],["在光照和天气条件变化的复杂户外场景中",{"2":{"691":1}}],["在大规模室外场景",{"2":{"935":1}}],["在大规模环境中",{"2":{"648":1}}],["在同一框架内融合空间地图的几何精度与拓扑地图的语义",{"2":{"935":1}}],["在同期工作中",{"2":{"482":1,"512":1}}],["在2d图像渲染中得到了广泛应用",{"2":{"932":1}}],["在2022年特斯拉ai日上",{"2":{"665":1}}],["在现有的创建精确占用标签的方法中",{"2":{"932":1}}],["在现有的多模态",{"2":{"421":1}}],["在相同的",{"2":{"928":1}}],["在相同的参数设置下",{"2":{"481":1}}],["在相似的实验设置下",{"2":{"922":1}}],["在从粗到细的上采样过程中逐渐稀疏化占用",{"2":{"922":1}}],["在从roi得到对应的特征图时",{"2":{"554":1}}],["在交叉注意力计算过程中选择性地选择前景和不确定的体素标记",{"2":{"922":1}}],["在交互式分割模型中",{"2":{"96":1}}],["在剩余部分",{"2":{"919":1}}],["在场景的边界框内随机采样大量点",{"2":{"916":1}}],["在场景中重建人类的密集网格",{"2":{"131":1}}],["在未占用空间中发现的高斯比例越高",{"2":{"916":1}}],["在未来的工作中",{"2":{"831":1}}],["在未来",{"2":{"302":1,"767":1}}],["在评估各种最新",{"2":{"915":1}}],["在评估过程中",{"2":{"866":1}}],["在评估过程中将忽略不可见的体素",{"2":{"712":1}}],["在极端气候",{"2":{"914":1}}],["在附近区域使用较小尺寸的圆柱体素进行细粒度建模是合理的",{"2":{"910":1}}],["在附录h中",{"2":{"553":1}}],["在圆柱坐标系中构建了三视角2d特征图",{"2":{"910":1}}],["在复杂的室外场景",{"2":{"903":1}}],["在复杂场景中",{"2":{"665":1}}],["在各个类别上",{"2":{"903":1}}],["在各种任务上验证了其有效性和强大的泛化能力",{"2":{"643":1}}],["在各种感知任务中展现出了令人鼓舞的性能",{"2":{"596":1}}],["在模块层面",{"2":{"880":1}}],["在模型训练和可视化期间未使用相机可见掩码",{"2":{"909":2}}],["在模型训练期间使用了相机可见掩码",{"2":{"800":1}}],["在模型输出处插入了通道到高度变换",{"2":{"811":1}}],["在模型复杂度方面",{"2":{"425":1}}],["在模型中增加了地点的拓扑图",{"2":{"172":1}}],["在voxformer",{"2":{"875":1}}],["在vla4ad中日益重要",{"2":{"176":1}}],["在穿过走廊时",{"2":{"872":1}}],["在资源受限的硬件上随环境复杂度线性或亚线性扩展",{"2":{"864":1}}],["在已有的实践中",{"2":{"863":1}}],["在两个优化步骤中完成",{"2":{"967":1}}],["在两个数据集的大结构类别上表现出色",{"2":{"903":1}}],["在两个数据集上都至少提高了",{"2":{"928":1}}],["在两个数据集上分别提高了",{"2":{"928":1}}],["在两个数据集上",{"2":{"903":1}}],["在两个视图上构造一对",{"2":{"579":1}}],["在两大公开数据集上达到或超越现有",{"2":{"862":1}}],["在高斯数量",{"2":{"851":1}}],["在白天场景中",{"2":{"847":1,"952":1}}],["在具有挑战性的场景下的定性研究",{"0":{"847":1}}],["在具身空间占用预测过程中某一时刻",{"2":{"793":1}}],["在具身空间占用预测任务中",{"2":{"682":1}}],["在具身智能与机器人学的文献中",{"2":{"786":1}}],["在具身智能与机器人学领域",{"2":{"252":1}}],["在具身智能中",{"2":{"525":1,"588":1,"619":1,"826":1}}],["在具身智能任务里",{"2":{"435":1}}],["在表",{"2":{"927":2,"928":2}}],["在表4中",{"2":{"842":1}}],["在表1中",{"2":{"842":1}}],["在表面",{"2":{"372":1}}],["在没有深度信息的引导下",{"2":{"833":1}}],["在没有噪声的情况下",{"2":{"390":1}}],["在处理了",{"2":{"833":1}}],["在初始化和后续块中的高斯的",{"2":{"832":1}}],["在初始化一个新场景时",{"2":{"728":1}}],["在夜间场景中",{"2":{"827":1,"847":1,"936":1,"944":1,"952":1}}],["在雨天场景中",{"2":{"827":1,"847":1,"936":1,"944":1,"952":1}}],["在噪声扰动下衡量系统鲁棒性",{"2":{"826":1}}],["在纯探索任务中会报告",{"2":{"826":1}}],["在测试集样本",{"2":{"899":1}}],["在测试集上达到54",{"2":{"825":1}}],["在测试时",{"2":{"184":1}}],["在elasticfusion的基础上通过强制所有surfels之间的一致重力方向进行构建",{"2":{"967":1}}],["在euroc的更具挑战性部分",{"2":{"836":1}}],["在euroc中",{"2":{"754":1}}],["在euroc中的定位和几何评估",{"2":{"754":1}}],["在embodiedocc",{"2":{"813":1}}],["在前两个优化层中设置为0",{"2":{"813":1}}],["在前向投影模块中",{"2":{"585":1}}],["在前向扩散时",{"2":{"312":1}}],["在uniocc上也得到了类似的结论",{"2":{"811":1}}],["在uhumans和uhumans2中的度量",{"2":{"754":1}}],["在uhumans和uhumans2数据集中",{"2":{"709":1}}],["在bevdetocc的情况下",{"2":{"811":1}}],["在bev特征上应用复杂的多尺度特征融合模块以捕捉更细致的细节",{"2":{"612":1}}],["在激光雷达模型中添加轻量级图像分支可实现合理的",{"2":{"803":1}}],["在激光雷达分支中",{"2":{"758":1}}],["在类似",{"2":{"803":1}}],["在保持相同体素大小的情况下",{"2":{"800":1}}],["在确保性能的同时显著减少资源消耗",{"2":{"799":1}}],["在局部空间占用预测任务中",{"2":{"793":1}}],["在局部空间占用预测模块中",{"2":{"705":1}}],["在完成这些操作后",{"2":{"789":1}}],["在有限标签下的整体高效学习性能",{"2":{"782":1}}],["在有限标签下表现良好",{"2":{"517":1}}],["在z轴上跨越",{"2":{"781":1}}],["在使用resnet50",{"2":{"779":1}}],["在使用mt提取表面网格后",{"2":{"400":1}}],["在语言驱动的",{"2":{"765":1}}],["在语义丰富度",{"2":{"864":1}}],["在语义类别上略有不同的是",{"2":{"739":1}}],["在语义地图中存储的是潜在特征",{"2":{"721":1}}],["在语义推理方法中",{"2":{"274":1}}],["在语义表达",{"2":{"209":1}}],["在语义分割中",{"2":{"96":1}}],["在儿童房找一只红蓝条纹的斑马玩具",{"2":{"765":1}}],["在巨量互联网图文对上联合训练",{"2":{"765":1}}],["在和在变形之前和之后",{"2":{"754":1}}],["在其上应用一系列",{"2":{"752":1}}],["在其他一些创新中",{"2":{"603":1}}],["在一定数量的更新之后",{"2":{"750":1}}],["在一个更一般的具身场景中",{"2":{"629":1}}],["在整个预测过程中",{"2":{"750":1}}],["在整个探索过程中",{"2":{"600":1}}],["在拓扑节点中存储隐式特征",{"2":{"743":1}}],["在拓扑地图的构建过程中",{"2":{"525":1}}],["在公式",{"2":{"738":1}}],["在步骤3中的体素化之后",{"2":{"735":1}}],["在后处理步骤中",{"2":{"735":2}}],["在后向去噪时",{"2":{"312":1}}],["在道路等地方仍然有许多占用的体素未被标记为占用",{"2":{"735":1}}],["在解析无纹理区域",{"2":{"732":1}}],["在当前的3d占用基准中",{"2":{"975":1}}],["在当前更新中",{"2":{"728":1}}],["在当前步骤",{"2":{"728":1}}],["在世界坐标系和相机坐标系之间保持一致",{"2":{"728":1}}],["在用中间属性细化旧属性时",{"2":{"716":1}}],["在获得更新后的3d高斯分布后",{"2":{"716":1}}],["在获得初始sdf后",{"2":{"372":1}}],["在感知层面",{"2":{"1003":1}}],["在感知相关主题中",{"2":{"714":1}}],["在感知压缩学习阶段",{"2":{"270":1}}],["在拥挤的动态环境中实现鲁棒和准确的度量",{"2":{"709":1}}],["在第6",{"2":{"939":1}}],["在第二个验证样本中",{"2":{"899":1}}],["在第",{"2":{"853":1}}],["在第4",{"2":{"709":1}}],["在第一个验证样本",{"2":{"899":1}}],["在第一步中",{"2":{"561":1}}],["在第一阶段",{"2":{"276":1}}],["在要求",{"2":{"698":1}}],["在输入数据未标注时仅使用蒸馏损失",{"2":{"694":1}}],["在点",{"2":{"681":1}}],["在点云领域",{"2":{"340":1}}],["在他们的研究中",{"2":{"678":1}}],["在学术界和工业界都得到了广泛的应用",{"2":{"931":1}}],["在学术界和工业界",{"2":{"667":1}}],["在学习的第二阶段",{"2":{"294":1}}],["在开放场景中",{"2":{"665":1}}],["在开源代码需要的",{"2":{"107":1}}],["在propagation",{"2":{"695":1}}],["在pvnet",{"2":{"664":1}}],["在pointgcn",{"2":{"607":1}}],["在pointnet基础上",{"2":{"574":1}}],["在point",{"2":{"420":1}}],["在无监督动态路由的基础上",{"2":{"664":1}}],["在无监督学习的加持下",{"2":{"265":1}}],["在编码阶段",{"2":{"664":1}}],["在动态且不可预测的现实驾驶环境中",{"2":{"1005":1}}],["在动态且部分遮挡条件下噪声容忍控制",{"2":{"145":1}}],["在动态环境中空间与语义的持续可靠性",{"2":{"943":1}}],["在动态",{"2":{"926":1}}],["在动态实体数量增加的情况下",{"2":{"662":1}}],["在所有实验中",{"2":{"800":1}}],["在所有尺度sss上重复这一过程",{"2":{"660":1}}],["在所有指标和数据集上的表现均优于现有方法",{"2":{"539":1}}],["在范围",{"2":{"652":2}}],["在滤波步骤中确定每个像素的可见视图",{"2":{"650":1}}],["在组合前必须审慎考虑各结构的弱点",{"2":{"648":1}}],["在标准交叉熵损失",{"2":{"632":1}}],["在密集预测型的任务上",{"2":{"631":1}}],["在结论的部分指出他们只是做了分类任务",{"2":{"631":1}}],["在渲染过程中使用的三维高斯分布的明确物理特性和基于溅射的光栅化也激励了场景编辑",{"2":{"629":1}}],["在渲染颜色的同时",{"2":{"619":1}}],["在深度估计模块中",{"2":{"621":1,"649":1}}],["在occ",{"2":{"813":1}}],["在occcylindrical框架中",{"2":{"621":1}}],["在occ3d",{"2":{"421":1,"779":3,"800":1,"820":1,"840":1,"909":1,"1000":1,"1001":1,"1006":1}}],["在特征通道维度上进行拼接",{"2":{"621":1}}],["在特征空间中构造一个图",{"2":{"574":1}}],["在特征空间中进行稠密匹配提高了重建质量",{"2":{"305":1}}],["在损失函数中加入图信号的平滑先验",{"2":{"607":1}}],["在厨房区域可以看到一个坐着的人类",{"2":{"605":1}}],["在记录",{"2":{"605":1}}],["在ros中",{"2":{"605":1}}],["在智能体连续探索同一场景的过程中",{"2":{"600":1}}],["在检测和分割任务中表现与基于激光雷达的方法相当",{"2":{"599":1}}],["在检测到环路闭合后",{"2":{"380":1}}],["在检测到图案后",{"2":{"191":1}}],["在该领域做出了开创性贡献",{"2":{"598":1}}],["在不同抽象层次上使用a",{"2":{"947":1}}],["在不同大洲收集数据",{"2":{"126":1}}],["在不确定区域中激活出更多的前景区域",{"2":{"591":1}}],["在研究界仍广泛使用",{"2":{"588":1}}],["在室内场景",{"2":{"903":1}}],["在室内场景中探索的智能体通过感知和理解周围环境来做出决策并执行下游任务",{"2":{"600":1}}],["在室内场景中的研究仍然相对较少",{"2":{"544":1}}],["在室外场景进行",{"2":{"588":1}}],["在实现准确和细粒度的语义占据预测方面是有效的",{"2":{"767":1}}],["在实际部署中更受青睐",{"2":{"665":1}}],["在实际应用中",{"2":{"601":1,"766":1,"794":1,"996":1}}],["在实践中选择合适的网格分辨率并非易事",{"2":{"962":1}}],["在实践中",{"2":{"660":1,"858":1}}],["在实践中发现",{"2":{"583":1}}],["在实验中我们选取",{"2":{"718":1}}],["在实验中",{"2":{"437":1,"522":1,"592":1}}],["在基本网络的基础上",{"2":{"576":1}}],["在基于视觉的占用感知中",{"2":{"957":1}}],["在基于几何的视图变换后删除空体素",{"2":{"517":1}}],["在基于图优化的",{"2":{"171":1}}],["在depthnet中",{"2":{"649":1}}],["在deformable",{"2":{"386":1}}],["在dgcnn",{"2":{"574":1}}],["在连续探索过程中",{"2":{"568":1}}],["在探索室内场景时的性能",{"2":{"902":1}}],["在探索当前场景的过程中",{"2":{"568":1}}],["在探索阶段",{"2":{"525":1}}],["在上述方法的推动下",{"2":{"956":1}}],["在上一步中我们根据pin与pout获得getoffset",{"2":{"561":1}}],["在上图中的例子中",{"2":{"554":1}}],["在mask",{"2":{"554":1}}],["在将特征图分块的时候",{"2":{"554":1}}],["在将信息瓶颈算法应用于任务驱动的3d场景理解时",{"2":{"271":1}}],["在得到特征图后",{"2":{"554":1}}],["在压缩级别上工作",{"2":{"552":1}}],["在生成器中提供了相对于后续点块的方向信息",{"2":{"549":1}}],["在生成设置中",{"2":{"314":1}}],["在体素空间中选择给定位置在特定半径内的",{"2":{"976":1}}],["在体素特征上应用神经渲染作为辅助监督",{"2":{"548":1}}],["在体积地图上查询从一个点到另一个点的路径在计算上是昂贵的",{"2":{"930":1}}],["在体函数卷积过程中引入球谐核",{"2":{"481":1}}],["在性能和复杂性之间取得了更好的平衡",{"2":{"547":1}}],["在nvidia",{"0":{"836":1},"2":{"816":1}}],["在nyuv2和occ",{"2":{"544":1}}],["在nuscenes数据集上进行的实验表明",{"2":{"898":1}}],["在nuscenes验证集上3d语义占用预测的可视化结果",{"2":{"842":1}}],["在nuscenes和semantickitti数据集上进行的广泛实验",{"2":{"475":1}}],["在nuscenes基准测试中达到了顶级性能",{"2":{"475":1}}],["在nuscenes",{"2":{"254":1,"421":1,"534":1}}],["在简明分类法下统一若干代表性方法",{"2":{"538":1}}],["在效率极高的情况下实现了最先进的性能",{"2":{"536":1}}],["在环绕视角感知中",{"2":{"535":1}}],["在环路闭合检测时",{"2":{"352":1}}],["在位置",{"2":{"532":1}}],["在hash",{"2":{"530":1}}],["在笛卡尔坐标系下从环视摄像头生成伪3d点云",{"2":{"527":1}}],["在笛卡尔坐标系下进行3d特征体的特征细化和融合不同",{"2":{"438":1}}],["在杂乱室内场景中可能遗漏对空间推理至关重要的视觉线索",{"2":{"525":1}}],["在指令跟随任务中",{"2":{"525":1}}],["在那里我们命令抓取3个随机目标对象",{"2":{"522":1}}],["在映射阶段",{"2":{"522":1}}],["在挑战背景下",{"2":{"520":1}}],["在挑战赛道中排名第一",{"2":{"490":1}}],["在除暴雨和浓雾外的各种天气条件下表现稳定",{"2":{"503":1}}],["在文献",{"2":{"497":1,"527":2}}],["在创建场景图之后",{"2":{"492":1}}],["在fbocc上实现了0",{"2":{"811":1}}],["在fb",{"2":{"490":1,"585":1}}],["在find",{"2":{"107":1}}],["在汽车硬件上以≥30hz运行视觉transformer加llm非易事",{"2":{"478":1}}],["在作者的设置中",{"2":{"466":1}}],["在嵌入步骤中",{"2":{"456":1}}],["在知识蒸馏过程中",{"2":{"455":1}}],["在统一的",{"2":{"444":1}}],["在统一框架内对齐视觉",{"2":{"145":1}}],["在预测场景布局和物体几何结构方面表现更好",{"2":{"992":1}}],["在预测几何结构和语义方面仍然表现更好",{"2":{"917":1}}],["在预测大面积区域",{"2":{"700":1}}],["在预测精度上达到了与基于多模态融合的最先进方法相当的水平",{"2":{"444":1}}],["在预训练后阶段",{"2":{"368":1}}],["在预训练结束后",{"2":{"315":1}}],["在预训练阶段结束后",{"2":{"315":1}}],["在预训练阶段",{"2":{"315":1}}],["在众多感知任务中",{"2":{"444":1}}],["在众多必备技能中",{"2":{"80":1}}],["在1400秒",{"2":{"437":1}}],["在图",{"2":{"902":1,"952":1,"989":1}}],["在图像语义分割掩码的指导下消除错误占用的体素",{"2":{"735":1}}],["在图节点中记录",{"2":{"698":1}}],["在图上采样子目标节点",{"2":{"525":1}}],["在图9中",{"2":{"437":1,"924":1}}],["在图论中",{"2":{"153":1}}],["在方程",{"2":{"437":1}}],["在更大的尺度上聚合特征信息",{"2":{"589":1}}],["在更大的场景",{"2":{"437":1}}],["在更新过程中",{"2":{"380":1}}],["在真实环境中的建图更为一致",{"2":{"435":1}}],["在任务层结束之前",{"2":{"526":1}}],["在任务过程中实时建图或更新地图",{"2":{"435":1}}],["在任务由封闭词典隐式指定的封闭集设置中与最新技术持平",{"2":{"320":1}}],["在线地图构建",{"2":{"1003":1}}],["在线服务器",{"2":{"853":1}}],["在线更新高斯记忆",{"0":{"728":1}}],["在线三维场景感知",{"2":{"629":1}}],["在线构建拓扑图",{"2":{"525":1}}],["在线",{"2":{"435":2}}],["在地图单元格存储平均音频强度",{"2":{"698":1}}],["在地图上保存分割后物体的文本标签",{"2":{"698":1}}],["在地图更新时",{"2":{"435":1}}],["在地点的子图中诱导的连通分量",{"2":{"276":1}}],["在构建空间网格地图时",{"2":{"435":1}}],["在构建daocc的基线网络时",{"2":{"421":1}}],["在sscbench",{"2":{"1000":3}}],["在semantickitti数据集上",{"2":{"1000":2}}],["在semantickitti和sscbench",{"2":{"1000":1}}],["在semantickitti测试集上3d占用预测的比较",{"2":{"1000":1}}],["在semantic3d的reduced",{"2":{"996":1}}],["在surroundocc上进行比较",{"2":{"779":1}}],["在surroundocc",{"2":{"700":1}}],["在surroundocc验证集上",{"2":{"421":1}}],["在spot上的在线评估",{"2":{"522":1}}],["在sfcnn",{"2":{"511":1}}],["在s3dis上最好的miou为68",{"2":{"366":1}}],["在三维占据预测任务中",{"2":{"800":1}}],["在三维目标检测任务中取得了比基于图像的三维检测器",{"2":{"421":1}}],["在三维重建的初始化阶段",{"2":{"31":1}}],["在kimera",{"2":{"419":1,"449":1}}],["在配对图像",{"2":{"417":1}}],["在掩模分支中",{"2":{"405":1}}],["在以下",{"2":{"390":1}}],["在节点",{"2":{"390":1}}],["在接受回路闭合时过于谨慎",{"2":{"390":1}}],["在应用第一次卷积之前",{"2":{"379":1}}],["在自行车和摩托车等类别上超越了基于密集网格表示的方法",{"2":{"792":1}}],["在自上而下的提议阶段",{"2":{"377":1}}],["在自下而上的分组阶段",{"2":{"377":1}}],["在自动驾驶中起着至关重要的作用",{"2":{"665":1}}],["在自动驾驶中",{"2":{"567":1}}],["在自动驾驶领域",{"2":{"547":1}}],["在自动驾驶",{"2":{"421":1}}],["在自动驾驶与路径规划领域",{"2":{"252":1}}],["在自动编码的设置中",{"2":{"314":1}}],["在早期的工作中",{"2":{"373":1}}],["在最后一个优化层中设置为0",{"2":{"813":1}}],["在最后一次优化后",{"2":{"705":1}}],["在最近的工作中被广泛使用",{"2":{"655":1}}],["在最大关节位移之间的时间跟踪和一致性检查",{"2":{"419":1}}],["在最坏情况下",{"2":{"402":1}}],["在最终表面计算的损失可以反向传播到所有层次的所有顶点",{"2":{"372":1}}],["在最低层次",{"2":{"352":1}}],["在迭代次数分别为20k和30k的时候",{"2":{"366":1}}],["在捆绑语义射线投射之后",{"2":{"362":1}}],["在捆绑射线投射期间",{"2":{"362":1}}],["在射线上遍历体素时",{"2":{"362":1}}],["在下一步构建特征体时使用了双线性插值来保证所有深度的特征图尺寸一致",{"2":{"355":1}}],["在另一种场景中表现欠佳",{"2":{"603":1}}],["在另一位姿下各像素点的应有的对应特征值",{"2":{"355":1}}],["在另一个位置用相机2拍照",{"2":{"355":1}}],["在代理层的外观描述符之间",{"2":{"352":1}}],["在执行环路闭合检测时",{"2":{"352":1}}],["在给定维度上对输入的张量序列seq",{"2":{"351":1}}],["在给定时间一个人在房间里",{"2":{"105":1}}],["在时间方法中",{"2":{"811":1}}],["在时间t",{"2":{"336":1}}],["在时间上早于此的样本",{"2":{"254":1}}],["在时间上跟随这个样本",{"2":{"254":1}}],["在3d占用算法发展之前",{"2":{"997":1}}],["在3d占用预测方法方面",{"2":{"969":1}}],["在3d点云的深度学习中",{"2":{"313":1}}],["在3d场景理解中",{"2":{"153":1}}],["在消除之前",{"2":{"310":1}}],["在g3d",{"2":{"574":1}}],["在gtsam",{"2":{"310":1}}],["在gvd更新后",{"2":{"276":1}}],["在每个时间步长直接获得人体的完整3d姿态",{"2":{"967":1}}],["在每个金字塔层的开始",{"2":{"922":1}}],["在每个包含",{"2":{"789":1}}],["在每个实验表的",{"2":{"770":1}}],["在每个层级之间实现了跳跃连接结构",{"2":{"746":1}}],["在每个层级使用",{"2":{"746":1}}],["在每个层次上",{"2":{"636":1}}],["在每个点patch的生成目标是预测后续点patch内点的坐标",{"2":{"582":1}}],["在每个",{"2":{"549":1}}],["在每个嵌入的体素网格内采样固定数量的点",{"2":{"363":1}}],["在每个关键帧中",{"2":{"362":1}}],["在每个关键帧上",{"2":{"310":1}}],["在每次更新过程中",{"2":{"833":1}}],["在每次更新时",{"2":{"568":1}}],["在每次更新中",{"2":{"568":1,"728":1,"813":1}}],["在每次isam2迭代中",{"2":{"310":1}}],["在每次环路闭合后重新整合体积地图",{"2":{"190":1}}],["在每次迭代",{"2":{"153":1}}],["在每次迭代中",{"2":{"153":1}}],["在帧间跟踪它们",{"2":{"310":1}}],["在长时程任务中效率明显不足",{"2":{"495":1}}],["在长时域推理",{"2":{"308":1}}],["在长期路径规划上表现不佳",{"2":{"252":1}}],["在waymo自动驾驶数据上训练大规模vlm",{"2":{"308":1}}],["在推理阶段",{"2":{"761":1}}],["在推理时",{"2":{"369":1}}],["在推理的不同阶段加不同强度的噪声",{"2":{"291":1}}],["在推理过程中",{"2":{"204":1,"469":1,"471":1}}],["在运行结束时自动构建",{"2":{"285":1}}],["在教堂处右转",{"2":{"283":1}}],["在收集驾驶数据后",{"2":{"277":1}}],["在计算描述符时",{"2":{"352":1}}],["在计算活动窗口的gvd后",{"2":{"276":1}}],["在计算机视觉中首次使用3d场景图",{"2":{"125":1}}],["在活动窗口内esdf集成过程中获得gvd作为副产品",{"2":{"276":1}}],["在活动窗口内提取3d网格后",{"2":{"253":1}}],["在数据集",{"2":{"712":1}}],["在数据密度较低的位置",{"0":{"267":1}}],["在数据分析中选择特征",{"2":{"137":1}}],["在6种不同的评价基准上取得了最佳效果",{"2":{"265":1}}],["在多摄像头视图的重叠区域中",{"2":{"957":1}}],["在多摄像头设置中",{"2":{"957":1}}],["在多相机视图重叠区域",{"2":{"942":1}}],["在多相机重叠区域进行空间信息融合",{"2":{"942":1}}],["在多样化方法上的通用flashocc",{"2":{"811":1}}],["在多样化的3d场景感知任务中已经展示了有前景的结果",{"2":{"566":1}}],["在多步或多目标场景",{"2":{"806":1}}],["在多目标导航中维护",{"2":{"698":1}}],["在多模态场景中",{"2":{"532":1}}],["在多个数据集上取得了良好的性能",{"2":{"945":1}}],["在多个3d点云下有任务中",{"2":{"290":1}}],["在多个抽象层次上表示场景",{"2":{"116":1}}],["在多层建筑中",{"2":{"262":1}}],["在此基础上评估了我们的embodiedocc的性能",{"2":{"833":1}}],["在此设置中",{"2":{"782":1,"823":1}}],["在此过程中可以减小深度单位间隔",{"2":{"618":1}}],["在此边缘折叠操作中",{"2":{"436":1}}],["在此语料上训练可测得闭环安全提升",{"2":{"360":1}}],["在此示例中",{"2":{"315":1}}],["在此时间之前",{"2":{"254":1}}],["在此样本识别的雷达扫描过程中计算点",{"2":{"254":1,"654":1}}],["在此样本识别的激光雷达扫描过程中计算点",{"2":{"254":1,"654":1}}],["在增量操作期间",{"2":{"253":1}}],["在单一框架内联合建模感知",{"2":{"252":1}}],["在单一策略内统一感知",{"2":{"145":1}}],["在某些情况下",{"2":{"216":1,"462":1,"745":1}}],["在全卷积点网络",{"2":{"962":1}}],["在全局中间地图上直接预测动作",{"2":{"252":1}}],["在全文后续章节中",{"2":{"209":1}}],["在全图像素上进行扩散",{"2":{"205":1,"428":1}}],["在内存受限硬件上同时保证",{"2":{"864":1}}],["在内部",{"2":{"196":1}}],["在内的最新研究工作通过检测对应于封闭语义集的对象和区域来构建度量",{"2":{"109":1}}],["在过滤掉移动物体的雷达回波后",{"2":{"191":1}}],["在训练策略方面",{"2":{"1005":1}}],["在训练时还需要语义点云",{"2":{"978":1}}],["在训练时随机初始化高斯物理属性",{"2":{"563":1}}],["在训练我们的embodiedocc时",{"2":{"833":1}}],["在训练和评估我们的embodiedocc框架时",{"2":{"793":1}}],["在训练阶段",{"2":{"959":1}}],["在训练阶段使用",{"2":{"761":1}}],["在训练阶段使用了相机可见掩码",{"2":{"736":1}}],["在训练阶段未使用相机可见掩码",{"2":{"736":1}}],["在训练sd的过程中",{"2":{"373":1}}],["在训练autoencoder过程中",{"2":{"345":1}}],["在训练期间",{"2":{"184":1}}],["在训练过程中保持冻结",{"2":{"813":1}}],["在训练过程中设置为1",{"2":{"647":1}}],["在训练过程中",{"2":{"184":1,"738":1,"941":1}}],["在训练中捕获真实数据的分布",{"2":{"129":1}}],["在imagenet数据集上训练同样的步数",{"2":{"345":1}}],["在imu速率下的高精度状态估计",{"2":{"285":1}}],["在ib算法中",{"2":{"153":2}}],["在is看来",{"2":{"13":1}}],["在信息瓶颈",{"2":{"153":1}}],["在我们基于",{"2":{"928":1}}],["在我们在查询和匹配代理节点",{"2":{"352":1}}],["在我们当前的实现中",{"2":{"285":1}}],["在我们的框架中整合相机和激光雷达数据可获得与纯视觉中心和纯激光雷达中心算法相比极具竞争力的性能",{"2":{"927":1}}],["在我们的先前论文",{"2":{"634":1}}],["在我们的案例中",{"2":{"590":1}}],["在我们的工作中",{"2":{"535":1}}],["在我们的测试中≤30像素",{"2":{"419":1}}],["在我们的方法中",{"2":{"390":1}}],["在我们的真实实验中",{"2":{"362":1}}],["在我们的设置中",{"2":{"325":1,"419":1}}],["在我们的实现中",{"2":{"310":1,"352":1}}],["在我们的情况下",{"2":{"210":1,"724":1}}],["在我们的问题中",{"2":{"153":2}}],["在我看来",{"2":{"41":1}}],["在罕见与长尾场景下鲁棒推理",{"2":{"145":1}}],["在户内环境中导航至发出特定声音的物体",{"2":{"139":1}}],["在仿真环境中与基于学习的智能体交互",{"2":{"139":1}}],["在机器人学中得到了广泛研究",{"2":{"967":1}}],["在机器人中可用于高保真场景重建及可微",{"2":{"588":1}}],["在机器人领域",{"2":{"588":1,"619":1}}],["在机器人或自动驾驶车辆等实时系统中",{"2":{"153":1}}],["在机器人视觉领域开创性地使用了3d场景图",{"2":{"116":1}}],["在机器学习",{"2":{"137":1}}],["在本研究中",{"2":{"977":1}}],["在本小节中",{"2":{"728":1,"757":1,"999":1}}],["在本综述中",{"2":{"610":1}}],["在本工作中",{"2":{"415":1,"474":1,"482":1,"512":1}}],["在本章中",{"2":{"324":1}}],["在本文中提到的",{"2":{"153":1}}],["在本文中",{"2":{"137":1,"178":1,"544":1,"547":1,"567":1,"568":1,"629":1,"665":1,"760":1,"767":1,"789":1,"793":1,"820":1,"831":1,"851":1,"852":1,"861":1,"867":1}}],["在本节中",{"2":{"100":1,"153":1,"419":1,"628":1,"634":1,"669":1,"748":1,"855":1,"877":1,"991":1,"1002":1}}],["在视野范围内移动和俯仰和横滚",{"2":{"136":1}}],["在视觉",{"2":{"131":1}}],["在许多应用中",{"2":{"116":1}}],["在二楼寻找幸存者",{"2":{"116":1}}],["在coco任务上",{"2":{"824":1}}],["在cloudcompare",{"2":{"686":1}}],["在cpu上运行的优点是",{"2":{"408":1}}],["在c++中",{"2":{"196":1}}],["在cv",{"2":{"107":1}}],["在cmakelist",{"2":{"40":1}}],["在骨干网络之前融合了交互和图像特征",{"2":{"96":1}}],["在这篇综述中",{"2":{"958":1}}],["在这种特定场景中",{"2":{"952":1}}],["在这种方法中",{"2":{"875":1}}],["在这种情况下",{"2":{"271":1,"571":2,"796":2,"998":1}}],["在这两种情况下",{"2":{"775":1}}],["在这两个步骤中",{"2":{"372":1}}],["在这些区域中",{"2":{"723":1}}],["在这些模块中",{"2":{"704":1}}],["在这些方法中",{"2":{"636":1,"923":1}}],["在这些传感器配置中",{"2":{"444":1}}],["在这些场景中",{"2":{"437":1,"936":1}}],["在这些环境中",{"2":{"90":1}}],["在这里笔者举例讲解一下roi",{"2":{"554":1}}],["在这里",{"2":{"271":1,"492":1,"549":1,"570":1,"684":1,"688":1,"736":1,"775":1}}],["在这里通过设置",{"2":{"17":1}}],["在这个过程中",{"2":{"728":1}}],["在这个橙色的窗口中只有右侧p1位置非零",{"2":{"561":1}}],["在这个",{"2":{"253":1}}],["在这个模型中",{"2":{"210":1}}],["在这项工作中",{"2":{"143":1,"967":1}}],["在终端界面中按照提示",{"2":{"87":1}}],["在安装完ros之后建议安装此工具",{"2":{"87":1}}],["在陌生环境中需要执行复杂的语义任务",{"2":{"80":1}}],["在英伟达官网找到合适的驱动版本",{"2":{"66":1}}],["在日常使用中",{"2":{"63":1}}],["在容器中安装某些大型软件",{"2":{"60":1}}],["在linux终端下",{"2":{"48":1}}],["在挂载成功以后",{"2":{"24":1}}],["在",{"2":{"17":1,"33":1,"126":1,"233":1,"301":1,"302":1,"349":1,"382":1,"425":1,"436":1,"455":1,"456":1,"463":1,"481":5,"511":1,"567":1,"588":1,"619":1,"652":1,"664":1,"677":1,"678":4,"700":5,"771":1,"808":1,"827":1,"851":1,"889":1,"900":2,"903":3,"917":4,"928":6,"960":1,"978":1,"982":2}}],["fq",{"2":{"957":1}}],["fq​",{"2":{"957":2}}],["fqf",{"2":{"957":1}}],["fg",{"2":{"823":1}}],["fg∈rc×d",{"2":{"609":2}}],["ft−k",{"2":{"957":2}}],["ft−k​",{"2":{"957":1}}],["ft−kf",{"2":{"957":1}}],["ft",{"2":{"694":4}}],["ft​",{"2":{"694":1}}],["ftf",{"2":{"694":1}}],["ftj",{"2":{"153":3}}],["ftj​",{"2":{"153":4}}],["ftjf",{"2":{"153":1}}],["fzr​=mlp",{"2":{"676":1}}],["fzr=mlp",{"2":{"676":1}}],["fℓkmi​",{"2":{"623":1}}],["fℓkmi",{"2":{"623":1}}],["f3d用作",{"2":{"660":1}}],["f3d=s∈s∑​φρ",{"2":{"660":1}}],["f3d=∑s∈sφρ",{"2":{"660":1}}],["f3d=fd⊗fc",{"2":{"595":1}}],["f3d可以表示为",{"2":{"660":1}}],["f3df^",{"2":{"660":2}}],["f3d",{"2":{"595":2,"660":2}}],["fdz​=mlp",{"2":{"676":1}}],["fdz=mlp",{"2":{"676":1}}],["fd",{"2":{"595":1,"707":3}}],["fdisk",{"2":{"24":1}}],["fk",{"2":{"579":1}}],["f的监督",{"2":{"559":1}}],["fpi​",{"2":{"998":1}}],["fpifp",{"2":{"915":1,"998":1}}],["fpfpfp",{"2":{"998":1}}],["fp32后端上测量的",{"2":{"840":1}}],["fpo​",{"2":{"778":1}}],["fpofp",{"2":{"778":1}}],["fp和",{"2":{"749":1}}],["fpc​",{"2":{"739":1,"742":1,"778":1}}],["fpcfp",{"2":{"739":1,"742":1,"778":1}}],["fp",{"2":{"632":1,"749":4,"802":5,"807":3,"814":2,"834":1,"848":1,"853":1,"877":1,"915":1}}],["fpn",{"2":{"609":1,"627":1,"670":1,"677":1,"699":4,"744":1,"768":1,"822":1,"867":1}}],["fpe",{"2":{"550":1,"583":1}}],["fps是通过在表中列出的相应gpu类型上进行测试获得的",{"2":{"859":1}}],["fps运行的基线方法",{"2":{"811":1}}],["fps的速度超越了以92",{"2":{"811":1}}],["fps",{"2":{"396":2,"447":1,"812":2,"840":1,"1001":1}}],["fbev",{"2":{"950":2}}],["fbc​",{"2":{"742":1}}],["fbcfb",{"2":{"742":1}}],["fb",{"0":{"635":1},"2":{"490":1,"585":1,"612":1,"635":1,"839":4,"875":1,"1000":1}}],["fbocc",{"0":{"458":1},"1":{"490":1,"520":1,"551":1,"585":1,"617":1,"646":1,"673":1,"697":1,"720":1,"742":1,"764":1,"785":1,"805":1,"825":1,"845":1}}],["fϕ​",{"2":{"422":1}}],["fϕ",{"2":{"422":1}}],["f^",{"2":{"372":2,"660":2,"694":2,"957":1}}],["f^2",{"2":{"208":2}}],["fv",{"2":{"976":7}}],["fvik​",{"2":{"976":2}}],["fvik",{"2":{"976":2}}],["fvi1​",{"2":{"976":2}}],["fvi1",{"2":{"976":2}}],["fvi​",{"2":{"372":2}}],["fvi",{"2":{"372":2}}],["fvol=f2d⊗disf",{"2":{"950":1}}],["fvol",{"2":{"344":1,"372":1,"429":1,"950":3,"957":2}}],["fvol​",{"2":{"318":2,"344":1,"372":1,"429":1,"950":3,"957":2}}],["f=​f1t​",{"2":{"357":1}}],["f=",{"2":{"357":1}}],["f=8f=8f=8",{"2":{"345":1}}],["f=h",{"2":{"345":1}}],["fmergedl​local​",{"2":{"746":2}}],["fmergedl​global​",{"2":{"746":2}}],["fmergedllocalf",{"2":{"746":2}}],["fmergedlglobalf",{"2":{"746":2}}],["fmono​",{"2":{"682":1}}],["fmonof",{"2":{"682":1}}],["fms​=",{"2":{"609":1}}],["fms=",{"2":{"609":1}}],["fm",{"2":{"292":2}}],["fcpn",{"2":{"962":1}}],["fccrf",{"2":{"962":1}}],["fcnn",{"2":{"962":1}}],["fcn",{"2":{"763":2,"955":1}}],["fcamllocalf",{"2":{"746":1}}],["fcamllocal∈rcl×xl×yl×zlf",{"2":{"746":1}}],["fcamlglobalf",{"2":{"746":1}}],["fcamlglobal∈rcl×xl×ylf",{"2":{"746":1}}],["fcaml​local​",{"2":{"746":1}}],["fcaml​local​∈rcl​×xl​×yl​×zl​",{"2":{"746":1}}],["fcaml​global​",{"2":{"746":1}}],["fcaml​global​∈rcl​×xl​×yl​",{"2":{"746":1}}],["fcam",{"2":{"676":6}}],["fc​∈rc×z×8h​×8w​",{"2":{"609":1}}],["fc∈rc×z×h8×w8f",{"2":{"609":1}}],["fc3d​",{"2":{"595":2}}],["fc3d",{"2":{"595":2}}],["fc",{"2":{"250":1,"296":1,"549":1,"595":1}}],["fcgf",{"2":{"243":1}}],["fcos3d",{"2":{"677":1,"744":1,"771":1,"867":1}}],["fcos",{"2":{"138":1}}],["f2d​",{"2":{"942":2,"950":2}}],["f2d",{"2":{"942":2,"950":2,"957":6}}],["f2",{"2":{"208":2}}],["fθ​",{"2":{"213":2,"304":1,"712":3}}],["fθ",{"2":{"193":1,"213":1,"712":3}}],["f5",{"2":{"173":1}}],["f1↑",{"2":{"522":1}}],["f1t",{"2":{"357":1}}],["f1",{"2":{"173":1,"609":7,"660":5,"806":1,"826":2}}],["f1进入命令行",{"2":{"66":1}}],["fxi",{"2":{"153":3}}],["fxi​",{"2":{"153":4}}],["fxif",{"2":{"153":1}}],["flv=",{"2":{"976":1}}],["flv=concat",{"2":{"976":2}}],["fl⋅ω",{"2":{"976":2}}],["flzr​​",{"2":{"699":2}}],["flzr",{"2":{"699":2}}],["fldz​​",{"2":{"699":2}}],["fldz",{"2":{"699":2}}],["flrd​​",{"2":{"699":2}}],["flrd",{"2":{"699":2}}],["fl",{"2":{"585":1,"976":4}}],["fli​",{"2":{"976":1}}],["flifl",{"2":{"976":1}}],["flidllocalf",{"2":{"746":1}}],["flidllocal∈rcl×xl×yl×zlf",{"2":{"746":1}}],["flidlglobalf",{"2":{"746":1}}],["flidlglobal∈rcl×xl×ylf",{"2":{"746":1}}],["flidl​local​",{"2":{"746":1}}],["flidl​local​∈rcl​×xl​×yl​×zl​",{"2":{"746":1}}],["flidl​global​",{"2":{"746":1}}],["flidl​global​∈rcl​×xl​×yl​",{"2":{"746":1}}],["flidar",{"2":{"676":6}}],["fliter",{"2":{"560":1}}],["flint",{"2":{"209":1}}],["flex",{"2":{"481":1}}],["flexible",{"2":{"384":1}}],["flat",{"2":{"790":5}}],["flatten",{"2":{"333":3,"659":1}}],["flashocc由五个基本模块组成",{"2":{"908":1}}],["flashocc是第一个将通道到高度范式应用于占用任务的方法",{"2":{"908":1}}],["flashocc的有效性和泛化性已在多样化体素级占据预测方法中得到验证",{"2":{"831":1}}],["flashocc的输入数据为环绕视角图像",{"2":{"598":1}}],["flashocc和fb",{"2":{"779":1}}],["flashocc通过成功实现高精度的实时环绕视角3d占据预测",{"2":{"598":1}}],["flashocc",{"0":{"477":1,"663":1},"1":{"505":1,"535":1,"566":1,"598":1,"627":1,"655":1,"680":1,"703":1,"726":1,"748":1,"770":1,"791":1,"811":1,"831":1},"2":{"482":1,"517":1,"612":1,"663":1,"823":3,"840":1,"908":1}}],["flase",{"2":{"146":1}}],["flosp",{"0":{"660":1},"2":{"539":1,"544":2,"570":1,"632":2,"660":1,"853":1,"875":1,"928":9,"945":1}}],["float32",{"2":{"504":1}}],["float>",{"2":{"254":8,"654":3}}],["flops",{"2":{"220":1,"517":1}}],["flow表示3d占用流",{"2":{"997":1}}],["flow",{"2":{"96":1,"203":1}}],["fembodied​",{"2":{"682":1}}],["fembodiedf",{"2":{"682":1}}],["feats",{"2":{"623":2}}],["feature只与少部分其他features做相似性计算",{"2":{"386":1}}],["feature超点特征",{"2":{"384":1}}],["feature转化为cls=2",{"2":{"321":1}}],["feature",{"0":{"330":1},"1":{"355":1,"383":1},"2":{"143":1,"158":1,"351":1,"420":1,"496":5,"528":1,"550":1,"554":1,"562":1,"594":1,"616":3,"659":2,"741":2,"914":1}}],["features",{"2":{"80":1,"158":1,"345":1,"351":1,"379":2,"384":5,"394":1,"405":1,"434":1,"440":1,"496":2,"660":1,"721":1,"839":1,"875":1}}],["feng等人",{"2":{"607":1}}],["feng",{"2":{"209":1,"914":1}}],["feeder",{"2":{"204":1}}],["feedforward",{"2":{"174":1}}],["ferris",{"2":{"155":1}}],["feb",{"2":{"135":1}}],["fni​",{"2":{"998":1}}],["fnifn",{"2":{"915":1,"998":1}}],["fnif^i",{"2":{"357":1}}],["fnfnfn",{"2":{"998":1}}],["fnf​",{"2":{"563":1}}],["fno​",{"2":{"778":1}}],["fnofn",{"2":{"778":1}}],["fn分别表示非空类别",{"2":{"749":1}}],["fnc​",{"2":{"739":1,"778":1}}],["fncfn",{"2":{"739":1,"778":1}}],["fn​",{"2":{"716":1}}],["fnt​​​",{"2":{"357":1}}],["fnt",{"2":{"357":1}}],["fn",{"2":{"124":1,"257":1,"716":1,"749":4,"802":5,"807":3,"848":1,"915":1}}],["f",{"0":{"84":1,"829":1,"843":1,"847":1,"936":1},"2":{"143":2,"149":2,"153":6,"171":1,"184":4,"208":24,"213":3,"221":3,"273":5,"304":1,"318":2,"344":3,"357":3,"372":10,"422":1,"429":1,"435":1,"453":1,"464":6,"492":1,"563":1,"595":8,"609":4,"623":4,"632":1,"638":2,"676":12,"682":3,"694":12,"699":10,"712":3,"716":4,"724":1,"877":1,"942":4,"950":8,"957":6}}],["fs",{"2":{"694":1,"707":3}}],["fsf^",{"2":{"694":1}}],["fsrgan",{"2":{"382":1}}],["fsl",{"2":{"60":1}}],["fstab",{"2":{"24":1,"33":1}}],["fstab文件",{"2":{"24":1}}],["ffn",{"2":{"880":1}}],["ffuse",{"2":{"676":6,"699":6}}],["fft",{"2":{"481":1}}],["fff​",{"2":{"609":1}}],["fff",{"2":{"221":1,"345":1,"427":1,"609":1,"716":1,"724":1}}],["ff=true",{"2":{"174":1}}],["ff=unix",{"2":{"48":1}}],["ff",{"2":{"41":2,"48":1,"174":3}}],["false",{"2":{"479":1}}],["fall",{"2":{"366":1}}],["fa875019",{"2":{"467":1}}],["fang",{"2":{"458":1}}],["farthest",{"2":{"396":1,"589":1}}],["faces",{"2":{"379":1}}],["face",{"2":{"379":1}}],["factor",{"2":{"345":1}}],["faf​",{"2":{"328":1}}],["faf​中采样",{"2":{"328":1}}],["fastocc的推理速度达到了12",{"2":{"1001":1}}],["fastocc的miou为40",{"2":{"1001":1}}],["fastocc在较低性能的gpu平台上具有比bevformer更高的fps值",{"2":{"1001":1}}],["fastocc",{"0":{"797":1},"2":{"517":1,"908":1,"1000":1}}],["faster",{"0":{"296":1},"1":{"321":1,"347":1,"375":1,"403":1,"432":1,"463":1,"493":1},"2":{"274":1,"296":1,"741":1}}],["fastsam",{"2":{"38":1}}],["fast",{"0":{"38":1,"229":1},"1":{"250":1,"272":1},"2":{"38":2,"272":1,"274":1,"741":1}}],["failed",{"2":{"17":1,"64":1,"66":1,"67":1}}],["fukui等人",{"2":{"961":1}}],["futr3d",{"2":{"678":1}}],["fuse",{"2":{"676":3,"699":3}}],["fuser",{"2":{"670":1}}],["fusion模块首先对这两个3d点云进行柱坐标划分",{"2":{"676":1}}],["fusion模块以",{"2":{"621":1}}],["fusion模块以伪3d点云和激光雷达点云为输入进行特征级融合",{"2":{"621":1}}],["fusion模块以伪三维点云和激光雷达点云作为输入",{"2":{"578":1}}],["fusion模块",{"2":{"438":1,"898":1}}],["fusion",{"0":{"445":1,"676":1},"2":{"23":1,"545":1,"578":1,"882":2,"967":3,"978":1}}],["fu",{"2":{"619":1}}],["furukawa",{"2":{"958":1}}],["furukawa等人",{"2":{"172":1}}],["furgale等人",{"2":{"605":2}}],["further",{"2":{"518":1}}],["funtions",{"0":{"472":1}}],["function的模型我们就统称为score",{"2":{"235":1}}],["function定义为",{"2":{"235":1}}],["function来避开处理这个规则化常数的问题",{"2":{"235":1}}],["function而非density",{"2":{"235":1}}],["function",{"2":{"31":1,"40":1,"235":1,"256":1,"365":1,"434":1}}],["fully",{"2":{"763":1,"776":1}}],["full",{"2":{"76":1}}],["fo",{"2":{"791":1}}],["fov",{"2":{"750":10,"945":1,"989":2}}],["fox",{"2":{"123":1,"209":2}}],["foo",{"0":{"86":1},"2":{"81":1,"85":1,"525":1}}],["foundation",{"2":{"584":1}}],["found",{"2":{"49":1,"64":1}}],["focal",{"2":{"651":1,"750":2,"766":2,"884":1}}],["focalclick",{"0":{"117":1},"2":{"45":1}}],["focc​=gridsample",{"2":{"638":1}}],["focc=gridsample",{"2":{"638":1}}],["focused",{"2":{"30":1}}],["foldingnet",{"2":{"574":1}}],["folder",{"2":{"38":1}}],["followed",{"2":{"434":1}}],["following",{"2":{"38":2}}],["formable",{"2":{"914":1}}],["former",{"2":{"334":1}}],["forst",{"2":{"904":1}}],["forster等人",{"2":{"285":1,"310":2,"634":1}}],["forward",{"2":{"34":3,"174":3,"333":1,"351":2,"623":1,"839":1}}],["for",{"0":{"79":1,"84":1,"264":1,"266":1,"314":1,"422":1,"445":1,"452":1,"890":1},"1":{"289":1},"2":{"23":2,"30":1,"31":1,"45":1,"62":1,"75":1,"84":1,"102":1,"106":4,"126":1,"146":1,"196":1,"201":3,"237":1,"243":1,"247":1,"264":1,"266":1,"268":1,"314":1,"315":2,"317":1,"323":2,"333":1,"366":1,"384":1,"405":1,"410":1,"422":1,"439":1,"452":1,"469":2,"496":1,"500":1,"515":2,"519":1,"528":1,"537":1,"545":1,"578":1,"589":1,"593":1,"623":1,"651":1,"659":1,"692":2,"715":2,"729":1,"741":1,"839":1,"912":1,"914":1,"929":2,"949":1}}],["fifo",{"2":{"718":1}}],["fischer",{"2":{"648":1}}],["fishros来运行脚本",{"2":{"87":1}}],["fishros",{"2":{"87":3}}],["fiℓ​=∑k",{"2":{"623":1}}],["fiℓ=1∑k",{"2":{"623":1}}],["fikmℓ​",{"2":{"623":1}}],["fikmℓf",{"2":{"623":1}}],["filters",{"2":{"616":1}}],["filter",{"2":{"616":2}}],["files",{"2":{"327":5}}],["fileformat",{"2":{"254":1}}],["fileformat＝dos",{"2":{"41":1}}],["filename",{"2":{"254":3,"504":4,"534":4}}],["file",{"2":{"17":4,"30":1,"34":4,"48":1,"244":1,"327":4,"369":1,"504":2,"687":1}}],["fij​−fˉj",{"2":{"464":1}}],["fij−fˉj",{"2":{"464":1}}],["fi​",{"2":{"464":1}}],["fi3​",{"2":{"464":1}}],["fi3",{"2":{"464":1}}],["fi2​",{"2":{"464":1}}],["fi2",{"2":{"464":1}}],["fi1​",{"2":{"464":1}}],["fi1",{"2":{"464":1}}],["fi",{"2":{"464":1}}],["figure",{"2":{"496":1,"659":1,"729":1}}],["fig",{"2":{"315":1,"518":1,"941":1}}],["fightingcsh的博客",{"2":{"196":1}}],["fioraio",{"2":{"209":1}}],["fit",{"2":{"111":1,"236":1,"904":1}}],["fine",{"2":{"75":1,"181":1}}],["find函数返回目标字符串在源字符串中的第一个匹配位置的索引",{"2":{"52":1}}],["find",{"0":{"509":1},"2":{"52":7,"107":1,"196":4,"509":1,"633":1}}],["first",{"0":{"65":1},"2":{"104":2,"115":2,"161":2,"177":2,"254":2,"384":1,"571":1,"671":1,"776":1,"904":3}}],["fixed",{"2":{"310":1,"616":1}}],["fix",{"2":{"64":1}}],["field",{"2":{"31":1,"616":2}}],["fields",{"2":{"31":1,"619":2}}],["fid",{"2":{"382":1}}],["fid是衡量多元正态分布",{"2":{"20":1}}],["fid=∣∣μr​−μg​∣∣2+tr​",{"2":{"20":1}}],["fid=∣∣μr−μg∣∣2+tr",{"2":{"20":1}}],["fid=||",{"2":{"20":1}}],["frustum",{"2":{"756":1}}],["frd​=mlp",{"2":{"676":1}}],["frd=mlp",{"2":{"676":1}}],["fr​",{"2":{"638":1}}],["fr​∈rcr​×8h​×8w​",{"2":{"609":1}}],["fr∈rcr×h8×w8f",{"2":{"609":1}}],["fr",{"2":{"579":1,"638":1}}],["frefined​=",{"2":{"699":1}}],["frefined=",{"2":{"699":1}}],["fredriksson",{"2":{"525":1}}],["free检测模型如",{"2":{"138":1}}],["free",{"0":{"422":1,"498":1,"513":1,"990":1},"2":{"26":1,"201":2,"422":1,"498":1,"513":1,"707":3,"741":1}}],["fradllocalf",{"2":{"746":1}}],["fradllocal∈rcl×xl×yl×zlf",{"2":{"746":1}}],["fradlglobalf",{"2":{"746":1}}],["fradlglobal∈rcl×xl×ylf",{"2":{"746":1}}],["fradl​local​",{"2":{"746":1}}],["fradl​local​∈rcl​×xl​×yl​×zl​",{"2":{"746":1}}],["fradl​global​",{"2":{"746":1}}],["fradl​global​∈rcl​×xl​×yl​",{"2":{"746":1}}],["framework",{"0":{"445":1},"2":{"515":2,"545":1,"593":1}}],["frame的一部分",{"2":{"254":1}}],["frame",{"2":{"254":1,"336":1}}],["frame=true的sample",{"2":{"254":1}}],["frame=true",{"2":{"254":1,"534":1}}],["fractional",{"2":{"153":1}}],["frac",{"2":{"5":2,"8":3,"31":1,"57":4,"137":1,"140":47,"153":2,"208":13,"213":1,"235":1,"268":1,"273":10,"280":47,"316":2,"464":1,"532":1,"563":2,"595":1,"609":6,"623":1,"647":1,"656":1,"666":2,"681":4,"693":2,"694":2,"712":3,"716":1,"738":1,"739":2,"742":2,"749":3,"752":1,"766":2,"768":3,"778":3,"794":4,"802":3,"807":3,"814":1,"848":3,"884":2,"915":2,"916":11,"957":1,"985":3,"988":1,"998":3}}],["friedman等人",{"2":{"172":1,"967":1}}],["frontier",{"2":{"274":1}}],["front",{"2":{"104":1,"130":1,"835":3,"904":3,"938":2}}],["fromfile",{"2":{"504":2,"534":1}}],["from",{"2":{"17":2,"23":2,"27":1,"43":1,"57":3,"67":1,"84":1,"94":1,"135":2,"181":3,"209":1,"290":1,"327":1,"333":2,"351":1,"373":5,"379":1,"384":2,"410":1,"414":1,"440":1,"496":2,"518":1,"616":1}}],["fréchet",{"0":{"20":1}}],["一组更稀疏的贡献涉及其他传感方式",{"2":{"967":1}}],["一组描述局部结构几何类型的可学习的点被定义为核",{"2":{"574":1}}],["一条鲁棒的地图应对传感器噪声",{"2":{"826":1}}],["一类工作采用显式变换",{"2":{"821":1}}],["一是与各结果整体miou相关的模型权重",{"2":{"697":1}}],["一是将图像特征与物体模型数据库匹配",{"2":{"209":1}}],["一方面",{"2":{"691":1,"950":1,"1000":1}}],["一共c+1类",{"2":{"463":1}}],["一起使用",{"2":{"603":1}}],["一起输入判别器",{"2":{"429":1}}],["一起发布的uhumans数据集",{"2":{"131":1}}],["一批语言",{"2":{"417":1}}],["一批驾驶",{"2":{"417":1}}],["一致性损失和蒸馏损失分别对应于空间一致性损失",{"2":{"985":1}}],["一致性损失",{"2":{"877":1,"985":1}}],["一致性与完整性",{"2":{"846":1}}],["一致性与鲁棒性",{"2":{"786":1,"881":1}}],["一致性是回环检测",{"2":{"826":1}}],["一致性",{"2":{"826":1,"943":1}}],["一致测量集被添加到姿态图中",{"2":{"390":1}}],["一致",{"2":{"390":1,"609":1,"841":1,"950":1}}],["一旦对齐完成",{"2":{"957":1}}],["一旦获得",{"2":{"384":1}}],["一旦任务定义发生变化",{"2":{"252":1}}],["一一对应",{"2":{"378":1}}],["一路向下比较描述符",{"2":{"352":1}}],["一步步添加高斯噪音",{"2":{"279":1}}],["一辆正在停放",{"2":{"254":1}}],["一样",{"2":{"253":1,"302":1,"774":1}}],["一张",{"2":{"234":1}}],["一些实时且易于部署的占用任务尝试已经展开",{"2":{"1004":1}}],["一些文献",{"2":{"996":1}}],["一些占用感知方法还采用了语义分割任务中常用的其他语义损失",{"2":{"985":1}}],["一些里程碑的方法如图11所示",{"2":{"983":1}}],["一些层",{"2":{"796":1}}],["一些基于图像的方法",{"2":{"779":1}}],["一些工作直接使用单一的二维分支来推理三维占用",{"2":{"923":1}}],["一些工作研究了如何自动或半自动生成高质量的密集3d占用注释",{"2":{"735":1}}],["一些工作采用",{"2":{"274":1}}],["一些模型需要构建多个任务分支",{"2":{"601":1}}],["一些方法进一步考虑了时间信息",{"2":{"975":1}}],["一些方法以类似nerf的方式将预测的3d占用渲染为2d地图",{"2":{"932":1}}],["一些方法开始探索采用从粗到细的特征学习范式",{"2":{"922":1}}],["一些方法从特征增强的角度改进了占用预测",{"2":{"819":1}}],["一些方法将观测的编码特征存放在拓扑图的节点内",{"2":{"743":1}}],["一些方法中也提出结合三维点云和二维图像来进行学习",{"2":{"664":1}}],["一些方法提出通过粗到细的上采样策略",{"2":{"612":1}}],["一些方法改为",{"2":{"525":1}}],["一些方法结合了对象和密集地图模型",{"2":{"172":1}}],["一些地点可能没有被标记",{"2":{"480":1}}],["一些在重建的3d场景图中的节点未标记",{"2":{"467":1}}],["一些作者交替更新",{"2":{"417":1}}],["一些研究将两种或多种结构结合",{"2":{"378":1}}],["一些错误",{"0":{"17":1}}],["一次性分配效率较高",{"2":{"146":1}}],["一种可行的方法是将3d占用预测与新兴的3d人工智能生成内容",{"2":{"963":1}}],["一种纯视觉中心方法",{"2":{"959":1}}],["一种方法是使用专门设计的卷积架构来桥接2d到3d的差距",{"2":{"875":1}}],["一种方法将密集网格划分为物体出现的区域",{"2":{"599":1}}],["一种直接的方法是利用从其他任务中学习的bev",{"2":{"839":1}}],["一种直接的方法是将3d空间离散化为规则的体素",{"2":{"612":1}}],["一种有效的学习占用的方法是基于鸟瞰图",{"2":{"839":1}}],["一种简单的方法可以在初始化高斯分布时直接利用这种深度信息",{"2":{"705":1}}],["一种简单的策略是使用跳跃连接将多尺度特征连接起来",{"2":{"603":1}}],["一种用于对",{"2":{"692":1}}],["一种用于预测3d占据的新型传感器融合框架",{"2":{"475":1}}],["一种构建拓扑地图的方式",{"2":{"525":1}}],["一种新的以对象为中心的表示法首次被探索用于基于视觉的3d语义占据预测",{"2":{"444":1}}],["一种新颖的占据学习框架",{"2":{"455":1}}],["一种新颖的多模态占据预测框架",{"2":{"392":1}}],["一种新颖的方法",{"2":{"109":1}}],["一种从噪音中剥离出图像",{"2":{"382":1}}],["一种将gpt概念扩展到点云的方法",{"2":{"290":1}}],["一种是受anchor",{"2":{"138":1}}],["一种是受one",{"2":{"138":1}}],["一种分类方法",{"2":{"138":1}}],["一个部署高效的占用方法需要在实时处理",{"2":{"1004":1}}],["一个实用的占用方法应具有高准确性",{"2":{"1001":1}}],["一个实例可以有多个注释",{"2":{"254":1,"654":1}}],["一个可能的解释是",{"2":{"1000":1}}],["一个可能的原因是占据网络需要同时处理前景",{"2":{"694":1}}],["一个更根本的区别是早期工作",{"2":{"961":1}}],["一个更有前景的主动智能体应该能够随着其位置和视角的变化逐步探索并更新三维场景的全局空间占用",{"2":{"600":1}}],["一个导航图和一个拓扑图",{"2":{"961":1}}],["一个空间表示和一个语义表示",{"2":{"961":1}}],["一个显著的缺点是部分丢失了高度信息",{"2":{"923":1}}],["一个显著的点是",{"2":{"603":1}}],["一个4",{"2":{"793":1}}],["一个具身框架",{"0":{"750":1}}],["一个具有3个节点的团",{"2":{"162":1}}],["一个图像交叉注意力模块",{"2":{"716":1}}],["一个在相机前走动的人类在网格中留下了",{"2":{"709":1}}],["一个使用了sw",{"2":{"659":1}}],["一个就是尺度上的问题",{"2":{"631":1}}],["一个关键环节是判定",{"2":{"525":1}}],["一个点的球面卷积核的输出是由其相邻点的加权激活值均值的非线性激活决定的",{"2":{"511":1}}],["一个针对最小边特征e的每个关联三角形",{"2":{"466":1}}],["一个基于多模态高斯的语义占据预测框架",{"2":{"444":1}}],["一个小公寓",{"2":{"437":1}}],["一个relu非线性激活层",{"2":{"420":1}}],["一个简单的多层感知器",{"2":{"405":1}}],["一个低层规划模块负责具体运动",{"2":{"274":1}}],["一个高层决策模块负责宏观策略",{"2":{"274":1}}],["一个高度并行化的架构",{"2":{"112":1}}],["一个sample是一个带注释的2hz关键帧",{"2":{"254":1}}],["一个对象在某个房间",{"2":{"210":1}}],["一个质心和一个边界框",{"2":{"210":1}}],["一个解决方法是将大图片拆分为若干小分辨率的图片进行训练",{"2":{"205":1}}],["一个有些平行的研究线调查了如何从2d或3d数据中解析建筑物布局",{"2":{"172":1}}],["一个固定过程",{"2":{"111":1,"236":1}}],["一个隔间和一个大规模建筑场景",{"2":{"109":1}}],["一个办公室和一个地铁站",{"2":{"437":1}}],["一个办公室",{"2":{"109":1}}],["一个公寓",{"2":{"109":1}}],["一个被指派调音钢琴的机器人必须将钢琴视为更多的对象",{"2":{"109":1}}],["一个被指派弹钢琴的机器人必须将钢琴视为许多对象",{"2":{"109":1}}],["一个建立的信息理论框架来讨论任务相关性",{"2":{"98":1}}],["一系列新的方法",{"2":{"109":1}}],["一般根据分类得分选取topk个前景目标的信息进行存储",{"2":{"718":1}}],["一般公开训练数据都是高品质的图像",{"2":{"220":1}}],["一般",{"2":{"149":1}}],["一般会让你确认细节",{"2":{"66":1}}],["一般取",{"2":{"8":1}}],["一",{"2":{"41":1,"196":1,"292":1}}],["5数据集",{"2":{"997":1}}],["5c",{"2":{"944":1}}],["5b",{"2":{"944":1}}],["5a",{"2":{"944":1}}],["5×10−5",{"2":{"867":1}}],["5×10−55",{"2":{"867":1}}],["5gb",{"2":{"865":1}}],["5秒的时间范围",{"2":{"836":1}}],["5毫秒",{"2":{"816":1}}],["5毫秒降至3",{"2":{"811":1}}],["5个周期",{"2":{"813":1}}],["5e",{"2":{"744":1}}],["5d视频约束问题",{"2":{"630":1}}],["5d信息生成候选查询",{"2":{"566":1}}],["5d",{"2":{"539":1,"632":1}}],["5m的最大尺度",{"2":{"924":1}}],["5miou",{"2":{"800":1}}],["5m到3m",{"2":{"638":1}}],["5m",{"2":{"480":2,"652":2,"736":4,"739":2,"781":1}}],["5mm",{"2":{"173":1}}],["5的miou",{"2":{"421":1}}],["5点",{"2":{"310":1}}],["5节讨论的提出的位姿图模型",{"2":{"775":1}}],["5节评估了kimera",{"2":{"541":1}}],["5节",{"0":{"419":1},"2":{"131":1,"285":1,"576":1,"634":1,"709":1}}],["58miou的提升",{"2":{"800":1}}],["588",{"2":{"545":1,"965":1}}],["581",{"2":{"277":1,"534":1}}],["589",{"2":{"136":2}}],["58",{"2":{"121":1,"128":2,"190":1,"283":1,"547":2,"574":1,"690":1,"709":1,"808":1,"841":1,"853":2,"867":1,"922":1,"978":1,"982":1,"1000":2}}],["5808",{"2":{"43":3}}],["512×1408",{"2":{"803":1}}],["512×512",{"2":{"321":1}}],["512",{"2":{"739":2}}],["51m",{"2":{"545":1,"965":1}}],["519",{"2":{"277":1,"534":1}}],["511",{"2":{"277":1,"534":1}}],["514",{"2":{"277":1,"534":1}}],["51",{"2":{"121":1,"172":1,"176":1,"421":2,"425":1,"482":1,"511":1,"603":1,"609":1,"612":1,"678":1,"736":1,"739":4,"749":2,"803":1,"841":1,"893":2,"922":1,"942":1,"950":1,"957":1}}],["56miou的提升",{"2":{"800":1}}],["569",{"2":{"277":1,"534":1}}],["56",{"2":{"114":1,"121":1,"172":1,"511":1,"545":2,"547":2,"570":1,"603":3,"612":1,"632":1,"666":1,"684":1,"829":1,"834":1,"841":2,"853":1,"893":1,"903":1,"908":2,"917":1,"922":1,"928":2,"942":2,"947":1,"957":1,"965":2}}],["59miou",{"2":{"800":1}}],["591",{"2":{"545":1,"965":1}}],["590",{"2":{"277":1,"534":1}}],["59",{"2":{"114":1,"121":1,"190":1,"216":1,"277":2,"380":6,"382":1,"421":1,"534":2,"603":3,"612":1,"686":2,"834":1,"841":1,"867":1,"893":2,"975":1,"997":1}}],["5960",{"2":{"51":3}}],["54",{"2":{"114":2,"121":1,"172":1,"277":1,"421":1,"511":1,"522":1,"534":1,"570":1,"595":1,"641":1,"758":4,"768":1,"800":2,"841":1,"875":1,"928":1,"942":1,"947":1,"971":1}}],["52",{"2":{"103":1,"121":1,"172":1,"421":2,"482":1,"511":1,"603":1,"641":1,"660":2,"678":1,"686":1,"700":3,"840":2,"841":1,"870":1,"876":1,"922":1,"928":1,"942":1,"996":2}}],["57miou的提升",{"2":{"876":1}}],["57miou",{"2":{"800":1}}],["57",{"2":{"82":1,"121":1,"145":2,"172":1,"195":1,"216":1,"308":1,"334":1,"421":2,"447":1,"482":1,"511":1,"570":1,"576":1,"603":1,"609":1,"612":1,"808":1,"840":1,"841":1,"867":1,"893":2}}],["534",{"2":{"947":1}}],["537",{"2":{"886":1}}],["530",{"2":{"277":1,"686":1}}],["53",{"2":{"82":1,"121":1,"172":1,"308":1,"334":1,"421":1,"511":1,"603":1,"612":1,"678":1,"690":1,"709":1,"808":1,"840":1,"841":1,"870":1,"876":2,"893":2,"903":1,"908":2,"922":1,"942":3,"950":2,"957":1,"998":1,"1000":2}}],["55794606",{"2":{"369":1}}],["559",{"2":{"277":1,"534":1}}],["55288",{"2":{"136":1}}],["55",{"2":{"51":2,"121":1,"145":1,"190":1,"360":3,"417":1,"421":2,"447":1,"511":1,"603":3,"609":2,"641":1,"768":1,"834":1,"841":1,"853":1,"867":1,"870":1,"893":1,"922":1,"928":1,"942":2,"950":2,"957":1,"978":1,"982":1,"985":3,"1000":1}}],["50表示resnet50",{"2":{"1001":1}}],["50gc",{"2":{"828":1}}],["50作为骨干网络",{"2":{"811":1}}],["50m",{"2":{"652":8,"736":2,"781":2,"944":3}}],["501",{"2":{"277":1,"534":1}}],["503",{"2":{"277":1,"534":1}}],["50022",{"2":{"60":3}}],["50",{"2":{"43":3,"51":2,"121":1,"125":4,"141":3,"172":2,"176":1,"190":1,"253":4,"276":1,"301":1,"308":1,"333":3,"334":1,"380":1,"421":2,"437":9,"471":1,"482":1,"492":1,"511":1,"547":2,"570":1,"609":1,"612":1,"636":1,"653":1,"690":1,"693":1,"700":1,"743":2,"749":8,"758":1,"781":1,"785":1,"787":2,"803":1,"808":1,"821":1,"823":1,"842":1,"893":1,"900":2,"917":1,"924":1}}],["5",{"0":{"36":1,"88":1,"168":1,"240":1,"360":1,"664":1,"675":1,"690":1,"698":1,"721":1,"726":1,"743":1,"745":1,"754":1,"765":1,"767":1,"799":1,"820":1,"831":1,"832":1,"851":1,"852":1,"861":1,"905":1,"917":1,"932":1,"937":1,"940":1,"943":1,"948":1,"955":1,"962":1,"968":1,"974":1,"983":1,"987":1,"990":1,"993":1,"1002":1,"1003":1,"1004":1,"1005":1,"1006":1},"1":{"186":1,"206":1,"228":1,"249":1,"271":1,"295":1,"698":1,"721":1,"743":2,"765":2,"878":1,"941":1,"945":1,"948":1,"949":1,"953":1,"955":2,"960":1,"962":2,"968":2,"974":2,"979":2,"983":1,"987":2,"990":2,"993":1,"996":1,"1003":1,"1004":1,"1005":1,"1006":1},"2":{"15":1,"66":1,"90":1,"93":1,"107":3,"126":1,"136":1,"146":1,"161":1,"171":1,"173":1,"176":1,"196":1,"271":1,"274":2,"277":2,"285":3,"314":1,"334":11,"351":2,"373":2,"390":3,"420":1,"435":2,"437":2,"496":1,"504":1,"517":1,"534":2,"545":4,"556":1,"564":1,"585":2,"627":1,"641":1,"643":1,"649":2,"652":4,"665":1,"667":1,"677":1,"681":1,"686":1,"700":1,"723":1,"736":1,"739":2,"742":1,"744":1,"745":1,"749":3,"752":2,"758":1,"787":2,"790":1,"808":1,"811":2,"812":2,"813":1,"832":1,"835":1,"843":1,"848":1,"867":2,"888":2,"893":2,"900":2,"908":1,"917":1,"928":1,"931":1,"947":1,"965":4,"974":1,"979":1,"989":2,"992":2,"996":1,"997":1,"1003":2}}],["凡是不像imagenet的数据",{"2":{"13":1}}],["6的map和60",{"2":{"893":1}}],["6的博客",{"2":{"99":1}}],["6hz的更快fps实现了显著的0",{"2":{"811":1}}],["6m",{"2":{"652":3,"800":2,"828":3}}],["6毫秒",{"2":{"437":1}}],["6但图一致性低",{"2":{"360":1}}],["654",{"2":{"853":1}}],["655",{"2":{"277":1,"534":1}}],["65",{"2":{"145":1,"190":1,"277":1,"481":1,"563":1,"574":1,"603":1,"643":1,"671":1,"709":1,"758":1,"800":1,"860":1,"876":1,"893":1,"941":1}}],["6节评估了人类和对象定位误差",{"2":{"541":1}}],["6节",{"0":{"449":1},"2":{"131":1,"285":1}}],["60×36×60",{"2":{"853":1}}],["601",{"2":{"545":1,"965":1}}],["60万视频",{"2":{"360":1}}],["605",{"2":{"277":1,"534":1}}],["60gc",{"2":{"173":1}}],["602",{"2":{"136":2}}],["60",{"2":{"128":1,"137":1,"254":2,"360":1,"421":2,"467":1,"574":3,"603":1,"709":1,"716":1,"779":1,"840":1,"841":1,"884":1,"893":1,"949":1,"997":1,"1000":1}}],["600",{"2":{"26":1,"677":1,"700":1,"914":1}}],["679108463",{"2":{"839":1}}],["6795935",{"2":{"256":1}}],["67miou",{"2":{"800":1}}],["671",{"2":{"277":1,"534":1}}],["67",{"2":{"125":3,"172":2,"176":1,"195":1,"467":1,"481":1,"482":1,"522":1,"545":1,"574":1,"603":1,"671":1,"677":1,"686":1,"839":2,"860":1,"893":1,"965":1}}],["638",{"2":{"277":1,"534":1}}],["63",{"2":{"125":3,"172":1,"176":1,"360":3,"481":1,"574":1,"603":1,"758":1,"860":1,"941":2,"949":1}}],["69",{"2":{"114":1,"352":1,"481":1,"522":1,"603":1,"808":1,"853":1,"858":1,"860":1,"870":1,"893":1,"908":1,"957":1,"978":1,"988":1}}],["68",{"2":{"114":1,"172":1,"481":1,"574":1,"603":1,"700":1,"858":1,"860":1,"893":3,"908":1}}],["6693",{"2":{"914":1}}],["6684",{"2":{"914":1}}],["6650",{"2":{"106":1}}],["66",{"2":{"103":1,"190":1,"277":1,"421":1,"481":1,"534":1,"574":1,"709":1,"839":1,"860":1,"893":1}}],["62022011",{"2":{"980":1}}],["621",{"2":{"277":1,"534":1,"687":1}}],["623",{"2":{"277":1,"534":1}}],["62",{"2":{"82":1,"172":1,"481":1,"482":1,"492":1,"570":1,"574":1,"671":1,"808":1,"840":1,"841":1,"941":1}}],["617",{"2":{"277":1,"534":1}}],["61",{"2":{"82":1,"172":1,"206":1,"421":2,"431":1,"482":2,"522":1,"574":1,"609":1,"632":1,"641":1,"690":1,"709":1,"808":1,"841":1,"884":1,"917":1,"928":2,"942":1,"949":2,"950":3,"957":1,"1003":1}}],["64miou和6",{"2":{"800":1}}],["64gb的ram",{"2":{"522":1}}],["64×64×64×6464",{"2":{"303":1,"328":1}}],["64×64",{"2":{"278":2}}],["641",{"2":{"277":1,"534":1}}],["64x64",{"2":{"181":1}}],["640×480",{"2":{"853":1}}],["640",{"2":{"136":1}}],["64无关",{"2":{"76":1}}],["64",{"2":{"66":3,"195":1,"277":1,"278":1,"328":1,"437":1,"481":1,"534":1,"552":1,"562":1,"574":1,"603":2,"652":1,"666":1,"700":2,"828":1,"860":1,"893":3,"899":2,"941":1,"947":1,"949":1,"1000":1}}],["6",{"0":{"99":1,"262":1,"320":1,"388":1,"417":1,"447":1,"775":1,"786":1,"806":1,"826":1,"846":1,"859":1,"919":1,"930":1,"939":1,"947":1,"951":1,"956":1,"1007":1},"1":{"346":1,"374":1,"402":1,"417":1,"431":1,"447":1,"462":1,"492":1,"522":1,"806":1,"826":1,"846":1,"930":1,"939":1,"947":1,"963":1,"969":1,"975":1},"2":{"13":2,"15":1,"40":2,"66":1,"90":1,"99":1,"126":1,"137":1,"143":1,"172":1,"173":1,"195":1,"196":1,"277":3,"285":1,"314":1,"345":1,"360":2,"363":1,"390":1,"412":2,"431":1,"435":1,"447":1,"503":1,"512":1,"517":1,"534":3,"585":1,"603":3,"612":1,"647":3,"652":1,"665":1,"667":1,"671":1,"676":2,"680":1,"681":1,"700":1,"709":1,"739":1,"745":1,"749":2,"765":1,"790":1,"792":1,"800":1,"808":1,"811":3,"814":1,"827":1,"832":1,"839":1,"864":1,"893":4,"900":1,"916":5,"917":2,"943":1,"947":2,"952":5,"959":2,"971":1,"979":1,"989":3,"992":3,"1003":1}}],["4的map和64",{"2":{"893":1}}],["4l=4",{"2":{"867":1}}],["4b",{"2":{"730":1,"928":1}}],["4a",{"2":{"707":1,"928":2}}],["4map",{"2":{"824":1}}],["4m³",{"2":{"781":1}}],["4m2的范围",{"2":{"749":1}}],["4m",{"2":{"652":4,"736":4,"739":1,"742":2,"800":2,"805":1}}],["4米体素的17个类别定义",{"2":{"770":1}}],["4米×0",{"2":{"770":2}}],["4米的空间范围",{"2":{"770":1}}],["4米",{"2":{"380":1}}],["4o",{"2":{"334":2}}],["4原尺寸",{"2":{"305":1}}],["4x4",{"2":{"181":1}}],["4节中呈现的消融研究外",{"2":{"876":1}}],["4节提供了kimera",{"2":{"541":1}}],["4节",{"0":{"390":1},"2":{"131":1,"285":1,"576":1}}],["465",{"2":{"686":1}}],["461",{"2":{"277":1,"534":1}}],["463",{"2":{"277":1,"534":1}}],["46",{"2":{"128":1,"277":2,"467":1,"481":1,"512":1,"534":1,"547":3,"808":1,"821":1,"853":1,"971":1,"1000":1}}],["472",{"2":{"545":1,"965":1}}],["470",{"2":{"277":1,"534":1}}],["47976",{"2":{"136":1}}],["47",{"2":{"128":1,"190":1,"421":1,"481":1,"603":1,"653":1,"686":1,"808":1,"821":1,"822":1,"839":1,"893":2,"971":2,"976":1,"1005":2}}],["48miou",{"2":{"800":1}}],["48gb",{"2":{"744":1}}],["482",{"2":{"686":1}}],["48米之间",{"2":{"686":1}}],["480",{"2":{"136":1,"686":1}}],["48",{"2":{"121":1,"172":1,"195":1,"277":1,"352":1,"421":1,"437":1,"481":1,"534":1,"603":1,"653":1,"659":2,"686":1,"693":1,"782":1,"803":1,"808":1,"821":2,"823":1,"917":1,"976":1,"1005":2}}],["420",{"2":{"277":1,"947":1}}],["427m",{"2":{"824":1}}],["427",{"2":{"277":1,"534":1}}],["42",{"2":{"121":1,"172":1,"195":1,"277":1,"421":1,"534":1,"603":2,"625":1,"641":1,"677":1,"686":1,"690":1,"709":2,"821":1,"829":1,"875":1,"893":1,"971":1,"989":1,"996":1,"1000":1}}],["411",{"2":{"686":1}}],["41毫秒",{"2":{"437":1}}],["414",{"2":{"277":1,"534":1}}],["41",{"2":{"121":1,"172":1,"176":1,"390":1,"545":1,"603":1,"625":1,"641":1,"666":2,"690":1,"800":2,"808":1,"821":1,"875":1,"965":1}}],["4096个点",{"2":{"996":1}}],["4090",{"2":{"813":3}}],["4090笔记本电脑gpu",{"2":{"522":1}}],["40米到40米",{"2":{"770":1}}],["40数据集是形状分类最常用的数据集",{"2":{"688":1}}],["40m",{"2":{"652":8,"736":2,"739":4,"742":4,"944":3}}],["400",{"2":{"495":1}}],["40×60×9",{"2":{"493":1}}],["408",{"2":{"173":1}}],["40",{"2":{"114":1,"121":1,"172":1,"254":2,"277":1,"425":1,"534":1,"603":3,"612":1,"677":1,"688":1,"694":1,"739":1,"752":1,"780":1,"782":1,"853":1,"858":1,"886":2,"900":2,"908":1,"950":1,"982":2}}],["45m",{"2":{"944":3}}],["451",{"2":{"686":1}}],["45",{"2":{"82":1,"190":1,"277":1,"301":1,"360":1,"421":1,"447":1,"471":1,"481":1,"534":1,"603":4,"641":1,"653":1,"686":2,"800":2,"821":1,"834":1,"839":1,"853":1,"875":1}}],["491",{"2":{"686":1}}],["493",{"2":{"277":1,"534":1}}],["49ad23d1ec9fa4bd8d77d02681df5cfa",{"2":{"244":1}}],["49",{"2":{"82":1,"121":1,"125":4,"141":3,"172":2,"210":1,"277":1,"421":2,"425":1,"482":1,"511":1,"534":1,"603":1,"609":1,"612":1,"653":1,"686":1,"690":1,"709":1,"803":1,"821":2,"840":1}}],["43miou提升",{"2":{"876":1}}],["432",{"2":{"686":1}}],["43",{"2":{"82":1,"121":1,"141":1,"253":2,"421":2,"481":1,"482":1,"603":1,"609":1,"612":1,"625":1,"690":1,"709":1,"771":1,"779":2,"808":1,"821":2,"829":1,"840":2,"875":1,"893":1,"971":6}}],["438",{"2":{"67":1}}],["430",{"2":{"66":1}}],["449对密集标注的对齐rgb和深度图像",{"2":{"757":1}}],["447",{"2":{"545":1,"965":1}}],["444",{"2":{"277":1}}],["443",{"2":{"277":1,"534":1}}],["44",{"2":{"43":2,"51":2,"114":1,"172":1,"216":1,"276":4,"360":1,"421":2,"481":1,"482":1,"609":1,"625":1,"736":1,"749":1,"779":1,"782":1,"821":2,"875":1,"893":3,"917":1,"957":1}}],["4gb",{"2":{"26":1}}],["4d占用预测",{"2":{"547":1}}],["4d",{"2":{"23":1,"567":1,"962":1}}],["4",{"0":{"36":1,"77":1,"145":1,"153":1,"218":1,"238":1,"260":1,"283":1,"308":1,"334":2,"435":1,"465":1,"495":1,"525":1,"556":1,"572":1,"588":1,"605":1,"618":1,"619":1,"624":1,"634":1,"636":1,"648":2,"652":1,"662":1,"666":1,"677":1,"686":1,"700":1,"703":1,"709":1,"711":1,"713":1,"723":2,"727":1,"732":2,"734":1,"736":1,"745":1,"748":1,"749":1,"750":1,"754":1,"756":1,"758":1,"760":1,"770":1,"771":1,"772":1,"775":1,"778":1,"779":1,"781":1,"791":1,"792":1,"793":1,"796":1,"800":2,"802":1,"811":1,"812":2,"813":1,"816":1,"822":1,"832":1,"833":1,"834":1,"836":1,"842":2,"845":1,"853":1,"855":1,"857":1,"870":1,"872":1,"887":1,"889":1,"892":1,"903":1,"907":1,"908":1,"917":1,"921":1,"928":1,"935":1,"974":1,"981":1,"985":1,"988":1,"991":1,"994":1,"997":1,"998":1,"999":1,"1000":1,"1001":1,"1006":1},"1":{"260":1,"283":1,"308":1,"334":1,"495":1,"525":1,"556":1,"588":2,"605":1,"619":2,"648":1,"652":1,"662":1,"677":1,"700":1,"709":1,"723":1,"734":1,"736":1,"745":1,"749":1,"756":2,"758":1,"770":1,"771":1,"777":3,"779":1,"781":1,"791":1,"792":1,"793":1,"798":3,"800":1,"811":1,"812":1,"813":1,"818":3,"832":1,"833":1,"838":3,"842":1,"857":2,"870":2,"872":1,"874":3,"887":2,"889":1,"891":3,"903":3,"907":1,"908":1,"917":3,"921":1,"922":1,"928":2,"931":1,"945":1,"953":1,"960":1,"985":1,"988":1,"994":1,"997":2,"998":2,"1000":1,"1001":1},"2":{"13":1,"15":2,"41":1,"47":1,"48":1,"66":2,"90":1,"104":2,"106":3,"107":4,"111":1,"115":2,"124":1,"125":4,"126":2,"130":4,"136":1,"145":1,"146":1,"161":1,"171":2,"172":2,"196":1,"220":1,"236":1,"252":1,"254":3,"257":1,"260":1,"265":2,"274":3,"277":2,"278":1,"285":1,"302":1,"305":2,"324":1,"325":1,"333":3,"334":1,"349":1,"351":5,"369":1,"378":1,"384":2,"390":3,"394":1,"417":1,"421":3,"431":1,"437":1,"449":1,"470":1,"482":1,"495":1,"503":1,"504":1,"517":1,"520":1,"525":1,"534":2,"545":1,"556":2,"562":1,"564":1,"566":1,"571":1,"572":1,"585":1,"605":1,"612":1,"621":2,"652":1,"654":1,"659":6,"660":7,"665":1,"667":2,"677":4,"681":2,"682":1,"686":1,"690":1,"691":1,"693":3,"700":5,"704":1,"707":2,"745":1,"749":2,"752":2,"758":1,"761":1,"764":1,"765":2,"770":1,"771":2,"790":1,"798":1,"802":1,"803":1,"808":1,"811":1,"812":1,"813":3,"822":1,"823":1,"824":1,"834":1,"835":1,"853":10,"870":2,"888":3,"893":2,"900":3,"903":1,"908":1,"914":1,"916":1,"917":1,"928":6,"936":2,"942":4,"947":1,"950":2,"957":3,"965":1,"978":1,"982":3,"985":1,"992":3,"1000":1,"1003":1}}],["对稀疏晶格的占用部分进行卷积",{"2":{"962":1}}],["对噪声",{"2":{"943":1}}],["对性能的影响",{"2":{"928":1}}],["对性能有益",{"2":{"928":1}}],["对无人机等",{"2":{"913":1}}],["对第",{"2":{"884":1}}],["对内在地图质量的度量却进展缓慢",{"2":{"864":1}}],["对话",{"2":{"864":1}}],["对所有属性",{"2":{"842":1}}],["对所有网格的平均特征进行加权求和",{"2":{"511":1}}],["对gaussianformer组件的分析",{"2":{"842":1}}],["对之前处理过的高斯分布进行适度更新",{"2":{"833":1}}],["对具身空间占用预测任务的影响",{"2":{"833":1}}],["对使用预训练模型的方法",{"2":{"826":1}}],["对拓扑图并不直接适用",{"2":{"826":1}}],["对地图本身的质量进行更精细的评估",{"2":{"806":1}}],["对smpl检测倾向于在人类被遮挡时产生不正确的估计",{"2":{"775":1}}],["对斑马",{"2":{"765":1}}],["对输入图像应用数据增强技术",{"2":{"758":1}}],["对输入的text进行tokenize",{"2":{"373":1}}],["对室内和室外场景的3d场景补全进行了文献综述",{"2":{"714":1}}],["对外提供统一的接口",{"2":{"685":1}}],["对同一区域的重新探索应保持全局一致性",{"2":{"682":1}}],["对这两类编码的代表性工作进行归纳",{"2":{"675":1}}],["对这些体素特征进行编码",{"2":{"609":1}}],["对这些语义",{"2":{"209":1}}],["对涵盖所有极端情况提出了挑战",{"2":{"665":1}}],["对融合特征和多视图特征采用残差连接进行形状识别",{"2":{"664":1}}],["对保留点的亚像素投影位置进行双线性插值",{"2":{"609":1}}],["对两个场景的rgb图像进行语义分割",{"2":{"605":1}}],["对两个特征进行线性投射",{"2":{"184":1}}],["对我们来说",{"2":{"603":1}}],["对场景中的每个体素进行标记",{"2":{"599":1}}],["对feature进行采样",{"2":{"594":1}}],["对深度分布特征和深度感知上下文特征进行外积操作",{"2":{"578":1,"621":1}}],["对vio来说难度越大",{"2":{"572":1}}],["对合并点云进行体素化",{"2":{"563":1}}],["对roi分类影响不大",{"2":{"554":1}}],["对体素深度和特征进行逐元素相乘",{"2":{"544":1}}],["对天气和光照变化具有极强的鲁棒性",{"2":{"503":1}}],["对三维世界的理解和建模对于自动驾驶车辆",{"2":{"503":1}}],["对环视摄像头和雷达进行早期特征融合",{"2":{"497":1}}],["对超过图像边界的proposal的边进行clip",{"2":{"493":1}}],["对20000个anchor进行第一次边框修正",{"2":{"493":1}}],["对抗损失",{"2":{"460":1}}],["对抗提示或补丁",{"2":{"447":1}}],["对原始语义属性",{"2":{"681":1}}],["对原始的二维全局视图特征进行增强",{"2":{"664":1}}],["对原",{"2":{"440":1}}],["对办公室场景",{"2":{"437":1}}],["对每一列书的每一页上的每个像素计算方差",{"2":{"411":1}}],["对每个分辨率的监督损失施加衰减权重",{"2":{"766":1}}],["对每个3d位置分配相同的存储和计算资源",{"2":{"693":1}}],["对每个层级的",{"2":{"545":1,"746":1}}],["对每个尺度进行视图变换",{"2":{"545":1,"746":1}}],["对每个像素点求期望",{"2":{"470":1}}],["对每个点的坐标进行了归一化处理",{"2":{"456":1}}],["对每个聚类的anchors中的maps进行平均",{"2":{"328":1}}],["对每个传入的帧进行背景的粗糙重建",{"2":{"206":1}}],["对每个传感器的外参和内参进行校准至关重要",{"2":{"191":1}}],["对小目标性能很不好",{"2":{"386":1}}],["对称对顶角",{"2":{"379":1}}],["对称的对比学习损失",{"2":{"184":1}}],["对网格进行语义注释",{"2":{"362":1}}],["对流形",{"2":{"325":1}}],["对其进行参数化",{"2":{"314":1}}],["对其内部推理进行言语化以供事后验证",{"2":{"82":1}}],["对齐过程可以表示为",{"2":{"957":1}}],["对齐视锥分布为网络提供了关于场景可见和遮挡结构的额外线索",{"2":{"814":1}}],["对齐的bev特征被传递到特征融合模块",{"2":{"726":1}}],["对齐的干净数据集",{"2":{"313":1}}],["对齐完成后",{"2":{"726":1}}],["对齐模块利用自车信息将历史bev特征与当前激光雷达系统对齐",{"2":{"726":1}}],["对齐局部视锥中的类别分布",{"2":{"632":1}}],["对齐",{"2":{"334":1,"634":2}}],["对齐张量",{"2":{"303":1}}],["对3d场景的全面理解在自动驾驶车辆",{"2":{"475":1}}],["对3d场景图的节点和边进行更丰富的关系和可供性标记将是有意义的",{"2":{"467":1}}],["对3d自由空间而不是2d占用网格",{"2":{"301":1}}],["对3d动态场景的高级理解涉及三个关键要素",{"2":{"116":1}}],["对基于体素的地图进行膨胀操作可以直接映射到gp中的拓扑变化",{"2":{"301":1}}],["对基于体素的地图进行膨胀操作有助于暴露环境中的房间",{"2":{"301":1}}],["对框进行分类",{"2":{"296":1}}],["对应采样点间共享投影权值",{"2":{"863":1}}],["对应位置感知调制因子",{"2":{"863":1}}],["对应超过32万张图像和10万次激光扫描",{"2":{"781":1}}],["对应点",{"2":{"660":1}}],["对应物理环境中的一块区域",{"2":{"378":1}}],["对应的偏移量",{"2":{"863":1}}],["对应的矩阵",{"2":{"355":1}}],["对应的特征",{"2":{"296":1}}],["对应4个偏移量",{"2":{"321":1}}],["对应于兴趣区域的语义占用",{"2":{"1004":1}}],["对应于",{"2":{"916":1}}],["对应于静态euroc数据集的测试",{"2":{"662":1}}],["对应于每个房间",{"2":{"480":1}}],["对应于到天花板的距离",{"2":{"480":1}}],["对应于在添加新的环路闭合时执行3d场景图优化",{"2":{"437":1}}],["对应于与关键帧相关的lidar点云",{"2":{"254":1,"534":1}}],["对应于自由空间中的位置",{"2":{"197":1}}],["对该模型做可控生成十分具有挑战性",{"2":{"289":1}}],["对该函数的简要介绍",{"2":{"196":1}}],["对旋转",{"2":{"275":1}}],["对数据加噪声",{"2":{"267":1}}],["对数通常以2为底",{"2":{"137":1}}],["对对应于零交叉的tsdf体素进行标记",{"2":{"253":1}}],["对对象原语进行任务相关的聚类",{"2":{"109":1}}],["对tsdf和esdf进行空间窗口化",{"2":{"253":1}}],["对空间进行逐像素",{"2":{"209":1}}],["对空任务有1的概率",{"2":{"153":1}}],["对高层理解的需求催生了语义",{"2":{"209":1}}],["对一个点云x",{"2":{"339":1}}],["对一个点云进行两种变换",{"2":{"339":1}}],["对一个分布p",{"2":{"235":1}}],["对一个batchsize样本生成随机的时刻t",{"2":{"124":1,"257":1}}],["对一帧图像",{"2":{"207":1}}],["对角线元素的labels",{"2":{"184":1}}],["对比学习的正样本是两个视图中空间位置接近的点对",{"2":{"579":1}}],["对比学习框架可以总结如下",{"2":{"579":1}}],["对比学习",{"0":{"579":1},"1":{"611":1}}],["对比了不同拓扑地图构建方法的具体实现",{"2":{"525":1}}],["对比最左边的原图与我们朴素的做法产生的结果我们可以看到",{"2":{"312":1}}],["对比的目的是使同一行",{"2":{"184":1}}],["对比度",{"2":{"8":1}}],["对",{"2":{"175":1,"360":1,"622":1,"649":1,"694":1,"792":1,"917":1,"928":1}}],["对路标",{"2":{"171":1}}],["对极其拥挤的环境鲁棒",{"2":{"162":1}}],["对另一个随机变量的不确定性减少了多少",{"2":{"137":1}}],["对动态环境和错误的地方识别具有鲁棒性",{"2":{"131":1}}],["对机器人导航有用",{"2":{"125":1}}],["对任意时刻t进行采样计算loss",{"2":{"124":1,"257":1}}],["对人像进行精细分割标注时",{"2":{"117":1}}],["对mask的每个像素进行新的预测",{"2":{"117":1}}],["对抽象的需求主要是由计算和通信限制所驱动的",{"2":{"116":1}}],["对罕见或快速演化场景脆弱",{"2":{"114":1}}],["对象级",{"2":{"940":1}}],["对象搜索",{"2":{"939":1}}],["对象等",{"2":{"905":1}}],["对象的信息",{"2":{"765":1}}],["对象中心点",{"2":{"718":1}}],["对象包含一个迭代器",{"2":{"571":1}}],["对象检测结果对比",{"2":{"931":1}}],["对象检测和",{"2":{"471":1}}],["对象检测或",{"2":{"349":1,"471":1}}],["对象姿态估计",{"0":{"449":1}}],["对象层的运行时间由活动窗口中的网格顶点数决定",{"2":{"437":1}}],["对象原语是指在场景中识别出的基本对象单元",{"2":{"271":1}}],["对象标识",{"2":{"254":1}}],["对象实例",{"2":{"254":1}}],["对象类别的分类",{"2":{"254":1}}],["对象之间的边描述关系",{"2":{"178":1}}],["对象代表环境中不被认为是结构的静态元素",{"2":{"178":1}}],["对象和地点",{"0":{"232":1},"1":{"253":1,"276":1},"2":{"437":1}}],["对象和代理的姿态图",{"2":{"380":1}}],["对象和代理",{"0":{"178":1},"1":{"197":1,"218":1,"240":1,"262":1},"2":{"147":1,"178":1}}],["对象和房间都有边界框属性",{"2":{"905":1}}],["对象和房间",{"2":{"141":1}}],["对象组合",{"2":{"116":1}}],["对象是通过将嵌入向量在预定义的相似性阈值内的片段关联起来构建的",{"2":{"109":1}}],["对象定位",{"2":{"105":1}}],["对象",{"2":{"105":1,"116":1,"131":1,"147":1,"162":1,"172":1,"196":1,"197":1,"209":1,"285":1,"571":1}}],["对全文进行总结与归纳",{"2":{"90":1}}],["对后面的文章产生了深远影响",{"2":{"54":1}}],["对于复杂的3d场景",{"2":{"1004":1}}],["对于薄物体",{"2":{"998":1}}],["对于来自点云分支的第",{"2":{"976":1}}],["对于以前未见过的未知类别",{"2":{"975":1}}],["对于以视觉为中心的任务",{"2":{"778":1}}],["对于当前帧的查询特征",{"2":{"957":1}}],["对于bev特征",{"2":{"950":1}}],["对于tpv特征",{"2":{"950":1}}],["对于tx2的所有基准测试",{"2":{"836":1}}],["对于带时间融合的方法",{"2":{"942":1}}],["对于带有is",{"2":{"254":1}}],["对于自行车和摩托车等小型动态物体",{"2":{"936":1}}],["对于自适应空间聚合",{"2":{"844":1}}],["对于汽车类别",{"2":{"936":1}}],["对于行人和骑自行车者为",{"2":{"931":1}}],["对于行业和学术界来说",{"2":{"302":1}}],["对于部署友好方法",{"2":{"922":1}}],["对于高斯分布",{"2":{"916":1}}],["对于占用解码器",{"2":{"875":1}}],["对于训练",{"2":{"870":1,"982":1}}],["对于训练和推理阶段",{"2":{"761":1}}],["对于多视图图像",{"2":{"866":1}}],["对于多个物体",{"2":{"603":1}}],["对于第",{"2":{"863":1}}],["对于评估指标",{"2":{"848":1}}],["对于长程依赖",{"2":{"844":1}}],["对于所有配置",{"2":{"836":1}}],["对于大多数机器人应用",{"2":{"967":1}}],["对于大尺度模型研究",{"2":{"824":1}}],["对于大型场景如",{"2":{"816":1}}],["对于优化",{"2":{"822":1}}],["对于kitti",{"2":{"822":1}}],["对于kimera",{"2":{"390":1,"836":1}}],["对于已知对象",{"2":{"816":1}}],["对于视锥kkk",{"2":{"814":1}}],["对于视觉特征的注册",{"2":{"352":1}}],["对于不带和带时间融合模块的实验设置",{"2":{"811":1}}],["对于基于nerf",{"2":{"957":1}}],["对于基于图像的占据预测",{"2":{"609":1}}],["对于基线方法fbocc",{"2":{"811":1}}],["对于基线方法uniocc",{"2":{"811":1}}],["对于包含点的体素网格",{"2":{"809":1}}],["对于uhumans2中的",{"2":{"796":1}}],["对于具身空间占用预测",{"2":{"793":1}}],["对于局部空间占用预测",{"2":{"793":1}}],["对于较大物体",{"2":{"778":1}}],["对于深度监督",{"2":{"766":1}}],["对于一份点云数据中的n个点",{"2":{"747":1}}],["对于一个即将被探索的新场景",{"2":{"728":1}}],["对于一个3d高斯分布",{"2":{"716":2}}],["对于一个大小为h×w×3",{"2":{"345":1}}],["对于道路场景的有效性",{"2":{"745":1}}],["对于这一任务",{"2":{"799":1}}],["对于这两个数据集",{"2":{"739":1}}],["对于这些实验",{"2":{"732":1}}],["对于这些参考点中的每一个",{"2":{"704":1}}],["对于这些对象原语",{"2":{"271":1}}],["对于这些原语",{"2":{"153":1}}],["对于32米长的轨迹为4cm",{"2":{"732":1}}],["对于3d空间中的任何查询点",{"2":{"858":1}}],["对于3d空间的点x",{"2":{"355":1}}],["对于3d点云的语义分割",{"2":{"306":1}}],["对于从记忆中取出的高斯分布",{"2":{"728":1}}],["对于那些从未被更新的高斯分布",{"2":{"728":1}}],["对于那些从未被更新过的高斯分布",{"2":{"728":1}}],["对于那些从未被更新过的随机高斯分布",{"2":{"728":1}}],["对于那些之前已被更新",{"2":{"728":1}}],["对于那些在视锥体内且被标记为之前已经更新过",{"2":{"728":1}}],["对于那些被认为已经很好地更新的高斯分布",{"2":{"728":1}}],["对于那些没有受到新测量影响的连通分量",{"2":{"153":1}}],["对于nuscenes",{"2":{"822":1}}],["对于nuscenes提供边界框标注的物体类别",{"2":{"617":1}}],["对于nnn个体素有n2n^2n2个关系",{"2":{"707":1}}],["对于障碍物和碎石",{"2":{"700":1}}],["对于表",{"2":{"700":2}}],["对于被遮挡的区域",{"2":{"691":1}}],["对于ls",{"2":{"680":1}}],["对于lss",{"2":{"680":1}}],["对于激光雷达传感",{"2":{"910":1}}],["对于激光雷达分支",{"2":{"677":1}}],["对于激光雷达编码器",{"2":{"638":1}}],["对于摄像头分支",{"2":{"677":1}}],["对于空间分组池化",{"2":{"676":1}}],["对于静态体素",{"2":{"673":1}}],["对于点云分支",{"2":{"670":1}}],["对于三维边界框中心点的偏移量以及高于地面的高度",{"2":{"666":1}}],["对于三种不同的环路闭合配置",{"2":{"437":1}}],["对于颈部模块",{"2":{"627":1}}],["对于无边界框标注的背景类别",{"2":{"617":1}}],["对于位于环绕摄像头重叠视野区域内的体素",{"2":{"609":1}}],["对于图像分支",{"2":{"670":1}}],["对于图像特征提取",{"2":{"609":1}}],["对于图片x",{"2":{"13":1}}],["对于属于查询视图的每个点",{"2":{"579":1}}],["对于属于nuscenes数据集中关键帧的激光雷达点云中的每个点",{"2":{"534":1}}],["对于形状分类",{"2":{"574":1}}],["对于我们的概率高斯叠加来说",{"2":{"704":1}}],["对于我们的实验评估",{"2":{"572":1}}],["对于我们生成的每个新的每帧3d网格",{"2":{"336":1}}],["对于超分辨率",{"2":{"552":1}}],["对于输入图像分辨率",{"2":{"545":1,"965":1}}],["对于输入text",{"2":{"373":1}}],["对于p1点而言",{"2":{"530":1}}],["对于分类",{"2":{"526":1,"636":1}}],["对于分层的公寓场景",{"2":{"437":1}}],["对于给定点",{"2":{"511":1}}],["对于给定的点云",{"2":{"579":1}}],["对于给定的点",{"2":{"511":1}}],["对于给定图片x",{"2":{"13":1}}],["对于墙壁网格的每个3d顶点",{"2":{"480":1}}],["对于类别标签为背景的roi",{"2":{"463":1}}],["对于涉及获取所有调味品包的任务",{"2":{"462":1}}],["对于surroundocc数据集",{"2":{"736":1}}],["对于sidpac楼层3",{"2":{"437":1}}],["对于sd模型",{"2":{"319":1}}],["对于估计的房间re",{"2":{"437":1}}],["对于地点层",{"2":{"437":1}}],["对于地点节点",{"2":{"380":1}}],["对于真实生活的",{"2":{"796":1}}],["对于真实和模拟数据集",{"2":{"437":1}}],["对于真实数据集",{"2":{"437":1}}],["对于模拟数据集",{"2":{"437":1}}],["对于标准针孔相机",{"2":{"435":1}}],["对于人体姿态和形状估计",{"2":{"419":1}}],["对于需要全局特征聚合的任务",{"2":{"407":1}}],["对于两个指标",{"2":{"402":1}}],["对于osr",{"2":{"402":1}}],["对于办公室",{"2":{"374":1}}],["对于捆绑射线投射中的每个射线束",{"2":{"362":1}}],["对于合适的δ选择",{"2":{"301":1}}],["对于对象层",{"2":{"437":1}}],["对于对象和地点的评估",{"2":{"437":1}}],["对于对象节点",{"2":{"380":1}}],["对于对象",{"2":{"285":1}}],["对于非关键帧",{"2":{"254":1}}],["对于非相机的传感器为空",{"2":{"254":1}}],["对于任意一般情况下的fθ",{"2":{"213":1}}],["对于存储空间的消耗很大",{"2":{"207":1}}],["对于每组",{"2":{"707":2}}],["对于每次预测",{"2":{"705":1}}],["对于每一个点云",{"2":{"524":1}}],["对于每一个roi",{"2":{"207":1}}],["对于每种类型的结构",{"2":{"480":1}}],["对于每个查询",{"2":{"950":1}}],["对于每个采样点",{"2":{"916":1}}],["对于每个帧",{"2":{"886":1}}],["对于每个场景",{"2":{"886":1}}],["对于每个3d高斯分布",{"2":{"738":1}}],["对于每个体素位置查询所有高斯分布是不可行的",{"2":{"738":1}}],["对于每个输入帧",{"2":{"712":1}}],["对于每个高斯分布",{"2":{"705":1}}],["对于每个掩蔽点",{"2":{"640":1}}],["对于每个目标查询",{"2":{"623":1}}],["对于每个点块",{"2":{"456":1}}],["对于每个roi而言",{"2":{"432":1,"741":1}}],["对于每个候选回路闭合",{"2":{"390":1}}],["对于每个代理节点",{"2":{"352":1}}],["对于每个膨胀距离",{"2":{"301":1}}],["对于每个esdf体素",{"2":{"253":1}}],["对于每个原语",{"2":{"153":1}}],["对于网络结构设计有很大限制",{"2":{"203":1}}],["对于代理来说",{"2":{"197":1}}],["对于完整的",{"2":{"157":1,"277":1}}],["对于",{"2":{"157":1,"277":1,"534":1,"670":1,"749":1,"796":1,"816":3,"866":1,"886":1,"978":4}}],["对于机器人来说",{"2":{"125":1}}],["对于二维vector变量",{"2":{"73":1}}],["q^​i​",{"2":{"705":1}}],["q^i",{"2":{"705":1}}],["qmono​=",{"2":{"705":1}}],["qmono=",{"2":{"705":1}}],["qdepth=mdepth",{"2":{"705":1}}],["qdepth​=mdepth",{"2":{"705":1}}],["qdepth​",{"2":{"705":2}}],["qdepthq",{"2":{"705":2}}],["q∈rmq",{"2":{"705":1}}],["q=",{"2":{"563":2,"716":2}}],["q2r",{"2":{"532":4,"656":4,"693":4}}],["qa对",{"2":{"360":1}}],["qa",{"2":{"360":2}}],["qwen",{"2":{"334":6}}],["qσ​",{"2":{"235":2}}],["qσ",{"2":{"235":2}}],["qqq",{"2":{"705":1,"716":2,"950":1,"957":1}}],["qq",{"2":{"185":1,"220":1,"369":1}}],["q|",{"2":{"132":3}}],["qiℓ+1​=qiℓ​+fiℓ​",{"2":{"623":1}}],["qiℓ+1=qiℓ+fiℓq",{"2":{"623":1}}],["qiu",{"2":{"619":1}}],["qiu等人",{"2":{"419":1,"967":2}}],["qi​∈rm∣i=1",{"2":{"716":1}}],["qi​∈rm",{"2":{"563":1}}],["qi∈rm∣i=1",{"2":{"716":1}}],["qi∈rm",{"2":{"563":1}}],["qi",{"2":{"450":1,"588":2}}],["qi等人",{"2":{"420":1}}],["qin",{"2":{"209":2}}],["qin等人",{"2":{"121":1,"190":1,"390":1,"634":1,"664":1}}],["qian",{"2":{"209":1}}],["qiang",{"2":{"126":1}}],["qianz423的博客",{"2":{"96":1}}],["q容器元素为3",{"2":{"93":1}}],["quaternion",{"2":{"654":8}}],["quadricslam",{"2":{"967":1}}],["quadratic",{"2":{"659":1}}],["quad",{"2":{"524":1,"532":2,"563":1,"656":2,"693":2,"716":1,"780":2,"802":1,"848":1}}],["quantization",{"0":{"385":1},"2":{"345":1}}],["que",{"2":{"854":1}}],["queue的大小是",{"2":{"718":1}}],["queue",{"0":{"718":1,"835":1,"854":1,"946":1},"1":{"854":1},"2":{"835":4,"854":1,"946":1}}],["queries语义查询是随机初始化的",{"2":{"441":1}}],["queries",{"2":{"333":1,"384":1,"550":3}}],["queries或者output",{"2":{"333":1}}],["query=query",{"2":{"623":1}}],["query中",{"2":{"594":1}}],["query相关的bounding",{"2":{"594":1}}],["query都有唯一匹配的目标",{"2":{"358":1}}],["query",{"0":{"405":1,"441":1,"471":1,"489":1,"644":1},"1":{"434":1},"2":{"174":2,"333":4,"384":2,"434":1,"489":3,"623":16,"644":3,"695":1,"762":1}}],["queryable",{"2":{"80":1}}],["queenstown",{"2":{"157":2}}],["question",{"2":{"139":1}}],["quit",{"2":{"99":1}}],["quot",{"2":{"48":2,"52":2,"133":2,"153":2,"173":2,"313":2,"595":2,"623":2}}],["qtformer",{"2":{"334":1}}],["qt",{"2":{"64":5,"123":1,"334":1}}],["qpa",{"0":{"53":1},"1":{"64":1,"74":1},"2":{"64":2,"74":2}}],["q",{"2":{"13":1,"93":1,"140":34,"235":3,"280":34,"304":1,"563":2,"595":8,"623":3,"705":6,"716":11,"950":3,"957":14}}],["vσ",{"2":{"957":2}}],["vσ​",{"2":{"957":3}}],["vσv",{"2":{"957":1}}],["v90",{"2":{"916":2}}],["v=f",{"2":{"910":1}}],["v=fconv",{"2":{"910":2}}],["v=1",{"2":{"738":1}}],["v=1xyz​",{"2":{"738":1}}],["v=1xyz",{"2":{"738":1}}],["vyi−vyˉ",{"2":{"809":1}}],["vyiv",{"2":{"809":1}}],["vyi​​−vy​ˉ​",{"2":{"809":1}}],["vyi​​",{"2":{"809":3}}],["vyi",{"2":{"809":2}}],["vxi−vxˉ",{"2":{"809":1}}],["vxiv",{"2":{"809":1}}],["vxi​​−vx​ˉ​",{"2":{"809":1}}],["vxi​​",{"2":{"809":3}}],["vxi",{"2":{"809":2}}],["vt=φo",{"2":{"780":1}}],["vt​=φo​",{"2":{"780":1}}],["vt​",{"2":{"780":1}}],["vtv",{"2":{"780":1}}],["vgl​",{"2":{"738":1}}],["vgl",{"2":{"738":1}}],["vgk​",{"2":{"738":1}}],["vgk",{"2":{"738":1}}],["vg1​",{"2":{"738":2}}],["vg1",{"2":{"738":2}}],["vgm",{"2":{"525":1}}],["v↔ν=",{"2":{"730":2}}],["vz×r×di​​",{"2":{"676":1}}],["vz×r×di",{"2":{"676":1}}],["vz×r×ci=maxpoold",{"2":{"676":1}}],["vz×r×ci​​=maxpoold",{"2":{"676":1}}],["vz×r×ci​​",{"2":{"676":1}}],["vz×r×ci",{"2":{"676":1}}],["vr×d×zi​​",{"2":{"676":1}}],["vr×d×zi",{"2":{"676":1}}],["vr×d×ci=maxpoolz",{"2":{"676":1}}],["vr×d×ci​​=maxpoolz",{"2":{"676":1}}],["vr×d×ci​​",{"2":{"676":1}}],["vr×d×ci",{"2":{"676":1}}],["vd×z×ri​​",{"2":{"676":1}}],["vd×z×ri",{"2":{"676":1}}],["vd×z×ci=maxpoolr",{"2":{"676":1}}],["vd×z×ci​​=maxpoolr",{"2":{"676":1}}],["vd×z×ci​​",{"2":{"676":1}}],["vd×z×ci",{"2":{"676":1}}],["vdepth​",{"2":{"621":1,"649":3}}],["vdepth​∈rn×d×h×w",{"2":{"621":1}}],["vdepthv",{"2":{"621":1,"649":2}}],["vdepth",{"2":{"621":2,"649":1}}],["vdepth∈rn×d×h×wv",{"2":{"621":1}}],["vfe",{"2":{"670":1}}],["vcam",{"2":{"676":2}}],["vcamcylin​=maxpool",{"2":{"676":1}}],["vcamcylin=maxpool",{"2":{"676":1}}],["vcylin​",{"2":{"676":1}}],["vcylin​∈rr×d×z×c",{"2":{"676":1}}],["vcylinv",{"2":{"676":1}}],["vcylin∈rr×d×z×cv",{"2":{"676":1}}],["vcoverage​=vscene​×ntotal​nin​​",{"2":{"916":1}}],["vcoverage=vscene×ninntotal",{"2":{"916":1}}],["vcoverage",{"2":{"916":1}}],["vcoordv",{"2":{"649":2}}],["vcoord​",{"2":{"649":3}}],["vcoord",{"2":{"649":1}}],["vcontextv",{"2":{"649":1}}],["vcontext=v+cnn1",{"2":{"649":1}}],["vcontext​=v+cnn1​",{"2":{"649":1}}],["vcontext​",{"2":{"621":1,"649":1}}],["vcontext​∈rn×c×h×w",{"2":{"621":1,"649":1}}],["vcontext",{"2":{"621":1}}],["vcontext∈rn×c×h×wv",{"2":{"621":1,"649":1}}],["vcs",{"2":{"27":1}}],["vcstool",{"2":{"27":1}}],["vnv​",{"2":{"563":1}}],["vng​",{"2":{"563":1}}],["vnc",{"2":{"64":1}}],["v∈rn×c×h×w",{"2":{"621":1}}],["v∈rn×c×h×wv",{"2":{"621":1}}],["v∈",{"2":{"563":2}}],["v|",{"2":{"563":2}}],["v^",{"2":{"372":1,"400":1,"676":1,"985":2}}],["vqgan或者dall",{"2":{"371":1}}],["vqgan",{"0":{"317":1,"399":1},"1":{"343":1,"371":1},"2":{"399":1}}],["vqvae原理解读",{"2":{"292":1}}],["vq",{"0":{"292":1}}],["vpv​",{"2":{"563":1}}],["vp",{"0":{"273":1},"2":{"273":1}}],["vso",{"2":{"967":1}}],["vs​",{"2":{"957":3}}],["vsv",{"2":{"957":2}}],["vs",{"2":{"435":3,"917":1,"957":1}}],["vsurfv",{"2":{"372":1}}],["vsurf​中每个顶点",{"2":{"372":1}}],["vsurf​",{"2":{"372":3}}],["vsurf",{"2":{"372":1}}],["vslam",{"2":{"189":1}}],["vscode",{"2":{"57":1}}],["vₜ",{"2":{"171":2}}],["vampire预测每个位置的占用为体积密度",{"2":{"941":1}}],["vampire",{"2":{"941":1,"988":1,"1000":1}}],["vasudevan",{"2":{"648":1}}],["vasudevan等人",{"2":{"116":1,"961":1}}],["vass",{"2":{"525":1}}],["van",{"2":{"525":1}}],["vanilla",{"2":{"518":1}}],["vavim",{"2":{"334":1}}],["varepsilonxt+δt​=xt​+f",{"2":{"273":1}}],["varepsilonxt+1​=1−βt+1​​xt​+βt+1​​ε",{"2":{"273":1}}],["varepsilonxt+1​=xt​+σt+12​−σt2​​ε",{"2":{"251":1}}],["varepsilonxt​=αˉt​​x0​+1−αˉt​​ε",{"2":{"273":2}}],["varepsilonxt​=x0​+σt​ε",{"2":{"251":2}}],["varepsilon",{"2":{"208":4,"221":1,"273":8}}],["variable",{"2":{"289":1}}],["variables",{"2":{"137":1}}],["variance",{"2":{"251":1,"273":1}}],["variation",{"0":{"199":1},"2":{"199":1}}],["varun",{"2":{"126":1}}],["vae",{"0":{"292":1},"2":{"129":1,"203":1,"292":1}}],["vad",{"2":{"114":1}}],["va",{"2":{"114":1}}],["validation",{"2":{"700":1}}],["valid",{"2":{"647":2}}],["valentin",{"2":{"556":1}}],["value=mlvl",{"2":{"623":1}}],["values",{"2":{"384":1}}],["value",{"2":{"43":2,"57":1,"67":4,"109":1,"177":1,"196":4,"550":1,"571":1,"765":1}}],["val",{"2":{"32":1,"38":1,"54":1}}],["vvv和",{"2":{"916":1}}],["vvv",{"2":{"429":3,"563":1,"621":2,"649":3,"705":1,"780":1,"916":1,"985":1}}],["vv",{"2":{"73":2}}],["vlfm",{"2":{"765":1}}],["vlidar",{"2":{"676":4}}],["vlcartesianv",{"2":{"699":1}}],["vlcartesian​​",{"2":{"699":2}}],["vlcartesian",{"2":{"699":1}}],["vlc",{"2":{"437":1}}],["vl",{"2":{"334":4}}],["vlmaps",{"2":{"765":1}}],["vlmnav",{"2":{"698":1}}],["vlm达bleu",{"2":{"447":1}}],["vlm通过token池化削减约90",{"2":{"447":1}}],["vlm通过软注意力池化报告10×加速",{"2":{"417":1}}],["vlm常见幻觉",{"2":{"128":1}}],["vlms",{"2":{"109":1}}],["vlm4ad",{"2":{"92":1}}],["vlm4ad及最新vla4ad",{"2":{"92":1}}],["vlm虽提升可解释性",{"2":{"82":1}}],["vlm增强栈仍是被动的",{"2":{"82":1}}],["vlm",{"2":{"82":2,"260":2,"274":1,"334":3,"360":1,"417":1,"447":1,"478":1,"507":1,"698":1}}],["vla需8万人工标注片段",{"2":{"478":1}}],["vla的rl前景可期",{"2":{"417":1}}],["vla模型自然将原始感知翻译为规范意图",{"2":{"507":1}}],["vla模型输出模态反映其抽象层次与操作目标",{"2":{"216":1}}],["vla模型在跨域与基准上展现强泛化能力",{"2":{"145":1}}],["vla模型在单一策略内融合相机流",{"2":{"82":1}}],["vla策略受真实驾驶三大需求驱动",{"2":{"145":1}}],["vla通过显式动作头解决上述缺口",{"2":{"145":1}}],["vla4ad模型已从将语言用作被动解释工具演进为将其集成为感知与控制主动组件",{"2":{"334":1}}],["vla4ad研究呈现明显波浪式推进",{"2":{"238":1}}],["vla4ad范式进展",{"0":{"238":1},"1":{"260":1,"283":1,"308":1,"334":1}}],["vla4ad基本架构在统一流水线中集成视觉感知",{"2":{"195":1}}],["vla4ad依赖丰富多模态传感器流和语言输入以捕捉外部环境与驾驶员高层意图",{"2":{"176":1}}],["vla4ad架构范式",{"0":{"160":1},"1":{"176":1,"195":1,"216":1}}],["vla4ad",{"2":{"72":1,"92":1,"334":1,"360":1,"538":1}}],["vla",{"0":{"260":1},"2":{"72":1,"82":1,"145":1,"195":2,"334":2,"360":3}}],["vln综述",{"0":{"62":1},"1":{"72":1,"82":1,"92":1,"103":1,"114":1,"128":1,"145":1,"160":1,"176":1,"195":1,"216":1,"238":1,"260":1,"283":1,"308":1,"334":1,"360":1,"388":1,"417":1,"447":1,"478":1,"507":1,"538":1}}],["vln",{"0":{"61":1},"1":{"70":1,"79":1,"89":1},"2":{"139":3}}],["v后跟地址映射",{"2":{"60":1}}],["vue",{"2":{"57":1}}],["vegetation",{"2":{"790":2}}],["veh",{"2":{"782":1}}],["vehicle",{"2":{"254":1,"702":11,"790":12}}],["very",{"2":{"366":1}}],["vertical",{"2":{"906":1}}],["vert",{"2":{"32":1}}],["vedaldi",{"2":{"252":1,"435":1,"495":3,"743":1}}],["ve",{"0":{"251":1},"2":{"273":1}}],["velodyne",{"2":{"173":1,"749":1}}],["venice",{"2":{"126":1}}],["vec",{"2":{"52":5}}],["vector没有",{"2":{"938":1}}],["vector有",{"2":{"938":2}}],["vectorize",{"2":{"504":1}}],["vectors",{"2":{"434":1}}],["vector其他函数",{"0":{"161":1}}],["vector的用法基本一致",{"2":{"938":1}}],["vector的容量会翻倍增加",{"2":{"146":1}}],["vector的特性",{"2":{"83":1}}],["vector关于元素数量函数",{"0":{"146":1}}],["vector遍历函数",{"0":{"130":1}}],["vector删除函数",{"0":{"115":1}}],["vector增加函数",{"0":{"104":1}}],["vector>",{"2":{"93":1,"104":1,"115":1,"130":1,"146":1,"161":1}}],["vector构造函数",{"0":{"93":1}}],["vector容器中没有push",{"2":{"104":1}}],["vector容器支持对序列中元素快速访问元素通过下标的方式",{"2":{"83":1}}],["vector容器是按照严格的线性序列排序",{"2":{"83":1}}],["vector容器常被成为向量容器",{"2":{"83":1}}],["vector是一个动态大小数组的顺序容器",{"2":{"83":1}}],["vector小指南",{"2":{"73":1}}],["vector",{"0":{"73":1},"1":{"83":1,"93":1,"104":1,"115":1,"130":1,"146":1,"161":1},"2":{"52":2,"73":1,"93":9,"104":2,"115":2,"130":3,"146":1,"161":3,"345":1,"685":1}}],["vetcor",{"2":{"83":1,"93":1}}],["vet",{"2":{"41":1}}],["v0",{"2":{"40":1}}],["v",{"0":{"408":1,"862":1,"898":1,"977":1},"2":{"33":1,"60":1,"131":1,"147":1,"318":3,"344":12,"372":17,"429":3,"437":1,"503":1,"552":1,"563":4,"572":1,"595":2,"621":1,"649":4,"676":10,"699":1,"705":3,"718":1,"738":14,"780":2,"809":8,"823":1,"882":1,"910":6,"916":9,"936":1,"942":12,"950":11,"957":6,"962":1,"985":15}}],["v2g",{"2":{"899":1}}],["v2v",{"2":{"334":1}}],["v2",{"0":{"804":1},"2":{"32":10,"38":10,"195":1,"334":1,"631":1,"662":1,"686":6}}],["vovnet",{"2":{"617":1}}],["vol​",{"2":{"950":1}}],["volumedeform",{"2":{"967":1}}],["volume",{"0":{"330":1,"372":1,"411":1},"1":{"355":1,"383":1},"2":{"440":2}}],["vol",{"2":{"318":2,"344":1,"372":1,"429":1,"877":1,"950":6,"957":2}}],["voronoi",{"2":{"228":1,"276":1}}],["vora",{"2":{"126":1,"619":1}}],["void",{"2":{"104":2,"115":1,"146":1,"161":3,"702":9,"790":12}}],["voxgraph",{"2":{"967":1}}],["voxposer",{"2":{"765":1}}],["voxformer的整体架构如图11所示",{"2":{"875":1}}],["voxformer从rgb图像中提取2d特征",{"2":{"875":1}}],["voxformer",{"2":{"566":1,"950":1}}],["voxelnet",{"2":{"746":1,"789":1,"867":1,"910":1}}],["voxel",{"2":{"31":1,"423":2,"424":1}}],["voxblox",{"0":{"31":1},"2":{"31":1,"125":1}}],["vocabulary",{"0":{"743":1,"765":1},"2":{"23":1,"80":1,"152":1,"406":2,"721":2}}],["vild",{"2":{"765":1}}],["village",{"2":{"157":2}}],["vicon房间的地面真实点云也可用",{"2":{"572":1}}],["vicon房间",{"2":{"572":1}}],["vicuna",{"2":{"334":6,"417":1}}],["viii",{"0":{"586":1},"2":{"971":1}}],["vii",{"0":{"467":1,"553":1},"2":{"882":1,"971":2}}],["view的视图",{"2":{"394":1}}],["view",{"2":{"392":1,"414":1,"671":1,"756":1}}],["view可以让训练样本更多样",{"2":{"366":1}}],["vi表示新的变形位置",{"2":{"390":1}}],["vinit−2d",{"2":{"910":4}}],["vinit−2d​∈rx×y×d",{"2":{"910":1}}],["vinit−2d∈rx×y×dv",{"2":{"910":1}}],["vinit−3d​∈rx×y×z×d",{"2":{"910":1}}],["vinit−3d∈rx×y×z×dv",{"2":{"910":1}}],["vinsmono",{"2":{"634":1,"686":1}}],["vins",{"2":{"390":1,"686":1}}],["vineet",{"2":{"209":1}}],["vi​",{"2":{"372":8,"595":1,"985":1}}],["vi",{"0":{"437":1},"2":{"372":17,"390":4,"400":1,"545":1,"552":1,"595":1,"823":1,"882":2,"965":2,"985":1}}],["viδvi",{"2":{"372":1}}],["vitamin",{"2":{"967":1}}],["vit存在的过度平滑问题",{"2":{"528":1}}],["vit",{"2":{"274":1,"334":5,"373":3,"627":1,"631":1}}],["vio处理时间的影响",{"2":{"836":1}}],["vio运行时间的影响",{"2":{"836":1}}],["vio能够在默认设置下实时运行euroc",{"2":{"836":1}}],["vio和地面真实深度的kimera",{"2":{"732":1}}],["vio和kimera",{"2":{"541":1,"634":1,"836":1}}],["vio也导致了微不足道的性能损失",{"2":{"732":1}}],["vio与svo",{"2":{"634":1}}],["vio与最先进的开源vio管道的绝对平移误差",{"2":{"634":1}}],["vio中的特征跟踪",{"2":{"605":1}}],["vio提供的重力方向知识",{"2":{"480":1}}],["vio+sg",{"2":{"437":3}}],["vio+v",{"2":{"437":3}}],["vio估计与realsense",{"2":{"437":1}}],["vio输出的世界变换将网格位置转换为全局框架",{"2":{"419":1}}],["vio产生的里程计边和回路闭合",{"2":{"390":1}}],["vio后端",{"2":{"310":1}}],["vio包括",{"2":{"310":1}}],["vio实现了forster等人",{"2":{"310":1}}],["vio的准确性在快速和更快的配置下会降低",{"2":{"836":1}}],["vio的漂移相关的ate",{"2":{"732":1}}],["vio的姿态图构建的",{"2":{"390":1}}],["vio的姿态估计和kimera",{"2":{"285":1}}],["vio的姿态估计",{"2":{"131":1,"285":1,"732":1}}],["vio的后端",{"2":{"285":1}}],["vio前端",{"2":{"285":1,"310":1}}],["vio",{"0":{"310":1},"2":{"131":2,"285":2,"437":2,"510":1,"572":1,"634":1,"686":1}}],["visualization",{"0":{"784":1}}],["visual",{"2":{"135":1,"139":1,"189":1,"274":2}}],["vistas",{"2":{"126":1}}],["visibility",{"2":{"254":3,"476":1,"654":1}}],["visible",{"2":{"43":1,"51":1,"800":1}}],["vision",{"0":{"79":1},"2":{"23":1,"62":1,"107":1,"139":2,"184":1,"537":1,"584":1,"631":2,"659":1,"1000":1}}],["via",{"0":{"75":1,"148":1},"1":{"164":1,"180":1,"198":1,"220":1},"2":{"148":2,"158":1,"163":1,"382":1,"384":1,"763":1}}],["virtualenv",{"2":{"27":1}}],["vim",{"2":{"24":1,"66":1,"69":1}}],["v3",{"0":{"824":1},"1":{"844":1,"863":1,"880":1,"896":1,"912":1},"2":{"13":1,"20":1}}],["v1和v2数据集中提供的地面真实点云来评估kimera产生的3d网格的质量",{"2":{"686":1}}],["v100",{"2":{"519":1,"982":2}}],["v1",{"2":{"11":1,"327":6,"373":2,"390":1,"476":3,"534":1,"686":8,"754":2,"804":1}}],["gmo",{"2":{"975":1}}],["gc",{"2":{"863":1}}],["gcn",{"2":{"372":1}}],["gδg",{"2":{"833":1}}],["g高出2",{"2":{"824":1}}],["gkt",{"2":{"1005":1}}],["gk",{"2":{"738":1,"863":7}}],["gkg",{"2":{"390":1}}],["g1",{"2":{"738":2}}],["g^=",{"2":{"716":4}}],["g^2",{"2":{"208":7}}],["ggg",{"2":{"716":1,"863":1}}],["ggg解释为高斯混合模型",{"2":{"681":1}}],["ggg的中心时分配较高的占用概率",{"2":{"681":1}}],["ggg诱导的点",{"2":{"681":1}}],["ggg进一步计算为位置",{"2":{"656":1}}],["gb",{"2":{"545":1,"965":1}}],["gsfusion",{"2":{"976":1}}],["gso",{"2":{"975":1}}],["gs文献中普遍存在的分裂和剪枝策略",{"2":{"934":1}}],["gs则是渲染2d",{"2":{"641":1}}],["gs则是离线优化的",{"2":{"641":1}}],["gs存在显著差异",{"2":{"641":1}}],["gs的最新进展包括对动态场景的适应",{"2":{"641":1}}],["gs通过基于溅射的光栅化实现快速渲染",{"2":{"641":1}}],["gs能够用更少的参数建模复杂形状",{"2":{"641":1}}],["gs",{"2":{"641":3,"860":1}}],["gspr",{"2":{"474":1}}],["gss",{"2":{"420":1}}],["gsa",{"2":{"420":1}}],["g是简化网格的边集合",{"2":{"390":1}}],["gj||",{"2":{"390":1}}],["gj",{"2":{"390":3}}],["g~​il​",{"2":{"390":1}}],["g~il",{"2":{"390":1}}],["gálvez",{"2":{"390":1}}],["gnew​=",{"2":{"705":1,"716":1}}],["gnew=",{"2":{"705":1,"716":1}}],["gng​",{"2":{"532":1,"563":1}}],["gnc",{"2":{"380":1}}],["gnss",{"2":{"173":1}}],["g=1",{"2":{"738":1,"863":1}}],["g=1p​",{"2":{"738":1}}],["g=1p",{"2":{"738":1}}],["g=",{"2":{"372":2,"532":2,"563":2,"656":1,"681":1,"693":2,"705":2,"716":4}}],["gpu类型",{"2":{"840":1}}],["gpu上",{"2":{"816":1}}],["gpu上进行训练",{"2":{"758":1}}],["gpu训练20个周期",{"2":{"813":1}}],["gpu训练我们的embodiedocc",{"2":{"813":1}}],["gpu训练我们的局部空间占用预测模块10个周期",{"2":{"813":1}}],["gpu",{"2":{"670":2,"677":1,"700":1,"744":2,"761":3,"764":1,"783":1,"865":1,"867":2,"882":1,"955":1,"965":1,"982":4}}],["gpus",{"2":{"519":1,"593":1}}],["gpu和intel",{"2":{"431":1}}],["gpt",{"2":{"334":3,"488":1,"765":2}}],["gps模块提供全局定位",{"2":{"176":1}}],["gps",{"2":{"126":1,"173":2,"435":2,"652":1}}],["gvd是与至少2个障碍物",{"2":{"276":1}}],["gvd",{"2":{"276":2}}],["g2",{"2":{"208":2}}],["g2o",{"2":{"67":4}}],["gwpscut的博客",{"2":{"164":1}}],["gi∣x",{"2":{"681":2}}],["gig",{"2":{"656":1,"681":1}}],["giou",{"2":{"651":1}}],["gi∈rd∣i=1",{"2":{"693":1,"716":1}}],["gi∈rd",{"2":{"563":1}}],["gi​∣x",{"2":{"681":2}}],["gi​∈rd∣i=1",{"2":{"693":1,"716":1}}],["gi​∈rd",{"2":{"563":1}}],["gi​",{"2":{"532":1,"656":2,"681":3,"728":1}}],["gi",{"2":{"390":2,"532":2,"656":2,"681":3,"728":1,"738":1}}],["gij的旋转权重ωr被设置为零",{"2":{"390":1}}],["gij∈¯g",{"2":{"390":1}}],["gij∈g",{"2":{"390":1}}],["gij||2",{"2":{"390":1}}],["gij",{"2":{"390":3}}],["given",{"2":{"351":1,"452":1,"741":1}}],["giancarlo",{"2":{"126":1}}],["git",{"2":{"27":3,"40":1,"58":2,"69":1,"120":4}}],["github仓库已公开",{"2":{"72":1}}],["github",{"2":{"12":1,"23":2,"27":1,"30":6,"40":1,"58":1,"79":1,"98":1,"107":1,"109":1,"120":3,"131":1,"141":1,"174":1,"175":1,"185":1,"247":1,"275":1,"290":1,"367":1,"369":1,"382":1,"387":1,"392":1,"409":1,"410":2,"414":1,"425":1,"428":1,"439":1,"445":1,"453":1,"469":1,"475":1,"486":1,"490":1,"500":1,"514":1,"528":1,"536":1,"539":1,"545":1,"568":1,"575":1,"577":1,"584":1,"589":1,"605":1,"610":1,"635":1,"637":1,"663":1,"671":1,"687":1,"688":1,"710":1,"733":1,"776":1,"890":1,"906":1,"920":1}}],["guerra和varun",{"2":{"973":1}}],["guerra等人",{"2":{"605":1}}],["gu",{"2":{"525":2,"556":1,"765":1,"826":1}}],["guaranteeing",{"2":{"379":1}}],["guan",{"2":{"123":1}}],["gupta",{"2":{"252":1,"495":2,"743":1}}],["guided",{"0":{"244":1},"2":{"96":1,"268":1,"287":1,"469":1,"550":1}}],["guidanceblended",{"2":{"201":1}}],["guidance",{"0":{"422":1,"513":1},"2":{"30":1,"106":4,"201":1,"244":1,"365":1,"399":1,"422":1,"513":2}}],["gui",{"2":{"64":1}}],["gomez等人",{"2":{"967":1}}],["google",{"2":{"912":1}}],["good",{"2":{"366":1}}],["gordon",{"2":{"698":1}}],["gordon等人",{"2":{"121":1}}],["goat",{"2":{"698":1}}],["goal",{"2":{"139":3,"806":1}}],["goetting",{"2":{"698":1}}],["gong",{"2":{"525":1}}],["gothoskar等人",{"2":{"172":1}}],["got",{"2":{"43":2}}],["gl",{"2":{"738":1}}],["glide",{"2":{"513":1}}],["globally",{"2":{"659":1}}],["global",{"0":{"407":1},"2":{"525":1,"654":1,"746":8}}],["glog",{"2":{"120":1}}],["gl​−gk​",{"2":{"390":1}}],["gl−gk",{"2":{"390":1}}],["glu=gated",{"2":{"174":1}}],["glx",{"2":{"17":1}}],["gtg",{"2":{"728":1}}],["gt姿态",{"2":{"709":4}}],["gtsam",{"2":{"634":1}}],["gtpg​t",{"2":{"582":1}}],["gt轨迹",{"2":{"437":1}}],["gtx3080的工作站",{"2":{"437":1}}],["gt",{"2":{"73":1,"146":2,"177":3,"188":2,"196":4,"345":1,"383":1,"411":1,"437":1,"440":1,"470":1,"597":1,"622":1,"647":1,"651":3,"732":2,"750":5,"816":1,"835":2,"854":1}}],["gtk3",{"2":{"36":1}}],["gtk",{"2":{"36":2}}],["galindo",{"2":{"648":1}}],["galindo等人",{"2":{"116":1,"961":3}}],["gatech",{"2":{"387":1,"514":1}}],["gated",{"2":{"174":1}}],["ga",{"2":{"387":1}}],["gadre",{"2":{"274":1,"765":1}}],["gap",{"2":{"220":1,"313":2,"366":1}}],["gawel等人",{"2":{"190":1}}],["gan中的一个三维cnn作为从预测的网格中计算出来的有符号距离场的判别器",{"2":{"429":1}}],["gans",{"0":{"244":1,"365":1},"2":{"158":1,"201":1,"203":1}}],["gan简介",{"2":{"129":1}}],["gan",{"2":{"129":7,"139":1,"143":2,"270":1,"345":1,"387":1,"498":1}}],["gan生成对抗模型",{"0":{"129":1}}],["garrett",{"2":{"123":1}}],["garcia等人",{"2":{"116":1}}],["garcia",{"2":{"116":1}}],["garg",{"2":{"90":1,"525":2,"765":1}}],["gains",{"2":{"109":1}}],["gasteratos",{"2":{"90":1,"209":1}}],["gautham",{"2":{"90":1}}],["gaussiangrasper",{"2":{"588":1}}],["gaussianformer优化了3d高斯函数的几何和语义属性",{"2":{"1004":1}}],["gaussianformer还能够捕捉场景中的复杂细节",{"2":{"924":1}}],["gaussianformer还需要大量的高斯分布才能达到满意的性能",{"2":{"878":1}}],["gaussianformer仅使用周围图像作为输入",{"2":{"911":1}}],["gaussianformer的性能随着3d高斯分布数量的增加而提升",{"2":{"861":1}}],["gaussianformer的内存效率源于其以物体为中心的特性",{"2":{"842":1}}],["gaussianformer在nuscenes和kitti",{"2":{"861":1}}],["gaussianformer在显著降低内存消耗方面超越了所有现有的竞争手",{"2":{"842":1}}],["gaussianformer在一些较小的类别",{"2":{"842":1}}],["gaussianformer在性能上与现有的最先进的方法相当",{"2":{"547":1}}],["gaussianformer在性能上与现有最先进的方法相当",{"2":{"516":1}}],["gaussianformer与其他方法在单目3d语义占用预测方面的性能",{"2":{"842":1}}],["gaussianformer模型的整体结构可以高效地进行端到端训练",{"2":{"738":1}}],["gaussianformer框架用于3d语义占用预测",{"2":{"716":1}}],["gaussianformer首次提出了一个以对象为中心的三维表示来完成三维空间占用预测任务",{"2":{"705":1}}],["gaussianformer首次将三维高斯分布应用于户外三维语义空间占用预测",{"2":{"629":1}}],["gaussianformer进一步采用稀疏卷积和基于局部聚合的高斯到体素溅射",{"2":{"547":1}}],["gaussianformer能够生成既整体又逼真的场景感知结果",{"2":{"516":1,"547":1}}],["gaussianformer2",{"0":{"506":1,"837":1},"1":{"536":1,"567":1,"599":1,"628":1,"656":1,"681":1,"704":1,"727":1,"749":1,"771":1,"792":1,"812":1,"832":1,"851":1,"868":1,"885":1,"901":1,"916":1}}],["gaussianformer",{"0":{"486":1,"716":1,"817":1},"1":{"516":1,"547":1,"580":1,"612":1,"641":1,"669":1,"693":1,"716":1,"738":1,"760":1,"781":1,"802":1,"822":1,"842":1,"861":1,"878":1,"895":1,"911":1,"924":1,"934":1},"2":{"536":1,"567":2,"599":1,"656":1,"700":2,"704":1,"745":1,"771":1,"792":4,"808":1,"812":5,"832":4,"851":2,"901":2,"914":2}}],["gaussianformer将3d场景表示为一组3d高斯",{"2":{"444":1}}],["gaussianformer3d",{"0":{"387":1,"514":1},"1":{"415":1,"444":1,"474":1,"502":1,"532":1,"563":1,"595":1,"624":1,"652":1,"677":1,"700":1,"723":1,"745":1,"767":1,"788":1,"808":1,"828":1,"848":1,"866":1,"883":1,"899":1,"914":1},"2":{"387":1,"444":5,"502":2,"514":1,"700":3,"723":1,"745":1,"767":2,"914":2}}],["gaussian",{"2":{"30":3,"514":1,"536":1,"588":2,"700":1}}],["gammaγ",{"2":{"728":3}}],["gamma",{"2":{"8":1,"153":2,"304":1,"513":5,"728":2,"789":2}}],["groom​=",{"2":{"728":1}}],["groom=",{"2":{"728":1}}],["ground",{"2":{"429":1}}],["group",{"2":{"234":1,"255":1,"315":1,"420":1,"863":1}}],["grupp",{"2":{"510":1}}],["gru",{"2":{"435":2,"698":1}}],["grpo",{"2":{"195":1}}],["gravityfusion",{"2":{"967":1}}],["gray",{"2":{"659":1}}],["gradient",{"2":{"235":1}}],["gradients",{"2":{"183":1,"382":1}}],["graphcmr的输出对遮挡的",{"2":{"419":1}}],["graphcmr的输出在几种情况下不可靠",{"2":{"419":1}}],["graphcmr的许多检测结果即使没有立即被一致性检查拒绝",{"2":{"419":1}}],["graphcmr提供的位置信息被建模为先验因子",{"2":{"419":1}}],["graphcmr输出相应人类的3d",{"2":{"419":1}}],["graphcmr",{"2":{"419":1}}],["graphad",{"2":{"114":1}}],["graphs",{"2":{"30":3,"80":1,"94":1,"125":1,"648":1}}],["graph",{"2":{"23":3,"54":1,"102":1,"111":1,"208":1,"236":1,"237":1,"271":1,"496":1,"525":1,"775":1}}],["griffith",{"2":{"973":1}}],["grid",{"2":{"328":1,"378":1,"423":1,"465":1}}],["gridsample",{"2":{"638":1}}],["grids",{"2":{"80":1}}],["grinvald",{"2":{"209":1}}],["grinvald等人",{"2":{"116":2,"967":2}}],["grep",{"2":{"26":1,"66":1,"78":1}}],["gelu",{"2":{"880":1}}],["geq",{"2":{"681":1,"780":1,"957":1}}],["geforce",{"2":{"522":1,"813":3}}],["gemini",{"2":{"334":2}}],["gervet",{"2":{"274":4}}],["geomae",{"0":{"715":1},"2":{"715":1}}],["geometry",{"2":{"120":1}}],["geometric",{"0":{"556":1},"1":{"588":1,"619":1},"2":{"23":1,"80":1,"378":1,"465":1,"715":2}}],["geo=mlp",{"2":{"621":1}}],["geo​=mlp",{"2":{"621":1}}],["geo​",{"2":{"621":2}}],["geo​∈rx×y×z×c1​",{"2":{"621":1}}],["geop",{"2":{"621":1}}],["geo∈rx×y×z×c1p",{"2":{"621":1}}],["geo",{"2":{"585":1,"621":5,"632":1,"670":4,"750":2,"794":5,"834":3,"928":1}}],["geoconv",{"2":{"511":1}}],["georgia",{"2":{"387":1}}],["georgakis",{"2":{"123":1,"698":1,"826":3,"864":1}}],["geneva等人",{"2":{"967":1}}],["general",{"2":{"659":1,"702":1,"790":1}}],["generalized",{"0":{"413":1},"2":{"276":1}}],["generative",{"2":{"170":1,"183":2,"203":1,"290":1,"382":1}}],["generation",{"0":{"314":1,"582":1},"2":{"23":1,"314":1,"399":1}}],["generator",{"0":{"549":1},"2":{"129":1,"315":2,"549":1}}],["generate",{"2":{"36":1,"321":1,"333":1,"434":1,"839":1,"850":1}}],["genci",{"2":{"960":1}}],["gen",{"2":{"268":1,"850":1}}],["genad",{"2":{"114":1}}],["gente",{"2":{"57":1}}],["getitem",{"2":{"504":1}}],["gets",{"2":{"225":1}}],["get",{"2":{"17":2,"36":5,"38":1,"57":1,"59":1,"66":1,"69":4,"74":1,"78":1,"379":6,"504":1,"534":1,"654":3}}],["gσg​",{"2":{"20":1}}],["gμg​",{"2":{"20":1}}],["g||^2+t",{"2":{"20":1}}],["g",{"0":{"865":1,"944":1},"2":{"13":5,"20":2,"129":4,"208":9,"221":1,"254":1,"273":7,"327":1,"372":4,"390":10,"412":1,"496":1,"532":19,"563":6,"595":5,"656":18,"659":1,"681":23,"693":9,"705":3,"716":6,"728":3,"738":14,"863":9,"916":3}}],["omran等人",{"2":{"967":1}}],["omegaω",{"2":{"976":1}}],["omega^i",{"2":{"57":1}}],["omega^r",{"2":{"57":1}}],["omega",{"2":{"57":4,"390":3,"780":3,"976":4,"985":2}}],["oio",{"2":{"728":1}}],["oi​",{"2":{"728":1}}],["oi",{"2":{"728":1}}],["oid",{"2":{"34":1}}],["oe​∈",{"2":{"712":1}}],["oe∈",{"2":{"712":1}}],["oθ​∈",{"2":{"712":1}}],["oθ∈",{"2":{"712":1}}],["odot⊙",{"2":{"970":1}}],["odom",{"2":{"34":4}}],["od",{"2":{"707":3}}],["o∈r",{"2":{"705":1}}],["o∈ro",{"2":{"705":1}}],["o∈cx×y×zo",{"2":{"656":1,"693":1}}],["o∈cx×y×z",{"2":{"532":2,"656":1,"693":1}}],["ooo",{"2":{"704":1}}],["ood",{"2":{"114":1}}],["ohem",{"2":{"670":1}}],["ohterwise",{"2":{"153":3}}],["o2l",{"2":{"638":1}}],["okvis",{"2":{"634":2,"686":1}}],["other",{"2":{"790":3}}],["otherwisel",{"2":{"666":1}}],["otherwise​",{"2":{"132":1}}],["otherwise",{"2":{"132":1,"666":1}}],["otherwiset",{"2":{"132":1}}],["otimes⊗",{"2":{"705":1,"950":1}}],["otimes",{"2":{"595":1,"705":1,"712":2,"950":1}}],["o^的无界性",{"2":{"656":1}}],["o^",{"2":{"532":2,"656":9,"681":2,"693":2,"738":2}}],["ox",{"2":{"469":1}}],["ogm",{"2":{"455":1,"566":1,"759":1}}],["oₜ",{"2":{"435":2}}],["obtains",{"2":{"384":1}}],["observe",{"2":{"379":1}}],["objs",{"2":{"402":1,"462":1}}],["obj",{"2":{"32":2,"38":2,"57":1}}],["objectnav",{"2":{"139":2,"252":1,"588":1,"698":1,"765":1}}],["objects正确检测到大多数对象",{"2":{"872":1}}],["objects使用teaser++拟合cad模型",{"2":{"816":1}}],["objects从3d度量",{"2":{"816":1}}],["objects从cad模型和相应的对象网格中提取3d关键点",{"2":{"449":1}}],["objects将尝试将已知形状拟合到对象网格上",{"2":{"449":1}}],["objects将尝试将网格拟合到",{"2":{"449":1}}],["objects获得对象的质心",{"2":{"449":1}}],["objects执行欧几里得聚类",{"2":{"449":1}}],["objects首先提取属于给定对象类别",{"2":{"449":1}}],["objects是从不",{"2":{"449":1}}],["objects",{"0":{"449":1},"2":{"131":1,"285":2,"616":1}}],["object",{"0":{"54":1,"132":1,"512":1},"1":{"576":1,"609":1,"638":1,"666":1,"690":1,"736":1,"758":1,"779":1,"800":1},"2":{"17":2,"23":1,"30":1,"34":2,"43":1,"51":1,"54":1,"84":1,"139":2,"204":2,"234":1,"235":2,"255":1,"271":1,"358":1,"384":1,"414":1,"702":5,"715":1,"763":1,"790":5}}],["oquab",{"2":{"274":1,"765":1}}],["oa",{"2":{"263":3,"688":1,"979":1}}],["ouster",{"2":{"828":1}}],["ours",{"2":{"840":1,"928":1}}],["our",{"2":{"235":3,"315":1,"700":1}}],["out表",{"2":{"530":1}}],["out的点",{"2":{"530":1}}],["outputs",{"2":{"351":5,"384":1,"741":1}}],["output",{"2":{"124":2,"257":2,"333":3}}],["outperforms",{"2":{"45":1}}],["out",{"2":{"11":1,"32":1,"38":1,"135":1,"351":2,"530":1,"904":1,"989":1}}],["oleynikova等人",{"2":{"131":1,"162":1,"285":2,"362":2,"480":2,"816":2,"930":1}}],["os1",{"2":{"828":1}}],["os",{"2":{"504":2,"534":1,"707":3}}],["osp",{"2":{"402":1}}],["osr",{"2":{"402":1,"806":1}}],["oscar",{"2":{"126":1}}],["oserror",{"2":{"17":1}}],["ocfbench",{"2":{"997":1}}],["ocf",{"2":{"985":1}}],["ochmann等人",{"2":{"967":3}}],["octreeocc",{"2":{"922":1}}],["octnet对高分辨率点云的内存和运行时间要求要少得多",{"2":{"363":1}}],["octnet",{"2":{"363":1}}],["occscore指标在cvpr",{"2":{"1000":1}}],["occscore=miou×0",{"2":{"998":2}}],["occscore克服了体素级指标的缺点",{"2":{"998":1}}],["occscore",{"2":{"998":2}}],["occscannet",{"2":{"886":1}}],["occworld",{"2":{"963":1,"1003":1}}],["occnerf的miou",{"2":{"1000":1}}],["occnerf以自监督的方式利用交叉熵损失进行语义优化",{"2":{"988":1}}],["occnerf",{"2":{"949":2,"988":1}}],["occnet",{"0":{"823":1},"2":{"425":4,"455":3,"642":2,"694":2,"782":2,"803":3}}],["occnets",{"2":{"425":5,"455":4,"517":3,"782":1,"862":2}}],["occ的整体架构如图6所示",{"2":{"839":1}}],["occ的真值数据标注与生成存在一定的难度",{"2":{"658":1}}],["occ基础设计后",{"2":{"805":1}}],["occ高出4",{"2":{"779":1}}],["occfiner",{"2":{"1000":1}}],["occflownet",{"2":{"941":1}}],["occformer的整体架构如图12所示",{"2":{"875":1}}],["occformer",{"0":{"733":1},"2":{"733":1,"791":1,"875":1,"1000":1}}],["occfusion使用了高分辨率输入900×1600的r101",{"2":{"779":1}}],["occfusion还结合了雷达数据",{"2":{"779":1}}],["occfusion上公开",{"2":{"475":1}}],["occfusion",{"0":{"416":1,"445":1,"545":1,"701":1},"1":{"445":1,"475":1,"503":1,"533":1,"564":1,"596":1,"625":1,"653":1,"678":1,"701":1,"724":2,"746":2,"768":2,"789":2,"809":2,"829":2,"849":1,"867":1,"884":1,"900":1,"915":1,"927":1,"936":1,"944":1,"952":1,"959":1,"965":1,"971":1,"977":1},"2":{"445":2,"474":1,"482":2,"503":1,"545":4,"746":1,"827":1,"847":1,"867":2,"900":1,"944":4,"952":1,"959":2,"965":3,"976":1,"977":2}}],["occupied",{"2":{"707":4}}],["occupancym3d首先学习占用以增强3d特征",{"2":{"1003":1}}],["occupancym3d",{"2":{"922":1,"1003":1}}],["occupancy真值通常不会直接进行人工标注",{"2":{"658":1}}],["occupancy",{"0":{"445":1,"482":1,"810":1,"890":1},"1":{"830":1,"850":1},"2":{"23":1,"423":1,"514":1,"537":1,"545":1,"577":1,"578":1,"610":1,"637":1,"698":1,"757":2,"776":1,"839":1,"850":1,"906":1,"941":1}}],["occ=f",{"2":{"724":2}}],["occ=∑i",{"2":{"694":1}}],["occ=m",{"2":{"590":2}}],["occ​=i∑",{"2":{"694":1}}],["occ​",{"2":{"694":2}}],["occloss=l=0∑3​2l1​×",{"2":{"766":1}}],["occloss=∑l=0312l×",{"2":{"766":1}}],["occloss",{"2":{"766":2}}],["occl",{"2":{"694":2}}],["occ任务则更关注通用几何信息",{"2":{"658":1}}],["occ任务的研究工作中",{"2":{"421":1}}],["occ∈rx×y×zocc",{"2":{"724":1}}],["occ∈rx×y×z",{"2":{"590":2,"724":1}}],["occ中",{"2":{"585":1}}],["occ综述",{"2":{"573":2}}],["occ方案基于fb",{"2":{"490":1}}],["occmamba",{"2":{"474":1}}],["occgen",{"2":{"474":1}}],["occ3d",{"2":{"425":3,"444":1,"566":1,"652":3,"670":3,"700":2,"736":3,"739":8,"761":1,"770":1,"782":3,"803":6,"893":2,"899":2,"900":3,"922":1,"927":1,"997":2,"999":1,"1000":3}}],["occcylindrical的整体架构",{"2":{"621":1}}],["occcylindrical的整体架构如下",{"2":{"578":1}}],["occcylindrical",{"0":{"409":1,"558":1,"578":1},"1":{"438":1,"468":1,"497":1,"527":1,"558":1,"590":2,"621":2,"649":2,"676":2,"699":2,"722":1,"744":1,"766":1,"787":1,"807":1,"827":1,"847":1,"865":1,"882":1,"898":1},"2":{"409":1,"744":1,"827":1}}],["occ",{"0":{"182":1,"573":1,"577":1,"635":1,"658":1},"1":{"606":1,"610":1,"635":1,"639":1,"663":1,"667":1,"687":1,"691":1,"710":1,"714":1,"733":1,"737":1,"755":1,"759":1,"776":1,"780":1,"797":1,"801":1,"817":1,"821":1,"837":1,"841":1,"856":1,"860":1,"873":1,"877":1,"890":1,"894":1,"906":1,"910":1,"920":1,"923":1,"933":1,"942":1,"950":1,"957":1,"964":1,"970":1,"976":1,"981":1,"985":1,"988":1,"991":1,"994":1,"997":1,"998":1,"999":1,"1000":1,"1001":1,"1002":1,"1003":1,"1004":1,"1005":1,"1006":1,"1007":1,"1008":1},"2":{"421":2,"423":1,"474":1,"482":1,"590":2,"612":1,"638":1,"694":5,"700":2,"724":1,"779":2,"839":2,"850":3,"870":1,"875":1,"886":4,"922":1,"976":1,"997":1,"1000":2}}],["ocrnet",{"2":{"96":1}}],["o",{"2":{"87":1,"532":2,"638":1,"647":1,"656":5,"681":1,"686":1,"693":1,"705":6,"712":3,"728":1,"738":4,"778":7,"780":2}}],["op",{"2":{"877":1}}],["opposite",{"2":{"379":4}}],["operator",{"2":{"196":1}}],["operations",{"2":{"496":1}}],["operation",{"2":{"153":1,"496":5}}],["openlex3d",{"2":{"826":1}}],["openocc",{"0":{"687":1},"2":{"757":1}}],["openoccupancy",{"2":{"425":1,"482":1,"585":1,"670":3,"687":1,"739":3,"803":2,"922":1,"997":1,"1000":1}}],["openin",{"2":{"648":1}}],["opengvlab",{"2":{"584":1}}],["openmask3d",{"2":{"492":1}}],["opendrivevla",{"2":{"283":1,"334":1}}],["openai",{"2":{"135":2,"373":2,"765":2,"864":1}}],["openscene",{"2":{"588":1,"826":1}}],["openssh",{"2":{"78":1}}],["openset",{"2":{"27":1}}],["open",{"0":{"765":1,"864":1},"2":{"17":2,"23":1,"80":1,"184":1,"399":1,"406":1,"455":1,"721":1,"739":1}}],["opencv3",{"2":{"107":1}}],["opencv4",{"2":{"67":1}}],["opencv",{"0":{"36":1},"2":{"15":1,"36":4,"107":2}}],["optimization",{"2":{"102":1}}],["options",{"2":{"66":1}}],["opt",{"2":{"87":1,"107":1,"123":1}}],["ovo",{"2":{"975":1}}],["overline",{"2":{"372":1}}],["overwritten",{"2":{"327":1}}],["overview",{"0":{"300":1,"501":1},"1":{"325":1,"351":1,"379":1,"407":1,"436":1,"466":1,"496":1}}],["overall",{"2":{"43":1,"51":1,"315":1,"916":6}}],["ov",{"2":{"30":1,"369":1,"687":1}}],["onnx和tensorrt",{"2":{"437":1}}],["once",{"2":{"360":1}}],["onemap",{"2":{"765":1}}],["onenorth",{"2":{"254":1}}],["one",{"2":{"124":2,"138":1,"153":1,"157":2,"257":2,"500":1,"700":2,"707":2}}],["oneformer3d",{"0":{"282":1,"306":1},"1":{"306":1,"331":2,"356":2,"384":2,"412":2,"441":2,"471":2},"2":{"17":2,"32":1,"38":1,"215":1,"384":3}}],["on",{"0":{"43":1,"51":1,"244":1,"365":1},"2":{"31":1,"201":1,"237":1,"394":1,"519":1,"593":1,"616":4,"700":2}}],["online3d引入了一个基于适配器的模型",{"2":{"629":1}}],["online实时执行",{"2":{"462":1}}],["online在大多数情况下性能相似",{"2":{"462":1}}],["online在除了2个案例之外的所有情况下都排名第一或第二",{"2":{"462":1}}],["online",{"2":{"23":1,"43":4,"51":3,"271":1,"431":1,"537":1,"668":2,"671":1}}],["only",{"2":{"23":1,"659":1}}],["orcvio",{"2":{"967":1}}],["oracle",{"2":{"806":1}}],["oreso​",{"2":{"638":4}}],["ortiz",{"2":{"619":1}}],["orientation",{"2":{"654":5}}],["original",{"2":{"496":2}}],["orion语言记忆暗示此类接口",{"2":{"507":1}}],["orion",{"2":{"334":2}}],["ordering",{"0":{"407":1},"2":{"379":1}}],["ordered",{"2":{"315":1}}],["orlbslam2",{"0":{"67":1}}],["orbvoc",{"2":{"152":1}}],["orbbec",{"2":{"120":1}}],["orb",{"2":{"58":3,"152":1,"189":1,"686":1}}],["orbslam2",{"0":{"22":1,"107":1},"1":{"29":1,"36":1,"40":1,"47":1,"58":1,"67":1},"2":{"58":1,"152":1}}],["org",{"2":{"23":1,"36":1,"47":1,"84":2,"96":1,"113":1,"205":1,"256":1,"264":1,"266":1,"414":1,"445":1,"453":1,"514":1,"545":1,"577":1,"578":1,"584":1,"671":1,"686":1,"776":1}}],["or",{"2":{"17":2,"48":1,"184":2,"384":1,"496":2,"500":1}}],["offocc",{"2":{"700":1}}],["offset",{"2":{"696":1}}],["offscreen",{"2":{"64":1}}],["off",{"2":{"66":2}}],["officer",{"2":{"702":1,"790":1}}],["office",{"2":{"34":2}}],["of=",{"2":{"26":1}}],["of",{"0":{"344":1,"452":1},"2":{"11":1,"40":1,"120":1,"153":1,"158":1,"183":1,"184":4,"201":1,"204":5,"235":2,"315":4,"327":5,"345":1,"366":2,"373":1,"379":3,"382":1,"384":3,"387":1,"394":1,"405":1,"452":2,"496":5,"518":3,"519":1,"616":5,"659":3,"660":1,"671":1,"700":3,"729":2,"741":1,"875":1,"904":1}}],["wg​∈rc×c",{"2":{"863":1}}],["wg∈rc×c",{"2":{"863":1}}],["wget",{"2":{"87":1}}],["w∈r3→v∈",{"2":{"780":2}}],["w∈ww",{"2":{"221":1}}],["w=2l1​",{"2":{"766":1,"884":1}}],["w=12lw",{"2":{"766":1,"884":1}}],["wm​=∑i​am",{"2":{"752":1}}],["wm=∑i",{"2":{"752":1}}],["w×hw×hw×h",{"2":{"741":1}}],["wr​",{"2":{"712":1}}],["wr",{"2":{"712":1}}],["wrapper",{"2":{"57":1}}],["wl−wrw",{"2":{"712":1}}],["wl​",{"2":{"712":1}}],["wl",{"2":{"712":1}}],["wc",{"2":{"957":2}}],["wc​",{"2":{"694":1,"957":1}}],["wcw",{"2":{"694":1,"957":1}}],["wce=wls=wgeo=wsem=1w",{"2":{"670":1}}],["wbcv​",{"2":{"694":1}}],["wbcvw",{"2":{"694":1}}],["wb​",{"2":{"694":1}}],["wbw",{"2":{"694":1}}],["wf=wb=wc=1w",{"2":{"694":1}}],["wf​",{"2":{"694":1}}],["wfw",{"2":{"694":1}}],["wp",{"2":{"609":2}}],["wd×h×w",{"2":{"609":1}}],["w911nf",{"2":{"467":1}}],["wj",{"2":{"390":2}}],["wkw",{"2":{"863":1}}],["wk∈rc×cw",{"2":{"844":1}}],["wk​∈rc×c",{"2":{"844":1}}],["wk​",{"2":{"278":1}}],["wk",{"2":{"278":1}}],["wthunt",{"2":{"220":1}}],["w2w",{"2":{"181":2}}],["w1w",{"2":{"181":2}}],["wₜ",{"2":{"171":2}}],["whole",{"2":{"989":1}}],["wheelchair",{"2":{"702":1,"790":1}}],["where",{"2":{"366":1,"712":3}}],["whelan等人",{"2":{"190":1,"967":3}}],["whelan",{"2":{"189":1,"588":1}}],["which",{"2":{"315":1,"496":1,"500":1,"518":1,"839":1}}],["while",{"2":{"52":1,"115":1,"130":2,"496":1}}],["what",{"2":{"135":1}}],["w",{"0":{"729":1},"2":{"133":3,"149":3,"184":5,"254":3,"278":1,"305":1,"321":1,"333":7,"345":2,"383":2,"411":2,"440":2,"470":5,"609":4,"621":4,"622":3,"649":1,"654":1,"659":4,"682":2,"686":1,"693":4,"694":5,"703":1,"712":12,"746":1,"752":2,"780":1,"844":1,"863":2,"950":4,"957":1}}],["w的过程",{"2":{"133":1}}],["wen",{"2":{"765":1}}],["weakly",{"2":{"410":2,"528":1}}],["we",{"2":{"366":1,"379":1,"405":1,"452":2,"496":1,"500":1}}],["wei等人",{"2":{"735":2}}],["weiyithu",{"2":{"710":1}}],["weighted",{"2":{"496":1,"528":1,"806":1}}],["weights=resnet50",{"2":{"333":1}}],["weights",{"2":{"333":2,"863":1}}],["weijiawu",{"2":{"439":1}}],["wei",{"2":{"387":1}}],["weihs",{"2":{"139":1}}],["werby",{"2":{"209":1,"648":1}}],["werby等人",{"2":{"121":1}}],["well",{"2":{"158":1}}],["welcome",{"2":{"57":2}}],["wu等人",{"2":{"172":1,"363":1,"955":1}}],["wu",{"2":{"90":1}}],["wovogen",{"2":{"963":1}}],["wolf等人",{"2":{"732":1}}],["wocc​",{"2":{"694":1}}],["woccw",{"2":{"694":1}}],["wooyang2018的博客",{"2":{"78":1}}],["would",{"2":{"66":2}}],["words",{"2":{"57":1,"571":3}}],["work",{"0":{"164":1},"2":{"43":4,"51":3}}],["workers",{"2":{"11":1}}],["worker",{"2":{"11":1,"702":1,"790":1}}],["wq",{"2":{"48":1}}],["wald等人",{"2":{"967":2}}],["wall之间",{"2":{"732":1}}],["walter",{"2":{"648":2}}],["waymo和kitti",{"2":{"997":1}}],["waymo等",{"2":{"997":1}}],["waymo数据集用于3d占用预测",{"2":{"757":1}}],["waymo",{"2":{"334":1,"360":2,"425":1,"455":1,"670":1,"739":4,"782":1,"803":3,"997":1}}],["warp",{"2":{"149":1,"743":1}}],["warning",{"2":{"57":1,"66":1,"107":1}}],["warnings",{"2":{"43":1}}],["warn",{"2":{"43":1,"57":1}}],["wani",{"2":{"139":1,"252":2,"495":2,"743":1,"806":1}}],["wang和qian",{"2":{"961":1}}],["wangyueft",{"2":{"414":1}}],["wang等人",{"2":{"121":1,"607":1,"735":1,"967":4}}],["wang",{"2":{"23":1,"209":1,"363":1,"619":1,"958":1}}],["wasserstein",{"2":{"328":2}}],["was",{"2":{"64":1,"67":1}}],["wi​",{"2":{"950":1}}],["wij​",{"2":{"950":1}}],["wij",{"2":{"950":1}}],["wijmans",{"2":{"139":3,"274":1}}],["wi",{"2":{"950":1}}],["wi∣si∣∑xw∑yl∑zhsi",{"2":{"694":1}}],["wi∣si∣∑xw∑ylsi",{"2":{"694":1}}],["window",{"2":{"631":1,"659":1,"729":4}}],["windows",{"2":{"729":3}}],["windows结束",{"2":{"41":1}}],["windows风格的行尾",{"2":{"41":1}}],["wildocc",{"0":{"828":1},"2":{"444":1,"652":2,"700":1,"828":2,"899":2}}],["wise",{"2":{"384":1,"452":1,"863":1}}],["width",{"2":{"136":1,"254":1}}],["within",{"2":{"659":1,"700":1,"729":1}}],["without",{"2":{"333":1,"776":1}}],["with",{"0":{"65":1,"372":1,"422":1,"488":1},"1":{"518":1,"549":1},"2":{"23":1,"30":1,"45":1,"94":1,"96":1,"106":4,"107":1,"148":1,"201":1,"205":1,"243":1,"268":1,"287":2,"289":1,"290":1,"306":1,"312":1,"315":1,"323":1,"327":2,"351":1,"394":1,"399":2,"410":2,"422":2,"439":1,"452":2,"469":1,"496":3,"498":2,"504":2,"513":2,"514":1,"515":1,"519":1,"578":1,"584":1,"593":2,"623":1,"668":3,"671":1,"692":1,"700":1,"715":3,"906":1}}],["wsn​​",{"2":{"957":1}}],["wsnw",{"2":{"957":1}}],["wsl",{"2":{"78":1}}],["ws",{"2":{"27":4,"34":1,"120":4}}],["wwl​−wr​​",{"2":{"712":1}}],["ww∈w",{"2":{"221":1}}],["www",{"2":{"31":1,"113":1,"208":1,"221":1,"276":2,"578":1,"780":1,"863":1}}],["ww",{"2":{"11":2}}],["bpifrance",{"2":{"960":1}}],["bvh提供了现成的机会",{"2":{"905":1}}],["bvh",{"2":{"905":1}}],["bvre",{"0":{"638":1},"2":{"421":1,"576":2,"800":2}}],["b仅需imagenet",{"2":{"824":1}}],["bg",{"2":{"823":1}}],["bgr",{"2":{"173":1}}],["b7来初始化我们局部空间占用预测模块中的图像编码器",{"2":{"813":1}}],["bhattacharyya",{"2":{"812":1,"916":2}}],["bcl",{"2":{"962":2}}],["bci",{"2":{"916":2}}],["bc",{"2":{"916":3}}],["bce损失表示为",{"2":{"985":1}}],["bce​",{"2":{"766":2}}],["bcel",{"2":{"766":1}}],["bce",{"2":{"698":1,"704":2,"766":3,"985":2}}],["bcv",{"2":{"694":1}}],["bc3180b07f8e4a728f504ded654df56f",{"2":{"654":1}}],["bnn",{"2":{"678":1}}],["b三个值所以展平后是16x3=48",{"2":{"659":1}}],["bs",{"2":{"623":4}}],["bs=1m",{"2":{"26":1}}],["bbb和分布预测器",{"2":{"704":1}}],["bbb和方向",{"2":{"704":1}}],["bbb",{"2":{"595":1,"716":2}}],["bboxes",{"2":{"333":4}}],["bbox",{"2":{"32":2,"333":2,"358":1,"651":1,"654":3}}],["b+d",{"2":{"351":3}}],["bdd100k提供10万段美国多样视频",{"2":{"360":1}}],["bdd100k",{"2":{"334":1,"360":2}}],["bdd",{"2":{"334":3,"360":4,"447":1}}],["b节",{"2":{"210":1,"320":1,"326":1}}],["b的每张图片由各自相应的latent",{"2":{"181":1}}],["b=",{"2":{"140":1,"280":1}}],["b=−2",{"2":{"140":2,"280":2}}],["b年",{"2":{"131":1}}],["brostow等人",{"2":{"967":1}}],["brownian",{"2":{"208":1}}],["brasch等人",{"2":{"967":1}}],["branches",{"2":{"623":1}}],["branches=reg",{"2":{"623":1}}],["branches=none",{"2":{"623":1}}],["branch",{"2":{"544":1}}],["breakdown",{"2":{"366":1}}],["briales和gonzalez",{"2":{"390":1}}],["brige",{"2":{"107":3}}],["bridgeman等人",{"2":{"967":1}}],["bridge文件夹下",{"2":{"107":1}}],["bridge中的cmakelists",{"2":{"107":1}}],["bridge",{"2":{"107":5}}],["brs",{"0":{"84":1}}],["bicycle",{"2":{"702":3,"790":3}}],["bifpn",{"2":{"627":1}}],["bilinear",{"2":{"594":1,"699":1}}],["bias=bias",{"2":{"351":1}}],["bias=true",{"2":{"351":1}}],["bird",{"2":{"204":4}}],["bit",{"2":{"290":1,"688":1}}],["bits",{"2":{"67":1}}],["bit库吗",{"2":{"66":2}}],["bins",{"2":{"741":1}}],["bin文件的名称",{"2":{"254":1,"534":1}}],["bin",{"0":{"48":1},"2":{"11":1,"32":4,"38":4,"41":1,"48":2,"254":1,"327":4,"476":1,"534":1,"621":2,"741":3,"882":1}}],["b",{"0":{"249":1,"301":1,"380":1,"492":1,"527":1,"548":1,"596":1,"621":1,"642":1,"746":1,"761":1,"766":1,"828":1,"884":1,"901":1,"902":1,"924":1,"986":1,"989":1,"992":1,"995":1},"1":{"271":1,"295":1,"989":1,"992":1,"995":1},"2":{"57":3,"92":1,"133":3,"140":3,"149":1,"162":2,"181":7,"197":1,"208":1,"276":1,"280":3,"285":3,"315":2,"325":3,"333":7,"336":1,"357":3,"379":6,"380":1,"390":1,"412":1,"419":2,"436":2,"437":1,"450":1,"480":2,"518":2,"552":1,"605":2,"616":1,"617":1,"659":2,"660":3,"686":2,"694":9,"695":1,"704":3,"707":1,"709":1,"732":2,"738":1,"756":1,"779":1,"782":1,"798":1,"800":2,"803":6,"824":1,"888":2,"899":1,"900":1,"903":1,"929":2,"942":1,"947":4}}],["blending",{"2":{"452":1}}],["blended",{"0":{"452":1},"2":{"452":2}}],["blip",{"2":{"274":1,"765":1}}],["blanco等人",{"2":{"967":1}}],["blanco",{"2":{"123":1,"648":1,"826":1,"864":1}}],["blacklist",{"2":{"66":4}}],["blochliger",{"2":{"698":1}}],["block",{"2":{"659":1,"880":1}}],["block的次数都是偶数",{"2":{"659":1}}],["block注意这里的block其实有两种结构",{"2":{"659":1}}],["block得到的特征",{"2":{"373":1}}],["blocks",{"2":{"57":1}}],["bloesch等人",{"2":{"634":1}}],["blob的相对路径",{"2":{"254":1}}],["blob",{"2":{"174":1}}],["blomqvist等人",{"2":{"121":1}}],["blog",{"2":{"41":1,"48":1,"106":5,"220":1,"351":1,"369":1,"508":1}}],["blkid",{"2":{"24":1}}],["bansal",{"2":{"274":1}}],["bankiti",{"2":{"126":1}}],["bay",{"2":{"189":1}}],["bayer8",{"2":{"173":1}}],["batra",{"2":{"139":1,"806":1}}],["batch和clio",{"2":{"462":2}}],["batch的结果",{"2":{"431":1}}],["batch",{"2":{"32":3,"124":2,"257":2,"271":1,"333":1,"351":1,"420":1,"519":1,"550":1,"700":1}}],["baldan",{"2":{"126":1}}],["baidu",{"2":{"117":1}}],["bao和savarese",{"2":{"116":1,"967":1}}],["bao",{"2":{"90":1,"209":3}}],["barrier",{"2":{"702":2,"790":2}}],["bar",{"0":{"85":1},"2":{"81":1,"111":4,"124":4,"140":48,"153":4,"175":6,"188":2,"236":4,"257":4,"273":9,"280":48,"316":7,"464":1,"563":1,"595":1,"789":3,"809":5}}],["backword",{"2":{"839":1}}],["back结果与首次预测进行比较",{"2":{"833":1}}],["back评估",{"2":{"833":1}}],["backbone的",{"2":{"803":1}}],["backbone的先进视觉模型相比",{"2":{"803":1}}],["backbone",{"0":{"134":1},"2":{"333":4,"659":1,"803":1}}],["backpropagating",{"0":{"75":1,"84":1},"2":{"75":2}}],["back函数仅适用于向字符串添加一个字符",{"2":{"52":1}}],["back",{"2":{"52":3,"104":4,"115":6,"130":4,"146":1,"476":2,"835":3,"904":3}}],["badrinarayanan等人",{"2":{"116":1}}],["bad",{"0":{"41":1},"2":{"41":1}}],["badge",{"0":{"39":1,"46":1,"57":1},"1":{"46":1,"57":2},"2":{"57":1}}],["bag",{"2":{"34":1}}],["basic",{"2":{"880":1}}],["basictransformerblock",{"2":{"174":1}}],["basalt",{"2":{"390":1,"634":1,"686":1}}],["basler",{"2":{"173":1,"828":1}}],["base的结果",{"2":{"791":1}}],["baseline",{"2":{"671":1}}],["basemodule",{"2":{"623":1}}],["base",{"2":{"43":1,"198":1,"379":1,"803":1}}],["based额",{"2":{"485":1}}],["based的方法结合了起来",{"2":{"485":1}}],["based的方法下作者选用了u",{"2":{"424":1}}],["based的方法下作者选用了pointnet++",{"2":{"424":1}}],["based的网络为两个增强视图提取特征",{"2":{"424":1}}],["based的网络和point",{"2":{"424":1}}],["based方法本质上是对预定义的密集anchors进行类别的分类和边框系数的回归",{"2":{"333":1}}],["based",{"0":{"183":1,"208":1,"235":1},"1":{"203":1,"225":1,"245":1,"267":1,"291":1,"316":1,"342":1,"370":1,"398":1},"2":{"23":1,"138":1,"170":1,"183":1,"203":1,"225":1,"235":1,"315":1,"379":1,"514":1,"537":1,"671":1,"756":3,"763":1}}],["bashrc",{"2":{"87":2}}],["bashr",{"0":{"48":1}}],["bash^m",{"2":{"41":1}}],["bash脚本问题",{"0":{"37":1},"1":{"41":1,"48":1}}],["bash",{"2":{"11":1,"34":1,"48":2,"49":1,"60":1,"87":1,"120":3,"152":1}}],["bogo等人",{"2":{"967":1}}],["bolded",{"2":{"700":1}}],["boldsymbol",{"2":{"595":2,"623":1}}],["both",{"2":{"659":1}}],["bottom",{"2":{"138":1,"616":1}}],["bottleneck",{"2":{"98":1,"153":1,"271":1}}],["boulch",{"2":{"955":1}}],["bouguet",{"2":{"310":1}}],["boundaries",{"2":{"729":1}}],["boundary",{"2":{"30":1}}],["bounding",{"2":{"138":1,"271":1}}],["bowman",{"2":{"209":1,"525":1}}],["bowman等人",{"2":{"116":2,"967":1}}],["bool>",{"2":{"254":1,"571":1}}],["bool",{"2":{"146":1,"571":1,"929":1}}],["bobkov等人",{"2":{"664":1}}],["bob",{"2":{"136":1}}],["board",{"2":{"31":1}}],["box的位置和语义信息间接生成",{"2":{"658":1}}],["box之间通过匈牙利算法进行二分匹配",{"2":{"358":1}}],["boxes",{"2":{"271":1,"651":4}}],["box",{"2":{"30":1,"138":1,"169":1,"187":1,"562":1,"594":2}}],["bucher",{"2":{"958":1}}],["bucket",{"0":{"661":1},"2":{"661":1}}],["bukhari",{"2":{"619":1}}],["bundled",{"2":{"362":1}}],["bundle",{"0":{"179":1},"2":{"163":1,"168":1,"179":1}}],["burri等人",{"2":{"131":1,"572":1}}],["buddy",{"2":{"106":1}}],["buddy的博客",{"2":{"106":1}}],["builds",{"2":{"659":1}}],["buildingparser将一个走廊过度分割为三个房间",{"2":{"872":1}}],["buildingparser过度分割了房间",{"2":{"872":1}}],["buildingparser首先使用voxblox",{"2":{"816":1}}],["buildingparser实现了简单但有效的方法",{"2":{"480":1}}],["buildingparser通过将第3层分割为房间生成第4层",{"2":{"285":1}}],["buildingparser",{"0":{"480":1},"2":{"131":2,"285":2}}],["build",{"2":{"27":3,"36":4,"40":3,"47":2,"58":2,"107":2,"120":2}}],["busch",{"2":{"765":1}}],["bus",{"2":{"11":1,"702":4,"790":4}}],["by",{"2":{"11":1,"41":1,"48":1,"84":2,"107":1,"135":1,"149":1,"183":1,"220":1,"235":1,"351":1,"382":1,"434":1,"496":1,"659":1,"806":1,"818":1}}],["bernadette",{"2":{"958":1}}],["berkeley",{"2":{"126":1}}],["beeching",{"2":{"806":1}}],["been",{"2":{"366":1}}],["ben",{"2":{"973":1}}],["bendy",{"2":{"702":1,"790":1}}],["bench2drive用于控制",{"2":{"447":1}}],["bench2drive挑战路线",{"2":{"417":1}}],["bench2drive等",{"2":{"417":1}}],["bench2drive",{"2":{"334":2,"360":3,"447":1}}],["bescos等人",{"2":{"967":2}}],["best",{"2":{"700":1}}],["bestrivern的博客",{"2":{"496":1}}],["besl和mackay",{"2":{"686":1}}],["behind",{"2":{"949":1}}],["behnke",{"2":{"556":1}}],["behley等人",{"2":{"116":1,"967":2}}],["beat",{"0":{"244":1,"365":1},"2":{"201":1}}],["better",{"0":{"804":1},"2":{"315":1,"804":1}}],["between",{"2":{"137":1,"366":1,"379":1}}],["beta参数检查也显著减少了误差",{"2":{"775":1}}],["beta参数由graphcmr",{"2":{"419":1}}],["beta检查",{"2":{"775":1}}],["betaβ",{"2":{"137":1,"153":1,"312":1,"666":1}}],["beta",{"2":{"8":1,"111":4,"137":1,"140":15,"236":4,"273":21,"280":15,"666":1}}],["beijbom",{"2":{"126":1}}],["below",{"2":{"120":1}}],["bev卷积网络处理特征",{"2":{"908":1}}],["bev切片操作",{"2":{"875":1}}],["bev的前向",{"2":{"839":1}}],["bev平面",{"2":{"821":1,"910":1}}],["bev激光雷达",{"2":{"821":1}}],["bev摄像头",{"2":{"821":1}}],["bev+wocc⋅ld",{"2":{"694":1}}],["bev=∑i",{"2":{"694":1}}],["bev​+wocc​⋅ld",{"2":{"694":1}}],["bev​=i∑",{"2":{"694":1}}],["bev​",{"2":{"694":1}}],["bevl",{"2":{"694":1}}],["bevpooling",{"2":{"670":1}}],["bevpoolv2",{"2":{"670":2}}],["bev感知主要分为三组",{"2":{"821":1}}],["bev感知解决了这一问题",{"2":{"714":1}}],["bev感知不监测高度信息",{"2":{"667":1}}],["bev感知为多源信息融合",{"2":{"630":1,"667":1}}],["bevbert",{"2":{"648":1}}],["bev视野范围扩展",{"0":{"638":1},"2":{"800":1}}],["bev检测任务主要完成语义清晰",{"2":{"630":1}}],["bev忽略的垂直结构",{"2":{"610":1,"658":1}}],["bev编码器的架构类似于图像编码器",{"2":{"680":1}}],["bev编码器通过视图变换增强粗糙的bev特征",{"2":{"680":1}}],["bev编码器",{"0":{"680":1},"2":{"598":1}}],["bev特征图作为查询在bev空间中关注图像编码器特征",{"2":{"585":1}}],["bev采用统一设计",{"2":{"585":1}}],["bev分割结果",{"2":{"566":1}}],["bevdetocc",{"2":{"791":3}}],["bevdetocc和uniocc的总训练周期设置为24",{"2":{"770":1}}],["bevdet",{"2":{"564":1,"823":1}}],["bevdriver",{"2":{"128":1}}],["bev表示中沿z轴的每个特征向量所表示的空间分辨率将不等于",{"2":{"638":1}}],["bev表示的映射",{"2":{"598":1}}],["bev表示",{"2":{"490":1,"839":1}}],["bev基础上",{"2":{"490":1}}],["bev语义理解",{"2":{"423":1}}],["bevfusion",{"2":{"123":1,"512":2,"625":1,"829":1}}],["bevformer",{"2":{"123":1,"599":1}}],["bev",{"0":{"166":1,"630":1},"2":{"114":1,"123":4,"176":1,"392":1,"421":1,"423":2,"444":1,"455":2,"474":1,"482":1,"490":2,"497":1,"505":1,"520":1,"545":3,"547":1,"548":1,"550":1,"564":2,"567":1,"576":2,"585":1,"599":4,"610":1,"612":1,"625":1,"635":1,"637":1,"644":1,"665":3,"667":1,"670":6,"678":2,"693":1,"694":13,"695":1,"746":6,"761":1,"768":1,"777":1,"789":1,"800":1,"808":4,"809":1,"819":1,"823":4,"829":1,"839":3,"877":1,"908":1,"950":1,"971":6,"1005":1}}],["be",{"2":{"64":1,"158":1,"333":1,"365":1,"440":1}}],["because",{"2":{"64":1,"405":1,"500":1}}],["bem",{"2":{"57":1}}],["beyond",{"2":{"43":2}}],["begin",{"2":{"8":2,"93":2,"104":3,"111":1,"115":3,"130":2,"132":1,"140":6,"153":2,"161":1,"196":3,"208":3,"235":2,"236":1,"261":1,"273":2,"280":6,"335":1,"342":1,"357":2,"372":1,"390":2,"513":1,"571":1,"633":1,"666":1,"888":2,"918":1,"929":4,"957":1}}],["tchapmi等人",{"2":{"962":1}}],["t−kt",{"2":{"957":1}}],["t−k≥0",{"2":{"780":2}}],["tσij−1​",{"2":{"916":1}}],["tσij−1",{"2":{"916":1}}],["tσi−1​",{"2":{"693":1}}],["tσi−1",{"2":{"693":1}}],["tt−k→t​",{"2":{"957":1}}],["tt−k→t​⋅ft−k​",{"2":{"957":1}}],["tt−k→tt",{"2":{"957":1}}],["tt−k→t⋅ft−k",{"2":{"957":1}}],["tta",{"2":{"673":1}}],["ttt",{"2":{"31":1,"221":1,"716":1,"728":1,"780":3,"793":1,"957":1}}],["tg",{"2":{"549":2}}],["tgt​",{"2":{"728":1}}],["tgt=query",{"2":{"333":1}}],["tgt",{"2":{"333":1}}],["tς−1",{"2":{"532":2,"656":2,"681":4,"693":2,"738":2,"916":4}}],["t|y",{"2":{"513":4}}],["t|x",{"2":{"140":4,"208":3,"280":4}}],["t265的输出融合以提高里程计轨迹的质量",{"2":{"437":1}}],["t265刚性地连接到kinect以提供外部里程计输入",{"2":{"437":1}}],["tn+m∈se",{"2":{"390":1}}],["t1",{"2":{"390":1}}],["t1−βt​=αt​",{"2":{"111":1,"236":1}}],["tm",{"2":{"390":4}}],["tmk−gkt",{"2":{"390":1}}],["tmp容器元素为1",{"2":{"93":1}}],["tmp",{"2":{"93":1}}],["typically",{"2":{"496":1}}],["typedef",{"2":{"67":2}}],["type>",{"2":{"67":1}}],["typename",{"2":{"67":1}}],["type",{"2":{"67":2,"120":1,"146":1,"196":1}}],["type=",{"2":{"36":1,"623":3}}],["type=release",{"2":{"27":1}}],["ty",{"2":{"375":1}}],["tf",{"2":{"273":1}}],["tδt是文本编码器对目标文本和原文本的编码向量的差",{"2":{"268":1}}],["tlabs",{"2":{"247":1}}],["t∈",{"2":{"208":4,"221":3,"273":2}}],["t表示两模态向量的内积",{"2":{"184":1}}],["tαˉt​",{"2":{"175":1}}],["t0t",{"2":{"153":1}}],["tj",{"2":{"153":4,"390":1}}],["tj∈yt",{"2":{"153":1}}],["tpi​",{"2":{"998":1}}],["tpitp",{"2":{"915":1,"998":1}}],["tpitpi+fpi+fni",{"2":{"749":1,"802":1,"848":1}}],["tptptp",{"2":{"998":1}}],["tp+fp+fn",{"2":{"998":1}}],["tpo​",{"2":{"778":1}}],["tpotp",{"2":{"778":1}}],["tpc​",{"2":{"739":1,"742":1,"778":1}}],["tpctp",{"2":{"739":1,"742":1,"778":1}}],["tpv特征",{"2":{"950":1}}],["tpv特征之间的跨视图混合注意力实现了三个平面之间的交互",{"2":{"858":1}}],["tpv特征通过基于transformer的编码器生成",{"2":{"858":1}}],["tpv特征能够灵活地恢复3d空间",{"2":{"858":1}}],["tpv极坐标平面",{"2":{"676":1}}],["tpvformer的整体架构如图8所示",{"2":{"858":1}}],["tpvformer和monoscene的做法",{"2":{"750":1}}],["tpvformer",{"2":{"547":1,"599":1,"791":1,"858":1,"950":1,"1000":1}}],["tpv",{"0":{"676":1},"2":{"438":1,"547":1,"567":1,"578":1,"621":4,"665":1,"676":1,"808":3,"819":1,"858":1,"865":1,"875":1,"877":1,"882":2,"898":1,"908":1,"942":1,"950":3}}],["tpf",{"2":{"402":1}}],["tp​",{"2":{"132":1}}],["tp",{"2":{"132":1,"739":2,"742":2,"749":7,"778":4,"802":7,"807":5,"848":5,"915":2,"998":3}}],["t+g",{"2":{"273":1}}],["t+1",{"2":{"251":2,"273":9}}],["t+f",{"2":{"208":2,"273":1}}],["t+δt",{"2":{"208":12,"273":8}}],["t+c",{"2":{"140":1,"280":1}}],["t+",{"2":{"111":1,"140":3,"208":35,"236":1,"251":1,"273":14,"280":3}}],["tx2嵌入式计算机上的计时",{"0":{"836":1}}],["tx2",{"2":{"605":1,"836":1}}],["tx2计算机上测试kimera",{"2":{"131":1}}],["tx0​→xt​",{"2":{"140":1,"280":1}}],["tx",{"2":{"111":1,"140":4,"236":1,"280":4,"375":1,"390":1}}],["txt​",{"2":{"111":1,"188":2,"236":1}}],["txt−1​→xt​",{"2":{"111":1,"140":1,"236":1,"280":1}}],["txt",{"2":{"107":2,"152":1}}],["t≈2000t",{"2":{"111":1,"236":1}}],["tz",{"2":{"111":1,"236":1}}],["t=25",{"2":{"568":1}}],["t=9",{"2":{"568":1}}],["t=5",{"2":{"568":1}}],["t=18",{"2":{"568":1}}],["t=1",{"2":{"568":1}}],["t=∇θ​edata​",{"2":{"235":1}}],["t=∇θedata",{"2":{"235":1}}],["t=",{"2":{"111":2,"236":2,"273":1,"693":2}}],["tucker",{"2":{"525":1}}],["turner和zakhor",{"2":{"967":1}}],["turk",{"2":{"826":1}}],["turennout",{"2":{"525":1}}],["turtlesim",{"2":{"97":2}}],["tuna",{"2":{"76":1}}],["tuning",{"2":{"75":1,"220":1}}],["tudo",{"2":{"57":1}}],["tuxfamily",{"2":{"47":1}}],["tw",{"2":{"375":1}}],["two",{"2":{"137":1,"333":1,"379":2,"452":1,"500":1,"616":5}}],["twoslash",{"2":{"57":1}}],["twitter",{"2":{"57":1}}],["tianhe",{"2":{"914":1}}],["tian等人",{"2":{"735":1,"757":1}}],["ti的计算能力明显低于rtx",{"2":{"859":1}}],["ti",{"2":{"816":1}}],["ti∈r4×4∣i=1",{"2":{"693":1}}],["ticmis",{"2":{"276":1}}],["ti​∈r4×4∣i=1",{"2":{"693":1}}],["ti​",{"2":{"273":1}}],["tiu",{"2":{"149":1}}],["tilde",{"2":{"137":12,"140":4,"153":16,"175":2,"280":4,"390":3,"524":1,"595":6,"681":3}}],["title=",{"2":{"126":1}}],["title=main",{"2":{"47":1}}],["title",{"2":{"57":3}}],["times",{"2":{"345":4,"412":1,"532":4,"590":2,"609":15,"621":31,"638":1,"649":3,"652":6,"656":2,"660":1,"676":21,"677":2,"682":11,"693":6,"694":2,"705":1,"712":8,"716":2,"724":2,"738":3,"746":17,"749":4,"752":3,"766":1,"771":3,"780":4,"793":4,"814":1,"828":2,"853":2,"867":1,"910":6,"916":2,"928":3,"957":2,"998":2}}],["times6464×64×64×64",{"2":{"303":1,"328":1}}],["times64",{"2":{"278":1,"303":2,"328":2}}],["times32",{"2":{"278":1}}],["times16",{"2":{"278":1}}],["times8",{"2":{"278":1}}],["timestamp",{"2":{"254":3}}],["time",{"2":{"30":1,"43":2,"51":2,"102":1,"519":1,"776":1}}],["t>>",{"2":{"40":1}}],["third",{"2":{"685":1}}],["this",{"2":{"38":1,"57":4,"64":2,"67":1,"315":1,"366":2}}],["than",{"2":{"500":1}}],["that",{"2":{"11":1,"158":1,"327":3,"366":3,"379":1,"384":2,"496":1,"500":1,"671":1}}],["th",{"2":{"375":1,"741":1}}],["threshold",{"2":{"328":1}}],["through",{"2":{"170":1,"384":2}}],["thrun",{"2":{"123":3,"155":1,"209":1,"525":1,"648":2,"961":1}}],["thus",{"2":{"158":1,"496":1,"659":1}}],["thomas",{"2":{"481":1,"588":1}}],["thor",{"2":{"139":1}}],["though",{"2":{"64":1}}],["them",{"2":{"379":1,"496":1,"729":1}}],["themes",{"2":{"57":1}}],["these",{"2":{"379":1,"384":1}}],["thereby",{"2":{"379":1}}],["then",{"2":{"315":1,"365":1,"384":1,"496":1}}],["thetaθ",{"2":{"153":1,"728":1,"813":1}}],["theta",{"2":{"153":3,"213":3,"225":1,"235":25,"304":1,"342":1,"621":2,"712":6}}],["the",{"2":{"38":2,"64":2,"66":2,"67":1,"120":1,"137":1,"158":2,"164":2,"183":1,"235":1,"315":6,"327":13,"333":1,"365":1,"366":3,"379":3,"382":1,"384":1,"405":2,"440":1,"452":4,"496":26,"500":2,"518":7,"616":11,"623":1,"659":1,"671":2,"700":2,"729":8,"741":2,"941":2,"949":3}}],["tsurft",{"2":{"372":2}}],["tsurf​的顶点和边",{"2":{"372":1}}],["tsurf​",{"2":{"372":4}}],["tsintotas",{"2":{"189":1}}],["tsinghua",{"2":{"76":1,"395":2}}],["ts",{"2":{"57":1,"417":1,"447":2,"478":1,"507":1}}],["tsv",{"2":{"32":2,"38":2}}],["tsdf^",{"2":{"870":2}}],["tsdf",{"2":{"31":14,"253":1,"362":1,"603":2,"870":2,"917":2,"978":2}}],["terrain",{"2":{"790":2}}],["term",{"2":{"500":1}}],["teed",{"2":{"588":1}}],["ten",{"2":{"571":1}}],["tensors",{"2":{"589":1}}],["tensors=",{"2":{"373":1}}],["tensor",{"0":{"385":1},"2":{"351":8,"623":1}}],["tensorrt构建",{"2":{"27":1}}],["tellex",{"2":{"525":1,"806":1}}],["tesla",{"2":{"519":1}}],["tested",{"2":{"700":1}}],["testing",{"2":{"75":1}}],["test",{"2":{"11":1,"43":4,"51":4,"327":5,"519":1}}],["techniques",{"0":{"431":1}}],["technology",{"2":{"387":1}}],["teaser++",{"2":{"352":1,"449":1}}],["tetrahedra",{"2":{"247":2}}],["temperature",{"2":{"184":1}}],["temp容器元素为0",{"2":{"93":1}}],["temp",{"2":{"93":1}}],["template>",{"2":{"57":2}}],["textit",{"2":{"712":1}}],["text2image",{"0":{"461":1}}],["texts",{"2":{"184":1}}],["text",{"0":{"373":1,"452":1},"2":{"31":3,"57":4,"135":1,"153":4,"184":4,"185":1,"201":1,"208":5,"235":1,"268":1,"273":1,"319":1,"373":12,"390":1,"401":1,"428":1,"437":2,"452":3,"464":1,"469":2,"532":4,"590":6,"595":2,"621":33,"632":8,"649":11,"656":2,"666":2,"670":13,"676":34,"682":15,"693":2,"694":14,"699":13,"704":4,"705":12,"716":5,"728":1,"738":5,"749":14,"750":32,"752":3,"766":13,"780":2,"794":10,"802":13,"807":12,"814":3,"834":11,"848":2,"853":2,"870":14,"910":3,"916":22,"928":5,"957":5,"976":3,"978":4,"988":1,"989":4,"998":5}}],["taylor等人",{"2":{"967":1}}],["tan等人",{"2":{"967":1}}],["tang等人",{"2":{"1004":1}}],["tang",{"2":{"525":1,"648":1}}],["ta",{"2":{"958":1}}],["tau",{"2":{"957":2}}],["tauτ",{"2":{"328":1,"957":1}}],["tatarchenko",{"2":{"955":1}}],["tateno",{"2":{"209":2}}],["tateno等人",{"2":{"116":1,"967":3}}],["talha",{"2":{"619":1}}],["taming",{"2":{"317":1}}],["tamp",{"2":{"123":1}}],["taketomi",{"2":{"209":1}}],["takmaz等人",{"2":{"121":1}}],["tar",{"2":{"268":1}}],["tardós",{"2":{"189":1}}],["target",{"0":{"582":1},"2":{"143":1,"715":2}}],["targetstring",{"2":{"52":1}}],["taheri",{"2":{"123":1,"209":1}}],["task在开放集召回率上严格比它们的任务不可知版本差",{"2":{"462":1}}],["task和conceptgraphs",{"2":{"431":1,"462":1}}],["task",{"2":{"80":1,"106":2,"139":3,"153":1,"180":1,"431":1,"550":1}}],["tasks",{"0":{"110":1},"1":{"123":1,"139":1},"2":{"23":1,"34":8,"100":1,"659":1}}],["table",{"2":{"700":1,"979":1}}],["tables",{"2":{"57":1}}],["tab补全名字",{"2":{"66":1}}],["tab=readme",{"2":{"30":1,"369":1,"687":1}}],["tag8",{"2":{"676":1}}],["tag7",{"2":{"676":1}}],["tag6",{"2":{"676":1}}],["tag5",{"2":{"649":1}}],["tag4",{"2":{"621":1}}],["tag3",{"2":{"532":1,"621":1}}],["tag2",{"2":{"532":1}}],["tag1",{"2":{"532":1,"670":1}}],["tag",{"2":{"32":1,"38":1,"464":2,"524":1,"590":1,"621":1,"647":1}}],["taioli",{"2":{"765":1}}],["taioli等人",{"2":{"121":1}}],["tai",{"2":{"23":1,"252":1}}],["tree",{"2":{"605":1,"635":1,"663":1,"776":1,"906":1}}],["tr",{"2":{"390":1}}],["triangle",{"2":{"950":3}}],["triangles",{"2":{"379":1}}],["trigger",{"2":{"120":1}}],["trafficcone",{"2":{"702":1,"790":1}}],["traffic",{"2":{"702":1,"790":1}}],["traveller59",{"2":{"500":1}}],["trabucco",{"2":{"350":1}}],["trajectory",{"2":{"437":1,"826":2}}],["trajectory时",{"2":{"437":1}}],["traj",{"2":{"334":8,"417":1}}],["track",{"2":{"206":1}}],["tracking",{"0":{"158":1},"2":{"158":1}}],["tradeoff",{"2":{"164":2}}],["transpose",{"2":{"333":1}}],["transporter",{"2":{"123":1}}],["transport",{"2":{"120":1}}],["translation",{"2":{"254":3,"289":1,"379":1,"654":4}}],["transfusion",{"2":{"512":1}}],["transfer",{"2":{"469":2}}],["transferable",{"2":{"135":1}}],["transformation",{"2":{"550":1}}],["transform",{"2":{"410":1}}],["transformer中",{"2":{"695":1}}],["transformer中讲的",{"2":{"659":1}}],["transformer没毛病",{"2":{"631":1}}],["transformer这篇论文的研究动机就是想告诉大家用",{"2":{"631":1}}],["transformer引入了分层结构",{"2":{"627":1}}],["transformerlayers=dict",{"2":{"623":1}}],["transformer的新颖的端到端3d实例分割方法",{"2":{"349":1}}],["transformer的泛化能力和扩散模型的细节保存能力相结合",{"2":{"294":1}}],["transformer并不对输入进行任何先验的假设",{"2":{"343":1}}],["transformers",{"2":{"317":1,"373":1,"410":1,"420":1,"659":1}}],["transformer擅长捕捉文本和图像中的语义结构",{"2":{"294":1}}],["transformer",{"0":{"488":1,"602":1,"740":1},"1":{"518":1,"549":1,"631":1,"659":1,"683":1,"706":1,"729":1,"751":1,"762":1},"2":{"123":1,"174":1,"184":2,"252":1,"315":1,"323":2,"333":6,"349":1,"351":2,"369":1,"377":1,"384":1,"405":6,"414":1,"425":1,"457":1,"473":1,"488":3,"517":1,"518":1,"549":3,"564":2,"588":1,"620":1,"623":1,"631":5,"637":1,"659":6,"678":1,"699":1,"715":1,"729":1,"765":1,"824":1}}],["trailer",{"2":{"702":2,"790":2}}],["trainval",{"2":{"327":3}}],["train",{"0":{"184":1},"2":{"111":1,"236":1,"384":1}}],["trained",{"2":{"84":2,"384":1,"519":1}}],["training",{"0":{"124":1,"257":1},"2":{"75":1,"106":4,"235":2,"243":1,"290":1,"296":1,"315":1,"366":1,"518":1,"593":1,"692":2,"715":2}}],["traits",{"2":{"40":1}}],["truck",{"2":{"702":2,"790":2}}],["truncation=true",{"2":{"373":1}}],["truncated",{"2":{"31":2}}],["true",{"2":{"146":1,"479":1}}],["truth的k个bbox和预测出的100个bbox作为二分图的两个集合",{"2":{"358":1}}],["truth的iou在0",{"2":{"347":2}}],["truth",{"2":{"84":1,"358":2,"429":1}}],["trt表示使用tensorrt",{"2":{"1001":1}}],["trt=off来禁用此功能",{"2":{"27":1}}],["trt",{"2":{"20":1}}],["try",{"2":{"11":1,"135":1}}],["t",{"2":{"11":1,"31":2,"40":3,"52":1,"93":2,"104":6,"111":27,"124":10,"140":121,"153":1,"161":1,"171":2,"175":11,"184":15,"188":4,"208":222,"235":2,"236":27,"251":6,"256":1,"257":10,"268":2,"273":88,"278":1,"280":121,"304":1,"312":1,"316":16,"338":1,"355":1,"390":2,"422":5,"435":3,"513":5,"524":2,"549":2,"550":1,"595":3,"638":1,"682":11,"693":2,"694":3,"716":6,"728":3,"780":15,"854":1,"877":1,"904":5,"950":2,"957":8,"958":1}}],["toolbox",{"2":{"978":1}}],["tools",{"2":{"27":1,"32":1,"38":1,"43":1,"51":1,"69":1,"605":1}}],["tommaso",{"2":{"958":1}}],["tomatis",{"2":{"648":2}}],["tomasi角点",{"2":{"310":1}}],["tong等人",{"2":{"735":1}}],["total",{"2":{"670":2,"690":1,"834":1,"916":4}}],["toc",{"2":{"650":1}}],["toco",{"0":{"528":1},"1":{"559":1,"591":1}}],["to2l是从占据坐标到激光雷达坐标的变换矩阵",{"2":{"638":1}}],["to2l​×po​",{"2":{"638":1}}],["to2l×po",{"2":{"638":1}}],["tourani",{"2":{"209":1}}],["touppercase",{"2":{"57":1}}],["token适配器",{"2":{"478":1}}],["tokenizer",{"2":{"373":4}}],["tokens",{"2":{"254":2,"315":1,"518":2,"559":1,"654":1}}],["token",{"0":{"559":1},"2":{"128":1,"254":29,"327":2,"334":2,"504":1,"518":2,"528":1,"534":3,"591":6,"654":6,"692":1}}],["torchsparse的优化策略包括",{"2":{"593":1}}],["torchsparse++",{"2":{"593":2}}],["torchsparse",{"0":{"593":1},"2":{"593":1}}],["torchvision",{"2":{"333":1}}],["torch",{"2":{"124":3,"257":3,"333":7,"351":6,"623":1}}],["topometric",{"2":{"648":1,"864":1}}],["topology",{"2":{"496":2}}],["topological",{"2":{"80":1,"378":1,"465":1,"525":1}}],["top",{"2":{"138":1,"153":1,"316":1,"616":2,"741":1,"753":1,"774":1}}],["topic",{"2":{"120":1,"152":1}}],["towards",{"0":{"117":1},"2":{"149":1}}],["todo>",{"2":{"57":1}}],["todo",{"2":{"57":3}}],["tolong",{"2":{"57":1}}],["to",{"0":{"53":1,"857":1},"1":{"64":1,"74":1,"874":1,"891":1},"2":{"5":1,"11":1,"17":1,"38":1,"57":4,"63":2,"64":2,"66":2,"74":2,"94":1,"111":1,"124":2,"153":1,"175":2,"184":2,"185":1,"220":1,"235":2,"236":1,"257":2,"296":1,"315":1,"327":2,"333":2,"373":3,"379":3,"384":2,"410":1,"423":2,"428":1,"434":1,"452":1,"496":7,"500":2,"518":2,"616":1,"654":2,"659":4,"780":1,"839":1,"904":1,"914":1,"941":1,"949":1,"957":2}}],["d表示深度图",{"2":{"997":1}}],["d传感相结合的基于cpu的方法",{"2":{"967":1}}],["d传感器数据",{"2":{"168":1}}],["d相机",{"2":{"967":1}}],["d相机的3d点云的侧视图",{"2":{"686":1}}],["d相机的流数据",{"2":{"285":1}}],["d^2",{"2":{"916":2}}],["dh×w×d的",{"2":{"752":1}}],["d=10+∣c∣d",{"2":{"693":1}}],["d=11+∣c∣d",{"2":{"563":1}}],["d或深度输入来预测三维场景的语义空间占用",{"2":{"682":1}}],["d或密集立体视觉的深度图和2d语义标签来获取度量",{"2":{"285":1}}],["dz​",{"2":{"676":3,"699":1}}],["dz",{"2":{"676":7,"699":4}}],["dvio已经实现了非常准确的定位",{"2":{"754":1}}],["dvio姿态",{"2":{"709":3}}],["dvio",{"2":{"662":1}}],["d树来实现特征学习和聚集",{"2":{"636":1}}],["d树来构建",{"2":{"636":1}}],["d序列",{"2":{"629":1}}],["d序列或对象检测中推断对象和关系",{"2":{"125":1}}],["d×h×wd",{"2":{"609":1}}],["d435i传感器的",{"2":{"947":1}}],["d435i的深度流质量",{"2":{"872":1,"947":1}}],["d435i",{"2":{"686":1}}],["d435i更密集",{"2":{"605":1}}],["d435i已经提供了kimera",{"2":{"605":1}}],["d435i设备和一个nvidia",{"2":{"605":1}}],["d435i设备",{"2":{"605":1}}],["d和imu数据",{"2":{"605":2}}],["dl",{"2":{"585":1}}],["dpam在语义空间中动态地挖掘点之间的关系并聚集点",{"2":{"574":1}}],["dpam",{"2":{"574":1}}],["d摄像机和里程计作为clio的输入",{"2":{"522":1}}],["dubé等人",{"2":{"967":2}}],["duy",{"2":{"958":1}}],["due",{"2":{"659":2}}],["dunn",{"2":{"588":1}}],["duvallet",{"2":{"525":1,"648":1,"698":1}}],["during",{"2":{"518":1,"519":1,"700":1}}],["dual",{"0":{"488":1,"518":1},"1":{"518":1,"549":1},"2":{"315":2,"518":2}}],["duan等人",{"2":{"420":1}}],["duan",{"2":{"90":1}}],["dᵢⱼ",{"2":{"435":2}}],["django",{"2":{"395":1}}],["django¹",{"2":{"395":1}}],["djs​",{"2":{"153":1}}],["djsd",{"2":{"153":1}}],["dmetric",{"2":{"705":1}}],["dmetric​",{"2":{"705":2}}],["dmetricd",{"2":{"705":1}}],["dm",{"2":{"552":1,"709":1}}],["dmax",{"2":{"390":1}}],["dmtet",{"0":{"247":1},"1":{"269":1,"293":1,"318":1,"344":1,"372":1,"400":1,"429":1,"460":1},"2":{"215":1,"247":1}}],["dcist",{"2":{"467":1}}],["dcn系列的扩展具有以下几个特性",{"2":{"863":1}}],["dcnv3",{"0":{"863":1},"2":{"824":1,"863":1}}],["dcnv2的调制因子通过sigmoid进行归一化处理",{"2":{"863":1}}],["dcnv2的不同卷积单元具有独立的线性投影权值",{"2":{"863":1}}],["dcnv2往往作为常规卷积的扩展",{"2":{"863":1}}],["dcnv2",{"0":{"844":1},"2":{"824":1,"844":1}}],["dcn",{"0":{"824":1},"1":{"844":1,"863":1,"880":1,"896":1,"912":1},"2":{"386":1,"421":1,"562":1,"616":3,"677":1,"746":1,"768":1,"771":1,"779":1,"822":1,"865":1,"867":1}}],["dcmake",{"2":{"27":1}}],["d获得",{"2":{"362":1}}],["d2≤χ3",{"2":{"916":2}}],["d2−d1",{"2":{"355":1}}],["d2​−d1​",{"2":{"355":1}}],["d2​",{"2":{"355":1}}],["d2",{"2":{"355":1,"916":2}}],["d1d",{"2":{"411":2}}],["d1​",{"2":{"355":1,"592":1}}],["d1",{"2":{"355":1,"592":3}}],["d|",{"2":{"351":1}}],["d节",{"2":{"320":1}}],["dynrsl",{"2":{"260":1,"447":1}}],["dynamicfusion",{"2":{"967":1}}],["dynamics",{"0":{"256":1}}],["dynamic",{"2":{"94":1,"237":1,"648":1}}],["dgcnn",{"0":{"237":1},"1":{"258":1},"2":{"215":1,"258":1}}],["dx采样",{"2":{"208":1}}],["dx",{"2":{"208":3,"235":3}}],["dx=s",{"2":{"235":1}}],["dx=sθ​",{"2":{"235":1}}],["dx=sθ",{"2":{"235":1}}],["dx=",{"2":{"208":1}}],["dx=确定性f",{"2":{"208":1}}],["dx=f",{"2":{"208":2,"273":2}}],["dw​",{"2":{"208":1}}],["dw​​",{"2":{"208":1}}],["dwdx=",{"2":{"208":2}}],["dw=",{"2":{"208":1}}],["dw采样",{"2":{"208":1}}],["dw",{"2":{"208":5,"273":3}}],["dw⏟不确定性dx",{"2":{"208":1}}],["dtype=np",{"2":{"504":2,"534":1}}],["dtf",{"2":{"273":1}}],["dtδtε",{"2":{"273":1}}],["dt+g",{"2":{"208":4,"273":2}}],["dt​​+不确定性g",{"2":{"208":1}}],["dt",{"2":{"208":3,"273":1}}],["dt⏟确定性+g",{"2":{"208":1}}],["d图像流和姿态",{"2":{"206":1}}],["d图像帧",{"2":{"153":1}}],["drl",{"2":{"782":1}}],["droid",{"2":{"588":1}}],["drop",{"2":{"424":2}}],["dropout=dropout",{"2":{"174":3}}],["dropout=0",{"2":{"174":1,"623":1}}],["driess",{"2":{"864":1}}],["drift",{"2":{"208":1}}],["driveworld",{"2":{"1003":2}}],["driveable",{"2":{"790":2}}],["driveaction",{"2":{"360":2}}],["drivemonkey在此训练后在跨视角qa上显著提升",{"2":{"360":1}}],["drivemoe",{"2":{"283":1,"334":1,"360":1,"417":2,"507":1}}],["drivelm用于推理",{"2":{"447":1}}],["drivelm",{"2":{"334":1,"360":3}}],["drivegpt",{"2":{"260":1,"334":1}}],["driven",{"0":{"452":1},"2":{"153":1,"201":1,"452":2}}],["driver检索文本地图规则",{"2":{"478":1}}],["driver",{"2":{"128":1,"195":1,"283":1,"334":1,"507":1}}],["drive",{"2":{"114":1,"126":1}}],["driving",{"0":{"79":1},"2":{"62":1,"126":1}}],["draggan",{"0":{"127":1},"1":{"143":1,"158":1}}],["da",{"2":{"716":4,"957":4}}],["dai",{"2":{"588":1,"968":1}}],["dai等人",{"2":{"190":1,"390":1}}],["dal",{"2":{"512":1,"782":1}}],["dawei",{"2":{"477":1}}],["david",{"2":{"458":1}}],["davison",{"2":{"116":1}}],["danielming123",{"2":{"409":1,"445":1,"475":1,"545":1}}],["daniel等人",{"2":{"363":1}}],["daocc能够相对完整地预测场景",{"2":{"909":1}}],["daocc的三维占据预测和检测性能",{"2":{"893":1}}],["daocc的fps是在pytorch",{"2":{"840":1}}],["daocc具有优越性",{"2":{"820":1}}],["daocc通过在多模态框架内充分利用点云数据的独特优势来实现这一目标",{"2":{"820":1}}],["daocc比occfusion",{"2":{"779":1}}],["daocc不需要对激光雷达分支进行预训练",{"2":{"779":1}}],["daocc提高了1",{"2":{"779":1}}],["daocc以环绕图像及其相应的时间同步点云作为输入",{"2":{"576":1}}],["daocc实现了45",{"2":{"421":1}}],["daocc实现了53",{"2":{"421":1}}],["daocc在occ3d",{"2":{"392":1,"421":1}}],["daocc",{"0":{"364":1,"484":1},"1":{"392":1,"421":1,"451":1,"482":1,"512":1,"543":1,"576":1,"609":1,"638":1,"666":1,"690":1,"713":1,"736":1,"758":1,"779":1,"800":1,"820":1,"840":1,"859":1,"876":1,"893":1,"909":1},"2":{"392":1,"840":1}}],["datmo",{"2":{"967":1}}],["date",{"2":{"254":1}}],["dataroot",{"2":{"504":1,"534":1}}],["data是key",{"2":{"254":1}}],["data相关联的示例",{"2":{"254":1}}],["data指向时间最接近的样本",{"2":{"254":1}}],["data对应于带注释的激光雷达pointcloud",{"2":{"254":1,"534":1}}],["data之间的映射",{"2":{"254":1,"534":1}}],["datasets",{"2":{"366":1}}],["dataset",{"2":{"126":1,"455":1,"739":1}}],["data的新文件夹",{"2":{"32":1}}],["data",{"2":{"32":9,"34":2,"38":10,"43":1,"51":1,"60":1,"80":1,"106":2,"120":2,"136":4,"149":1,"183":1,"235":17,"254":6,"360":2,"382":1,"476":1,"500":1,"504":2,"525":1,"534":2,"654":10,"938":1}}],["dataloader",{"2":{"11":2}}],["dsg从uhumans复制并形成一个网格状的办公室区域",{"2":{"947":1}}],["dsg从kimera",{"2":{"285":1}}],["dsg上的路径规划性能",{"0":{"947":1}}],["dsg还为涉及自然语言的高级路径规划查询提供了强大的工具",{"2":{"939":1}}],["dsg提供的多个抽象层次有潜力启用层次和多分辨率规划方法",{"2":{"930":1}}],["dsg提供了一个框架",{"2":{"905":1}}],["dsg继承了标准场景图提供的记忆优势",{"2":{"905":1}}],["dsgs为",{"2":{"905":1}}],["dsg能够构建一个有意义的场景dsg",{"2":{"872":1}}],["dsg能够无缝捕捉动态环境的度量和语义方面",{"2":{"105":1}}],["dsg构建包含对象和代理的第二层",{"2":{"285":1}}],["dsg的层次性质确保了较高层的边界框包含较低层的边界框",{"2":{"905":1}}],["dsg的模块在kimera",{"2":{"816":1}}],["dsg的架构",{"2":{"285":1}}],["dsg的第二个确保属性是其组合性",{"2":{"262":1}}],["dsg的组合",{"2":{"262":1}}],["dsg的底层是一个语义注释的3d网格",{"2":{"162":1}}],["dsg中房间之间的边正确表示了房间之间的可通行性",{"2":{"872":1}}],["dsg中的地方和对象的",{"2":{"939":1}}],["dsg中的较高层是场景的更紧凑和抽象的表示",{"2":{"905":1}}],["dsg中的房间层准确地表示了场景的布局",{"2":{"872":1}}],["dsg中的边捕捉时空关系",{"2":{"131":1}}],["dsg中",{"2":{"449":1}}],["dsg中节点的选择不是唯一的",{"2":{"262":1}}],["dsg也捕捉了每个房间中包含的对象",{"2":{"218":1}}],["dsg包括以下模块",{"2":{"131":1}}],["dsg负责构建场景的dsg",{"2":{"131":1}}],["dsg是一个层次表示",{"2":{"131":1}}],["dsg是一个分层有向图",{"2":{"131":1,"147":1}}],["dsg是一个分层图",{"2":{"105":1,"131":1,"147":1}}],["dsg",{"2":{"105":1,"125":3,"131":2,"147":1,"162":1,"285":6}}],["dsemantic",{"2":{"27":1}}],["ddr",{"2":{"752":1,"982":3}}],["ddd",{"2":{"355":2,"429":1,"649":1,"676":1,"693":1,"704":1,"705":2,"910":1,"950":1}}],["ddim",{"0":{"144":1}}],["ddpm的噪声假设",{"2":{"316":1}}],["ddpm模型已经在无条件生成方面取得了显著的成就",{"2":{"289":1}}],["ddpm",{"0":{"91":1,"194":1,"224":1,"279":1},"2":{"81":1,"118":1,"175":1,"273":2,"382":1}}],["dd",{"2":{"26":1,"254":1,"274":1}}],["dfa3d",{"2":{"866":2,"914":1}}],["dfa",{"2":{"595":4}}],["df",{"2":{"24":1}}],["dfm",{"0":{"23":1}}],["dou等人",{"2":{"967":1}}],["double型变量",{"2":{"63":1}}],["dong等人",{"2":{"967":2}}],["does",{"2":{"327":2,"496":1}}],["domain",{"2":{"289":1,"313":1,"399":1}}],["dominic",{"2":{"34":3}}],["dosovitskiy",{"2":{"274":1}}],["document",{"2":{"256":1}}],["docker容器使用mobaxterm连接",{"2":{"78":1}}],["docker",{"0":{"11":1,"50":1},"1":{"17":1,"60":1,"69":1,"78":1},"2":{"11":1,"30":1,"60":3,"78":1}}],["dobrevski",{"2":{"252":1}}],["dog",{"2":{"204":1}}],["dot",{"2":{"184":3,"235":1,"379":2,"654":2}}],["dots0",{"2":{"153":1}}],["dots",{"2":{"153":1,"563":2,"590":1,"621":1,"682":1,"693":4,"705":1,"716":3,"724":2,"728":1,"738":2,"746":2}}],["downsampling",{"2":{"345":1}}],["downstream",{"2":{"23":1}}],["down",{"2":{"66":1,"138":1}}],["down是上面建立的",{"2":{"66":1}}],["deq",{"2":{"904":20,"918":6,"929":10}}],["deque是可以两边扩展的",{"2":{"938":1}}],["deque是一个双向队列",{"2":{"685":1}}],["deque与",{"2":{"938":1}}],["deque>",{"2":{"888":1}}],["dequeue",{"2":{"835":1,"871":1}}],["deque",{"0":{"871":1},"1":{"888":1,"904":1,"918":1,"929":1,"938":1},"2":{"685":1,"871":1,"888":8,"904":1,"929":1,"938":3}}],["de",{"2":{"390":1,"914":1}}],["deem",{"2":{"366":1}}],["deeper",{"2":{"659":1}}],["deep",{"0":{"54":1},"2":{"54":1,"57":3,"126":1,"247":1,"345":1}}],["designs",{"2":{"776":1}}],["description",{"2":{"254":4}}],["desktop",{"2":{"76":1}}],["deartifacts等",{"2":{"220":1}}],["dehze",{"2":{"220":1}}],["delmerico和scaramuzza",{"2":{"634":2}}],["delaunay三角剖分",{"2":{"336":1}}],["dellaert和kaess",{"2":{"419":1}}],["dellaert",{"2":{"171":1,"310":1,"525":1}}],["deltaδ",{"2":{"970":1}}],["deltaδˉ",{"2":{"153":2}}],["delta",{"2":{"153":7,"208":62,"268":6,"273":23,"372":6,"595":9,"696":1,"705":11,"716":2,"833":1,"844":4,"863":3}}],["delete",{"2":{"57":1}}],["deformsslice",{"2":{"962":1}}],["deformable",{"0":{"386":1,"616":1,"645":1,"696":1,"804":2},"1":{"645":1,"672":2,"696":2,"719":1,"741":1,"763":1,"784":1},"2":{"514":1,"584":1,"616":2,"623":1,"804":1}}],["defomable",{"0":{"719":1},"1":{"741":1,"763":1}}],["defferrard等人",{"2":{"607":1}}],["default",{"2":{"333":1}}],["def",{"2":{"124":1,"174":3,"257":1,"333":2,"351":2,"379":3,"623":1}}],["deng",{"2":{"588":1}}],["deng³",{"2":{"477":1}}],["denote",{"2":{"452":1}}],["denoise",{"2":{"220":1}}],["denoiser",{"2":{"198":1}}],["denoising",{"0":{"101":1,"214":1,"264":1,"266":1,"312":1},"1":{"111":1,"124":1,"140":1,"236":1,"257":1,"280":1,"289":1},"2":{"201":2,"264":1,"266":1,"312":1,"382":2}}],["density",{"2":{"235":1}}],["densepoint",{"2":{"481":1}}],["denseclip",{"2":{"469":1}}],["dense",{"0":{"556":1},"1":{"588":1,"619":1},"2":{"30":2,"80":1,"158":1,"378":1,"465":1,"469":2,"659":1,"746":1,"776":1,"839":1}}],["deitke",{"2":{"90":1,"806":1}}],["decoding",{"2":{"496":1}}],["decoder架构的图像压缩模型",{"2":{"345":1}}],["decoder",{"0":{"405":1,"441":1,"457":1,"488":1},"1":{"434":1,"518":1,"549":1},"2":{"174":1,"315":1,"333":4,"377":1,"384":2,"457":1,"518":1,"623":2,"877":1}}],["declared",{"2":{"67":1}}],["decay",{"2":{"40":3}}],["demonstrated",{"2":{"496":1}}],["demo",{"0":{"81":1},"2":{"57":1}}],["debris",{"2":{"702":1,"790":1}}],["deblur",{"2":{"220":1}}],["deblurring",{"0":{"148":1},"1":{"164":1,"180":1,"198":1,"220":1},"2":{"148":2}}],["deb",{"2":{"36":2,"76":1}}],["detrtransformerdecoderlayer",{"2":{"623":1}}],["detr中",{"2":{"386":1}}],["detr问题",{"2":{"386":1}}],["detr3dtransformer",{"2":{"623":1}}],["detr3dcrossatten",{"2":{"623":1}}],["detr3d",{"2":{"341":1,"369":1,"414":2,"562":1}}],["detr则是将目标检测视为一个集合预测问题",{"2":{"333":1}}],["detr",{"0":{"333":1,"386":1,"414":1},"1":{"358":1,"443":1,"473":1,"501":1,"531":1,"562":1,"594":1,"623":1,"651":1},"2":{"333":5,"341":2,"359":1,"369":1,"489":1,"651":1}}],["detector",{"2":{"715":1}}],["detection",{"0":{"512":1},"1":{"576":1,"609":1,"638":1,"666":1,"690":1,"736":1,"758":1,"779":1,"800":1},"2":{"23":1,"30":1,"414":1,"562":1,"702":1,"763":1}}],["detesan",{"2":{"123":1}}],["details",{"2":{"41":1,"48":1,"106":1,"220":1,"351":1,"369":1,"508":1}}],["det",{"2":{"30":2,"550":1,"644":1,"666":1,"690":1}}],["devkit",{"0":{"504":1}}],["device",{"2":{"124":2,"257":2}}],["devices=0",{"2":{"43":1,"51":1}}],["devel",{"2":{"34":1,"120":3,"152":1}}],["dev",{"2":{"24":2,"26":1,"36":7,"120":4}}],["depthcontrast",{"0":{"394":1},"1":{"424":1,"454":1,"485":1}}],["depthcontrast同样认为局部特征的学习比较重要",{"2":{"313":1}}],["depth",{"2":{"23":1,"34":2,"106":1,"544":1,"560":1,"621":3,"649":3,"705":6,"766":2,"870":2,"941":1}}],["divides",{"2":{"741":1}}],["divided",{"2":{"315":1}}],["dict",{"2":{"623":2}}],["dice损失",{"2":{"585":1,"690":1}}],["di​",{"2":{"595":1}}],["diag",{"2":{"532":4,"656":4,"693":4}}],["diagram",{"2":{"228":1,"276":1}}],["dihedral",{"2":{"379":1}}],["dino",{"2":{"274":1,"765":1}}],["di",{"2":{"209":1,"592":1,"595":1}}],["dimension为256的全连接层",{"2":{"562":1}}],["dimensional",{"2":{"500":4,"589":1}}],["dimension",{"2":{"500":1}}],["dimensions",{"2":{"333":1}}],["dims=256",{"2":{"623":2}}],["dims",{"2":{"379":5,"623":1}}],["dim=1",{"2":{"623":1}}],["dim=3",{"2":{"351":1}}],["dim=256",{"2":{"333":1}}],["dim=",{"2":{"333":1,"351":1}}],["dim=context",{"2":{"174":1}}],["dim=dim",{"2":{"174":2}}],["dim=none",{"2":{"174":1}}],["dim=0",{"2":{"124":1,"257":1}}],["dim",{"2":{"174":8,"333":15,"351":2}}],["dij​",{"2":{"153":1}}],["dij​=",{"2":{"153":1}}],["dijd",{"2":{"153":1}}],["dij=",{"2":{"153":1}}],["dilu",{"2":{"128":1}}],["difs",{"2":{"870":1,"1000":1}}],["different",{"2":{"616":1,"700":1,"707":1}}],["differentiable",{"0":{"355":1}}],["differential",{"2":{"170":1,"287":1}}],["diff",{"2":{"589":1}}],["diffumask",{"2":{"439":2}}],["diffumasks",{"0":{"439":1}}],["diffuse",{"2":{"159":1}}],["diffusion中的ldm均采用一个随机初始化的tranformer模型来提取text的特征",{"2":{"373":1}}],["diffusion论文中实验了不同参数下的autoencoder模型",{"2":{"345":1}}],["diffusionclip",{"2":{"268":1}}],["diffusioncllp",{"0":{"268":1}}],["diffusion不仅节省了内存",{"2":{"248":1}}],["diffusion模型不直接在操作图像",{"2":{"205":1}}],["diffusion模型给出了不一样的方法",{"2":{"205":1}}],["diffusion的出现就是为了解决上述问题",{"2":{"205":1}}],["diffusion",{"0":{"101":1,"183":1,"208":1,"214":1,"244":2,"248":1,"264":1,"266":1,"312":1,"314":1,"365":1,"422":1,"428":1,"452":1,"513":1},"1":{"111":1,"124":1,"140":1,"203":1,"225":1,"236":1,"245":1,"257":1,"267":1,"280":1,"289":1,"291":1,"316":1,"342":1,"370":1,"398":1,"459":1},"2":{"124":1,"159":1,"163":1,"174":1,"175":2,"185":3,"195":1,"201":5,"205":3,"208":1,"248":1,"257":1,"264":1,"266":1,"268":1,"312":1,"314":1,"373":2,"382":2,"422":1,"428":4,"439":1,"452":3,"513":2}}],["diffvla通过pdms层减半错误",{"2":{"447":1}}],["diffvla",{"2":{"195":1,"308":1,"334":1}}],["diffseg",{"0":{"159":1},"1":{"174":1,"192":1,"212":1,"234":1,"255":1,"278":1,"303":1,"328":1,"353":1,"381":1,"410":1,"439":1,"469":1,"498":1,"528":1,"559":1,"591":1}}],["difussion",{"0":{"111":1,"236":1}}],["disfvol​=f2d​⊗dis",{"2":{"950":1}}],["disdisdis",{"2":{"950":1}}],["disentangled",{"2":{"384":1}}],["disco",{"2":{"205":1,"428":1}}],["discriminative",{"2":{"158":1}}],["discriminator",{"0":{"429":1},"2":{"129":1}}],["display",{"2":{"64":1,"74":1}}],["display问题",{"0":{"53":1},"1":{"64":1,"74":1},"2":{"74":1}}],["disp",{"2":{"60":1}}],["dist",{"2":{"916":4}}],["distill",{"2":{"694":2}}],["distillation",{"2":{"619":1}}],["distortion",{"2":{"136":2,"164":2}}],["distro",{"2":{"120":4}}],["distribution",{"2":{"66":1,"183":1,"382":1}}],["distributed",{"2":{"30":1}}],["distance",{"0":{"20":1},"2":{"31":3,"328":2}}],["did",{"2":{"40":1,"355":1,"411":1}}],["directly",{"2":{"434":1}}],["direction",{"2":{"268":1,"549":1}}],["directory把前面的覆盖掉了",{"2":{"48":1}}],["directory",{"2":{"17":2,"38":2}}],["dirs",{"2":{"43":3,"51":2}}],["dir",{"2":{"32":1,"38":1,"43":1,"51":1,"107":1}}],["dkl",{"2":{"13":1}}],["dkl​",{"2":{"13":2}}],["dkld",{"2":{"13":1}}],["d",{"0":{"653":1,"676":1,"694":1,"789":1,"803":1,"807":1,"866":1,"915":1},"2":{"11":1,"13":2,"36":3,"40":1,"60":1,"66":1,"76":1,"77":1,"129":4,"152":1,"153":2,"162":1,"174":1,"184":6,"189":2,"221":1,"273":4,"285":3,"325":3,"333":1,"334":2,"336":1,"355":4,"380":1,"383":1,"390":1,"405":1,"411":2,"440":2,"449":1,"452":1,"470":1,"480":1,"518":2,"522":1,"544":2,"585":1,"588":1,"592":2,"595":2,"609":1,"621":3,"622":5,"642":1,"647":2,"676":15,"694":6,"705":1,"712":4,"743":1,"752":1,"814":1,"824":1,"910":2,"928":1,"950":3,"967":1,"973":1}}],["db",{"2":{"5":3}}],["ae",{"2":{"962":1}}],["aeroastro",{"2":{"605":6}}],["a^进行监督也能够进一步提升所有指标",{"2":{"928":1}}],["a^",{"2":{"928":1}}],["a^m",{"2":{"752":1}}],["a6000和a100",{"2":{"859":1}}],["a6000",{"2":{"761":2,"840":1}}],["aap",{"2":{"757":1}}],["aaa作为高斯的先验分布",{"2":{"681":1}}],["aaai",{"2":{"323":1}}],["aaa",{"2":{"41":1}}],["aj​∑i=1p​p",{"2":{"681":1}}],["aj",{"2":{"681":1}}],["a40",{"2":{"677":1,"700":1,"744":1}}],["above",{"2":{"616":1}}],["abdulla",{"2":{"605":1}}],["absolute",{"2":{"549":1,"826":2}}],["abstract",{"0":{"322":1,"631":1},"2":{"256":1}}],["abs",{"2":{"84":1,"351":2,"577":1,"584":1}}],["a⃝",{"2":{"550":1}}],["a100",{"2":{"764":1,"840":1}}],["a10",{"2":{"545":1,"867":1,"965":1}}],["aydemir",{"2":{"525":1}}],["azure",{"2":{"947":1}}],["azure相机作为主要收集设备",{"2":{"437":1}}],["azim和aycard",{"2":{"419":1,"967":2}}],["ahn",{"2":{"410":1}}],["ahmed",{"2":{"189":1}}],["after",{"2":{"496":1}}],["affinity​",{"2":{"884":1}}],["affinity",{"2":{"410":2,"884":2}}],["affinitynet",{"0":{"410":1},"2":{"410":1}}],["afa",{"2":{"328":2,"420":1}}],["a+c",{"2":{"351":3}}],["a+x",{"2":{"66":1}}],["a节",{"2":{"210":1,"301":1,"320":1,"326":1}}],["av",{"2":{"520":1}}],["average",{"0":{"741":1},"2":{"496":1,"528":2}}],["averaging",{"2":{"180":1,"384":1}}],["avs通常配备多种传感器",{"2":{"438":1}}],["avs",{"2":{"409":1,"438":1,"475":1,"503":1,"564":1}}],["available",{"2":{"64":1}}],["a506df5756472e2ebaf9078affdde2c4f1502cd4",{"2":{"174":1}}],["a=βt​αt​​+1−αˉt−1​1​",{"2":{"140":1,"280":1}}],["a=αtβt+11−αˉt−1a",{"2":{"140":1,"280":1}}],["axis",{"2":{"550":1}}],["axis=0",{"2":{"184":1,"379":5}}],["axis=1",{"2":{"184":3,"379":1,"504":1}}],["axt−12​+bxt​+c",{"2":{"140":1,"280":1}}],["axt−12+bxt+c",{"2":{"140":1,"280":1}}],["ax^2",{"2":{"140":1,"280":1}}],["austin",{"2":{"458":1,"958":1}}],["augmentation",{"2":{"519":1}}],["aug",{"2":{"159":1}}],["audio",{"2":{"139":1}}],["autoencoders",{"2":{"692":2}}],["autoencoder模型时在openimages数据集上基于256x256大小训练的",{"2":{"345":1}}],["autoencoder",{"0":{"345":1}}],["autovla",{"2":{"334":2}}],["auto",{"2":{"196":1,"270":1,"290":1,"315":1,"571":2,"589":1}}],["autonomous",{"0":{"79":1},"2":{"62":1,"126":1}}],["author=",{"2":{"126":1}}],["amazon",{"2":{"826":1}}],["among",{"2":{"729":1,"863":1}}],["amotp",{"2":{"263":1}}],["amota",{"2":{"263":1,"671":1}}],["ambulance",{"2":{"702":1,"790":1}}],["ambiguity",{"2":{"379":1}}],["aml",{"2":{"124":2,"257":2}}],["amp",{"2":{"8":3,"90":2,"93":2,"104":7,"106":3,"111":2,"123":4,"140":20,"153":4,"161":2,"173":1,"189":2,"208":20,"209":13,"235":7,"236":2,"252":2,"273":11,"280":20,"357":9,"372":2,"390":4,"435":1,"495":3,"513":3,"525":5,"556":1,"588":3,"648":2,"666":2,"698":1,"743":1,"806":1,"826":1,"854":1,"904":6,"957":2}}],["agcn",{"2":{"607":1}}],["agapito",{"2":{"588":1}}],["aggregation",{"0":{"303":1}}],["agglomerative",{"2":{"121":1}}],["agent用l",{"2":{"417":1}}],["agent",{"2":{"283":1,"334":1,"360":1,"417":1}}],["agentdriver",{"2":{"128":1}}],["agnostic",{"0":{"43":1,"51":1},"2":{"80":1}}],["aigc",{"2":{"963":1}}],["aij​",{"2":{"950":1}}],["aija",{"2":{"950":1}}],["aicnetrgb^",{"2":{"870":2,"978":1,"989":2}}],["aicnet",{"2":{"870":1,"917":2,"978":2}}],["aic~i∑j=1pp",{"2":{"681":1}}],["ai​c~i​​",{"2":{"681":1}}],["ai​",{"2":{"656":1}}],["aia",{"2":{"656":1}}],["ai驾驶测试",{"2":{"478":1}}],["ai驾照",{"2":{"447":1}}],["ai使用了非常大规模的batch",{"2":{"184":1}}],["aided",{"2":{"163":1}}],["ai2",{"2":{"139":1}}],["ai",{"2":{"90":1,"139":4,"209":2,"656":1,"958":1}}],["aca1920",{"2":{"828":1}}],["aca1600",{"2":{"173":1}}],["ac",{"2":{"469":1}}],["accuracy",{"2":{"826":1}}],["accumulation",{"2":{"435":1}}],["acc",{"2":{"732":1}}],["accepts",{"2":{"384":1}}],["across",{"2":{"379":1}}],["activation",{"2":{"496":1,"528":1,"616":3}}],["activations",{"2":{"496":2}}],["active",{"2":{"189":1,"698":1}}],["action",{"0":{"79":1},"2":{"62":1}}],["achieves",{"2":{"671":1}}],["achieving",{"2":{"96":1}}],["achlioptas等人",{"2":{"420":1}}],["achour",{"2":{"90":1}}],["ad011012808",{"2":{"960":1}}],["adh表示辅助检测头",{"2":{"800":1}}],["adopted",{"2":{"384":1,"729":1}}],["adjacencies",{"2":{"496":1}}],["adjacent",{"2":{"379":1}}],["adjustment原理及应用",{"2":{"179":1}}],["adjustment",{"0":{"179":1},"2":{"163":1,"168":1,"420":1}}],["adriver",{"2":{"308":1,"334":1}}],["adult",{"2":{"254":1,"702":1,"790":1}}],["adabins",{"2":{"917":1,"978":3}}],["adabin",{"2":{"870":1}}],["adamw优化器",{"2":{"764":1}}],["adamw",{"2":{"677":1,"744":1,"761":1,"771":1,"853":1,"867":1}}],["adapter",{"2":{"685":1,"805":1}}],["adaptive",{"2":{"149":2,"616":1}}],["adaptation",{"2":{"84":1}}],["adain",{"2":{"149":2}}],["ad",{"2":{"82":1}}],["advanced",{"2":{"173":1}}],["adv",{"2":{"76":1}}],["addition",{"2":{"405":1}}],["additionally",{"2":{"518":1}}],["additional",{"2":{"315":1}}],["addneighbortofrontier",{"2":{"276":1}}],["add",{"2":{"36":2,"333":1}}],["aware​",{"2":{"705":2}}],["awarem",{"2":{"705":1}}],["aware",{"2":{"377":1,"434":1,"469":1,"705":3,"826":1}}],["await",{"2":{"57":1}}],["awesome",{"0":{"79":1},"2":{"62":1,"637":1}}],["asia",{"2":{"616":1}}],["aside",{"2":{"57":1}}],["aspp",{"2":{"603":1,"632":1,"752":1,"982":2}}],["astronaut",{"2":{"373":1}}],["astrapro",{"2":{"152":1}}],["astra",{"2":{"15":1,"120":4,"152":2}}],["association",{"2":{"525":1}}],["associated",{"2":{"327":2}}],["assign",{"2":{"161":4,"904":1}}],["assuming",{"2":{"120":1}}],["assert",{"2":{"67":1}}],["assertion",{"2":{"67":1}}],["as",{"2":{"67":1,"345":1,"365":1,"384":3,"496":1,"659":1}}],["ate",{"2":{"634":1,"686":3,"826":2}}],["atrous",{"2":{"603":1}}],["atlanta",{"2":{"387":1}}],["atanasov",{"2":{"209":1}}],["attribute",{"2":{"254":3,"327":1,"476":1,"654":1}}],["attn",{"2":{"174":1,"234":1,"255":1,"328":1,"623":1}}],["attn2",{"2":{"174":2}}],["attn1",{"2":{"174":2}}],["attending",{"2":{"518":1}}],["attend",{"2":{"159":1}}],["attention则实现rnn式的时序交互",{"2":{"740":1}}],["attention做多模态的条件扩散生成",{"2":{"459":1,"552":1}}],["attention的方式送入unet中",{"2":{"373":1}}],["attention的计算复杂度是随着序列长度的增长以平方级增长的",{"2":{"343":1}}],["attention",{"0":{"65":1,"234":1,"255":1,"278":1,"303":1,"328":1},"2":{"174":2,"384":1,"405":1,"410":1,"420":2,"513":1,"514":1,"562":1,"659":1,"729":3,"914":1}}],["at",{"2":{"57":1,"130":1,"217":1,"904":3,"929":1}}],["apolloscape",{"2":{"997":1}}],["apolloscapes",{"2":{"126":1}}],["appendix",{"0":{"895":1},"1":{"911":1,"924":1,"934":1}}],["approach",{"2":{"729":1}}],["approch",{"0":{"546":1},"1":{"579":1,"611":1,"640":1}}],["approx",{"2":{"111":1,"208":2,"225":1,"235":1,"236":1,"273":2,"916":2}}],["applies",{"2":{"839":1}}],["applied",{"2":{"315":1}}],["application",{"2":{"64":2}}],["app",{"2":{"57":3}}],["app2",{"2":{"41":1}}],["api抓取命令",{"2":{"522":1}}],["api",{"2":{"57":1}}],["ap",{"2":{"43":6,"51":6,"78":1,"263":1}}],["apartment",{"2":{"34":6}}],["apt",{"2":{"17":2,"27":1,"36":9,"59":1,"66":1,"69":4,"74":1,"76":4,"78":1,"120":1}}],["animal",{"2":{"702":1,"790":1}}],["anticipation",{"2":{"668":2}}],["ann",{"2":{"654":3,"997":1}}],["annotations",{"2":{"254":1,"439":1}}],["annotation",{"2":{"57":1,"254":4,"476":1,"654":3}}],["annotate",{"2":{"57":1}}],["annotated",{"2":{"32":2,"38":2,"162":1}}],["another",{"2":{"616":1}}],["angle",{"2":{"379":2}}],["angles",{"2":{"379":15}}],["any",{"2":{"327":2,"394":1,"776":1}}],["anything",{"2":{"30":1,"45":1,"617":1,"765":1}}],["anchors进行训练",{"2":{"321":1}}],["anchors+128个negative",{"2":{"321":1}}],["anchors",{"2":{"321":1,"328":1}}],["anchor",{"2":{"321":1,"333":1}}],["anchot",{"2":{"138":1}}],["answering",{"2":{"139":1}}],["anush",{"2":{"126":1}}],["anaconda3",{"2":{"64":1}}],["analysis",{"2":{"45":1}}],["an",{"2":{"30":2,"45":1,"204":1,"315":2,"373":1,"384":3,"525":1,"571":3,"589":1,"648":2,"729":1}}],["andriluka等人",{"2":{"967":2}}],["anderson等人",{"2":{"961":1}}],["anderson",{"2":{"139":2,"806":1}}],["and",{"0":{"155":1},"1":{"171":1,"189":1,"209":1},"2":{"23":1,"30":1,"45":1,"90":1,"102":1,"106":2,"126":9,"132":4,"135":2,"139":2,"158":1,"159":1,"287":1,"315":1,"333":3,"366":1,"379":3,"384":4,"399":1,"452":2,"469":2,"496":3,"593":1,"616":2,"623":1,"659":3,"668":2,"671":1,"700":1,"729":1,"741":3,"756":1,"839":1,"914":1,"941":1,"949":1,"976":1}}],["a",{"0":{"186":1,"232":1,"346":1,"352":1,"488":1,"497":1,"517":1,"564":1,"590":1,"613":1,"724":1,"739":1,"744":1,"808":1,"867":1,"885":1,"886":1,"911":1,"972":1,"978":1,"982":1},"1":{"206":1,"228":1,"253":1,"276":1,"374":1,"402":1,"431":1,"462":1,"518":1,"549":1,"978":1,"982":1},"2":{"27":1,"31":1,"40":1,"57":3,"63":2,"77":1,"92":1,"102":1,"111":2,"114":1,"124":2,"126":1,"133":2,"140":3,"149":2,"153":1,"158":1,"162":3,"174":1,"181":5,"185":1,"204":7,"236":2,"247":1,"257":2,"262":1,"276":2,"280":3,"285":4,"315":3,"325":4,"327":4,"345":1,"351":1,"366":1,"373":2,"379":6,"380":1,"384":12,"390":1,"419":2,"428":1,"434":1,"437":1,"450":1,"452":1,"480":1,"496":5,"500":3,"511":2,"515":2,"518":1,"519":1,"535":1,"552":1,"571":3,"605":2,"616":2,"656":2,"659":3,"660":1,"681":2,"686":3,"695":1,"707":1,"709":2,"729":1,"732":2,"741":3,"752":8,"756":1,"777":1,"800":2,"824":1,"853":1,"888":8,"900":1,"928":1,"929":2,"942":1,"950":1}}],["alzantot和youssef",{"2":{"967":1}}],["algorithm>",{"2":{"929":2}}],["alayrac",{"2":{"864":1}}],["ala​",{"2":{"328":1}}],["alvarez",{"2":{"458":1}}],["aldoma等人",{"2":{"419":1,"967":1}}],["also",{"2":{"384":1}}],["along",{"2":{"315":1,"863":1}}],["alex",{"2":{"126":1}}],["al",{"2":{"90":16,"123":18,"139":12,"155":4,"171":1,"189":17,"209":49,"252":7,"274":30,"350":8,"435":1,"495":14,"525":43,"556":5,"588":18,"619":18,"648":26,"698":22,"721":1,"743":4,"765":18,"806":14,"826":16,"864":4}}],["alt",{"2":{"66":1}}],["alias",{"2":{"66":2}}],["align的作用主要就是剔除了roi",{"2":{"554":1}}],["align的主要创新点是",{"2":{"554":1}}],["align",{"2":{"111":2,"140":12,"208":6,"236":2,"273":4,"280":12,"372":2,"513":2,"554":1}}],["aligned",{"2":{"32":1,"57":1,"67":2,"184":2}}],["alignment",{"2":{"23":1}}],["almost",{"2":{"45":1,"109":1}}],["allocentric",{"2":{"435":1,"495":3,"743":1}}],["alloc",{"2":{"67":1}}],["allocator",{"2":{"67":3}}],["all",{"2":{"43":3,"45":1,"51":3,"379":1,"518":1,"519":1,"842":1}}],["alphaplustt",{"2":{"392":1}}],["alphaα",{"2":{"153":1,"666":1,"988":1}}],["alphas",{"2":{"124":4,"257":4}}],["alpha",{"2":{"8":1,"111":16,"140":71,"153":2,"175":6,"188":2,"236":16,"273":5,"280":71,"316":7,"666":2,"681":11,"988":2}}],["arjun",{"2":{"973":1}}],["arnab等人",{"2":{"967":1}}],["armeni",{"2":{"648":1}}],["armeni等人",{"2":{"116":3,"125":1,"172":1,"178":1,"905":2,"961":3,"967":3}}],["arkin",{"2":{"525":2,"698":1}}],["arl",{"2":{"467":1}}],["arccos",{"2":{"379":1}}],["architecture",{"2":{"315":1,"729":1}}],["array",{"2":{"654":4}}],["arranged",{"2":{"315":1}}],["arr+5",{"2":{"261":1,"361":1,"389":1}}],["arr",{"2":{"261":1,"361":1,"389":1}}],["artal和tardós",{"2":{"967":1}}],["artal",{"2":{"189":2}}],["article",{"2":{"41":1,"48":1,"106":1,"126":1,"220":1,"351":1,"369":1,"508":1}}],["arange",{"2":{"184":1}}],["ars",{"2":{"173":1}}],["argoverse",{"2":{"997":1}}],["argmax",{"2":{"957":3}}],["argmin",{"2":{"470":1}}],["argminx1",{"2":{"390":2}}],["argx1​",{"2":{"390":1}}],["arg⁡min⁡x1",{"2":{"390":1}}],["args",{"2":{"104":4}}],["arg",{"2":{"30":1,"171":2,"390":3,"571":1}}],["arxiv",{"2":{"23":1,"62":1,"84":2,"96":1,"126":2,"205":1,"264":1,"266":1,"414":1,"445":1,"453":1,"514":1,"545":1,"577":1,"578":1,"584":1,"671":1,"776":1}}],["area5",{"2":{"979":1}}],["are",{"2":{"11":1,"57":2,"64":1,"315":1,"379":1,"519":2,"616":1,"700":1,"839":1}}],["γi​",{"2":{"789":2}}],["γi",{"2":{"789":2}}],["γ=1",{"2":{"728":2}}],["γ与训练次数t相关",{"2":{"329":1}}],["γγγ",{"2":{"206":1,"304":2}}],["γl",{"2":{"153":1}}],["γ",{"2":{"8":2,"304":2,"728":3}}],["0rc4",{"2":{"761":1}}],["0c0​",{"2":{"749":1,"802":1}}],["0c0​表示自由空间类别",{"2":{"632":1}}],["0≤i",{"2":{"741":1}}],["0或1",{"2":{"540":1}}],["0m时",{"2":{"686":1}}],["0m",{"2":{"480":1,"652":3,"800":2,"828":3}}],["0ab9ec2730894df2b48df70d0d2e84a9",{"2":{"476":1,"534":1}}],["0i0​",{"2":{"464":1}}],["0的iou和30",{"2":{"421":1}}],["05778",{"2":{"584":1}}],["05173",{"2":{"577":1}}],["05m",{"2":{"449":1}}],["05",{"2":{"277":1,"534":1,"686":12,"709":6,"764":1}}],["08m",{"2":{"793":3}}],["08",{"2":{"277":4,"476":1,"534":4,"686":8,"709":2,"917":1}}],["087",{"2":{"277":1,"534":1}}],["06211",{"2":{"616":1}}],["06922",{"2":{"414":1}}],["061",{"2":{"277":1,"534":1}}],["063",{"2":{"277":1,"534":1}}],["06",{"2":{"277":1,"437":1,"522":1,"534":1,"686":7,"709":13}}],["066",{"2":{"277":1,"534":1}}],["06045",{"2":{"136":1}}],["075",{"2":{"758":2}}],["070",{"2":{"277":1,"534":1}}],["072",{"2":{"277":1,"534":1}}],["07",{"2":{"277":3,"425":1,"534":3,"686":2,"709":4,"782":1}}],["024帧未标记帧",{"2":{"757":1}}],["02",{"2":{"277":2,"522":5,"534":2,"686":6}}],["02938v2",{"2":{"264":1,"266":1}}],["020",{"2":{"136":1}}],["0t0​",{"2":{"153":1}}],["0xt​",{"2":{"188":1}}],["0x5",{"2":{"120":1}}],["0x0​",{"2":{"111":1,"236":1}}],["0+p",{"2":{"741":1,"844":1}}],["0+",{"2":{"111":1,"140":1,"236":1,"273":2,"280":1,"672":1,"696":1}}],["09406",{"2":{"96":1}}],["09",{"2":{"43":3,"51":2,"277":1,"534":1,"686":2,"709":1,"803":1}}],["004",{"2":{"947":1}}],["00",{"2":{"277":5,"522":4,"534":5,"686":6,"971":2}}],["001",{"2":{"32":3,"38":2,"634":1,"700":1,"947":2}}],["000个场景的约390k",{"2":{"997":1}}],["000个点云和850个场景",{"2":{"534":1}}],["0007",{"2":{"828":1}}],["0008",{"2":{"828":1}}],["0001",{"2":{"761":1,"973":1}}],["000129",{"2":{"136":1}}],["000帧和17个语义类别",{"2":{"757":1}}],["000帧",{"2":{"757":1}}],["000人小时",{"2":{"735":1}}],["000000",{"2":{"136":1}}],["000417",{"2":{"136":1}}],["000",{"2":{"32":3,"38":2,"700":1,"780":1,"828":1,"947":2}}],["0400",{"2":{"476":1}}],["04032",{"2":{"136":1}}],["04398",{"2":{"84":1}}],["045",{"2":{"32":1}}],["04",{"2":{"15":1,"277":2,"522":1,"534":2,"686":4,"782":1}}],["03行",{"2":{"662":1}}],["03284",{"2":{"578":1}}],["03对vio来说更容易",{"2":{"572":1}}],["03",{"2":{"8":1,"277":1,"522":3,"534":1,"686":6,"709":6,"903":1}}],["03k1​=0",{"2":{"8":1}}],["03k",{"2":{"8":1}}],["0",{"2":{"8":1,"15":2,"17":4,"26":3,"31":1,"32":4,"36":1,"38":4,"40":2,"41":1,"43":14,"47":1,"48":1,"51":12,"52":2,"57":1,"63":1,"93":3,"104":1,"111":9,"115":1,"120":2,"124":6,"129":1,"130":1,"132":1,"136":23,"140":12,"146":1,"153":6,"161":1,"173":2,"175":1,"188":1,"196":1,"208":10,"220":1,"221":3,"235":1,"236":9,"251":2,"254":1,"256":1,"257":6,"271":1,"273":3,"277":31,"280":12,"301":1,"316":4,"327":6,"333":4,"351":3,"373":1,"379":7,"390":6,"431":5,"435":1,"476":3,"480":1,"522":55,"532":3,"534":32,"561":7,"592":3,"623":4,"632":1,"634":1,"651":1,"652":3,"660":1,"670":1,"671":1,"672":1,"677":1,"686":127,"696":1,"698":1,"700":2,"709":64,"712":12,"724":2,"732":1,"736":6,"739":2,"741":1,"744":2,"749":5,"758":9,"761":3,"771":1,"780":9,"787":1,"790":12,"793":3,"802":4,"803":2,"811":1,"827":2,"828":3,"840":2,"844":7,"848":5,"853":1,"863":3,"867":1,"893":4,"900":1,"910":1,"916":6,"917":3,"924":1,"928":1,"929":1,"931":2,"936":1,"945":1,"947":11,"989":1,"996":1,"998":8}}],["012",{"2":{"947":1}}],["01数据集的重建",{"2":{"754":1}}],["01数据集的网格重建",{"2":{"754":1}}],["01数据集的全局网格估计的云",{"2":{"686":1}}],["01数据集",{"2":{"686":1}}],["01数据集上不同循环闭合阈值α下的绝对平移误差",{"2":{"686":1}}],["01数据集优化了728个姿态节点和1031个网格节点",{"2":{"390":1}}],["01∣dreproj​−d1​∣",{"2":{"592":1}}],["01|d",{"2":{"592":1}}],["01比mh",{"2":{"572":1}}],["0181和onr",{"2":{"467":1}}],["01644",{"2":{"445":1,"545":1}}],["016",{"2":{"277":1,"534":1}}],["010000",{"2":{"32":2,"38":2}}],["01",{"2":{"8":3,"277":5,"476":1,"522":13,"534":5,"592":1,"662":1,"677":1,"686":4,"744":1,"758":1,"761":1,"771":1,"813":1,"822":1,"867":1,"971":1}}],["σ​",{"2":{"957":1}}],["σ=rsstrt",{"2":{"532":2,"656":2,"693":2}}],["σikmℓ​",{"2":{"623":1}}],["σikmℓ",{"2":{"623":1}}],["σi=1∣pv∣∑j∈pvηj",{"2":{"563":1}}],["σi​=∣pv​∣1​j∈pv​∑​ηj​",{"2":{"563":1}}],["σi​",{"2":{"532":1}}],["σi​∈",{"2":{"532":1}}],["σi",{"2":{"532":1}}],["σi∈",{"2":{"532":1}}],["σt2​",{"2":{"273":2}}],["σt2",{"2":{"273":2}}],["σt↑",{"2":{"251":1}}],["σ",{"2":{"171":1,"437":2,"532":2,"656":1,"693":1,"957":1}}],["σᵢ",{"2":{"171":1}}],["σₜ",{"2":{"171":1}}],["σ2​=a1​=βt​αt​​+1−αˉt−1​1​1​=1−αt​αˉt−1​βt​",{"2":{"140":1,"280":1}}],["σ2=a1​",{"2":{"140":1,"280":1}}],["σ2=1a=1αtβt+11−αˉt−1=βt",{"2":{"140":1,"280":1}}],["σ2=1a",{"2":{"140":1,"280":1}}],["σ2",{"2":{"140":2,"280":2}}],["σg",{"2":{"20":1}}],["σr",{"2":{"20":1}}],["σr​σg​",{"2":{"20":1}}],["σr​+σg​−2",{"2":{"20":1}}],["σrσg",{"2":{"20":1}}],["σr+σg−2",{"2":{"20":1}}],["σxy​",{"2":{"8":1}}],["σxy",{"2":{"8":1}}],["σx2",{"2":{"8":1}}],["σy2",{"2":{"8":1}}],["μ​=1−αˉt​αt​​",{"2":{"140":1,"280":1}}],["μ​=2ab​=",{"2":{"140":1,"280":1}}],["μ=αt",{"2":{"140":1,"280":1}}],["μ=2ab​",{"2":{"140":1,"280":1}}],["μ=b2a=",{"2":{"140":1,"280":1}}],["μ=b2a",{"2":{"140":1,"280":1}}],["μ",{"2":{"140":3,"280":3}}],["μg",{"2":{"20":1}}],["μr",{"2":{"20":1}}],["μy",{"2":{"8":1}}],["μx",{"2":{"8":1}}],["的进展展示了推理和视觉理解的强大能力",{"2":{"1006":1}}],["的进展表明",{"2":{"957":1}}],["的准确性",{"2":{"1003":1}}],["的miou分数显著高于弱监督或自监督方法",{"2":{"1000":1}}],["的miou已经超过了以激光雷达为中心的方法",{"2":{"1000":1}}],["的miou最高",{"2":{"1000":1}}],["的miou最高分",{"2":{"825":1}}],["的真正例",{"2":{"998":1}}],["的真阳性",{"2":{"739":1,"742":1,"778":1}}],["的iou最高",{"2":{"1000":1}}],["的iou",{"2":{"996":2}}],["的领域差距较小",{"2":{"995":1}}],["的泛化能力优于",{"2":{"989":1}}],["的测试集性能相比",{"2":{"989":1}}],["的官方代码",{"2":{"978":2}}],["的官方实现",{"2":{"978":2}}],["的几何",{"2":{"976":1}}],["的几何结构作为",{"2":{"917":1}}],["的占用预测",{"2":{"975":1}}],["的占用方法",{"2":{"957":1}}],["的组合",{"2":{"970":1}}],["的稀疏格子网络",{"2":{"962":1}}],["的框架",{"2":{"961":1}}],["的框架如图",{"2":{"642":1}}],["的开创性论文中得到认可",{"2":{"961":1}}],["的开源工作",{"2":{"930":1}}],["的变换矩阵",{"2":{"957":1}}],["的变化",{"2":{"944":1}}],["的高效",{"2":{"955":1}}],["的高斯数量",{"2":{"832":1}}],["的高斯数量就超越了它",{"2":{"812":1}}],["的高斯分布",{"2":{"728":2}}],["的端到端网络",{"2":{"955":1}}],["的端到端特性",{"2":{"369":1}}],["的上部",{"2":{"952":1}}],["的上部所示",{"2":{"829":1}}],["的增加或减少",{"2":{"945":1}}],["的增强鲁棒性",{"2":{"709":1}}],["的长度",{"2":{"944":1}}],["的提升",{"2":{"936":1}}],["的影响",{"2":{"928":1,"995":1}}],["的效果",{"2":{"928":1}}],["的投影组合表现最佳",{"2":{"928":1}}],["的任务中的效果",{"2":{"928":1}}],["的可视化结果",{"2":{"924":1}}],["的轻量版本接近实际部署的要求",{"2":{"922":1}}],["的好处",{"2":{"917":1}}],["的椭球体体积为",{"2":{"916":1}}],["的连接节点",{"2":{"905":1}}],["的连续函数来建立核元素位置和点云之间的关系",{"2":{"481":1}}],["的范围",{"2":{"905":1}}],["的范围限制在本地窗口以降低成本",{"2":{"824":1}}],["的标签和可见性掩码限制了其优势",{"2":{"927":1}}],["的标签是为纯视觉中心算法设计的",{"2":{"900":1}}],["的标签范围在",{"2":{"900":1}}],["的标注数据时",{"2":{"782":1}}],["的标注序列就实现了",{"2":{"782":1}}],["的标注仅可用于非商业目的",{"2":{"302":1}}],["的标注人员指导说明",{"2":{"277":1,"534":1}}],["的灵活性",{"2":{"886":1}}],["的减少",{"2":{"882":1}}],["的消融研究",{"2":{"882":2,"971":1}}],["的地图表征",{"2":{"913":1}}],["的地图表示发展",{"2":{"80":1}}],["的地图",{"2":{"881":1}}],["的机制",{"2":{"875":1}}],["的机器人状态",{"2":{"171":1}}],["的学习率分别降低",{"2":{"853":1}}],["的比例",{"2":{"853":1}}],["的比较",{"2":{"732":1}}],["的监督关系数为",{"2":{"853":1}}],["的尺度为",{"2":{"853":1}}],["的第",{"2":{"853":1}}],["的第一个参数",{"2":{"571":1}}],["的第一层",{"2":{"285":1}}],["的训练集",{"2":{"886":1}}],["的训练",{"2":{"853":1}}],["的训练数据进行",{"2":{"803":1}}],["的体素网格",{"2":{"853":1}}],["的体素分辨率",{"2":{"638":1}}],["的非平凡调整",{"2":{"853":1}}],["的底部",{"2":{"847":1}}],["的底层容器可以在创建时指定",{"2":{"835":1}}],["的中部",{"2":{"847":1}}],["的中间步骤",{"2":{"786":1}}],["的顶部",{"2":{"847":1}}],["的大规模基础模型",{"2":{"844":1}}],["的大小与物体的表面积成正比",{"2":{"372":1}}],["的大小",{"2":{"143":1}}],["的实例",{"2":{"905":1}}],["的实验崩溃了",{"2":{"842":1}}],["的实时构建是kimera",{"2":{"253":1}}],["的发布",{"2":{"841":1}}],["的处理时间",{"2":{"836":2}}],["的参数配置",{"2":{"836":1}}],["的参数数量大约是resnet50的3倍",{"2":{"779":1}}],["的使用及push与emplace异同点",{"2":{"835":1}}],["的系数",{"2":{"833":1}}],["的系统更具成本效益",{"2":{"567":1}}],["的下部",{"2":{"829":1}}],["的思路",{"2":{"829":1}}],["的覆盖比例",{"2":{"826":1}}],["的全局聚合",{"2":{"824":1}}],["的全局坐标系",{"2":{"254":1}}],["的单帧图像的",{"2":{"823":1}}],["的单个对象掩码",{"2":{"384":1}}],["的设计选择进行了消融研究",{"2":{"812":1}}],["的设置一致",{"2":{"928":1}}],["的设置",{"2":{"137":1}}],["的语义往往模糊且笼统",{"2":{"975":1}}],["的语义占据网络中使用",{"2":{"808":1}}],["的语义和几何信息转换为体素特征向量",{"2":{"808":1}}],["的激光雷达比",{"2":{"803":1}}],["的激光雷达点集",{"2":{"563":1}}],["的做法",{"2":{"803":1}}],["的先进性能",{"2":{"803":1}}],["的教师模型",{"2":{"803":1}}],["的有效性",{"2":{"800":1}}],["的有符号距离值",{"2":{"31":1}}],["的精度",{"2":{"796":1,"824":1}}],["的平均召回率",{"2":{"796":2}}],["的平均精度",{"2":{"796":1}}],["的视觉输入仍然是单目的",{"2":{"793":1}}],["的定性可视化如图3所示",{"2":{"791":1}}],["的定义",{"2":{"422":1}}],["的检测预训练检查点进行初始化",{"2":{"823":1}}],["的检测检查点初始化",{"2":{"782":1}}],["的检测标记为不正确",{"2":{"419":1}}],["的误差",{"2":{"775":3}}],["的块级特征和分层编码器主干",{"2":{"765":1}}],["的空体素",{"2":{"758":1}}],["的空间概念",{"2":{"131":1}}],["的封闭类别",{"2":{"743":1}}],["的关键帧率标注",{"2":{"739":1}}],["的关系",{"2":{"111":1,"236":1}}],["的通用目标类别",{"2":{"736":1}}],["的感知范围",{"2":{"736":1}}],["的感兴趣区域",{"2":{"173":1}}],["的卓越性能做出了贡献",{"2":{"723":1}}],["的kimera",{"2":{"709":1}}],["的更新机制",{"2":{"718":1}}],["的更新通过直接更新其对应的高维特征向量",{"2":{"705":1}}],["的更新位置",{"2":{"400":1}}],["的支柱包含背景",{"2":{"694":1}}],["的支柱包含前景物体",{"2":{"694":1}}],["的知识迁移到仅视觉",{"2":{"694":1}}],["的瓶颈处",{"2":{"684":1}}],["的研究",{"2":{"676":1}}],["的算子作为融合层",{"2":{"670":1}}],["的转换",{"2":{"670":1}}],["的转置",{"2":{"171":1}}],["的细节对比",{"2":{"670":1}}],["的超参数",{"2":{"666":1}}],["的基于视觉的3d占用预测方法",{"2":{"665":1}}],["的基础上增加了两个额外的垂直平面",{"2":{"808":1}}],["的基础上",{"2":{"253":1,"632":1}}],["的结果则受到了相机设置变化和大型城市场景",{"2":{"995":1}}],["的结果",{"0":{"823":1},"2":{"914":1}}],["的结果是一组聚类",{"2":{"137":1}}],["的结构",{"2":{"659":1}}],["的操作来细化特征",{"2":{"865":1}}],["的操作",{"2":{"659":1,"865":1}}],["的贡献如预期不同",{"2":{"928":1}}],["的贡献相等",{"2":{"928":1}}],["的贡献",{"2":{"656":1}}],["的整数倍",{"2":{"638":2}}],["的整体架构",{"0":{"315":1}}],["的层次结构是通过执行点到点k近邻搜索来构建的",{"2":{"636":1}}],["的均方根误差",{"2":{"634":1,"686":3}}],["的均值",{"2":{"8":2}}],["的复杂性",{"2":{"632":1}}],["的复杂场景重建问题",{"2":{"539":1}}],["的概率值",{"2":{"681":1}}],["的概率估计较低",{"2":{"622":1}}],["的概率分布",{"2":{"622":1}}],["的概念",{"2":{"512":1}}],["的神经场",{"2":{"619":1}}],["的形状",{"2":{"609":1}}],["的形式写出",{"2":{"153":1}}],["的形式",{"2":{"105":1}}],["的三维体素网格",{"2":{"609":2}}],["的三维张量",{"2":{"495":1}}],["的外积生成",{"2":{"595":1}}],["的深度方面存在困难",{"2":{"732":1}}],["的深度估计",{"2":{"592":2}}],["的深度理解",{"2":{"133":1}}],["的成熟",{"2":{"588":1}}],["的lovasz",{"2":{"585":1}}],["的latent",{"2":{"345":1}}],["的亲和力损失",{"2":{"585":1}}],["的对比学习损失",{"2":{"579":1}}],["的对数密度梯度",{"2":{"235":1}}],["的探索进度",{"2":{"568":1}}],["的拼接操作",{"2":{"550":1}}],["的坐标系中",{"2":{"550":1}}],["的启发",{"2":{"535":1,"547":1,"649":1,"684":1,"976":1}}],["的选取",{"2":{"525":1}}],["的选择有效地为clip嵌入中余弦相似性最高的",{"2":{"153":1}}],["的导航方式",{"2":{"525":1}}],["的抓取成功率",{"2":{"522":1}}],["的纯几何方法和更简单的clio",{"2":{"522":1}}],["的纯几何房间分割方法",{"2":{"522":1}}],["的预测结果",{"2":{"995":1}}],["的预测",{"2":{"842":1}}],["的预测能力",{"2":{"723":1}}],["的预测房间的几何准确性",{"2":{"522":1}}],["的预训练模型",{"2":{"437":1}}],["的预训练流程包括使用点云序列模块构建有序的点块序列",{"2":{"368":1}}],["的内存消耗",{"2":{"700":1,"861":1,"1004":1}}],["的内存",{"2":{"516":1,"547":1,"842":1}}],["的简单而有效的特征融合方法",{"2":{"512":1}}],["的校正局部相体积",{"2":{"511":1}}],["的总体架构",{"2":{"746":1}}],["的总体架构如图",{"2":{"502":1}}],["的总体框架",{"2":{"503":1}}],["的俯视图",{"2":{"495":1}}],["的住宅或办公空间",{"2":{"495":1}}],["的图像大小",{"2":{"803":3}}],["的图像",{"2":{"492":1}}],["的图像中对人脸和车牌进行模糊处理",{"2":{"233":1}}],["的蒙特卡罗估计过程",{"2":{"481":1}}],["的核心思想是利用几何先验和占用信息",{"2":{"875":1}}],["的核心层",{"2":{"481":1}}],["的核心模块已经开源发布",{"2":{"105":1}}],["的情况下更加鲁棒",{"2":{"480":1}}],["的隐式体积渲染正则化来增强融合表示",{"2":{"474":1}}],["的输入来评估",{"2":{"917":1}}],["的输入尺寸为",{"2":{"853":1}}],["的输入图像分辨率为",{"2":{"771":2}}],["的输入图像分辨率设置为376×1408",{"2":{"822":1}}],["的输入图像分辨率设置为900×1600",{"2":{"822":1}}],["的输入图像分辨率设置为",{"2":{"677":2}}],["的输入",{"2":{"660":2}}],["的输入是未标记图像的集合以及要分割的概念的文本描述列表",{"2":{"469":1}}],["的输出通过完成头中的反卷积层放大到",{"2":{"853":1}}],["的输出特征",{"2":{"632":1}}],["的输出外接辅助分类层得到mm",{"2":{"559":1}}],["的输出实现了更高的样本质量分数",{"2":{"382":1}}],["的输出在feature",{"2":{"296":1}}],["的性能趋势与",{"2":{"944":1}}],["的性能提升",{"2":{"936":4,"959":2}}],["的性能显著优于",{"2":{"928":1}}],["的性能与",{"2":{"867":1}}],["的性能进行了比较",{"2":{"791":1}}],["的性能",{"2":{"455":1,"642":1,"700":1,"782":1,"792":1,"794":1,"807":1,"827":1,"853":1,"928":1,"998":1}}],["的表示在",{"2":{"808":1}}],["的表示",{"2":{"808":2}}],["的表示以及对应映射",{"2":{"579":1}}],["的表示法来描绘3d场景",{"2":{"444":1}}],["的表示很重要",{"2":{"313":1}}],["的安全导航至关重要",{"2":{"503":1}}],["的安全性至关重要",{"2":{"438":1}}],["的安全运行高度依赖于其对周围环境的理解",{"2":{"409":1}}],["的房间分割估计与hydra",{"2":{"437":1}}],["的二维卷积网络对特征图进行下采样",{"2":{"433":1}}],["的映射对象",{"2":{"431":1}}],["的梯度可以反向传播到m中的顶点位置",{"2":{"429":1}}],["的解析函数",{"2":{"429":1}}],["的符号距离场",{"2":{"429":2}}],["的蒸馏训练",{"2":{"425":1}}],["的车载部署",{"2":{"425":1}}],["的resnet101",{"2":{"421":1}}],["的graphcnn方法",{"2":{"419":1}}],["的主要结果中分别将高斯的数量设置为",{"2":{"771":1}}],["的主要灵感来源于博弈论中零和博弈的思想",{"2":{"129":1}}],["的主干来提取逐点特征",{"2":{"412":1}}],["的话",{"2":{"411":1}}],["的feature",{"2":{"410":1}}],["的场景中",{"2":{"698":1}}],["的场景图中",{"2":{"408":1}}],["的场景数量",{"2":{"157":1}}],["的潜在特征和可学习的查询向量被用作变压器解码器的输入",{"2":{"405":1}}],["的无序性和数量的不确定性",{"2":{"405":1}}],["的未变形方向为恒等",{"2":{"390":1}}],["的未变形",{"2":{"390":1}}],["的邻近网格顶点",{"2":{"390":1}}],["的里程计姿态坐标系中的未变形位置",{"2":{"390":1}}],["的里程计姿态",{"2":{"390":1}}],["的局部旋转",{"2":{"390":1}}],["的原理及pytorch实现",{"2":{"528":1}}],["的原始世界坐标系位置",{"2":{"390":1}}],["的原创文章",{"2":{"41":1,"48":1,"220":1,"351":1}}],["的姿态顶点",{"2":{"390":1}}],["的网格",{"2":{"853":1,"900":1}}],["的网格部分",{"2":{"449":1}}],["的网格顶点",{"2":{"390":1}}],["的网格变形和姿态图优化",{"2":{"390":1}}],["的网络结构",{"2":{"440":1}}],["的网络结构包含两个部分",{"2":{"133":1}}],["的网络部分使用b的style",{"2":{"181":3}}],["的快速最大团实现来计算最大的一致测量集",{"2":{"390":1}}],["的快速进展为视觉",{"2":{"72":1}}],["的smpl网格检测和姿态",{"2":{"419":1}}],["的sdf值被更新为",{"2":{"372":1}}],["的skinned",{"2":{"131":1}}],["的离散编码向量",{"2":{"371":1}}],["的重要数据集与基准",{"2":{"360":1}}],["的位置和方向",{"2":{"654":1}}],["的位置偏移量",{"2":{"372":1}}],["的位置",{"2":{"355":1}}],["的维度大小",{"2":{"351":1}}],["的新型查询解码器",{"2":{"349":1}}],["的新研究前沿",{"2":{"82":1}}],["的建模用处不大",{"2":{"343":1}}],["的最优miou分数",{"2":{"490":1}}],["的最简单快速的理解",{"2":{"325":1}}],["的最高概率输出",{"2":{"274":1}}],["的不变性",{"2":{"325":1}}],["的数据",{"2":{"1001":2}}],["的数据相关插值模块",{"2":{"962":1}}],["的数据上进行",{"2":{"803":1}}],["的数据集",{"2":{"313":1}}],["的数据感知环境",{"2":{"171":1}}],["的估计",{"2":{"310":1,"967":1}}],["的充分统计量作为输入",{"2":{"304":1}}],["的其余部分兼容",{"2":{"302":1}}],["的分割文件",{"2":{"828":1}}],["的分类体系与",{"2":{"302":1}}],["的分布",{"2":{"149":1}}],["的首次发布中",{"2":{"302":1}}],["的每帧和多帧3d网格",{"2":{"285":1}}],["的频率捕获的",{"2":{"828":1}}],["的频率进行全标注",{"2":{"749":1}}],["的频率进行标注",{"2":{"652":1}}],["的频率对同步良好的关键帧",{"2":{"277":1}}],["的频率为",{"2":{"126":1}}],["的批处理方法",{"2":{"276":1}}],["的dsg的顶部和底部添加更多层",{"2":{"262":1}}],["的扩展",{"2":{"253":1}}],["的架构",{"2":{"252":1,"285":2,"875":1}}],["的架构如",{"2":{"123":1}}],["的期望平方距离",{"2":{"235":1}}],["的抽象逻辑其实可以用一句话概括",{"2":{"235":1}}],["的格式自定义新文本",{"2":{"204":1}}],["的键值对所在的范围",{"2":{"196":1}}],["的迭代器至少是前向迭代器",{"2":{"196":1}}],["的特征图被输入到",{"2":{"744":1}}],["的特征最终被反馈到全连接层以预测分类得分",{"2":{"636":1}}],["的特征向量",{"2":{"429":1}}],["的特征",{"2":{"181":1,"475":1}}],["的本意是去找到控制不同style的latent",{"2":{"181":1}}],["的残差",{"2":{"180":1}}],["的航向精度",{"2":{"173":1}}],["的观测",{"2":{"171":1,"435":1}}],["的信息融合将有助于更全面的感知",{"2":{"691":1}}],["的信息",{"2":{"153":1,"724":1}}],["的权重",{"2":{"153":1,"985":1}}],["的密度是非均匀的",{"2":{"149":1}}],["的条件熵",{"2":{"137":1}}],["的条件熵和给定",{"2":{"137":1}}],["的熵",{"2":{"137":1}}],["的边缘概率分布",{"2":{"137":2}}],["的联合概率分布",{"2":{"137":1}}],["的同时保留任务相关信息",{"2":{"137":1}}],["的问题通过骨干中几个块后的特征扩散得到改善",{"2":{"680":1}}],["的问题",{"2":{"137":1}}],["的工作与我们的提议最接近",{"2":{"967":1}}],["的工作流程",{"2":{"902":1}}],["的工作中的真值标签来建立对应于雨天和夜间场景的子集",{"2":{"900":1}}],["的工作原理是通过一系列细化步骤学习将标准正态分布转换为经验数据分布",{"2":{"175":1}}],["的工作推向成熟",{"2":{"131":1}}],["的工作",{"2":{"131":1,"175":1,"900":1}}],["的拓扑图",{"2":{"131":1}}],["的纳什均衡点是一个鞍点",{"2":{"129":1}}],["的目标迈进",{"2":{"881":1}}],["的目标体素网格中",{"2":{"738":1}}],["的目标检测中获得启发",{"2":{"716":1}}],["的目标是联合推断三维场景的几何和语义信息",{"2":{"632":1}}],["的目标是在存在传感器噪声和运动估计误差的条件下",{"2":{"171":1}}],["的目标是研究整个传感器套件",{"2":{"126":1}}],["的目的是在高维非凸的参数空间中找到纳什均衡点",{"2":{"129":1}}],["的丰富复杂性将鼓励开发能够在有数十个物体的场景中实现安全驾驶的方法",{"2":{"126":1}}],["的元素",{"2":{"115":1,"197":1}}],["的cmake路径",{"2":{"107":1}}],["的正确粒度是什么",{"2":{"98":1}}],["的值描述",{"2":{"780":1}}],["的值到vector中",{"2":{"93":1}}],["的值是vector的列数",{"2":{"73":1}}],["的值vector的行数",{"2":{"73":1}}],["的能力",{"2":{"57":1,"116":1,"723":1}}],["的出现提高了以视觉为中心的3d物体检测的准确性",{"2":{"665":1}}],["的出现",{"2":{"57":1,"121":1}}],["的一部分",{"2":{"57":1}}],["的时候提示了",{"2":{"41":1}}],["的行",{"2":{"33":1}}],["的文件夹中",{"2":{"32":1}}],["的构建通常涉及到从传感器数据",{"2":{"31":1}}],["的计算公式为",{"2":{"31":1}}],["的",{"0":{"55":1},"1":{"66":1},"2":{"31":1,"78":1,"99":1,"117":1,"136":1,"177":1,"325":1,"469":1,"495":1,"517":2,"582":1,"595":1,"619":1,"670":1,"677":2,"739":1,"744":1,"803":1,"853":1,"867":1,"917":1,"927":1,"962":1}}],["的方法能够缓解潜在的几何歧义",{"2":{"875":1}}],["的方法利用三个正交投影平面来建模3d环境",{"2":{"858":1}}],["的方法缓解了由空网格引起的冗余问题",{"2":{"808":1}}],["的方法通过深度引导将图像特征积极投影到3d空间",{"2":{"612":1}}],["的方法",{"2":{"547":1,"564":2,"834":1,"967":1,"1000":1}}],["的方法构建地点子图",{"2":{"228":1}}],["的方法进行3d网格重建和对象原语提取",{"2":{"206":1}}],["的方法就是引入噪声",{"2":{"199":1}}],["的方法的联系",{"2":{"90":1}}],["的方式选择下一层的中心点",{"2":{"589":1}}],["的方式生成",{"2":{"550":1}}],["的方式更新",{"2":{"31":1}}],["的方式限制了距离值的范围",{"2":{"31":1}}],["的方差",{"2":{"8":2}}],["的虚拟内存",{"2":{"26":1}}],["的协方差",{"2":{"8":1}}],["的干净图像",{"2":{"5":1}}],["为10",{"2":{"1000":1}}],["为半径",{"2":{"944":1}}],["为混合现实",{"2":{"937":1,"953":1}}],["为消除该不稳定问题",{"2":{"863":1}}],["为解决上述问题",{"2":{"863":1}}],["为解决这一挑战",{"2":{"617":1}}],["为解决这一问题",{"2":{"525":1,"563":1}}],["为部署提供了灵活性",{"2":{"842":1}}],["为前缀的类别",{"2":{"842":1}}],["为lcel",{"2":{"834":1}}],["为多粒度",{"2":{"826":1}}],["为主",{"2":{"806":1}}],["为空则返回1",{"2":{"795":1}}],["为空返回true",{"2":{"146":1}}],["为弥补这一缺陷",{"2":{"765":1}}],["为弥合这一差距并整合快速扩张的工作",{"2":{"82":1}}],["为总类别数",{"2":{"742":1}}],["为类别数",{"2":{"739":1}}],["为自动驾驶中的三维场景理解提供了密集的体素级注释",{"2":{"736":1}}],["为高斯提供更准确且整体的样本特定初始化",{"2":{"704":1}}],["为不同任务提供了清晰",{"2":{"698":1}}],["为中间表示的对移动对象进行时序建模的",{"2":{"695":1}}],["为中心的局部邻域",{"2":{"450":1}}],["为场景遮挡提供了额外的监督",{"2":{"632":1}}],["为遮挡部分提供额外的监督",{"2":{"632":1}}],["为避免模型过度偏向深度信息而丢失语义先验",{"2":{"617":1}}],["为从高斯坐标系到相机",{"2":{"595":1}}],["为3d占用预测任务提供了一些有用的数据集和基准",{"2":{"735":1}}],["为3d空间中的每个体素分配一个特征",{"2":{"693":1}}],["为3d空间中未定义的长尾障碍物提供细粒度表示和鲁棒检测",{"2":{"665":1}}],["为3d可变形注意力操作",{"2":{"595":1}}],["为3d高斯提供来自激光雷达数据的几何先验",{"2":{"415":1}}],["为代表的学习式",{"2":{"588":1}}],["为代表",{"2":{"585":2}}],["为网络提供全局感受野以及体素语义关系的洞察",{"2":{"570":1}}],["为落入体素",{"2":{"563":1}}],["为非空体素索引",{"2":{"563":1}}],["为待初始化高斯的索引",{"2":{"563":1}}],["为特征维度",{"2":{"563":1}}],["为例",{"2":{"561":1}}],["为室内场景分析的未来可扩展研究提供了便利",{"2":{"544":1}}],["为相对较小的感知范围提供了真值标签",{"2":{"900":1}}],["为相对方向",{"2":{"525":1}}],["为相对距离",{"2":{"525":1}}],["为减少",{"2":{"517":1}}],["为评估不同融合策略的准确性",{"2":{"503":1}}],["为实现精准高效的3d占据预测",{"2":{"503":1}}],["为四维张量",{"2":{"495":1}}],["为存储该位置语义信息的通道数",{"2":{"495":1}}],["为地图的平面尺寸",{"2":{"495":1}}],["为早期示例",{"2":{"467":1}}],["为0",{"2":{"449":1}}],["为保证地图完整",{"2":{"435":1}}],["为将",{"2":{"435":1}}],["为简化问题",{"2":{"435":1}}],["为展示有限标签下的学习效果",{"2":{"425":1}}],["为行列索引",{"2":{"378":1}}],["为covla",{"2":{"360":1}}],["为后续基于",{"2":{"899":1}}],["为后续占据预测任务提供更优初始模型",{"2":{"617":1}}],["为后续的预训练和任务学习提供有序的输入",{"2":{"340":1}}],["为后文即将介绍的建图方法提供背景",{"2":{"231":1}}],["为hr图像",{"2":{"329":1}}],["为每条边的四个邻居定义两种可能的排序",{"2":{"325":1}}],["为每个语义组创建相应的掩码查询",{"2":{"875":1}}],["为每个3d高斯分布分配了明确的语义含义",{"2":{"842":1}}],["为每个投影分配不同的权重",{"2":{"839":1}}],["为每个投影参考点生成可学习的采样偏移",{"2":{"595":1}}],["为每个物体提取图像特征并存入对应节点",{"2":{"765":1}}],["为每个高斯分布提供明确的提示信息",{"2":{"600":1}}],["为每个高斯生成一组3d参考点",{"2":{"595":1}}],["为每个体素分配一个特征向量",{"2":{"547":1}}],["为每个像素分配一个权重",{"2":{"511":1}}],["为每个时间步提供估计的全局坐标",{"2":{"419":1}}],["为每个位置生成9种预先设置好长宽比与面积的目标框",{"2":{"321":1}}],["为每个原语",{"2":{"153":1}}],["为已知形状的对象拟合一个cad模型",{"2":{"285":1}}],["为超参",{"2":{"279":1}}],["为随时间累积全局地图",{"2":{"274":1}}],["为什么选择occ",{"0":{"569":1},"1":{"601":1,"630":1,"658":1},"2":{"573":1}}],["为什么要估计噪声",{"2":{"398":1}}],["为什么要加噪声",{"2":{"398":1}}],["为什么要多此一举将",{"2":{"133":1}}],["为什么是",{"2":{"355":1}}],["为什么我们选择这组节点或边",{"2":{"262":1}}],["为具身智能体设计系统时",{"2":{"231":1}}],["为所有的roi提特征大约花费47s",{"2":{"207":1}}],["为键的键值对",{"2":{"196":1}}],["为参数的函数",{"2":{"193":1}}],["为提升空间覆盖与安全性",{"2":{"176":1}}],["为马氏距离",{"2":{"171":1}}],["为由当前估计得到的预测相对测量",{"2":{"171":1}}],["为节点",{"2":{"171":1}}],["为位姿图中的边",{"2":{"171":1}}],["为加权平方误差",{"2":{"171":1}}],["为误差",{"2":{"171":1}}],["为信息矩阵",{"2":{"171":1}}],["为测量噪声",{"2":{"171":1}}],["为路标位置",{"2":{"171":1}}],["为过程噪声",{"2":{"171":1}}],["为控制输入",{"2":{"171":1}}],["为时刻",{"2":{"171":2}}],["为5",{"2":{"146":1}}],["为更安全",{"2":{"145":1}}],["为未知形状的物体估计边界框",{"2":{"131":1}}],["为真实数据的概率",{"2":{"129":1}}],["为此采用流行的segment",{"2":{"617":1}}],["为此我们引入后向投影方法优化稀疏3d表示",{"2":{"585":1}}],["为此",{"2":{"126":1,"233":1,"252":1,"314":1,"363":1,"379":1,"390":1,"409":1,"435":1,"455":1,"480":1,"505":1,"588":1,"617":1,"691":1,"728":1,"794":1,"803":1,"962":1,"974":1,"988":1}}],["为轨迹优化设计此类目标函数既昂贵又费力",{"2":{"114":1}}],["为端到端驾驶系统提供更统一可扩展框架",{"2":{"114":1}}],["为应对挑战",{"2":{"114":1}}],["为建模自车与其他交通参与者交互",{"2":{"114":1}}],["为缓解此问题",{"2":{"114":1}}],["为机器人感知和映射提供了前所未有的机会",{"2":{"98":1}}],["为了促进进一步的研究",{"2":{"1007":1}}],["为了促进训练的收敛性",{"2":{"456":1}}],["为了摆脱对3d标签的依赖",{"2":{"1006":1}}],["为了支持3d占用感知的基准测试",{"2":{"997":1}}],["为了建立文本和3d占用之间的跨模态对应关系",{"2":{"988":1}}],["为了缓解这一问题",{"2":{"976":1}}],["为了缓解这些挑战",{"2":{"535":1}}],["为了全面理解场景",{"2":{"957":1}}],["为了全面评估我们的模型在具有挑战性的雨天和夜间场景下的能力",{"2":{"827":1}}],["为了兼得二者之长",{"2":{"935":1}}],["为了简单起见",{"2":{"931":1,"979":1}}],["为了简化设计",{"2":{"666":1}}],["为了展示这种能力",{"2":{"930":1}}],["为了展示我们即插即用flashocc的泛化性",{"2":{"811":1}}],["为了公平起见",{"2":{"1000":2}}],["为了公平地评估仅特征投影的效果",{"2":{"928":1}}],["为了公平比较",{"2":{"870":1,"914":1}}],["为了完整性",{"2":{"917":1}}],["为了完成机器人节点",{"2":{"419":1}}],["为了计算这一指标",{"2":{"916":1}}],["为了估计",{"2":{"916":1}}],["为了充分展示我们",{"2":{"902":1}}],["为了充分利用gpu的并行计算能力",{"2":{"738":1}}],["为了充分利用局部几何结构",{"2":{"574":1}}],["为了充分利用点云特征中固有的几何信息",{"2":{"482":1}}],["为了充分利用点云特征中固有的几何和结构信息",{"2":{"421":1,"576":2,"666":1,"800":1}}],["为了从tpv特征中检索3d空间中某个位置的特征",{"2":{"858":1}}],["为了从kimera",{"2":{"686":1}}],["为了将这些方法扩展到占用学习",{"2":{"839":1}}],["为了将网格分解为多个对象实例",{"2":{"449":1}}],["为了清晰起见",{"2":{"816":1}}],["为了减轻这种效应",{"2":{"814":1}}],["为了减少计算量",{"2":{"707":1}}],["为了减少计算复杂度",{"2":{"659":1}}],["为了验证时间模块的有效性",{"2":{"811":1}}],["为了验证所提出的daocc的效率和有效性",{"2":{"421":1}}],["为了确保与",{"2":{"828":1}}],["为了确保公平比较",{"2":{"811":1}}],["为了确保一致性",{"2":{"750":1}}],["为了与视觉方法的评估对齐",{"2":{"803":1}}],["为了更具一般性",{"2":{"794":1}}],["为了更好地说明目的",{"2":{"315":1}}],["为了更好的对数据进行分类或生成",{"2":{"149":1}}],["为了说明数据的效率",{"2":{"782":1}}],["为了高效地从3d高斯分布生成体素化的占用预测",{"2":{"861":1}}],["为了高效地处理3d高斯分布之间的交互",{"2":{"547":1}}],["为了高效训练",{"2":{"750":1}}],["为了以迭代方式细化高斯属性",{"2":{"738":1}}],["为了分解不同天气条件下的性能提升",{"2":{"914":1}}],["为了分解两个设计模块带来的性能提升",{"2":{"723":1}}],["为了分析语义性能",{"2":{"732":1}}],["为了回答这个问题",{"2":{"715":1}}],["为了独立于vio定位误差评估网格精度",{"2":{"709":1}}],["为了增强融合后的tpv",{"2":{"699":1}}],["为了限制高斯仅对占用区域进行几何预测",{"2":{"681":1}}],["为了获取点云的语义特征",{"2":{"664":1}}],["为了获得最佳结果",{"2":{"779":1}}],["为了获得2d",{"2":{"676":1}}],["为了获得密集的占据预测",{"2":{"482":1}}],["为了获得对简单遮挡的鲁棒性",{"2":{"419":1}}],["为了获得地点的语义特征",{"2":{"228":1}}],["为了获得高质量的多传感器数据集",{"2":{"191":1}}],["为了这个层级式",{"2":{"659":1}}],["为了优化gpu效率",{"2":{"950":1}}],["为了优化",{"2":{"656":1}}],["为了进一步利用所有可用信息",{"2":{"968":1}}],["为了进一步提高分割精度",{"2":{"955":1}}],["为了进一步强调我们方法的可扩展性",{"2":{"947":1}}],["为了进一步评估我们所提出的框架的有效性",{"2":{"927":1}}],["为了进一步评估kimera构建dsg的性能",{"2":{"889":1}}],["为了进一步验证我们方法的有效性",{"2":{"900":1}}],["为了进一步推导出整体占用概率",{"2":{"681":1}}],["为了进一步抑制重建噪声",{"2":{"650":1}}],["为了进一步增强上下文理解能力",{"2":{"570":1}}],["为了为研究人员提供有价值的参考",{"2":{"637":1}}],["为了指导",{"2":{"632":1}}],["为了利用局部结构信息",{"2":{"607":1}}],["为了使相邻顶点的特征更加相似",{"2":{"607":1}}],["为了使方法在两个房间相遇",{"2":{"480":1}}],["为了收集",{"2":{"605":2}}],["为了避免复杂的手动设计",{"2":{"638":1}}],["为了避免对特定的2d语义分割方法产生偏见",{"2":{"605":1}}],["为了避免将新人类与之前人类的位姿图关联",{"2":{"419":1}}],["为了评估各种最新算法",{"2":{"807":1}}],["为了评估度量",{"2":{"605":1}}],["为了评估目的",{"2":{"374":1}}],["为了弥合现有研究与实际场景之间的差距",{"2":{"600":1}}],["为了消除密集表示固有的空间冗余性",{"2":{"599":1}}],["为了推动该领域的进一步研究",{"2":{"544":1}}],["为了在三维分支中提高内存效率",{"2":{"923":1}}],["为了在空间",{"2":{"881":1}}],["为了在较小的数据规模上快速验证",{"2":{"803":1}}],["为了在非空区域有效初始化高斯",{"2":{"536":1}}],["为了在真实多样的场景中测试clio",{"2":{"374":1}}],["为了应对从整个3d空间学习的计算负担",{"2":{"908":1}}],["为了应对这两种设置",{"2":{"853":1}}],["为了应对这一问题",{"2":{"536":1}}],["为了应对高计算和非本地化的挑战",{"2":{"607":1}}],["为了应对点云数据的低级语义和生成任务与下游任务之间的差距",{"2":{"488":1}}],["为了演示clio在机器人上的实时使用",{"2":{"522":1}}],["为了降低3d",{"2":{"511":1}}],["为了维护一张全局",{"2":{"495":1}}],["为了维护有关人类位置的持久信息",{"2":{"419":1}}],["为了生成密集的3d占用预测",{"2":{"486":1}}],["为了最大化利用三维检测预训练的好处",{"2":{"482":1}}],["为了加快计算速度",{"2":{"481":1}}],["为了标记这些地点",{"2":{"480":1}}],["为了补偿噪声",{"2":{"480":1}}],["为了平衡语义和几何信息",{"2":{"444":1}}],["为了平衡类别频率分布",{"2":{"157":1}}],["为了克服单智能体的瓶颈",{"2":{"969":1}}],["为了克服这个挑战",{"2":{"640":1}}],["为了克服这些挑战并获得一个有序的点云序列",{"2":{"340":1}}],["为了克服这些限制",{"2":{"109":1}}],["为了克服上述限制并尽可能保留细粒度信息",{"2":{"438":1}}],["为了基准测试",{"2":{"437":1}}],["为了得到准确的地图",{"2":{"435":1}}],["为了显示任务驱动的重要性",{"2":{"431":1}}],["为了解决动态和静态类别之间的不平衡问题",{"2":{"941":1}}],["为了解决由lidar噪声和定位误差引起的物体3d形状放大问题",{"2":{"735":1}}],["为了解决由数据的不同的图形拓扑所带来的挑战",{"2":{"607":1}}],["为了解决三维点云中的噪声和遮挡问题",{"2":{"664":1}}],["为了解决这一困境",{"2":{"997":1}}],["为了解决这一局限性",{"2":{"916":1}}],["为了解决这一挑战",{"2":{"821":1}}],["为了解决这一极具挑战性的问题",{"2":{"570":1}}],["为了解决这一问题",{"2":{"516":1,"693":1,"704":1,"819":1,"963":1}}],["为了解决这个问题",{"2":{"488":1,"549":1,"667":1,"957":1}}],["为了解决这些问题",{"2":{"301":1,"349":1,"998":1}}],["为了解决点云的固有无序性",{"2":{"426":1}}],["为了检查一致性",{"2":{"419":1}}],["为了创建人类节点",{"2":{"419":1}}],["为了响应环路闭合",{"2":{"380":1}}],["为了导航",{"2":{"378":1}}],["为了找到匹配项",{"2":{"352":1}}],["为了提取",{"2":{"867":1}}],["为了提高它的描述能力",{"2":{"664":1}}],["为了提高效率",{"2":{"612":1}}],["为了提高效率并减少不必要的计算和存储",{"2":{"532":1}}],["为了提高clip在replica数据集的低纹理区域的可靠性",{"2":{"492":1}}],["为了提高内存和计算效率",{"2":{"481":1}}],["为了提高识别精度",{"2":{"337":1}}],["为了提供对语义地图构建方法的原则性理解",{"2":{"90":1}}],["为了捕获点级别的信息",{"2":{"313":1}}],["为了识别节点之间的边",{"2":{"276":1}}],["为了实现自动驾驶应用的实时性能",{"2":{"1004":1}}],["为了实现3d点云的快速准确分割",{"2":{"955":1}}],["为了实现3d语义占用预测",{"2":{"738":1}}],["为了实现更好的性能",{"2":{"800":1}}],["为了实现概率建模",{"2":{"681":1}}],["为了实现可靠和安全的自动驾驶",{"2":{"667":1}}],["为了实现时间对齐",{"2":{"550":1}}],["为了实现激光雷达和摄像头之间良好的跨模态数据对齐",{"2":{"211":1}}],["为了实现这一目标",{"2":{"153":1,"369":1,"437":1,"656":1}}],["为了保持一致性",{"2":{"206":1}}],["为了构造这个模型需要一种表示这种概率分布的方式",{"2":{"193":1}}],["为了强制一致性",{"2":{"814":1}}],["为了强调任务相似性的排名",{"2":{"153":1}}],["为了强化这种归纳偏置",{"2":{"153":1}}],["为了便于开展常见的计算机视觉任务",{"2":{"126":1}}],["为了防止特征稀释",{"2":{"96":1}}],["为n的vector容器且每个元素值为t",{"2":{"93":1}}],["为n的vector容器",{"2":{"93":1}}],["为默认值",{"2":{"8":1}}],["为像素值的范围",{"2":{"8":1}}],["为两个常数",{"2":{"8":1}}],["为",{"2":{"8":5,"67":1,"444":1,"534":1,"660":1,"694":1,"767":1,"782":1,"823":1,"916":1}}],["3x3",{"2":{"916":1}}],["3的nds",{"2":{"893":1}}],["3λ=3​",{"2":{"766":1}}],["3×10−4",{"2":{"677":1}}],["3×10−43",{"2":{"677":1}}],["3+",{"2":{"500":1}}],["3+1",{"2":{"470":1}}],["3m处切割的2d",{"2":{"480":1}}],["3m",{"2":{"480":1,"652":3,"736":1,"739":2,"781":1,"924":1}}],["3mothn",{"2":{"106":2}}],["3楼和4楼",{"2":{"437":1}}],["3rmk​=i3​且tmk=gkt",{"2":{"390":1}}],["3rscan",{"0":{"32":1,"38":2,"43":1,"51":1},"2":{"32":17,"38":19,"43":2,"51":2}}],["3以下",{"2":{"347":1}}],["3h×w×3的输入图像",{"2":{"345":1}}],["3b",{"2":{"334":1}}],["3点",{"2":{"310":1}}],["3层",{"0":{"232":1},"1":{"253":1,"276":1}}],["3层的方法",{"2":{"210":1}}],["311",{"2":{"947":1}}],["316",{"2":{"277":1,"534":1}}],["31",{"2":{"172":1,"334":1,"464":2,"478":1,"482":1,"507":1,"535":1,"566":2,"596":1,"603":1,"612":1,"735":2,"736":1,"757":1,"759":1,"770":1,"791":1,"928":1,"932":1,"942":3,"950":2,"985":1,"988":1,"1006":1}}],["3节中",{"2":{"939":1}}],["3节中评估它们",{"2":{"919":1}}],["3节进行了广泛的消融实验",{"2":{"748":1}}],["3节所述",{"2":{"732":1}}],["3节概述后处理策略",{"2":{"551":1}}],["3节使用提供地面真实点云的euroc子集",{"2":{"541":1}}],["3节",{"0":{"362":1},"2":{"131":1,"178":1,"285":1,"576":1,"686":2,"930":1}}],["3960x的24核和两个nvidia",{"2":{"437":1}}],["391",{"2":{"277":1,"534":1}}],["395",{"2":{"277":1,"534":1}}],["39",{"2":{"121":1,"126":1,"172":1,"360":3,"603":3,"612":1,"686":1,"780":1,"808":1,"853":2,"870":1,"876":1,"942":1,"978":1,"1001":1}}],["390",{"2":{"66":2}}],["376×1408376",{"2":{"771":1}}],["374",{"2":{"663":1,"686":1}}],["37",{"2":{"121":1,"128":1,"172":1,"421":2,"482":1,"566":1,"603":1,"641":1,"686":1,"690":1,"759":1,"779":1,"808":2,"841":1,"917":1,"971":1,"997":1}}],["339",{"2":{"947":1}}],["33miou",{"2":{"800":1}}],["331",{"2":{"277":1}}],["337",{"2":{"277":1,"534":1}}],["33",{"2":{"121":1,"176":1,"190":1,"283":1,"334":1,"417":1,"420":1,"512":3,"535":1,"547":1,"596":1,"603":1,"612":1,"709":1,"757":1,"759":1,"791":1,"811":1,"823":1,"842":1,"893":1,"928":1,"942":2,"950":2,"957":2,"985":1,"1000":1}}],["336745141",{"2":{"31":1}}],["364",{"2":{"686":1}}],["360测试集上的3d占用基准测试结果",{"2":{"1000":1}}],["360相比",{"2":{"1000":1}}],["360的分数",{"2":{"1000":1}}],["360的高斯分布数量设置为38400",{"2":{"822":1}}],["360仅包含11个场景",{"2":{"997":1}}],["360是两个大型数据集",{"2":{"997":1}}],["360设置了144000",{"2":{"924":1}}],["360数据集上",{"2":{"1000":2}}],["360数据集上评估了3d占用方法的性能",{"2":{"1000":1}}],["360数据集上的性能与最先进的方法相当",{"2":{"861":1}}],["360数据集上进行了大量实验",{"2":{"516":1,"547":1}}],["360上的miou分别为11",{"2":{"1000":1}}],["360上",{"2":{"842":1}}],["360",{"0":{"901":1},"2":{"302":2,"536":1,"567":1,"613":1,"749":3,"760":1,"771":4,"781":2,"792":1,"822":2,"851":1,"901":1,"924":1,"995":1,"997":2,"999":1}}],["360°",{"2":{"173":1}}],["36",{"2":{"114":1,"121":1,"190":1,"476":1,"535":1,"570":1,"625":1,"640":1,"641":1,"709":2,"759":1,"778":1,"791":1,"808":1,"875":2,"917":2,"942":2,"950":2,"957":1,"997":2,"1000":1}}],["353",{"2":{"686":1}}],["35毫秒",{"2":{"437":1}}],["35m",{"2":{"425":1,"944":3}}],["357",{"2":{"277":1,"534":1,"733":1}}],["351",{"2":{"277":1,"534":1}}],["35",{"2":{"114":1,"121":1,"190":1,"277":1,"366":1,"534":1,"535":1,"596":1,"603":1,"612":1,"677":1,"686":1,"709":2,"757":1,"758":1,"759":1,"789":3,"917":1}}],["32gb",{"2":{"982":2}}],["329",{"2":{"947":1}}],["321​",{"2":{"768":1}}],["32​",{"2":{"609":1}}],["32和1",{"2":{"562":1}}],["32倍",{"2":{"420":1}}],["32大小的图像",{"2":{"343":1}}],["32通道的特征图",{"2":{"305":1}}],["32×32",{"2":{"278":2}}],["32256×256×32",{"2":{"749":1}}],["322",{"2":{"277":1,"534":1}}],["32768",{"2":{"184":1}}],["32x32",{"2":{"181":1}}],["320k",{"2":{"749":1}}],["320",{"2":{"136":2}}],["32",{"2":{"82":1,"126":1,"172":1,"173":2,"278":1,"302":1,"383":2,"411":2,"420":1,"440":1,"566":1,"596":1,"603":1,"609":2,"686":1,"735":1,"739":1,"759":1,"768":1,"779":1,"789":1,"803":1,"822":1,"841":1,"867":1,"886":1,"942":3,"947":1,"950":2,"957":2,"985":2,"1000":1}}],["340",{"2":{"947":1}}],["345",{"2":{"277":1}}],["34",{"2":{"66":1,"82":1,"121":1,"172":2,"277":1,"420":1,"421":1,"426":1,"534":1,"566":1,"596":1,"603":1,"641":1,"686":2,"757":2,"759":1,"808":1,"893":1,"928":1,"989":1}}],["3834",{"2":{"853":1}}],["38400个高斯分布",{"2":{"924":1}}],["38400",{"2":{"771":1}}],["384",{"2":{"277":1,"534":1,"686":1}}],["385",{"2":{"277":1,"534":1}}],["3851",{"2":{"43":1}}],["38",{"2":{"51":2,"121":1,"128":1,"172":1,"277":2,"421":2,"425":2,"482":1,"534":2,"603":1,"690":1,"759":1,"782":1,"808":1,"840":1,"875":1,"928":1,"942":4,"950":2,"957":2,"988":2,"998":1,"1000":3,"1006":1}}],["30m",{"2":{"944":3}}],["3070",{"2":{"859":1}}],["3070ti",{"2":{"840":1}}],["30帧",{"2":{"833":1}}],["3090",{"2":{"431":1,"783":1}}],["305",{"2":{"277":1,"534":1}}],["30°",{"2":{"173":1}}],["300",{"2":{"278":1}}],["3001",{"2":{"106":1}}],["3000",{"2":{"57":1}}],["30",{"2":{"43":3,"51":2,"62":1,"145":3,"195":1,"216":1,"276":1,"277":2,"334":1,"360":1,"421":1,"425":1,"495":1,"534":2,"566":1,"603":1,"686":1,"709":1,"735":2,"757":1,"759":1,"771":1,"782":1,"803":1,"822":1,"886":1,"893":1,"910":5,"922":1,"923":2,"932":1,"985":1,"1000":1}}],["3d扫描",{"2":{"997":3}}],["3d扫描数量",{"2":{"997":1}}],["3d提出计算语言",{"2":{"988":1}}],["3d使用交叉熵损失和lovasz",{"2":{"988":1}}],["3dmatch",{"2":{"978":1}}],["3dmfv",{"2":{"664":1}}],["3d结构和全局上下文特征",{"2":{"968":1}}],["3d激光雷达",{"2":{"967":1}}],["3d特征体积中的一个体素在投影后会命中多个2d前视特征图",{"2":{"957":1}}],["3d特征体积中的每个体积特征作为查询",{"2":{"950":1}}],["3d特征变换",{"2":{"875":1}}],["3d和bev基准上都有很大的优势",{"2":{"931":1}}],["3d注意力将低分辨率高级语义特征提升到粗粒度3d体素空间",{"2":{"922":1}}],["3d场景流估计",{"0":{"921":1}}],["3d场景图优化",{"0":{"380":1}}],["3d场景图的层级",{"2":{"352":2}}],["3d场景图的第3层",{"2":{"276":1}}],["3d场景图的第2层",{"2":{"253":1}}],["3d场景图的第1层",{"2":{"253":1}}],["3d场景图中的代理层存储了描述机器人轨迹的姿态图",{"2":{"352":1}}],["3d场景图被提出作为3d环境的表达性层次化模型",{"2":{"172":1}}],["3d场景图",{"2":{"112":1,"125":3,"326":1}}],["3d场景图将环境描述为一个分层图",{"2":{"112":1}}],["3d场景图最近作为一种强大的3d环境高级表示形式出现",{"2":{"112":1}}],["3d​",{"2":{"910":1}}],["3d​=φv​",{"2":{"910":1}}],["3d=φv",{"2":{"910":1}}],["3d目标跟踪",{"0":{"907":1}}],["3d目标检测任务中",{"2":{"617":1}}],["3d体素表示的高维度和密集计算使得学习过程资源消耗大",{"2":{"892":1}}],["3d体素表示与优化后的bev表示的融合特征随后输入任务头",{"2":{"585":1}}],["3dsketchrgb^",{"2":{"870":1,"978":1}}],["3dsketch",{"2":{"870":1,"917":1,"978":2,"982":1}}],["3d重建强调场景的几何质量和视觉外观",{"2":{"860":1}}],["3d重建是计算机视觉和机器人社区中的一个传统但重要的话题",{"2":{"860":1}}],["3d骨干网络表示用于点云特征提取的网络",{"2":{"779":1}}],["3d语义场景补全",{"0":{"841":1},"2":{"841":2}}],["3d语义高斯分布可以高效地表示3d场景",{"2":{"738":1}}],["3d语义分割",{"2":{"714":1}}],["3d语义占用预测因其对驾驶场景的全面描述而受到越来越多的关注",{"2":{"612":1}}],["3d语义占用预测",{"0":{"612":1}}],["3d语义占用预测方法的出现解决了这一问题",{"2":{"547":1}}],["3d语义占用预测旨在获取周围场景的3d细粒度几何结构和语义信息",{"2":{"516":1}}],["3d语义占据表示的引入进一步增强了avs的感知能力",{"2":{"438":1}}],["3d语义占据预测",{"2":{"475":1}}],["3d语义占据预测尤为重要",{"2":{"444":1}}],["3d语义占据预测对于实现安全可靠的自动驾驶至关重要",{"2":{"415":1}}],["3d语义占据预测任务将传感器周围的三维空间划分为体素",{"2":{"409":1}}],["3d网格的嘈杂和不完整性似乎并没有对dsg的更高层次的抽象产生负面影响",{"2":{"872":1}}],["3d网格实现了更好的几何精度",{"2":{"754":1}}],["3d网格rmse",{"2":{"709":1}}],["3d网格重建",{"0":{"336":1}}],["3d空间的空间表示被离散化为200×200×1的网格大小",{"2":{"811":1}}],["3d空间中的某些体素可能仅包含来自点云分支或视觉分支的特征",{"2":{"976":1}}],["3d空间中的多个体素对应于前视特征图中的同一位置",{"2":{"950":1}}],["3d空间中的计算负载较重",{"2":{"799":1}}],["3d空间中x",{"2":{"703":1}}],["3d空间在推理时水平和垂直翻转",{"2":{"673":1}}],["3d边界框仅估计前景物体的最大可能边界",{"2":{"665":1}}],["3d框回归损失",{"2":{"651":1}}],["3d高斯泼溅",{"2":{"860":1}}],["3d高斯分布的密度更高",{"2":{"924":1}}],["3d高斯分布的灵活性也有利于对一般物体",{"2":{"842":1}}],["3d高斯分布与预测占用之间的相似性表明了高效3d高斯表示的表达能力",{"2":{"911":1}}],["3d高斯分布会调整其协方差矩阵以捕获物体形状的细节",{"2":{"842":1}}],["3d高斯分布数量的影响",{"2":{"842":1}}],["3d高斯表示以3d高斯分布为基本单元",{"2":{"693":1}}],["3d高斯表示能够自适应地建模感兴趣区域",{"2":{"532":1}}],["3d高斯溅射",{"0":{"641":1}}],["3dcontextnet",{"2":{"636":1}}],["3d占用数据集",{"2":{"997":1}}],["3d占用提供了场景的细粒度和可操作表示",{"2":{"963":1}}],["3d占用预测挑战赛",{"2":{"1000":1}}],["3d占用预测涉及预测高分辨率体素的占用状态和语义类别",{"2":{"799":1}}],["3d占用预测通常需要使用3d体素特征表示环境空间",{"2":{"799":1}}],["3d占用预测通常使用平均交并比",{"2":{"778":1}}],["3d占用预测需要预测每个体素是否被占用",{"2":{"778":1}}],["3d占用预测任务中的真实标签表示3d空间中每个体素是否被占用以及占用体素的语义标签",{"2":{"735":1}}],["3d占用预测",{"2":{"637":1}}],["3d占用感知能够全面理解3d世界",{"2":{"1003":1}}],["3d占用感知的按时间顺序概述",{"2":{"759":1}}],["3d占用感知具有多源输入的性质",{"2":{"610":1}}],["3d占用感知技术旨在观察和理解自动驾驶车辆的密集3d环境",{"2":{"610":1}}],["3d占据预测挑战赛中的获胜方案",{"2":{"845":1}}],["3d占据预测的最早起源可以追溯到占据网格地图",{"2":{"566":1}}],["3d占据预测是指预测3d体素空间中每个体素的占据状态和语义类别",{"2":{"520":1}}],["3d占据表征的提出成功解决了传统3d物体检测网络的局限性",{"2":{"503":1}}],["3d可变形注意力和细化模块的迭代块优化高斯属性",{"2":{"595":1}}],["3d可变形注意力算子dfa3d",{"2":{"595":1}}],["3d物体检测器",{"2":{"715":1}}],["3d物体检测作为自动驾驶感知系统的基本组成部分",{"2":{"665":1}}],["3d物体检测",{"2":{"566":1}}],["3d物体检测任务仅限于在预定义类别内生成边界框",{"2":{"535":1}}],["3d物体检测在自动驾驶系统中扮演着至关重要的角色",{"2":{"535":1}}],["3d卷积进一步简化为两个运算",{"2":{"481":1}}],["3docc",{"2":{"425":1}}],["3d度量",{"0":{"362":1}}],["3d领域缺少高质量",{"2":{"265":1}}],["3d地点原语",{"0":{"228":1}}],["3d自监督",{"0":{"223":1},"1":{"243":1,"265":1,"288":1,"313":1,"339":1,"366":1,"394":1,"424":1,"454":1,"485":1,"515":1,"546":1,"579":1,"611":1,"640":1,"668":1,"692":1,"715":1},"2":{"215":1}}],["3d点云学习综述",{"0":{"219":1},"1":{"241":1,"263":1,"286":1,"311":1,"337":1,"363":1,"391":1,"420":1,"450":1,"481":1,"511":1,"542":1,"574":1,"607":1,"636":1,"664":1,"688":1,"711":1,"734":1,"756":1,"777":1,"798":1,"818":1,"838":1,"857":1,"874":1,"891":1,"907":1,"921":1,"931":1,"940":1,"948":1,"955":1,"962":1,"968":1,"974":1,"979":1,"983":1,"987":1,"990":1,"993":1,"996":1},"2":{"215":1}}],["3d概览",{"0":{"215":1}}],["3d对象原语",{"0":{"206":1}}],["3d对象姿态",{"2":{"178":1}}],["3d姿态",{"2":{"197":1,"218":1,"240":1}}],["3d位置",{"2":{"162":1}}],["3d动态场景图",{"0":{"147":1},"1":{"162":1},"2":{"105":1,"131":1,"147":1,"162":1}}],["3dgs",{"2":{"30":2}}],["3d",{"0":{"16":1,"132":1,"137":1,"150":1,"269":1,"314":1,"404":1,"412":1,"414":1,"427":1,"429":1,"445":1,"482":1,"512":1,"613":1,"656":1,"684":2,"734":1,"752":1,"789":1,"809":1,"829":1,"917":1,"948":1},"1":{"23":1,"30":1,"433":1,"443":1,"464":1,"473":1,"501":1,"531":1,"562":1,"576":1,"594":1,"609":1,"623":1,"638":1,"651":1,"666":1,"690":1,"707":2,"730":2,"736":1,"752":2,"756":1,"758":1,"777":1,"779":1,"798":1,"800":1,"818":1,"838":1,"857":1,"874":1,"891":1,"955":1,"962":1,"968":1,"974":1,"979":1},"2":{"23":3,"30":2,"31":1,"94":1,"102":1,"125":2,"126":2,"137":1,"162":1,"189":1,"195":1,"243":1,"247":2,"263":6,"271":1,"277":1,"285":1,"302":1,"306":1,"314":1,"323":2,"341":1,"349":5,"366":2,"369":8,"378":4,"384":5,"394":1,"412":2,"414":2,"423":2,"425":2,"435":5,"440":1,"441":1,"444":7,"455":5,"465":4,"471":3,"473":1,"474":9,"480":2,"481":4,"495":3,"502":5,"503":4,"508":1,"514":1,"515":2,"517":5,"525":1,"536":2,"537":1,"539":7,"545":8,"550":1,"556":3,"564":7,"567":16,"570":12,"577":1,"578":1,"588":11,"595":4,"596":8,"599":8,"603":1,"610":1,"613":1,"615":1,"619":6,"622":1,"625":2,"628":2,"632":16,"637":1,"641":4,"648":4,"652":2,"653":3,"656":5,"660":26,"670":4,"677":3,"678":6,"681":2,"684":3,"688":1,"692":1,"694":7,"700":2,"704":1,"715":1,"723":3,"724":3,"739":2,"745":1,"746":16,"749":2,"752":3,"765":4,"766":2,"767":7,"768":1,"782":2,"787":2,"789":12,"792":3,"808":7,"809":7,"814":1,"823":4,"826":1,"827":1,"828":3,"829":5,"832":1,"839":1,"841":1,"851":1,"853":2,"860":1,"865":1,"866":4,"867":4,"870":4,"875":1,"882":4,"884":2,"885":1,"899":2,"900":2,"901":2,"903":1,"906":1,"910":4,"913":3,"914":2,"915":1,"916":3,"917":3,"927":3,"928":10,"931":3,"935":1,"936":2,"937":2,"941":1,"945":1,"948":1,"952":3,"953":1,"955":3,"958":1,"962":7,"963":1,"968":4,"971":7,"975":1,"977":6,"978":1,"982":5,"988":1,"989":1,"1006":1}}],["3=c",{"2":{"8":1}}],["3",{"0":{"36":1,"68":1,"128":1,"137":1,"140":1,"160":1,"176":1,"195":1,"197":1,"209":1,"216":2,"231":1,"252":1,"274":1,"280":1,"285":1,"286":1,"299":2,"308":1,"311":1,"324":1,"337":1,"350":1,"363":1,"378":1,"391":1,"406":2,"420":1,"435":1,"450":1,"494":1,"502":1,"524":1,"532":1,"542":2,"543":1,"555":1,"556":1,"563":1,"576":1,"587":2,"588":1,"593":1,"595":2,"598":1,"609":1,"619":1,"627":1,"628":1,"632":1,"636":1,"638":2,"655":1,"656":1,"657":1,"660":1,"664":1,"666":1,"669":1,"673":1,"680":2,"681":1,"682":1,"684":1,"686":1,"690":1,"693":1,"697":1,"700":1,"703":1,"704":2,"705":1,"709":1,"716":1,"720":1,"726":1,"728":2,"738":2,"750":1,"757":1,"773":2,"779":1,"792":1,"794":2,"801":1,"810":1,"811":1,"814":2,"819":1,"821":1,"822":1,"830":1,"833":1,"834":1,"839":1,"841":1,"846":1,"850":1,"858":1,"860":2,"875":2,"877":1,"894":1,"910":1,"921":1,"923":1,"926":1,"928":1,"933":1,"942":1,"947":1,"950":1,"957":2,"964":2,"968":1,"970":2,"976":2,"981":1,"985":1,"988":1,"993":1,"995":1,"1005":1},"1":{"176":1,"195":1,"216":1,"252":1,"274":1,"299":1,"310":1,"311":1,"336":1,"337":2,"350":1,"362":1,"363":2,"378":1,"390":1,"391":1,"406":1,"419":1,"420":2,"435":1,"449":1,"450":2,"480":1,"481":3,"510":1,"511":3,"524":1,"532":1,"542":2,"555":1,"563":1,"574":4,"576":1,"587":1,"588":1,"595":1,"607":4,"609":1,"619":1,"627":1,"636":2,"638":1,"655":1,"656":1,"660":1,"664":2,"666":1,"680":1,"681":1,"682":1,"684":1,"688":2,"690":1,"693":1,"703":1,"704":1,"707":2,"709":1,"716":1,"726":1,"730":2,"738":1,"742":1,"752":2,"764":1,"773":1,"785":1,"794":3,"805":1,"814":3,"821":1,"825":1,"830":1,"834":1,"839":1,"841":1,"842":1,"850":1,"858":1,"860":1,"870":1,"875":1,"887":1,"894":1,"903":1,"910":2,"917":1,"923":2,"928":1,"933":1,"942":2,"945":1,"950":2,"953":1,"957":2,"960":1,"964":1,"970":3,"976":3,"985":1,"988":1},"2":{"8":2,"13":1,"15":2,"27":2,"47":1,"57":2,"66":2,"90":1,"93":13,"104":5,"107":2,"109":1,"115":3,"120":1,"126":1,"130":3,"136":5,"153":1,"161":8,"171":1,"189":2,"190":1,"196":1,"216":1,"231":4,"254":6,"265":3,"271":1,"274":1,"277":1,"285":1,"324":5,"333":1,"334":2,"349":1,"351":4,"379":3,"384":8,"390":14,"394":1,"413":1,"417":1,"421":1,"464":7,"466":1,"495":2,"504":1,"517":1,"520":1,"524":3,"532":3,"534":1,"547":1,"556":2,"562":1,"566":1,"570":6,"571":2,"604":1,"605":1,"616":6,"617":1,"621":4,"628":4,"632":12,"634":3,"654":2,"659":1,"660":3,"665":1,"667":1,"670":1,"671":1,"681":5,"682":3,"686":6,"693":3,"700":2,"705":2,"731":1,"736":1,"738":2,"744":1,"745":1,"749":4,"758":2,"760":1,"766":1,"773":4,"780":1,"781":1,"782":1,"787":2,"790":2,"791":3,"799":1,"812":1,"822":1,"824":1,"829":3,"835":1,"840":1,"847":4,"853":3,"854":1,"867":1,"888":2,"893":6,"900":1,"903":5,"908":1,"910":1,"911":1,"916":12,"917":1,"924":1,"928":13,"931":1,"936":1,"945":3,"947":1,"948":1,"950":1,"976":1,"978":1,"982":3,"988":1,"989":3,"1000":2,"1003":1}}],["+8",{"2":{"928":1}}],["+9",{"2":{"928":1}}],["+6",{"2":{"917":1,"928":1}}],["+4",{"2":{"803":1,"903":1}}],["+sc​",{"2":{"794":1}}],["+sc",{"2":{"794":1}}],["+rc​",{"2":{"794":1}}],["+rc",{"2":{"794":1}}],["+​​llscalsem​​",{"2":{"766":1}}],["+llscalsem",{"2":{"766":1}}],["+llov​",{"2":{"750":1}}],["+llov",{"2":{"750":1}}],["+lsemscal​",{"2":{"750":1}}],["+lsemscal",{"2":{"750":1}}],["+lgeoscal​",{"2":{"750":1}}],["+lgeoscal",{"2":{"750":1}}],["+fn",{"2":{"739":1,"742":1,"778":2,"848":1,"998":1}}],["+fp",{"2":{"739":1,"742":1,"778":2,"848":1,"998":1}}],["+wm​am",{"2":{"752":1}}],["+wmam",{"2":{"752":1}}],["+w",{"2":{"670":3,"694":1}}],["+=",{"2":{"651":2}}],["+=0∇x​log",{"2":{"235":1}}],["+k",{"2":{"524":1}}],["+γ∇logp",{"2":{"513":1}}],["+γ∇log⁡p",{"2":{"513":1}}],["+γ",{"2":{"513":2}}],["+y",{"2":{"435":1}}],["+tmk​−tml​∣∣2ωkl​+i=0∑n​l∈nm",{"2":{"390":1}}],["+tmk−tml∣∣2ωkl+∑i=0n∑l∈nm",{"2":{"390":1}}],["+δs",{"2":{"372":2}}],["+δt∂t∂​logp",{"2":{"208":1}}],["+δt∂∂tlog⁡p",{"2":{"208":1}}],["+3",{"2":{"306":1,"888":1,"903":1,"917":1}}],["+21",{"2":{"306":1}}],["+2",{"2":{"306":1,"903":1,"928":1}}],["+2ϵ​zi​",{"2":{"225":1}}],["+2ϵzi",{"2":{"225":1}}],["+0−2∇θ​epdata​",{"2":{"235":1}}],["+0−2∇θepdata",{"2":{"235":1}}],["+0",{"2":{"235":1,"306":1,"903":1,"928":5}}],["+∇xlog",{"2":{"235":1}}],["+g",{"2":{"208":3}}],["++iter",{"2":{"196":1}}],["+10",{"2":{"928":1}}],["+10°",{"2":{"173":1}}],["+14",{"2":{"928":1}}],["+12",{"2":{"928":1}}],["+1",{"2":{"803":1,"844":8,"928":4}}],["+1−αt​​zt​​​",{"2":{"111":1,"236":1}}],["+1−αtzt",{"2":{"111":1,"236":1}}],["+p",{"2":{"153":2}}],["+αt​​z~​1−αˉt​​βt​​=α​t​1​",{"2":{"140":1,"280":1}}],["+z~αtβt1−αˉt=1αt",{"2":{"140":1,"280":1}}],["+bx",{"2":{"140":1,"280":1}}],["+~",{"2":{"140":1,"280":1}}],["+x",{"2":{"58":1}}],["+cnn2​",{"2":{"649":1}}],["+cnn2",{"2":{"649":1}}],["+c",{"2":{"8":3}}],["+",{"2":{"8":2,"43":20,"51":20,"52":3,"57":2,"66":2,"77":2,"111":4,"124":1,"140":14,"153":1,"171":2,"174":3,"175":1,"184":1,"205":1,"208":12,"225":2,"235":2,"236":4,"251":2,"257":1,"273":6,"280":14,"333":3,"334":17,"351":2,"372":2,"390":7,"417":3,"423":1,"428":1,"441":2,"513":3,"525":1,"534":1,"563":1,"582":1,"595":2,"623":2,"649":2,"651":1,"666":1,"690":1,"693":1,"705":5,"716":2,"729":1,"738":1,"749":4,"750":3,"752":1,"766":4,"794":2,"802":4,"807":4,"834":4,"844":2,"863":2,"884":2,"888":1,"915":2,"916":1,"917":1,"977":4,"988":3,"998":1}}],["e提出了在不同的划分和排序方向上集成多个rcnet",{"2":{"664":1}}],["euroc数据不包括语义标签",{"2":{"836":1}}],["euroc数据集总共包括十一个数据集",{"2":{"572":1}}],["euroc序列",{"2":{"686":2}}],["euroc",{"2":{"572":1,"686":2,"754":1}}],["euclidean",{"2":{"31":2}}],["e都使用了transformer架构将潜在空间里的离散索引序列的建模问题转化为了一维的序列生成问题",{"2":{"371":1}}],["e4",{"2":{"351":2}}],["e3",{"2":{"351":2}}],["e1",{"2":{"351":2}}],["egopose",{"2":{"597":1}}],["egocentric",{"2":{"435":1,"495":6,"743":1}}],["ego",{"2":{"254":4,"597":1,"654":7,"790":1}}],["eglfs",{"2":{"64":1}}],["e^4",{"2":{"351":1}}],["e^3",{"2":{"351":1}}],["e^2",{"2":{"351":1}}],["e^1",{"2":{"351":1}}],["e^",{"2":{"213":1,"985":2}}],["e2",{"2":{"351":2}}],["e2和谷歌的imagen",{"2":{"205":1}}],["e2label",{"2":{"24":1}}],["elhayek等人",{"2":{"967":1}}],["elasticfusion",{"2":{"967":1}}],["elem",{"2":{"835":1}}],["element",{"2":{"196":1,"452":1}}],["elfes",{"2":{"698":1}}],["ell^2",{"2":{"814":2}}],["ellℓ×ℓ的增大",{"2":{"928":1}}],["ellℓ×ℓ",{"2":{"928":1}}],["ellℓ×ℓ大小的局部块",{"2":{"814":1}}],["ellℓ层",{"2":{"623":1}}],["ell+1",{"2":{"623":1}}],["ellqiℓ​​",{"2":{"623":1}}],["ellfiℓ​添加到目标查询qiℓq",{"2":{"623":1}}],["ell",{"2":{"623":10,"814":1,"853":2,"928":2}}],["else",{"2":{"52":2,"115":1,"795":1}}],["eₜ",{"2":{"171":7}}],["ekin",{"2":{"149":1}}],["eq",{"2":{"413":1}}],["equiv",{"2":{"235":1}}],["equal",{"2":{"196":1}}],["equations",{"2":{"170":1,"287":1}}],["equation",{"2":{"8":2,"235":2,"342":2}}],["eqa",{"2":{"139":1}}],["ep24",{"2":{"876":1}}],["ep15和ep24分别表示训练6个",{"2":{"876":1}}],["ep15",{"2":{"876":1}}],["ep6",{"2":{"876":2}}],["epσi​​",{"2":{"342":1}}],["epσi",{"2":{"342":1}}],["ep",{"2":{"235":2}}],["epstein",{"2":{"525":1}}],["epsilon$",{"2":{"623":1}}],["epsilonϵ",{"2":{"225":1}}],["epsilon",{"2":{"225":2,"623":1}}],["eps的系数",{"2":{"124":1,"257":1}}],["epochs",{"2":{"519":1}}],["epoch",{"2":{"43":3,"51":2,"771":2,"853":1}}],["effect",{"2":{"700":1}}],["effective",{"2":{"500":1}}],["effectiveness",{"2":{"345":1}}],["effectively",{"2":{"158":1,"496":1}}],["efficiency",{"2":{"700":1,"864":1}}],["efficientnet网络详解",{"2":{"912":1}}],["efficientnet",{"2":{"912":2}}],["efficientnetb7",{"2":{"632":1}}],["efficient",{"2":{"30":2,"593":2}}],["effocc和fb",{"2":{"779":1}}],["effocc需要对激光雷达分支进行三维目标检测预训练",{"2":{"779":1}}],["effocc中的图像特征提取网络swin",{"2":{"779":1}}],["effocc融合占据网络框架与密集融合占据网络",{"2":{"670":1}}],["effocc框架示意图",{"2":{"642":1}}],["effocc不得不调整其网络架构",{"2":{"482":1}}],["effocc",{"0":{"367":1,"395":1,"453":1},"1":{"425":1,"455":1,"487":1,"517":1,"548":1,"581":1,"613":1,"642":1,"670":1,"694":1,"717":1,"739":1,"761":1,"782":1,"803":1,"823":1,"843":1,"862":1,"879":1},"2":{"367":1,"425":1,"453":1,"455":2,"482":1,"517":1,"548":2,"642":1,"782":8,"803":7,"840":1}}],["effort",{"2":{"366":1}}],["eftekhar等人",{"2":{"121":1}}],["eij||2",{"2":{"390":1}}],["eij",{"2":{"390":1}}],["eij是对应于变形图中边的变换",{"2":{"390":1}}],["eiseg正式开源",{"2":{"117":1}}],["eigen3",{"2":{"47":1}}],["eigen",{"0":{"47":1},"2":{"15":1,"47":3,"67":2}}],["erin",{"2":{"126":1}}],["erase",{"0":{"633":1},"2":{"115":5,"633":3,"904":2}}],["errors",{"2":{"57":2}}],["error",{"2":{"11":1,"40":1,"57":2,"67":2,"806":2,"826":3}}],["each",{"2":{"111":1,"236":1,"327":2,"379":1,"384":1,"496":2,"518":2,"659":1,"700":1,"729":1}}],["ed",{"2":{"910":3}}],["edit",{"2":{"452":1}}],["editing",{"0":{"452":1},"2":{"201":1,"287":1,"289":1,"399":1,"452":1}}],["edges",{"2":{"271":1,"351":2,"496":2}}],["edgeconv",{"2":{"258":1}}],["edge~and",{"2":{"132":1}}],["edge",{"2":{"96":1,"132":2,"351":1,"379":13,"496":4}}],["edgeflow",{"0":{"96":1},"2":{"96":2,"117":1}}],["edu",{"2":{"76":1,"395":2}}],["etaη",{"2":{"153":1}}],["eta",{"2":{"153":1,"532":1,"563":1}}],["et",{"2":{"90":16,"123":18,"139":12,"155":4,"171":1,"189":17,"209":49,"252":7,"274":30,"350":8,"435":1,"495":14,"525":43,"556":5,"588":18,"619":18,"648":26,"698":22,"721":1,"743":4,"765":18,"806":14,"826":16,"864":4}}],["etc",{"2":{"24":2,"33":1,"66":1,"76":2,"78":2,"327":1}}],["eckenhoff等人",{"2":{"967":1}}],["ecall",{"2":{"794":1}}],["ecc",{"2":{"574":1}}],["eccv",{"2":{"243":1,"259":1,"369":1,"550":1,"817":1,"890":1}}],["eccv2020",{"2":{"84":1}}],["eccb",{"2":{"30":1}}],["echo",{"2":{"76":1,"78":2,"87":1}}],["evic∑c",{"2":{"985":1}}],["evetar",{"2":{"173":1}}],["everett等人",{"2":{"116":1}}],["even",{"2":{"64":1}}],["evaluation",{"0":{"786":1,"806":1,"826":1},"1":{"806":1,"826":1,"846":1}}],["evaluate",{"0":{"43":1,"51":1}}],["eval",{"2":{"27":1,"333":1}}],["engine",{"2":{"589":1,"593":1}}],["engel等人",{"2":{"967":1}}],["engel",{"2":{"189":1}}],["enables",{"2":{"518":1}}],["encder",{"0":{"373":1}}],["encourage",{"2":{"518":1}}],["encouraging",{"2":{"366":1}}],["encodings",{"2":{"549":1}}],["encoding",{"0":{"675":1,"698":1,"721":1,"743":1,"765":1},"1":{"698":1,"721":1,"743":2,"765":2},"2":{"333":4,"496":1,"549":1}}],["encoder来提出文本特征",{"2":{"373":1}}],["encoder来对输入text提取text",{"2":{"373":1}}],["encoder后得到最后的hidden",{"2":{"373":1}}],["encoder是一个transformer模型",{"2":{"373":1}}],["encoder模型是冻结的",{"2":{"373":1}}],["encoder模型大小为123m",{"2":{"319":1}}],["encoder模块将其编码为一个大小为h×w×ch",{"2":{"345":1}}],["encoder",{"0":{"318":1,"427":1},"2":{"184":4,"270":1,"274":2,"333":4,"373":5,"550":1}}],["encode",{"2":{"41":1}}],["enhancement",{"2":{"220":1,"382":1}}],["entropy",{"2":{"184":3,"826":1}}],["enqvist等人",{"2":{"116":1}}],["environment",{"2":{"120":1}}],["environmental",{"2":{"80":1}}],["env",{"0":{"48":1},"2":{"48":2}}],["end的模型来学习这类",{"2":{"220":1}}],["endl",{"2":{"196":3,"929":2}}],["endres",{"2":{"189":1}}],["end",{"0":{"857":2},"1":{"874":2,"891":2},"2":{"8":2,"93":2,"104":2,"111":1,"115":2,"120":1,"130":2,"132":1,"140":6,"153":2,"161":1,"177":1,"196":4,"208":3,"235":2,"236":1,"261":1,"273":2,"280":6,"296":2,"335":1,"342":1,"357":2,"372":1,"384":2,"390":2,"410":2,"513":1,"571":2,"633":1,"666":1,"888":1,"918":1,"929":4,"957":1}}],["esteves等人",{"2":{"481":1}}],["estimating",{"2":{"183":1,"382":1}}],["estimation",{"2":{"163":1,"235":1}}],["esurfv",{"2":{"372":1}}],["esurf​对应于tsurft",{"2":{"372":1}}],["esurf​",{"2":{"372":1}}],["esurf",{"2":{"372":1}}],["essential",{"2":{"36":1,"366":1}}],["esdf和地点层在",{"2":{"872":1}}],["esdf场",{"2":{"796":1}}],["esdf房间内的",{"2":{"480":1}}],["esdf房间",{"2":{"480":1}}],["esdf为esdf截面",{"2":{"480":1}}],["esdf的水平2d截面",{"2":{"480":1}}],["esdf的可用性以及",{"2":{"480":1}}],["esdf的2d切片",{"2":{"480":1}}],["esdf是根据机器人轨迹估计重建的",{"2":{"141":1}}],["esdf所需的内存随着环境大小的增加而扩展得很差",{"2":{"141":1}}],["esdf",{"2":{"31":5,"112":1,"125":2,"141":1,"285":1,"480":2,"947":2}}],["esam",{"0":{"7":1,"43":1,"51":1},"1":{"11":1,"17":1,"25":1,"32":1,"38":1,"43":1,"51":1},"2":{"11":1,"38":1,"43":5,"51":4}}],["emergency",{"2":{"702":2,"790":2}}],["emebeding",{"2":{"692":1}}],["ema",{"2":{"528":2,"758":1,"761":1}}],["emma",{"2":{"334":1}}],["embracing",{"2":{"715":1}}],["embeding层外",{"2":{"659":1}}],["embeding层对每个像素的channel数据做线性变换",{"2":{"659":1}}],["embeding就是直接通过一个卷积层实现的",{"2":{"659":1}}],["embedding层结构一模一样",{"2":{"659":1}}],["embedding",{"0":{"683":1},"2":{"340":1,"405":1,"456":1,"623":3}}],["embeddings将以cross",{"2":{"373":1}}],["embeddings",{"2":{"333":1,"373":2,"401":1}}],["embed",{"2":{"184":2,"333":5,"623":6}}],["embodiedscan引入了一个能够从多模态序列输入中进行连续空间占用预测的综合框架",{"2":{"629":1}}],["embodied",{"0":{"110":1},"1":{"123":1,"139":1},"2":{"23":1,"90":1,"100":1,"139":2,"537":1,"682":3}}],["embodiedocc框架",{"2":{"813":1}}],["embodiedocc对全局场景的空间占用预测不断改进",{"2":{"568":1}}],["embodiedocc",{"0":{"537":1,"750":1,"793":1,"886":1,"920":1},"1":{"568":1,"600":1,"629":1,"657":1,"682":1,"705":1,"728":1,"750":1,"772":1,"793":1,"813":1,"833":1,"852":1,"869":1,"886":1,"902":1},"2":{"23":1,"537":1,"793":1,"886":4,"902":3,"920":1}}],["empirically",{"2":{"405":1}}],["employed",{"2":{"315":1}}],["emplace",{"0":{"604":1},"2":{"104":2,"604":1,"835":1}}],["empty​if",{"2":{"957":1}}],["empty",{"0":{"479":1},"2":{"146":3,"479":1,"795":1,"854":2,"904":1,"957":1}}],["empower",{"2":{"30":1}}],["e",{"0":{"51":1,"678":1,"699":1,"809":1,"823":1,"827":1,"883":1,"899":1,"914":1,"927":1},"1":{"899":1,"914":1},"2":{"13":2,"27":1,"51":4,"111":1,"124":3,"162":1,"184":6,"235":10,"236":1,"254":1,"257":3,"285":2,"325":1,"327":1,"342":1,"351":2,"372":2,"449":1,"496":1,"681":7,"712":1,"718":1,"800":2,"928":1,"931":1,"967":1}}],["excitation层",{"2":{"976":1}}],["except",{"2":{"842":1}}],["exiawsh",{"2":{"671":1}}],["example",{"2":{"315":1,"333":1,"500":1}}],["examples",{"2":{"40":1,"152":1}}],["extrinsic",{"0":{"806":1}}],["extracts",{"2":{"384":1}}],["extractor",{"0":{"549":1},"2":{"315":2,"549":1}}],["extra",{"2":{"32":1,"38":1}}],["extension",{"2":{"392":1}}],["ext4",{"2":{"24":1}}],["ex∼pg​​",{"2":{"13":1}}],["ex∼pg​​dkl​",{"2":{"13":1}}],["ex∼pg",{"2":{"13":1}}],["ex∼pgdkl",{"2":{"13":1}}],["exponential",{"2":{"528":1}}],["expand",{"2":{"379":5,"496":1,"623":2}}],["experiment",{"0":{"614":1}}],["experiments",{"2":{"519":1}}],["experimental",{"2":{"45":1}}],["expected",{"2":{"333":1,"826":1}}],["expects",{"2":{"333":1}}],["exp⁡",{"2":{"208":2,"738":1}}],["explained",{"2":{"513":1}}],["exploring",{"2":{"584":1}}],["explorer",{"2":{"274":1}}],["exploration",{"2":{"139":1,"274":1}}],["exploding",{"2":{"251":1}}],["explicit",{"0":{"698":1},"2":{"80":1}}],["express",{"2":{"57":3}}],["exp",{"2":{"13":1,"140":5,"184":1,"208":8,"280":5,"316":1,"532":1,"656":1,"681":2,"693":2,"738":2,"916":2}}],["c表示摄像头",{"2":{"997":1}}],["c表示语义的总数",{"2":{"682":1}}],["c×",{"2":{"863":1}}],["c×c",{"2":{"844":1}}],["c​是它们的软预测对应物",{"2":{"814":1}}],["c​是其被预测为类别ccc的概率",{"2":{"794":1}}],["c​作为类别ccc在kkk中的比例",{"2":{"814":1}}],["c​",{"2":{"794":1}}],["c​ipi​=c​​",{"2":{"794":2}}],["c​∑i​p^​i",{"2":{"794":1}}],["c和l分别表示相机和激光雷达",{"2":{"736":1,"779":1,"840":1}}],["c∈rcc",{"2":{"705":1}}],["c∈r∣c∣",{"2":{"693":2}}],["c~i",{"2":{"681":1}}],["c~i​=∑j=1p​p",{"2":{"681":1}}],["c~i=∑i=1pp",{"2":{"681":1}}],["cxc​",{"2":{"660":3}}],["c0c",{"2":{"749":1,"802":1}}],["c0​",{"2":{"632":1,"780":2}}],["c0",{"2":{"632":1,"780":2}}],["cylinv",{"2":{"676":2}}],["cylin=maxpool",{"2":{"676":1}}],["cylin​=maxpool",{"2":{"676":1}}],["cylin​",{"2":{"621":2,"676":6}}],["cylin​∈rr×θ×z×c",{"2":{"621":2}}],["cylinp",{"2":{"621":2,"676":2}}],["cylin",{"2":{"621":4,"676":12}}],["cylin∈rr×θ×z×cp",{"2":{"621":2}}],["cylindrical",{"2":{"578":1}}],["ctfocc",{"2":{"791":1}}],["ctc",{"0":{"591":1},"2":{"591":1}}],["ctrl",{"2":{"77":1}}],["cj",{"2":{"579":1}}],["cj=n∑i=1n​",{"2":{"464":1}}],["cj=∑i=1n",{"2":{"464":1}}],["c⃝",{"2":{"550":1}}],["c+c",{"2":{"623":1}}],["c+l+r",{"2":{"545":1,"827":1,"847":1,"944":1,"952":1,"965":1}}],["c+l",{"2":{"545":1,"840":3,"900":1,"944":1,"965":1}}],["c+r",{"2":{"545":1,"944":1,"959":1,"965":1}}],["c++中deque是stack和queue默认的底层实现容器",{"2":{"938":1}}],["c++中的deque",{"2":{"871":1}}],["c++中申请哈希表的函数",{"2":{"196":1}}],["c++创建vector",{"2":{"73":1}}],["c++vector容器无敌详细",{"2":{"73":1}}],["c++",{"2":{"63":1,"67":1,"73":1,"217":1,"871":1}}],["c++字符串转换",{"2":{"63":1}}],["c++stl",{"0":{"44":1},"1":{"52":1,"63":1,"73":1,"83":1,"93":1,"104":1,"115":1,"130":1,"146":1,"161":1,"177":1,"196":1,"217":1,"239":1,"261":1,"284":1,"309":1,"335":1,"361":1,"389":1,"418":1,"448":1,"479":1,"509":1,"540":1,"571":1,"604":1,"633":1,"661":1,"685":1,"708":1,"731":1,"753":1,"774":1,"795":1,"815":1,"835":1,"854":1,"871":1,"888":1,"904":1,"918":1,"929":1,"938":1,"946":1}}],["c++14",{"2":{"40":1}}],["c++11新增函数",{"2":{"104":1}}],["c++11",{"2":{"40":1}}],["cpc​和rcr",{"2":{"794":1}}],["cpnet",{"2":{"684":1}}],["cp",{"2":{"609":2,"814":1}}],["cpu",{"2":{"522":1}}],["cpu生成结果",{"2":{"431":1}}],["cpkc^k",{"2":{"464":1}}],["cp​=",{"2":{"464":1}}],["cpj​",{"2":{"464":1}}],["cpj",{"2":{"464":1}}],["cp=",{"2":{"464":1}}],["c^",{"2":{"464":1,"595":2,"716":8,"863":1,"985":1}}],["ce损失和bce损失也广泛用于语义分割",{"2":{"985":1}}],["ce",{"2":{"532":1,"632":1,"670":4,"690":1,"738":2,"834":3,"985":2}}],["cell",{"2":{"378":1}}],["centric",{"2":{"1000":1}}],["central",{"2":{"351":1}}],["centers",{"2":{"594":1}}],["center",{"2":{"123":1,"254":2,"654":9}}],["centered",{"2":{"57":1}}],["cend",{"2":{"196":1,"918":1}}],["cfgs=",{"2":{"623":1}}],["cf",{"2":{"366":1}}],["c=0",{"2":{"985":1}}],["c=1",{"2":{"595":1,"739":1,"742":1,"778":1,"794":1}}],["c=​x1​xn​​y1​",{"2":{"357":1}}],["c=",{"2":{"357":1,"632":1}}],["c|",{"2":{"351":1}}],["c节",{"2":{"320":1}}],["c节验证了这些设计选择",{"2":{"228":1}}],["cguangyan",{"2":{"290":1,"688":1}}],["ckyh的博客",{"2":{"258":1}}],["cifar",{"2":{"958":1}}],["cipi=c∑iipi=c",{"2":{"794":1}}],["cipi=c∑ip^i",{"2":{"794":1}}],["cic",{"2":{"656":1,"728":1,"739":1}}],["cimℓ​",{"2":{"623":1}}],["cimℓc",{"2":{"623":1}}],["ci​",{"2":{"532":1,"656":1,"693":2,"728":1,"738":1,"739":1}}],["ci​∈r∣c∣",{"2":{"532":1}}],["ci",{"2":{"532":1,"579":1,"656":1,"693":2,"728":1,"738":1}}],["ci∈r∣c∣",{"2":{"532":1}}],["cider",{"2":{"447":1}}],["cider式或基于强化学习的描述调优已探索",{"2":{"417":1}}],["cin",{"2":{"413":1}}],["civera",{"2":{"209":1}}],["cityscapes",{"2":{"126":1,"995":2}}],["cbgs",{"2":{"876":1}}],["cbegin",{"2":{"196":1,"918":1}}],["cbow",{"2":{"184":1}}],["cm​",{"2":{"632":1}}],["cmtp",{"2":{"525":1}}],["cmp",{"2":{"495":1,"743":1}}],["cm²",{"2":{"495":1}}],["cm",{"2":{"435":1,"495":1,"632":1}}],["cmos",{"2":{"173":1}}],["cmaklist",{"2":{"107":1}}],["cmake单独编译cv",{"2":{"107":1}}],["cmake",{"2":{"36":3,"40":1,"47":1,"107":2,"120":1}}],["crf",{"2":{"955":1,"962":1}}],["crc​衡量相似类别ccc体素的性能",{"2":{"794":1}}],["crp",{"0":{"684":1},"1":{"707":1,"730":1,"752":1},"2":{"539":1,"570":1,"632":2,"684":1,"752":1,"853":1,"875":1,"928":4}}],["cra",{"2":{"467":2}}],["craig",{"2":{"123":1}}],["crop指随机从视图中挖出一块作为正样本",{"2":{"424":1}}],["crop",{"2":{"424":1}}],["crosses",{"2":{"729":1}}],["crossentropy",{"2":{"651":1}}],["cross",{"2":{"184":2,"384":1,"631":1}}],["crossattention",{"2":{"174":2}}],["createhighlighter",{"2":{"57":2}}],["create",{"2":{"32":1,"38":1,"120":1}}],["c1​",{"2":{"632":1}}],["c1",{"2":{"632":1}}],["c1cf6e31e6bade8868b172b4f42ed6fbab17c654",{"2":{"76":1}}],["c1=",{"2":{"8":1}}],["cn​",{"2":{"780":2}}],["cnet",{"2":{"759":1}}],["cnc​",{"2":{"532":1}}],["cnblogs",{"2":{"170":1,"207":1,"276":2,"325":1,"382":1}}],["cnn以进行体素分割",{"2":{"962":1}}],["cnn方法",{"2":{"775":1}}],["cnn再到mask",{"2":{"741":1}}],["cnn详解",{"2":{"741":1}}],["cnn中",{"2":{"741":1}}],["cnn中被称为quantization",{"2":{"554":1}}],["cnn1和cnn2是基于conv2d的小型网络",{"2":{"649":1}}],["cnn对roi",{"2":{"554":1}}],["cnn学习局部子集中邻域点之间的关系",{"2":{"511":1}}],["cnn应用到三维形状曲面所占用的八分角点上",{"2":{"363":1}}],["cnns的计算和存储成本",{"2":{"511":1}}],["cnns",{"2":{"306":1}}],["cnn真正实现了端到端的训练",{"2":{"296":1}}],["cnn的归纳偏置可以很好地概括图像的底层结构特性",{"2":{"343":1}}],["cnn的架构了",{"2":{"296":1}}],["cnn的串行特征提取方式",{"2":{"272":1}}],["cnn的贡献可以主要分为两个方面",{"2":{"272":1}}],["cnn",{"0":{"154":1,"229":1,"296":1,"523":1},"1":{"169":1,"187":1,"207":1,"250":1,"272":1,"321":1,"347":1,"375":1,"403":1,"432":1,"463":1,"493":1,"554":1},"2":{"122":1,"138":1,"237":1,"274":2,"363":1,"440":1,"481":2,"511":1,"622":1,"649":2,"670":1,"698":1,"741":3,"743":1,"844":1,"962":2,"967":1,"968":1,"974":1}}],["cnnmask",{"2":{"122":1}}],["cnnfaster",{"2":{"122":1}}],["cnnfast",{"2":{"122":1}}],["cn",{"2":{"76":1,"395":2,"780":2}}],["ccc进行归一化",{"2":{"681":1}}],["ccc中移除表示空类别的通道",{"2":{"681":1}}],["ccc来描述占用和未占用区域",{"2":{"656":1}}],["ccc",{"2":{"345":1,"595":1,"609":1,"656":1,"693":2,"712":1,"739":1,"742":2,"778":1,"780":1,"985":1}}],["cc",{"2":{"67":1,"244":1}}],["cv2",{"2":{"64":1}}],["cv",{"2":{"62":1,"107":6}}],["cvpr2022",{"0":{"117":1},"2":{"405":1}}],["cvpr2019",{"2":{"75":1}}],["cvpr",{"0":{"54":1,"65":1,"75":1,"84":1},"2":{"30":1,"75":1,"126":1,"148":1,"164":1,"185":1,"237":1,"268":1,"306":1,"312":1,"317":1,"410":2,"428":1,"452":1,"498":1,"515":1,"528":1,"668":1,"715":1,"837":1}}],["cui和ma",{"2":{"967":1}}],["curve",{"2":{"500":1}}],["cubes算法",{"2":{"253":1}}],["cubes实现提取3d度量语义网格和地点",{"2":{"253":1}}],["cut",{"2":{"54":1}}],["cuda",{"2":{"43":1,"51":1,"373":3,"866":1}}],["custom",{"2":{"17":1,"57":4}}],["csc​衡量不同类别体素",{"2":{"794":1}}],["css",{"2":{"57":4}}],["csdn博客",{"2":{"63":1,"73":1,"78":1,"96":1,"99":1,"106":3,"129":1,"149":1,"164":1,"177":1,"183":1,"196":1,"207":1,"223":1,"258":1,"325":2,"396":1,"410":1,"426":1,"496":1,"871":1,"912":1,"946":1}}],["csdn",{"2":{"41":1,"48":1,"106":1,"220":1,"351":1,"369":1,"508":1}}],["cs",{"2":{"30":1,"62":1}}],["cd",{"2":{"27":3,"36":1,"40":3,"47":2,"58":1,"87":1,"107":1,"120":5,"582":1}}],["cdots",{"2":{"57":1,"780":2,"976":2}}],["cdot",{"2":{"5":1,"532":3,"595":2,"656":4,"660":3,"670":4,"672":1,"681":1,"693":2,"694":2,"696":1,"716":2,"957":1,"976":1}}],["chiang等人",{"2":{"968":1}}],["chi^2",{"2":{"916":4}}],["child",{"2":{"702":1,"790":1}}],["children",{"2":{"333":1}}],["ch×w×c",{"2":{"345":1}}],["chen²",{"2":{"477":1}}],["chen等人",{"2":{"362":1}}],["cheng",{"2":{"189":1}}],["chen",{"2":{"139":1,"209":4,"274":1,"525":4,"588":1,"648":1,"698":2,"743":1,"765":1,"806":1}}],["checkpoint=true",{"2":{"174":1}}],["checkpoint",{"2":{"43":1,"174":4}}],["choy",{"2":{"962":1}}],["choset",{"2":{"698":1}}],["chojnacki和indelman",{"2":{"419":1,"967":1}}],["choi等人",{"2":{"116":1,"961":1}}],["chown",{"2":{"24":1}}],["challenges",{"0":{"864":1}}],["chamfer",{"2":{"582":5}}],["chain",{"2":{"256":1}}],["chaplot",{"2":{"139":2,"274":2,"495":1,"525":3,"698":3,"743":1,"806":1,"826":1}}],["chan",{"2":{"525":1}}],["chang",{"2":{"495":1,"698":2}}],["changyong",{"2":{"477":1}}],["chang等人",{"2":{"121":1}}],["channels=out",{"2":{"351":1}}],["channels=in",{"2":{"351":1}}],["channel",{"2":{"54":1,"106":1,"198":1,"254":1}}],["chatila和laumond",{"2":{"116":1,"961":2}}],["chmod",{"2":{"26":1,"58":1,"66":1}}],["clr",{"2":{"678":1}}],["clusternet",{"2":{"574":1}}],["clsclscls",{"2":{"915":1}}],["cls",{"0":{"347":1},"2":{"651":2,"666":2,"807":3,"915":2}}],["clear",{"2":{"115":2,"146":1,"904":1}}],["clip+vild",{"2":{"765":1}}],["clip2scene",{"2":{"588":1}}],["clip系列paper解读",{"2":{"469":1}}],["clip训练时所采用的设置",{"2":{"373":1}}],["cliptokenizer",{"2":{"373":3}}],["cliptextmodel",{"2":{"373":3}}],["clip损失引导生成",{"0":{"246":1},"1":{"268":1}}],["clip模型对用于图像描述的单词很敏感",{"2":{"204":1}}],["clip模型就可以用来解决这种问题",{"2":{"151":1}}],["clip使用4亿个配对的数据和文本来进行训练",{"2":{"167":1}}],["clip在完全不使用imagenet中所有训练数据的前提下直接zero",{"2":{"167":1}}],["clip",{"0":{"373":1,"399":1},"2":{"135":2,"184":1,"205":1,"268":1,"274":1,"319":1,"334":6,"373":4,"379":1,"399":1,"428":1,"469":2,"525":2,"588":3,"619":4,"698":1,"765":3}}],["clip引导生成",{"0":{"135":1},"1":{"151":1,"167":1,"184":1,"204":1,"226":1}}],["click的目标就是把球拍加入前景",{"2":{"117":1}}],["click都是有前景",{"2":{"84":1}}],["click",{"0":{"65":1}}],["clio可能会过度聚类",{"2":{"553":1}}],["clio将堆表示为按酱类型区分的多个对象",{"2":{"462":1}}],["clio将不同类型的调味品包集体表示为一个对象",{"2":{"462":1}}],["clio能够使用任务信息形成适当的场景表示",{"2":{"462":1}}],["clio与任务不可知基线相比保留了一个数量级更少的对象",{"2":{"462":1}}],["clioprim是clio前端的输出",{"2":{"431":1}}],["clio在场景图中仅选择了一次错误的目標对象",{"2":{"522":1}}],["clio在每次试验期间一直运行",{"2":{"522":1}}],["clio在每个后端更新时执行聚合ib",{"2":{"295":1}}],["clio在前端过度分割的3d对象原语上运行我们的聚合ib方法",{"2":{"271":1}}],["clio在操作开始时接收一个用自然语言指定的任务列表",{"2":{"109":1}}],["clio后端",{"0":{"249":1},"1":{"271":1,"295":1}}],["clio前端",{"0":{"186":1},"1":{"206":1,"228":1}}],["clio的后端执行增量聚合ib",{"2":{"168":1}}],["clio的前端接收rgb",{"2":{"168":1}}],["clio的依赖项之一",{"2":{"27":1}}],["clio由两个主要组件组成",{"2":{"168":1}}],["clio上开源了clio以及我们的定制数据集",{"2":{"109":1}}],["clio实时运行并且仅依赖于轻量级基础模型",{"2":{"109":1}}],["clio实时创建环境的层次地图",{"2":{"109":1}}],["clio不仅允许实时开放集3d场景图构建",{"2":{"109":1}}],["clio不仅允许实时构建紧凑的开放集3d场景图",{"2":{"98":1}}],["clio不需要这",{"2":{"27":1}}],["clio",{"0":{"12":1,"27":1,"34":1,"98":1,"168":1},"1":{"19":1,"27":1,"34":1,"109":1,"121":1,"137":1,"153":1,"168":1,"186":2,"206":2,"228":2,"249":2,"271":2,"295":2,"320":1,"346":1,"374":1,"402":1,"431":1,"462":1,"492":1,"522":1,"553":1,"586":1},"2":{"12":1,"27":8,"34":2,"95":1,"98":2,"271":2,"320":1,"462":2,"522":6,"586":1}}],["classification",{"2":{"659":1}}],["classifier",{"0":{"403":1,"513":1},"1":{"432":1,"463":1},"2":{"244":1,"365":1,"513":2}}],["classtokencontrast",{"0":{"591":1}}],["class",{"0":{"43":1,"51":1},"2":{"174":1,"333":3,"351":1,"492":1,"528":1,"591":1,"623":1,"702":2,"790":2}}],["classes=91",{"2":{"333":1}}],["classes",{"2":{"32":2,"38":2,"43":1,"51":1,"333":3}}],["closed",{"0":{"743":1},"2":{"366":1,"406":1,"721":1}}],["closure",{"2":{"189":1,"826":1}}],["cloudcompare",{"2":{"686":1}}],["cloud",{"0":{"314":1,"340":1},"1":{"368":1,"396":1,"426":1,"456":1},"2":{"243":1,"314":1,"315":2,"327":2,"394":1,"593":1,"623":1,"692":2,"715":2}}],["clouds",{"0":{"132":1},"2":{"23":1,"237":1,"290":1}}],["clock",{"2":{"34":1}}],["clone",{"2":{"27":1,"58":1,"120":2}}],["castellanos",{"2":{"826":1}}],["case",{"2":{"496":1}}],["cases",{"2":{"153":4,"957":2}}],["case的参数更新",{"2":{"84":1}}],["car",{"2":{"702":2,"790":2}}],["cartesian",{"2":{"699":2}}],["cartillier",{"2":{"435":1,"495":3,"698":1,"826":1}}],["carllava利用指令条件轨迹",{"2":{"507":1}}],["carllava",{"2":{"417":1}}],["carla",{"2":{"334":5,"360":1,"417":1,"447":2}}],["carlo",{"2":{"256":1}}],["carlone等人",{"2":{"310":1}}],["carlone",{"2":{"123":1,"155":1,"826":1}}],["caron",{"2":{"274":1}}],["cam4docc基于nuscenes和lyft",{"2":{"997":1}}],["cam4docc",{"2":{"975":1,"997":1}}],["cam=",{"2":{"724":3}}],["campari",{"2":{"958":1}}],["camps",{"2":{"619":1}}],["campos等人",{"2":{"390":1,"634":1}}],["campos",{"2":{"209":1,"525":1}}],["camn​",{"2":{"590":1,"724":1}}],["camn",{"2":{"590":1,"724":1}}],["cam2​",{"2":{"590":1,"724":1}}],["cam2",{"2":{"590":1,"724":1}}],["cam1​",{"2":{"590":1,"724":1}}],["cam1",{"2":{"590":1,"724":1}}],["cam",{"2":{"476":2,"528":1,"590":3,"621":3,"676":8,"724":6,"746":4}}],["cam中稀疏的激活区域通过随机游走策略传播到周围语义相同的区域",{"2":{"410":1}}],["cameracalibrator",{"2":{"136":1}}],["camera",{"2":{"15":1,"34":3,"120":4,"136":5,"152":1,"254":2,"597":1,"800":1}}],["cai",{"2":{"189":1}}],["cap",{"2":{"417":1}}],["captures",{"2":{"384":1}}],["captured",{"2":{"254":1}}],["capture",{"2":{"158":1}}],["capacity",{"2":{"83":1,"146":3,"938":1}}],["calib",{"2":{"654":3}}],["calibrated",{"2":{"254":3,"327":1,"476":1,"654":2}}],["calibrate",{"2":{"136":1}}],["calibration",{"2":{"136":2,"605":1}}],["calm",{"2":{"41":1}}],["can",{"2":{"135":1,"158":1,"365":1,"384":1,"659":1}}],["cannot",{"2":{"17":2}}],["caesar",{"2":{"126":1}}],["categories",{"2":{"327":1}}],["category",{"2":{"254":4,"327":2,"476":1}}],["cat",{"2":{"124":1,"257":1,"333":1,"351":1,"621":3,"676":9}}],["catkin",{"2":{"27":9,"34":1,"120":1}}],["cadena等人",{"2":{"116":2,"178":1,"961":1}}],["cadena",{"2":{"90":1,"189":1,"209":2}}],["ca",{"2":{"43":5,"51":4}}],["cohff",{"2":{"969":1}}],["coherently",{"2":{"452":1}}],["coco新纪录65",{"2":{"824":1}}],["cow",{"2":{"765":1}}],["cosine",{"2":{"823":1}}],["cos",{"2":{"694":1}}],["cost",{"0":{"411":1},"2":{"440":1,"651":3}}],["cofusion",{"2":{"588":1}}],["co",{"2":{"469":2,"474":1,"482":1,"700":2,"967":1,"976":1}}],["coverage",{"2":{"668":2,"806":1,"916":5}}],["covariance",{"2":{"328":1}}],["covla",{"2":{"283":1,"334":2,"417":1}}],["coord​",{"2":{"676":2}}],["coord​∈rn×d×h×w×3",{"2":{"621":1}}],["coord",{"2":{"621":1,"649":3,"676":4}}],["coord∈rn×d×h×w×3v",{"2":{"621":1}}],["coordinates",{"2":{"321":1}}],["cool",{"2":{"57":1}}],["coefficient",{"2":{"208":2}}],["coefficients",{"2":{"136":1}}],["coarse",{"2":{"181":1}}],["corner",{"2":{"741":1}}],["corners",{"2":{"379":1}}],["correct",{"2":{"916":2}}],["correction",{"2":{"117":1}}],["corrections",{"2":{"84":1}}],["correspond",{"2":{"616":1}}],["correspondence",{"2":{"158":1}}],["corresponding",{"2":{"153":1}}],["corrupt",{"2":{"120":1}}],["core能够重建一个一致的3d网格",{"2":{"872":1}}],["core重建的3d网格在全球范围内是一致的",{"2":{"872":1}}],["core重建的3d网格",{"2":{"872":1}}],["corenet",{"2":{"870":1,"928":4}}],["core构建3d度量",{"2":{"816":1}}],["core模块的计时性能",{"2":{"816":1}}],["core所需的rgb",{"2":{"605":1}}],["core生成的全局一致的3d度量",{"2":{"285":1}}],["core大量并行化",{"2":{"285":1}}],["core的架构",{"2":{"285":1}}],["core是开源的",{"2":{"285":1}}],["core中",{"2":{"131":1}}],["core之上工作",{"2":{"131":1}}],["core和kimera",{"2":{"131":1}}],["core",{"2":{"107":2,"131":1,"285":8,"836":1}}],["cotr",{"2":{"875":1,"950":1,"1000":1}}],["cot",{"2":{"82":1,"145":1,"334":1}}],["cout",{"2":{"130":2,"146":5,"196":3,"413":1,"774":1,"795":2,"929":2}}],["count为各个卷积权重的数量统计",{"2":{"561":1}}],["count=",{"2":{"504":1}}],["count=4096",{"2":{"26":2}}],["count",{"0":{"540":1,"661":1},"2":{"57":2,"540":1,"661":1}}],["could",{"0":{"53":1},"1":{"64":1,"74":1},"2":{"64":3,"74":2,"366":1,"440":1}}],["cols",{"2":{"136":4}}],["col",{"2":{"57":2,"333":2}}],["color",{"2":{"34":1,"43":2,"136":1}}],["colmap",{"2":{"34":1}}],["collaborative",{"2":{"30":1}}],["codes",{"2":{"721":1}}],["code的区域位置",{"2":{"181":1}}],["code组成的空间就是",{"2":{"149":1}}],["codename",{"2":{"76":1}}],["code",{"2":{"30":1,"45":1,"57":1,"148":1,"149":1,"181":2,"221":1,"243":1,"268":1,"287":1,"290":1,"306":1,"312":1,"323":1,"394":1,"399":1,"422":1,"426":1,"452":1,"498":1,"513":2,"515":1,"593":2,"668":1,"692":1,"715":2}}],["con",{"2":{"922":1}}],["cone",{"2":{"702":1,"790":1}}],["conet",{"2":{"474":1,"976":1}}],["consuming",{"2":{"776":1}}],["consistency",{"2":{"382":1,"826":1,"949":1}}],["construction",{"2":{"102":1,"702":3,"790":3}}],["const",{"2":{"57":13,"67":2,"93":2,"104":4,"161":3,"196":2,"782":1,"904":5,"929":2}}],["convnets",{"0":{"804":1}}],["convnext",{"2":{"195":1}}],["conv实现置换不变性转换",{"2":{"511":1}}],["convpoint",{"2":{"481":2}}],["conv3d",{"2":{"425":1,"670":1,"829":1,"865":1}}],["convexity",{"2":{"380":1}}],["conv2d",{"2":{"333":1,"351":1,"670":3,"865":1}}],["conv",{"0":{"672":1,"696":1},"2":{"333":2,"351":4,"379":1,"696":1,"910":1}}],["convolutional",{"0":{"616":1},"1":{"645":1,"672":1,"696":1,"719":1,"741":1,"763":1,"784":1},"2":{"589":1,"616":1,"763":1,"863":1,"912":1}}],["convolutions",{"2":{"496":1,"584":1}}],["convolution",{"0":{"325":1,"351":1,"413":1,"645":1},"1":{"351":1,"672":1,"696":1},"2":{"481":1,"496":1,"500":1,"589":1,"593":1,"616":2}}],["condition",{"2":{"806":1}}],["conditional~score",{"2":{"513":1}}],["condition将通过crossattention模块嵌入进来",{"2":{"401":1}}],["conditioned",{"2":{"251":1}}],["conditioning",{"0":{"264":1,"266":1},"1":{"289":1},"2":{"201":1,"264":1,"266":1}}],["conceptgraphs",{"2":{"765":2,"826":1}}],["conceptgraphs使用多个对象视图查询大型视觉",{"2":{"121":1}}],["conceptgraphs使用clip和sam聚类场景中的对象",{"2":{"121":1}}],["conceptfusion",{"2":{"588":1}}],["concatenate",{"2":{"379":2,"504":1}}],["concat",{"2":{"175":1,"464":3,"976":4}}],["conflict",{"2":{"107":1}}],["conf",{"2":{"66":1}}],["configs",{"2":{"43":1,"51":1}}],["config",{"2":{"27":3,"36":1,"47":1,"78":3,"152":1}}],["connections",{"2":{"729":1}}],["connection",{"2":{"631":1}}],["connectivity",{"2":{"496":2}}],["connecting",{"2":{"135":1}}],["connected",{"2":{"153":1,"379":1}}],["connect",{"0":{"53":1},"1":{"64":1,"74":1},"2":{"64":1,"74":2}}],["content",{"2":{"623":1}}],["context=context",{"2":{"174":1}}],["context=none",{"2":{"174":2}}],["context",{"2":{"174":4,"469":1,"621":2,"649":3,"875":1}}],["contaminated",{"2":{"440":1}}],["contains",{"2":{"57":1,"327":7}}],["continental",{"2":{"173":1}}],["continuous",{"2":{"84":1}}],["continue",{"2":{"52":1,"66":2}}],["control",{"0":{"422":1},"2":{"120":1,"201":1,"422":1}}],["contrast",{"0":{"515":1,"559":1},"1":{"546":1,"579":1,"611":1,"640":1},"2":{"8":1,"515":1,"528":1,"591":1,"659":1}}],["combination",{"2":{"496":2}}],["combined",{"2":{"496":1}}],["comp",{"2":{"929":2}}],["comparison",{"2":{"700":1}}],["comparable",{"2":{"671":1}}],["compared",{"0":{"431":1}}],["completescannet",{"2":{"886":1}}],["completeness",{"2":{"826":1}}],["completion",{"2":{"508":1}}],["complexity",{"2":{"659":2}}],["computing",{"2":{"729":1}}],["compute",{"2":{"651":1}}],["computed",{"2":{"440":1,"729":1}}],["computation",{"2":{"496":1,"659":4,"729":1}}],["compressing",{"2":{"496":1}}],["compvis",{"2":{"174":1,"185":1,"428":1}}],["components",{"2":{"153":1}}],["command",{"2":{"49":1}}],["commands",{"2":{"38":1}}],["com",{"2":{"12":1,"23":2,"27":1,"30":8,"31":1,"36":2,"40":1,"58":1,"73":1,"76":1,"87":1,"98":1,"107":1,"109":1,"117":1,"120":2,"126":1,"131":1,"133":1,"135":1,"141":1,"170":1,"174":1,"179":1,"185":2,"201":1,"207":1,"223":1,"243":1,"258":1,"264":1,"266":1,"276":2,"290":1,"292":2,"302":1,"325":2,"328":1,"367":1,"369":1,"382":3,"392":1,"409":1,"410":2,"414":2,"428":1,"439":1,"445":1,"453":1,"469":2,"475":1,"490":1,"500":2,"513":1,"528":2,"545":1,"577":1,"584":1,"589":2,"605":1,"610":1,"635":1,"637":1,"663":2,"671":1,"687":1,"688":1,"710":1,"715":1,"733":1,"763":1,"776":1,"804":1,"824":1,"839":1,"890":1,"906":1,"920":1}}],["c2dc2dc2d",{"2":{"699":1}}],["c2d",{"2":{"699":3}}],["c2​=",{"2":{"8":1}}],["c2=",{"2":{"8":1}}],["c3=c2",{"2":{"8":1}}],["c",{"0":{"522":1,"625":1,"649":1,"670":1,"768":1,"782":1,"787":1,"848":1,"900":1,"916":1,"934":1},"2":{"8":4,"57":2,"76":1,"92":1,"111":1,"145":1,"149":1,"162":2,"184":1,"197":1,"208":1,"236":1,"285":2,"325":4,"333":1,"336":1,"351":6,"357":1,"380":1,"390":1,"419":2,"423":1,"436":2,"450":1,"464":2,"480":2,"532":11,"563":1,"595":4,"609":4,"621":8,"622":2,"623":2,"632":4,"642":1,"649":1,"656":5,"659":1,"660":1,"676":7,"681":3,"682":2,"693":10,"694":9,"703":3,"705":6,"712":9,"716":7,"728":1,"736":2,"738":1,"739":9,"742":9,"746":7,"749":8,"756":1,"778":9,"780":4,"794":21,"800":1,"802":8,"814":14,"818":1,"824":1,"840":1,"848":8,"863":4,"867":1,"877":1,"900":1,"942":1,"944":1,"957":4,"959":1,"985":6,"997":1,"998":3,"1000":1}}],["l表示激光雷达",{"2":{"997":1}}],["lpho​=2α​",{"2":{"988":1}}],["lpho=α2",{"2":{"988":1}}],["lbce​=−nv​1​i=0∑nv​​v^i​log",{"2":{"985":1}}],["lbce=−1nv∑i=0nvv^ilog",{"2":{"985":1}}],["lbm",{"2":{"66":2}}],["l主干和vit",{"2":{"805":1}}],["lx​×ly​×lz​",{"2":{"793":2}}],["lx×ly×lz",{"2":{"793":2}}],["lvlms",{"2":{"1006":1}}],["lvlm",{"2":{"765":3}}],["l∈",{"2":{"746":2}}],["l和r分别表示相机",{"2":{"736":2}}],["l^n",{"2":{"746":2}}],["l^",{"2":{"704":4}}],["l^g",{"2":{"582":2}}],["l=l=1∑l​2l1​",{"2":{"884":1}}],["l=∑l=1l12l",{"2":{"884":1}}],["l=∑i=1b​",{"2":{"738":1}}],["l=∑i=1b",{"2":{"738":1}}],["l=0",{"2":{"766":1}}],["l=λ1​lfocal​",{"2":{"750":1}}],["l=λ1lfocal",{"2":{"750":1}}],["l=",{"2":{"704":2}}],["l=4l",{"2":{"867":1}}],["l=4",{"2":{"699":5}}],["l=1l=4=bilinear",{"2":{"699":1}}],["l=1l=4=fpn",{"2":{"699":3}}],["l=1l=4​=bilinear",{"2":{"699":1}}],["l=1l=4​=fpn",{"2":{"699":3}}],["l=1l=4​",{"2":{"699":1}}],["l=1l=4",{"2":{"699":1}}],["l=1",{"2":{"153":1,"699":5,"884":1}}],["lfocal+llovaˊsz+lscene",{"2":{"884":1}}],["lfocal​+llovaˊsz​+lscene",{"2":{"884":1}}],["lfocal​",{"2":{"750":1,"766":1}}],["lfocall",{"2":{"750":1,"766":1}}],["lfp=∑k=1ℓ2dkl",{"2":{"814":1}}],["lfp​=k=1∑ℓ2​dkl​",{"2":{"814":1}}],["lfp​作为局部视锥的",{"2":{"814":1}}],["lfp​",{"2":{"632":1,"853":1}}],["lfpl",{"2":{"632":1,"853":1}}],["lfloor",{"2":{"712":1}}],["lfl​",{"2":{"585":1}}],["lfll",{"2":{"585":1}}],["lgeoscal​",{"2":{"750":1}}],["lgeoscall",{"2":{"750":1}}],["lgeo",{"2":{"632":2,"794":2,"834":1,"928":2}}],["lg=l1g+l2gl^g",{"2":{"582":1}}],["lg2",{"2":{"582":3}}],["lg1",{"2":{"582":3}}],["lg",{"2":{"582":1}}],["lcd",{"2":{"816":1}}],["lcls​=−n1​ij∑​",{"2":{"666":1}}],["lcls=−1n∑ij",{"2":{"666":1}}],["lce=−1nc∑i=0nv∑c=0ncωcv^iclog",{"2":{"985":1}}],["lcei​+llovi​",{"2":{"738":1}}],["lcei+llovi",{"2":{"738":1}}],["lce",{"2":{"670":1}}],["lce​=−nc​1​i=0∑nv​​c=0∑nc​​ωc​v^ic​log",{"2":{"985":1}}],["lce​使用类别权重",{"2":{"834":1}}],["lce​",{"2":{"532":1,"632":1,"670":1,"738":1,"834":1}}],["lcel",{"2":{"532":1,"632":1,"738":1,"834":1}}],["lc保持相似的精度和召回率水平",{"2":{"437":1}}],["lc保持相似",{"2":{"437":1}}],["lc和vio+v",{"2":{"437":2}}],["lc和vio+sg",{"2":{"437":1}}],["lc通常会导致结果的标准差降低",{"2":{"437":1}}],["lc在对象准确性方面大大优于vio+v",{"2":{"437":1}}],["lc在对象和地点的准确性上保持了合理的水平",{"2":{"437":1}}],["lc",{"2":{"437":7,"686":1,"803":4}}],["l||^2",{"2":{"390":2}}],["lópez和tardós",{"2":{"390":1}}],["l1l1l1距离",{"2":{"916":1}}],["l1l1l1",{"2":{"666":1,"681":1}}],["l1",{"2":{"375":1,"499":1,"582":2,"651":1,"823":1}}],["l196c40",{"2":{"174":2}}],["l2",{"2":{"184":2,"582":2}}],["lmscnetrgb^",{"2":{"870":1,"978":1}}],["lmscnet",{"2":{"870":1,"917":2,"923":1,"978":2}}],["lmdrive",{"2":{"308":1}}],["lm",{"2":{"179":1,"525":1}}],["ldepth",{"2":{"766":2}}],["ldet​=lcls​+λl​lloc​",{"2":{"666":1}}],["ldet=lcls+λlllocl",{"2":{"666":1}}],["ldistill​",{"2":{"694":1}}],["ldistill​=wbev​⋅ld",{"2":{"694":1}}],["ldistilll",{"2":{"694":1}}],["ldistill=wbev⋅ld",{"2":{"694":1}}],["ldirection​",{"2":{"268":1}}],["ldirection",{"2":{"268":1}}],["ld",{"2":{"694":6}}],["ld​",{"2":{"585":1}}],["ldl",{"2":{"585":1}}],["ldl​",{"2":{"585":1}}],["ldll",{"2":{"585":1}}],["ldgcnn",{"2":{"574":1}}],["ldots",{"2":{"524":1,"632":1,"730":3,"780":3}}],["ldm",{"2":{"174":1}}],["ldconfig",{"2":{"36":1,"120":1}}],["lγl​",{"2":{"153":1}}],["lrel=−∑m∈m",{"2":{"752":1}}],["lrel​对关系矩阵",{"2":{"928":1}}],["lrel​=−m∈m",{"2":{"752":1}}],["lrel​",{"2":{"752":2,"834":1,"853":1,"928":1}}],["lrell",{"2":{"752":1,"853":1,"928":2}}],["lr图像x",{"2":{"329":1}}],["lr",{"2":{"111":1,"175":1,"208":1,"236":1,"329":1}}],["llfocal​​+lllovasz​​+llscalgeo",{"2":{"766":1}}],["llfocal+lllovasz+llscalgeo",{"2":{"766":1}}],["llava",{"2":{"765":1}}],["llamagen",{"2":{"334":1}}],["llama",{"2":{"334":1}}],["lloc​=n1​k=1∑n​∣s^k​−sk​∣",{"2":{"666":1}}],["lloc=1n∑k=1n∣s^k−sk∣l",{"2":{"666":1}}],["llovasz​",{"2":{"766":1}}],["llovaszl",{"2":{"766":1}}],["llov​",{"2":{"532":1,"738":1,"750":1}}],["llovl",{"2":{"532":1,"738":1,"750":1}}],["ll层利用一个可学习的距离度量来参数化图上两个顶点之间的相似性",{"2":{"607":1}}],["lls",{"2":{"670":1}}],["lls​",{"2":{"585":1,"670":1}}],["llsl",{"2":{"585":1}}],["llc",{"2":{"334":9}}],["lluvia",{"2":{"209":1}}],["llm可能幻觉危险或误解俚语",{"2":{"478":1}}],["llm内仅更新数百万参数",{"2":{"417":1}}],["llm总结历史并输出下一轨迹及对应自然语言解释",{"2":{"334":1}}],["llm置于控制循环中心",{"2":{"334":1}}],["llms",{"2":{"109":1,"1006":1}}],["llm",{"2":{"82":1,"128":2,"274":1,"334":1,"417":1,"765":3}}],["lll进行匹配",{"2":{"704":1}}],["lll",{"2":{"8":1,"153":2,"647":1,"699":1,"738":1,"746":1,"766":2,"884":3}}],["loc",{"2":{"666":2}}],["locations",{"2":{"496":1,"616":3}}],["location",{"2":{"254":1}}],["locally",{"2":{"452":1}}],["localization",{"0":{"155":1},"1":{"171":1,"189":1,"209":1},"2":{"90":1}}],["local",{"2":{"36":1,"41":1,"107":1,"525":1,"659":1,"746":8,"870":1}}],["lovasz",{"2":{"670":3,"750":1,"766":2,"782":1,"988":1}}],["lov",{"2":{"532":1,"738":2,"750":2}}],["lovász",{"2":{"532":1,"690":1,"766":1,"884":2}}],["lost",{"2":{"496":1}}],["lossinit​=bce",{"2":{"704":1}}],["lossinit=bce",{"2":{"704":1}}],["loss=occloss+λldepth",{"2":{"766":2}}],["loss=i=0∑l​​s",{"2":{"647":1}}],["loss=∑i=0l",{"2":{"647":1}}],["loss计算损失",{"2":{"424":1}}],["loss和gan共同完成",{"2":{"371":1}}],["loss和giou",{"2":{"358":1}}],["loss采用了l1",{"2":{"358":1}}],["loss对两种视角下点云的点进行对比学习",{"2":{"339":1}}],["loss与交叉熵损失的联系",{"2":{"223":1}}],["loss",{"2":{"124":1,"153":1,"184":8,"223":2,"257":1,"268":1,"345":2,"358":1,"375":1,"463":1,"591":1,"651":6,"704":1,"766":1}}],["loper等人",{"2":{"419":2,"967":1}}],["lorbach",{"2":{"525":1}}],["lora在语言增广数据上适配llm",{"2":{"417":1}}],["lora与适配器在70b",{"2":{"417":1}}],["lora适配器",{"2":{"417":1}}],["lorensen和cline",{"2":{"362":2}}],["loop",{"2":{"189":1,"826":1}}],["loopclosing",{"2":{"67":2}}],["lower",{"2":{"500":1}}],["lowe",{"2":{"189":1}}],["low",{"2":{"180":1,"220":2,"659":1}}],["loeliger",{"2":{"171":1}}],["longrightarrow",{"2":{"140":2,"280":2}}],["long型变量",{"2":{"63":3}}],["long",{"2":{"57":4,"63":1,"765":2}}],["load",{"2":{"32":5,"38":6,"43":1,"64":1,"504":1}}],["logfile",{"2":{"254":1}}],["logp^k​",{"2":{"814":1}}],["logp",{"2":{"208":2}}],["logits",{"2":{"184":3,"333":4}}],["log⁡qσ",{"2":{"235":1}}],["log⁡pk",{"2":{"814":1}}],["log⁡p",{"2":{"208":2,"235":1,"256":1}}],["log⁡",{"2":{"137":1,"752":1}}],["log⁡y",{"2":{"57":2}}],["logy",{"2":{"57":2}}],["log",{"2":{"5":1,"57":4,"137":2,"208":19,"225":2,"235":6,"254":5,"316":2,"338":1,"342":1,"422":1,"476":1,"513":9,"666":2,"752":3,"794":3,"814":1,"985":5}}],["leq",{"2":{"916":1}}],["leutenegger等人",{"2":{"634":1}}],["leibler",{"2":{"814":1,"823":1,"985":1}}],["lei",{"2":{"588":1,"914":1}}],["lei等人",{"2":{"511":1,"636":1}}],["leverage",{"2":{"452":1}}],["levels",{"2":{"616":1}}],["level的全局级别的表示是不够的",{"2":{"313":1}}],["level的模型",{"2":{"220":1}}],["level的增强网络",{"2":{"220":1}}],["level之间的联系",{"2":{"220":1}}],["level任务",{"2":{"220":2}}],["level",{"2":{"145":1,"175":1,"180":1,"254":1,"313":1,"410":2,"439":1,"997":2}}],["leonard",{"2":{"209":2}}],["learn",{"2":{"941":1}}],["learnable",{"0":{"400":1},"2":{"384":1,"496":2}}],["learned",{"2":{"184":3,"365":1,"384":1}}],["learning",{"2":{"23":1,"84":1,"135":1,"149":1,"237":1,"325":1,"366":1,"410":2,"504":1,"515":2,"518":1}}],["le",{"2":{"132":3,"363":1}}],["lemon",{"2":{"129":1}}],["lerf可以通过文本查询",{"2":{"121":1}}],["less",{"2":{"67":2}}],["lens",{"2":{"173":1}}],["length=tokenizer",{"2":{"373":1}}],["length",{"0":{"221":1},"2":{"52":2,"221":1,"333":1,"373":2,"379":1,"806":1}}],["len",{"2":{"52":1,"351":3}}],["left|",{"2":{"957":1}}],["leftrightarrow",{"2":{"730":6}}],["leftrightarrow↔体素关系",{"0":{"707":1,"730":1},"2":{"707":1}}],["leftrightarrow↔",{"2":{"684":1,"707":1,"730":1}}],["left",{"2":{"31":2,"57":3,"132":1,"137":1,"193":1,"208":4,"268":3,"357":2,"464":2,"532":1,"647":2,"656":1,"666":1,"681":3,"693":2,"694":2,"729":1,"738":4,"741":1,"752":1,"780":3,"910":2,"916":3,"942":4,"950":13,"957":11,"976":3,"985":5,"988":3}}],["lassner等人",{"2":{"967":1}}],["last",{"2":{"104":2,"115":2,"161":2,"254":2,"333":1,"904":4}}],["lawin",{"2":{"955":1}}],["laboratory提供的基于照片真实的unity模拟器生成的",{"2":{"605":1}}],["lab",{"2":{"584":1}}],["label",{"2":{"32":3,"504":4,"534":1,"562":1,"651":1,"698":1}}],["labels",{"2":{"32":2,"38":2,"184":3,"327":3,"504":2,"534":2,"949":1}}],["lambdaλ",{"2":{"766":1}}],["lambda^",{"2":{"647":2}}],["lambda",{"2":{"342":1,"666":1,"690":1,"750":2,"766":2}}],["lal",{"2":{"328":1}}],["lag",{"2":{"310":1}}],["layer的四舍五入取整操作导致其进行了偏移",{"2":{"554":1}}],["layers=6",{"2":{"333":2}}],["layers=num",{"2":{"333":2}}],["layers",{"2":{"333":6,"351":1,"379":1,"496":2,"616":1,"659":1}}],["layer在全图特征上摘取每一个roi对应的特征",{"2":{"250":1}}],["layer",{"0":{"347":1,"375":1},"2":{"247":1,"250":1,"296":2,"345":1,"496":3,"729":3,"762":1}}],["layernorm",{"2":{"174":3}}],["lai",{"2":{"209":1}}],["latent",{"0":{"165":1,"248":1},"2":{"149":4,"165":1,"174":1,"185":1,"205":2,"221":1,"248":2,"278":1,"289":1,"345":1,"428":1,"721":2}}],["latest",{"2":{"60":1,"76":1}}],["lane",{"2":{"550":1,"644":1}}],["lanesegnet",{"2":{"123":1}}],["lan",{"2":{"458":1}}],["lantent",{"0":{"227":1}}],["landsiedel",{"2":{"209":1}}],["lang等人",{"2":{"362":1}}],["langcoop",{"2":{"283":1,"334":1}}],["langle",{"2":{"268":1}}],["langevin",{"0":{"256":1},"2":{"354":1}}],["language",{"0":{"79":1},"2":{"62":1,"135":1,"139":2,"399":1,"469":1}}],["lang=",{"2":{"57":1}}],["langs",{"2":{"57":1}}],["lang",{"2":{"30":1,"126":1}}],["larsson等人",{"2":{"930":1}}],["larsson和akenine",{"2":{"905":1}}],["larsson",{"2":{"121":1}}],["largekernel3d",{"2":{"306":1}}],["large",{"2":{"8":2,"13":1,"20":1,"213":1,"235":2,"373":3,"584":1,"671":1}}],["launch",{"2":{"34":2,"120":1,"152":1}}],["lu等人",{"2":{"961":1}}],["luperto",{"2":{"826":1}}],["lu²",{"2":{"477":1}}],["lunarlab",{"2":{"387":1,"514":1}}],["lu",{"2":{"387":1}}],["luo",{"2":{"274":1}}],["lukierski等人",{"2":{"172":1,"967":1}}],["luca",{"2":{"30":1}}],["luminance",{"2":{"8":1}}],["lsd",{"2":{"967":1}}],["ls依赖于均匀分布深度的假设来传递特征",{"2":{"655":1}}],["lsemscal​",{"2":{"750":1}}],["lsemscall",{"2":{"750":1}}],["lsem",{"2":{"632":2,"794":2,"928":4}}],["lseg",{"2":{"274":1,"765":1}}],["ls​",{"2":{"585":1}}],["lsl",{"2":{"585":1}}],["lscal",{"2":{"794":1}}],["lscalseml",{"2":{"766":1}}],["lscalsem​",{"2":{"670":1,"766":1}}],["lscalsem",{"2":{"670":1}}],["lscalserm​",{"2":{"585":1}}],["lscalserml",{"2":{"585":1}}],["lscal​最大化上述类别级指标",{"2":{"794":1}}],["lscal​",{"2":{"632":1,"794":1}}],["lscall",{"2":{"632":1}}],["lscalgeo",{"2":{"670":1}}],["lscalgeo​",{"2":{"585":1,"670":1,"766":1}}],["lscalgeol",{"2":{"585":1,"766":1}}],["lss利用像素级密集深度预测和相机内外参数将图像特征投影到预定义的3d网格体素上",{"2":{"655":1}}],["lss生成的3d表示较稀疏",{"2":{"585":1}}],["lssviewtransformer",{"2":{"423":1}}],["lss",{"2":{"423":1,"564":2,"585":1,"595":1,"612":1,"627":1,"655":1}}],["lstm",{"2":{"252":1,"435":1,"495":2}}],["lsb",{"2":{"76":1}}],["lsmod",{"2":{"66":1}}],["ls",{"2":{"26":1,"49":1,"68":1,"99":1,"585":1,"655":1,"670":4}}],["li和stevenson",{"2":{"967":1}}],["lianos等人",{"2":{"967":2}}],["liang等人",{"2":{"961":1}}],["lid",{"2":{"724":3,"746":4,"789":3}}],["lidar",{"2":{"189":1,"254":2,"360":2,"421":1,"504":3,"534":1,"547":1,"567":1,"570":1,"590":3,"621":17,"654":4,"671":1,"676":8,"790":2,"864":1,"926":1,"931":1,"955":1}}],["lidarseg在34",{"2":{"534":1}}],["lidarseg标签的",{"2":{"254":1,"534":1}}],["lidarseg注释和sample",{"2":{"254":1,"534":1}}],["lidarseg中",{"2":{"254":1,"534":1}}],["lidarseg",{"0":{"534":1,"790":1},"2":{"126":3,"254":1,"277":3,"302":1,"327":2,"476":3,"504":3,"534":12,"790":1}}],["li​",{"2":{"704":2}}],["lives",{"2":{"500":1}}],["li²",{"2":{"477":1}}],["lifting",{"2":{"914":1}}],["lift",{"2":{"423":1,"564":1,"595":1,"655":1}}],["light",{"2":{"220":1,"928":1}}],["lightdm",{"2":{"66":2}}],["li等人",{"2":{"162":1,"197":1,"419":1,"967":2}}],["liong",{"2":{"126":1}}],["liu²",{"2":{"477":1}}],["liu等人",{"2":{"172":1,"190":1,"574":1,"967":1,"1004":1}}],["liu",{"2":{"123":1,"350":1,"765":1,"806":1,"914":1}}],["li",{"2":{"90":1,"123":2,"274":2,"458":1,"525":1,"588":1,"704":2,"914":2}}],["list插入元素",{"2":{"571":1}}],["list初始化",{"2":{"261":1}}],["list",{"2":{"76":2,"120":3,"333":1,"571":1,"685":1,"835":2}}],["listen",{"2":{"57":1}}],["likelihood",{"2":{"203":1}}],["like",{"2":{"66":2,"124":1,"257":1}}],["line",{"2":{"660":1,"875":1}}],["linear",{"2":{"111":1,"131":1,"221":1,"236":1,"333":6,"659":1,"957":1,"967":1,"976":1}}],["lincoln",{"2":{"605":1}}],["lingjun",{"2":{"387":1}}],["lin等人",{"2":{"190":1,"420":1}}],["linbai",{"2":{"99":1}}],["lin",{"2":{"90":1,"252":1}}],["linux教程",{"2":{"196":2}}],["linux",{"2":{"64":1,"66":3,"196":2}}],["linkage准则的无监督凝聚层次聚类方法构造点云的层次结构",{"2":{"574":1}}],["link",{"2":{"38":2}}],["librealsense",{"2":{"605":1}}],["library",{"2":{"500":1,"589":1}}],["libuvc",{"2":{"120":4}}],["libusb",{"2":{"120":1}}],["libeigen3",{"2":{"120":1}}],["libcv",{"2":{"107":1}}],["libcanberra",{"2":{"36":3}}],["libopencv",{"2":{"107":2}}],["liborbslam2",{"0":{"58":1},"1":{"67":1}}],["lib",{"2":{"64":1,"107":1}}],["libjasper",{"2":{"36":1}}],["libjpeg",{"2":{"36":1}}],["libswscale",{"2":{"36":1}}],["libtiff5",{"2":{"36":1}}],["libavformat",{"2":{"36":1}}],["libavcodec",{"2":{"36":1}}],["libgoogle",{"2":{"120":1}}],["libgflags",{"2":{"120":1}}],["libgtk2",{"2":{"36":1}}],["libgthread",{"2":{"17":1}}],["libglib2",{"2":{"17":1}}],["libgl1",{"2":{"17":1}}],["libgl",{"2":{"17":1}}],["limit",{"2":{"11":1}}],["ltotal=lce+lrel+lsem",{"2":{"834":1}}],["ltotal=lce+λldetl",{"2":{"690":1}}],["ltotal=wce⋅lce+wls⋅lls+wgeo⋅lscalgeo+wsem⋅lscalsem",{"2":{"670":1}}],["ltotal​=lce​+lrel​+lsem",{"2":{"834":1}}],["ltotal​=lce​+λldet​",{"2":{"690":1}}],["ltotal​=wce​⋅lce​+wls​⋅lls​+wgeo​⋅lscalgeo​+wsem​⋅lscalsem​",{"2":{"670":1}}],["ltotal​",{"2":{"670":1}}],["ltotal",{"2":{"670":1}}],["lt",{"2":{"15":1,"73":1,"153":3,"177":2,"196":4,"285":1,"351":2,"563":3,"592":6,"670":1,"732":2,"741":3,"835":2,"854":1,"957":3}}],["lts",{"2":{"15":1}}],["l",{"2":{"8":6,"24":1,"153":1,"184":1,"268":1,"390":5,"405":1,"417":1,"423":1,"431":1,"489":1,"617":1,"647":2,"666":3,"670":10,"690":2,"694":9,"699":14,"704":10,"712":10,"729":3,"738":3,"746":44,"750":5,"752":1,"766":9,"793":6,"794":5,"814":1,"834":6,"877":1,"884":5,"931":1,"985":2,"988":1,"997":1,"1000":1}}],["亮度",{"2":{"8":1,"220":1}}],["y∗",{"2":{"950":2}}],["ykiwu",{"2":{"920":1}}],["ygeo​和ama",{"2":{"834":1}}],["ygeo​",{"2":{"794":2}}],["ygeo",{"2":{"794":2}}],["yfovgt",{"2":{"750":4}}],["yfovgt​",{"2":{"750":5}}],["yfovgty",{"2":{"750":1}}],["yfovmono",{"2":{"750":4}}],["yfovmono​",{"2":{"750":5}}],["yfovmonoy",{"2":{"750":1}}],["y⊗m",{"2":{"712":2}}],["y∈",{"2":{"712":2}}],["yli​​",{"2":{"699":2}}],["yli",{"2":{"699":2}}],["yroom​",{"2":{"682":1}}],["yroomy",{"2":{"682":1}}],["yref​",{"2":{"268":1}}],["yref",{"2":{"268":1}}],["y1​=fembodied​",{"2":{"682":1}}],["y1=fembodied",{"2":{"682":1}}],["ymono​∈rx×y×z×c",{"2":{"682":1}}],["ymono​=fmono​",{"2":{"682":1}}],["ymono∈rx×y×z×cy",{"2":{"682":1}}],["ymono=fmono",{"2":{"682":1}}],["yzichen",{"2":{"663":1}}],["y到y",{"2":{"638":1}}],["y范围从",{"2":{"638":1}}],["y轴为概率",{"2":{"622":1}}],["yj​",{"2":{"563":1}}],["yj",{"2":{"563":1}}],["y作为global",{"2":{"559":1}}],["yi−yˉ",{"2":{"789":1,"809":1}}],["yijy",{"2":{"666":1}}],["yij​=1otherwise​",{"2":{"666":1}}],["yij=1",{"2":{"666":1}}],["yi​−yˉ​",{"2":{"789":1,"809":1}}],["yi​",{"2":{"532":1,"789":2,"809":2}}],["yi",{"2":{"532":1,"789":2,"809":2}}],["yin",{"2":{"209":1}}],["ydg",{"2":{"395":1}}],["yn​​z1​",{"2":{"357":1}}],["y0",{"2":{"304":1,"329":1}}],["yt​∈rxroom​×yroom​×zroom​×c",{"2":{"682":1}}],["yt​=fembodied​",{"2":{"682":1}}],["yt∈rxroom×yroom×zroom×cy",{"2":{"682":1}}],["yt−1​",{"2":{"682":1}}],["yt−1",{"2":{"682":1}}],["yt=fembodied",{"2":{"682":1}}],["yt",{"2":{"329":1}}],["ytar​",{"2":{"268":1}}],["ytar",{"2":{"268":1}}],["ytj​∈y",{"2":{"153":1}}],["y平面上是二维的",{"2":{"254":1}}],["y|",{"2":{"153":2}}],["y|x",{"2":{"13":3,"137":2,"153":6,"271":1,"295":1,"422":2}}],["years",{"2":{"366":1}}],["year=",{"2":{"126":1}}],["yes",{"2":{"78":1,"423":3}}],["yu²",{"2":{"477":1}}],["yu¹",{"2":{"477":1}}],["yu",{"2":{"126":1,"458":1}}],["yokozuka等人",{"2":{"967":1}}],["yokoyama",{"2":{"274":1,"765":1}}],["yoshikawa",{"2":{"123":1}}],["younes",{"2":{"209":1}}],["you",{"2":{"38":1,"40":1,"66":2,"120":1,"135":1}}],["yourself",{"2":{"135":1}}],["your",{"2":{"11":1,"68":1}}],["yωω",{"2":{"57":2}}],["yasutaka",{"2":{"958":1}}],["yan",{"2":{"477":1,"958":1}}],["yang和carlone",{"2":{"967":1}}],["yang²",{"2":{"477":1}}],["yang",{"2":{"183":2,"189":1,"209":1,"382":2,"525":1,"826":1}}],["yang等人",{"2":{"131":1,"285":1,"337":1,"362":1,"449":1,"816":1}}],["yangcaoai",{"2":{"30":1}}],["yangtiming",{"2":{"23":1}}],["yadav",{"2":{"139":1}}],["yamauchi",{"2":{"274":1}}],["yam的博客",{"2":{"129":1}}],["yaml",{"2":{"34":4,"152":1}}],["y∣xt​",{"2":{"422":1}}],["y∣xt",{"2":{"422":1}}],["y∣xi​",{"2":{"153":2}}],["y∣xi",{"2":{"153":2}}],["y∣x~j​",{"2":{"153":1}}],["y∣x~j",{"2":{"153":1}}],["y∣x~i​",{"2":{"153":1}}],["y∣x~i",{"2":{"153":1}}],["y∣x",{"2":{"13":6,"137":4,"153":6,"271":2}}],["yyy和",{"2":{"749":1}}],["yyyy",{"2":{"254":1}}],["yyy",{"2":{"8":3,"137":9,"153":3,"741":1}}],["yμy​",{"2":{"8":1}}],["y^geo",{"2":{"794":2}}],["y^​geo​",{"2":{"794":2}}],["y^​通过处理",{"2":{"632":1}}],["y^​=f",{"2":{"632":1}}],["y^​",{"2":{"304":1,"794":2}}],["y^2σy2​",{"2":{"8":1}}],["y^",{"2":{"8":2,"57":2,"304":1,"794":2,"950":1}}],["y+c",{"2":{"8":3}}],["y",{"2":{"8":22,"13":6,"27":1,"57":2,"132":1,"137":35,"153":28,"254":6,"268":2,"304":1,"321":1,"355":2,"357":3,"378":7,"406":2,"412":1,"422":3,"435":4,"507":1,"532":3,"563":1,"590":1,"619":1,"621":4,"632":2,"654":2,"656":4,"666":2,"672":3,"682":7,"693":7,"694":23,"696":3,"699":2,"703":1,"712":8,"716":1,"724":1,"738":1,"741":3,"746":6,"750":8,"780":5,"787":1,"789":4,"793":2,"794":12,"809":10,"844":3,"863":3,"900":2,"910":5,"947":4,"950":9,"957":15}}],["和导航",{"2":{"1003":1}}],["和车道线分割",{"2":{"1003":1}}],["和车道查询",{"2":{"550":1}}],["和uniscene",{"2":{"1003":1}}],["和uniocc",{"2":{"791":1}}],["和快速推理速度",{"2":{"1001":1}}],["和cam4docc",{"2":{"1003":1}}],["和cotr",{"2":{"1000":1}}],["和co",{"2":{"1000":1}}],["和clip以获得每个图像的语义分割",{"2":{"206":1}}],["和nuscenes数据集",{"2":{"997":1}}],["和nuscenes检测得分",{"2":{"893":1}}],["和沙发",{"2":{"992":1}}],["和目标图像",{"2":{"988":1}}],["和renderocc",{"2":{"988":1}}],["和radocc",{"2":{"949":1}}],["和kitti",{"2":{"997":1}}],["和kullback",{"2":{"985":1}}],["和k近邻",{"2":{"396":1}}],["和掩码分类损失",{"2":{"985":1}}],["和预测置信度",{"2":{"985":1}}],["和软iou损失",{"2":{"985":1}}],["和简化",{"2":{"979":1}}],["和一般静态对象",{"2":{"975":1}}],["和一般类别",{"2":{"842":1}}],["和voxblox++",{"2":{"967":1}}],["和视觉",{"2":{"967":1}}],["和我们的提议所提供的一些抽象层次",{"2":{"961":1}}],["和我们的方法对高斯的利用率",{"2":{"812":1}}],["和动作检测",{"2":{"961":1}}],["和li等人",{"2":{"961":1}}],["和lovász",{"2":{"738":1}}],["和mid",{"2":{"967":1}}],["和mask2former",{"2":{"957":1,"985":1}}],["和mlp",{"2":{"910":1}}],["和条件随机场",{"2":{"955":1}}],["和深度图像预测的分数",{"2":{"955":1}}],["和深度快照",{"2":{"955":1}}],["和深度信息",{"2":{"917":1}}],["和混合表示",{"2":{"948":1}}],["和地方",{"2":{"947":1}}],["和自监督的lof",{"2":{"1003":1}}],["和自监督3d场景理解",{"2":{"547":1}}],["和自适应混合",{"2":{"942":1}}],["和交叉注意力",{"2":{"942":1,"950":1,"957":1}}],["和交并比",{"2":{"749":1,"802":1}}],["和部件分割",{"2":{"940":1}}],["和投影尺度",{"2":{"928":1}}],["和低光照条件",{"2":{"914":1}}],["和蒸馏损失",{"2":{"877":1}}],["和focal损失",{"2":{"985":1}}],["和fusion4d",{"2":{"967":1}}],["和fusion++",{"2":{"967":1}}],["和fastocc",{"2":{"922":1}}],["和fpn",{"2":{"875":1}}],["和fbocc",{"2":{"770":1,"811":1}}],["和室外",{"2":{"853":1}}],["和跨不同编码方式",{"2":{"846":1}}],["和调制标量",{"2":{"844":1}}],["和50",{"2":{"836":2}}],["和更快",{"2":{"836":1}}],["和更精细的分辨率",{"2":{"739":1}}],["和bev表示空间中整合多模态信息的方法",{"2":{"976":1}}],["和bevformer",{"2":{"839":1}}],["和bev融合",{"2":{"821":1}}],["和bev检测相互配合",{"2":{"658":1}}],["和最佳的几何",{"2":{"803":1}}],["和67",{"2":{"796":1}}],["和61",{"2":{"796":1}}],["和66",{"2":{"366":1}}],["和90",{"2":{"796":1}}],["和91",{"2":{"796":1}}],["和92",{"2":{"796":1}}],["和87",{"2":{"796":1}}],["和80",{"2":{"254":1}}],["和13",{"2":{"1000":1}}],["和1种空闲空间",{"2":{"793":1}}],["和1点",{"2":{"310":1}}],["和延伸到道路上方的树",{"2":{"791":1}}],["和pointocc",{"2":{"923":1}}],["和panoocc",{"2":{"791":1}}],["和ppad",{"2":{"114":1}}],["和effocc",{"2":{"779":1}}],["和esdf中",{"2":{"253":1}}],["和esdf",{"2":{"31":1}}],["和图像",{"2":{"777":1,"931":1}}],["和图像处理",{"2":{"643":1}}],["和场景类别亲和力损失",{"2":{"766":1,"884":1}}],["和描述",{"2":{"765":1}}],["和相应的真值",{"2":{"750":1}}],["和环视雷达生成的稀疏",{"2":{"746":1}}],["和4",{"2":{"735":1}}],["和waymo",{"2":{"735":1,"997":1}}],["和捆绑射线投射",{"2":{"732":1}}],["和近路表面",{"2":{"723":1}}],["和大视觉语言模型",{"2":{"1006":1}}],["和大面积表面",{"2":{"723":1}}],["和大型语言模型",{"2":{"109":1,"121":1}}],["和姿态矩阵",{"2":{"718":1}}],["和内参",{"2":{"716":1}}],["和周围表面",{"2":{"700":1}}],["和表",{"2":{"700":2,"827":1,"927":1,"936":1}}],["和表示节点之间连接性的边",{"2":{"380":1}}],["和空区域掩码",{"2":{"694":1}}],["和学生",{"2":{"694":1}}],["和外参",{"2":{"693":1}}],["和远距离物体",{"2":{"691":1}}],["和伪3d点云",{"2":{"676":1}}],["和运动状态",{"2":{"667":1}}],["和跟踪",{"2":{"667":1}}],["和标签效率",{"2":{"665":1}}],["和之前vision",{"2":{"659":1}}],["和体素",{"2":{"641":1}}],["和基元渲染",{"2":{"640":1}}],["和基于多摄像头图像序列的世界模型",{"2":{"1003":1}}],["和基于transformer的vit",{"2":{"942":1}}],["和基于三视图",{"2":{"808":1}}],["和基于2d注意力的方法",{"2":{"595":1}}],["和基于学习的方法",{"2":{"172":1}}],["和基于深度学习的语义分割",{"2":{"116":1}}],["和全局上下文线索",{"2":{"636":1}}],["和全局池化",{"2":{"603":1}}],["和openocc",{"2":{"997":1}}],["和openscene",{"2":{"997":2}}],["和occsora",{"2":{"1003":1}}],["和occnerf",{"2":{"1000":1}}],["和occgen",{"2":{"976":1}}],["和occ3d",{"2":{"482":1,"503":1}}],["和orb",{"2":{"634":1}}],["和几何感知能力",{"2":{"1000":1}}],["和几何",{"2":{"632":1,"794":1,"928":1}}],["和几何验证",{"2":{"352":1}}],["和众多下游应用",{"2":{"630":1,"667":1}}],["和强大的swintransformer",{"2":{"627":1}}],["和离群点像素",{"2":{"622":1}}],["和激光雷达",{"2":{"808":1,"967":1}}],["和激光雷达lidlidlid",{"2":{"724":1}}],["和激光雷达结构",{"2":{"655":1}}],["和激光雷达生成的密集3d点云",{"2":{"621":1}}],["和激光雷达点云",{"2":{"532":1}}],["和常用主干如convnext",{"2":{"617":1}}],["和模拟",{"2":{"605":1,"947":1}}],["和局部",{"2":{"746":2}}],["和局部class",{"2":{"591":1}}],["和局部视锥比例",{"2":{"570":1}}],["和2",{"2":{"735":1}}],["和2d语义损失",{"2":{"585":1}}],["和256×704输入图像分辨率的情况下",{"2":{"779":1}}],["和256×704输入图像分辨率",{"2":{"421":1}}],["和后向投影",{"2":{"585":1}}],["和与排序后的点patch序列中最后",{"2":{"582":1}}],["和点混合矩阵",{"2":{"957":1}}],["和点云",{"2":{"780":1}}],["和点",{"2":{"579":1}}],["和关键视图",{"2":{"579":1}}],["和数据集上实现了有竞争力的性能",{"2":{"552":1}}],["和值",{"2":{"550":1}}],["和双特征视线投影",{"2":{"544":1}}],["和三视角",{"2":{"908":1}}],["和三视角表示",{"2":{"535":1}}],["和三个房间",{"2":{"872":1}}],["和三个坐标",{"2":{"412":1}}],["和语义体积",{"2":{"957":1}}],["和语义上",{"2":{"732":1}}],["和语义对数几率",{"2":{"705":1}}],["和语义标签",{"2":{"532":1}}],["和语义编码",{"2":{"90":1}}],["和多摄像头解决方案",{"2":{"942":1}}],["和多个帧",{"2":{"691":1}}],["和多传感器融合的方法",{"2":{"503":1}}],["和多视图立体视觉",{"2":{"116":1}}],["和频率加权平均交并比",{"2":{"492":1}}],["和密度函数",{"2":{"481":1}}],["和密集地图",{"2":{"172":1}}],["和密集网格模型",{"2":{"131":1}}],["和其对应的房间",{"2":{"480":1}}],["和dvio估计姿态",{"2":{"709":1}}],["和dgcnn",{"2":{"574":1}}],["和d是从墙壁顶点到地点节点的向量",{"2":{"480":1}}],["和drivetransformer",{"2":{"114":1}}],["和估计场景图中具有正确语义标签的地面真实对象的百分比",{"2":{"437":1}}],["和机器人系统",{"2":{"421":1}}],["和机器人规划",{"2":{"121":1}}],["和transformer",{"2":{"780":1}}],["和tpv",{"2":{"693":2}}],["和t",{"2":{"419":1}}],["和每帧处理的平均运行时间",{"2":{"402":1}}],["和每个任务",{"2":{"153":1}}],["和开放集精确度",{"2":{"402":1}}],["和开放集语义理解",{"2":{"98":1}}],["和节点",{"2":{"390":1}}],["和两个边长比",{"2":{"379":1}}],["和它们的近邻进行细分",{"2":{"372":1}}],["和加在原图上的噪声仅仅相差一个系数的关系",{"2":{"316":1}}],["和异常值",{"2":{"310":1}}],["和立体3点ransac",{"2":{"390":1}}],["和立体",{"2":{"310":1}}],["和活动窗口内的网格",{"2":{"276":1}}],["和平均交并比",{"2":{"677":1,"848":1}}],["和平均类精度",{"2":{"263":1}}],["和平均类别精度",{"2":{"263":1}}],["和平均多目标跟踪精度",{"2":{"263":1}}],["和围绕地点位置的无障碍边界框",{"2":{"197":1}}],["和去噪分数匹配",{"2":{"175":1}}],["和高精度激光雷达地图",{"2":{"173":1}}],["和高斯溅射",{"2":{"121":1}}],["和sogdet",{"2":{"1003":1}}],["和sparseocc",{"2":{"1001":1}}],["和sparsedrive",{"2":{"114":1}}],["和semantickitti",{"2":{"996":1}}],["和sgn",{"2":{"950":1}}],["和suncg",{"2":{"841":1}}],["和surroundocc",{"2":{"421":1,"1000":1}}],["和sidpac",{"2":{"437":1}}],["和s3dis",{"2":{"306":1}}],["和stekovic等人",{"2":{"172":1}}],["和3d体素表示中学习",{"2":{"819":1}}],["和3d体素的特征表示方法",{"2":{"665":1}}],["和3d目标检测",{"2":{"714":1}}],["和3d占据特征空间上从教师模型蒸馏多阶段特征",{"2":{"642":1}}],["和3d物体跟踪",{"2":{"566":1}}],["和3d车道",{"2":{"550":1}}],["和3d度量",{"2":{"285":1}}],["和3d网格",{"2":{"172":1}}],["和3d动态场景图",{"2":{"131":1}}],["和路标位置",{"2":{"171":1}}],["和房间",{"2":{"162":1}}],["和边用于运动规划",{"2":{"262":1}}],["和边代表成对的时空关系",{"2":{"147":1}}],["和边缘代表概念之间的关系",{"2":{"125":1}}],["和任务",{"2":{"137":1}}],["和未来工作讨论",{"2":{"131":1}}],["和判别网络",{"2":{"129":1}}],["和azure",{"2":{"686":1}}],["和agentthink",{"2":{"128":1}}],["和armeni等人",{"2":{"116":1}}],["和四个真实环境中",{"2":{"109":1}}],["和控制",{"2":{"82":1}}],["和原图concat成5",{"2":{"54":1}}],["和上面一样",{"2":{"38":1}}],["和结构",{"2":{"8":1,"162":1}}],["和",{"0":{"38":1,"872":1},"2":{"8":2,"13":1,"117":1,"123":3,"133":2,"137":5,"149":1,"153":2,"177":2,"181":5,"196":2,"198":1,"209":1,"235":1,"262":1,"277":1,"285":4,"302":1,"325":2,"349":1,"372":1,"382":5,"425":1,"436":1,"437":1,"444":1,"450":1,"455":2,"456":1,"474":1,"490":1,"495":2,"499":1,"517":1,"532":3,"534":1,"536":1,"539":1,"552":1,"562":2,"567":2,"570":2,"579":3,"582":2,"585":1,"588":1,"592":1,"603":1,"605":5,"609":2,"621":2,"632":3,"649":2,"652":3,"656":1,"660":2,"666":3,"670":3,"676":3,"677":1,"681":2,"682":1,"685":1,"693":2,"694":2,"700":4,"707":1,"716":1,"728":2,"738":1,"739":3,"744":1,"746":3,"749":1,"750":1,"754":1,"765":2,"766":1,"768":1,"771":3,"774":1,"775":1,"778":5,"780":1,"782":2,"794":1,"796":7,"800":3,"802":1,"803":3,"807":1,"808":1,"823":2,"827":1,"828":3,"829":1,"835":1,"848":2,"851":1,"853":3,"855":1,"867":1,"870":3,"872":2,"886":1,"900":3,"903":3,"910":1,"914":1,"915":1,"917":5,"928":8,"931":1,"936":1,"937":1,"938":1,"944":1,"950":1,"958":1,"961":1,"967":1,"968":1,"975":2,"977":1,"978":1,"979":2,"989":1,"995":1,"998":2,"1000":2}}],["和噪声图像",{"2":{"5":1}}],["x∗",{"2":{"950":2}}],["xg​∈rc",{"2":{"863":1}}],["xg∈rc",{"2":{"863":1}}],["xgen​",{"2":{"268":1}}],["xgen",{"2":{"268":1}}],["x×y×z",{"2":{"780":4}}],["x×y×zx",{"2":{"532":1,"716":1,"738":1}}],["xli​​",{"2":{"699":2}}],["xli",{"2":{"699":2}}],["xlog~z",{"2":{"235":1}}],["xlog~p",{"2":{"235":2}}],["x|g",{"2":{"681":4}}],["x|y",{"2":{"137":2}}],["x∣gj​",{"2":{"681":1}}],["x∣gj",{"2":{"681":1}}],["x∣gi​",{"2":{"681":3}}],["x∣gi",{"2":{"681":3}}],["x∣y",{"2":{"137":4}}],["x和y必须是",{"2":{"638":1}}],["x和y图像位置和对应弱透视相机模型的比例因子",{"2":{"419":1}}],["x到x",{"2":{"638":1}}],["x​",{"2":{"609":1}}],["xk",{"2":{"579":1}}],["xroom​",{"2":{"682":1}}],["xroomx",{"2":{"682":1}}],["xrgbx",{"2":{"870":1}}],["xrgb​",{"2":{"632":2,"870":1}}],["xrgb​解决体素化的",{"2":{"632":1}}],["xrgb",{"2":{"632":1}}],["xr",{"2":{"579":1}}],["xref​",{"2":{"268":1}}],["xref",{"2":{"268":1}}],["x−m",{"2":{"532":4,"656":4,"681":8,"916":8}}],["x−μ",{"2":{"140":2,"280":2}}],["x风格理由人工评分",{"2":{"447":1}}],["xavier",{"2":{"437":2}}],["xj​",{"2":{"563":1}}],["xj",{"2":{"390":1,"563":1}}],["x子集",{"2":{"360":1}}],["xs",{"2":{"235":1}}],["xpx",{"2":{"464":1}}],["xp​",{"2":{"464":1}}],["xp",{"2":{"235":3,"464":1}}],["xf",{"2":{"235":2,"609":1,"736":2,"840":1}}],["xn​∈se",{"2":{"390":1}}],["xn∈se",{"2":{"390":4}}],["xnynznbn",{"2":{"357":1}}],["xn",{"2":{"193":3}}],["x2​",{"2":{"682":1}}],["x27",{"2":{"372":4,"400":1,"405":1,"434":1,"749":3,"802":3,"848":2}}],["x2",{"2":{"193":3,"682":1}}],["x26",{"2":{"36":2,"76":2,"87":2,"120":6,"571":1,"888":2,"929":2}}],["xₜ₋₁",{"2":{"171":1}}],["xₜ",{"2":{"171":4}}],["x~k​",{"2":{"153":3}}],["x~k−1​",{"2":{"153":4}}],["x~k−1",{"2":{"153":4}}],["x~k",{"2":{"153":4}}],["x~j​",{"2":{"153":1}}],["x~j",{"2":{"153":2}}],["x~i​",{"2":{"153":1}}],["x~i",{"2":{"153":2}}],["x~∣x",{"2":{"137":6}}],["x~",{"2":{"137":18,"153":4}}],["xu等人",{"2":{"961":1,"967":2}}],["xu",{"2":{"126":1,"556":1,"588":1}}],["xt∣y",{"2":{"513":4}}],["xt∣xt+δt",{"2":{"208":3}}],["xt∣xt−1",{"2":{"140":4,"280":4}}],["xtf",{"2":{"273":1}}],["xt+1​t→∞",{"2":{"273":1}}],["xt+1​",{"2":{"273":1}}],["xt+1=1−βt+1xt+βt+1ε",{"2":{"273":1}}],["xt+1=1−βt+1xt+βt+1εx",{"2":{"273":1}}],["xt+1=xt+σt+12−σt2εx",{"2":{"251":1}}],["xt+β",{"2":{"273":2}}],["xt+f",{"2":{"208":1}}],["xt+δt=xt+σt+δt2−σt2ε=xt+σt+δt2−σt2δtδtε=xt+d",{"2":{"273":1}}],["xt+δt=xt+f",{"2":{"208":1,"273":1}}],["xt+δt​​=1−βt+1​​xt​+βt+1​​ε",{"2":{"273":1}}],["xt+δt​​=xt​+σt+δt2​−σt2​​ε=xt​+δtσt+δt2​−σt2​​​δt​ε=xt​+dtd",{"2":{"273":1}}],["xt+δt​−xt​​均值",{"2":{"208":1}}],["xt+δt​−xt​",{"2":{"208":7}}],["xt+δt​−xt​xt+δt​p",{"2":{"208":1}}],["xt+δt​",{"2":{"208":6}}],["xt+δt​→xt​−2g2",{"2":{"208":1}}],["xt+δt​→xt​",{"2":{"208":1}}],["xt+δt​∣xt​",{"2":{"208":4}}],["xt+δt−xt=",{"2":{"208":1}}],["xt+δt−xt=f",{"2":{"208":1}}],["xt+δt−xt",{"2":{"208":7}}],["xt+δt",{"2":{"208":6}}],["xt+δt→xt≈exp⁡",{"2":{"208":1}}],["xt+δt→xt",{"2":{"208":1}}],["xt+δt∣xt",{"2":{"208":4}}],["xt→xt+δtdx",{"2":{"273":1}}],["xt→xt+δt",{"2":{"208":1}}],["xt→n",{"2":{"111":1,"236":1}}],["xt∼n",{"2":{"188":1,"316":1}}],["xt−βt1−αˉtz~",{"2":{"140":1,"280":1}}],["xt−αtˉx0",{"2":{"316":2}}],["xt−αtxt−1",{"2":{"140":1,"280":1}}],["xt−αˉtx0",{"2":{"140":1,"280":1}}],["xt−1−αˉtz~",{"2":{"140":2,"280":2}}],["xt−1−αˉt−1x0",{"2":{"140":1,"280":1}}],["xt−12​−2",{"2":{"140":1,"280":1}}],["xt−12−2",{"2":{"140":1,"280":1}}],["xt−1+b2a",{"2":{"140":1,"280":1}}],["xt−1​加一次噪声至xt",{"2":{"312":1}}],["xt−1​+2ab​",{"2":{"140":1,"280":1}}],["xt−1​−αˉt−1​​x0​",{"2":{"140":1,"280":1}}],["xt−1​",{"2":{"140":5,"188":1,"280":5}}],["xt−1​∣xt​",{"2":{"140":1,"280":1}}],["xt−1",{"2":{"140":5,"188":1,"280":5}}],["xt−1∣xt",{"2":{"140":1,"280":1}}],["xt−1→xtx",{"2":{"111":1,"140":1,"236":1,"280":1}}],["xtx",{"2":{"111":1,"188":2,"236":1}}],["xt​∣y",{"2":{"513":4}}],["xt​∣xt+δt​",{"2":{"208":3}}],["xt​∣xt−1​",{"2":{"140":4,"280":4}}],["xt​+β",{"2":{"273":2}}],["xt​+f",{"2":{"208":1}}],["xt​→xt+δt​",{"2":{"273":1}}],["xt​→n",{"2":{"111":1,"236":1}}],["xt​∼n",{"2":{"188":1,"316":1}}],["xt​−1−αˉt​​βt​​z~",{"2":{"140":1,"280":1}}],["xt​−1−αˉt​​z~",{"2":{"140":2,"280":2}}],["xt​−αt​ˉ​​x0​",{"2":{"316":2}}],["xt​−αˉt​​x0​",{"2":{"140":1,"280":1}}],["xt​−α​t​xt−1​",{"2":{"140":1,"280":1}}],["xt​xt​​=αt​​xt−1​+1−αt​​z∼n",{"2":{"140":1,"280":1}}],["xt​",{"2":{"140":6,"175":2,"208":24,"273":4,"280":6,"316":3,"338":1,"422":1,"513":5,"682":2}}],["xt​=",{"2":{"682":2,"728":1}}],["xt​=αˉt​​x0​+1−αˉt​​z",{"2":{"111":1,"236":1}}],["xt​=αt​αt−1​​xt−2​+1−αt​αt−1​​z",{"2":{"111":1,"236":1}}],["xt​=1−βt​​xt−1​+β​t​zt​",{"2":{"111":1,"236":1}}],["xt​​=α​t​xt​+1−αt​​zt​=α​t​",{"2":{"111":1,"236":1}}],["xt=",{"2":{"682":2,"728":1}}],["xt=x0+σtεx",{"2":{"251":2}}],["xt=αˉtx0+1−αˉtεx",{"2":{"273":2}}],["xt=αˉtx0+1−αˉtz∼n",{"2":{"140":1,"280":1}}],["xt=αˉtx0+1−αˉtzx",{"2":{"111":1,"175":1,"236":1}}],["xt=αtxt−1+1−αtzx",{"2":{"140":1,"280":1}}],["xt=αtxt−1+1−αtz∼n",{"2":{"140":1,"280":1}}],["xt=αtxt+1−αtzt=αt",{"2":{"111":1,"236":1}}],["xt=αtαt−1xt−2+1−αtαt−1z",{"2":{"111":1,"236":1}}],["xt=1−βtxt−1+βtzt",{"2":{"111":1,"236":1}}],["xt",{"2":{"111":4,"140":6,"175":2,"188":1,"208":25,"236":4,"273":3,"279":1,"280":6,"312":2,"316":3,"338":1,"422":1,"513":5,"682":2}}],["x1y1z1b1",{"2":{"357":1}}],["x1​",{"2":{"188":1,"682":2}}],["x1",{"2":{"111":1,"188":1,"193":3,"236":1,"390":1,"682":2}}],["x0​",{"2":{"188":1}}],["x0​=αˉt​​1​",{"2":{"140":1,"280":1}}],["x0=1αˉt",{"2":{"140":1,"280":1}}],["x0→xtx",{"2":{"140":1,"280":1}}],["x0的系数",{"2":{"124":1,"257":1}}],["x0x",{"2":{"111":1,"188":1,"236":1}}],["x0",{"2":{"111":1,"180":1,"208":1,"236":1,"279":1}}],["xivo",{"2":{"967":2}}],["xingguang",{"2":{"958":1}}],["xinjieyuan",{"2":{"351":1}}],["xi−xˉ",{"2":{"789":1,"809":1}}],["xie等人",{"2":{"664":1}}],["xi+1​←xi​+ϵ∇x​logp",{"2":{"225":1}}],["xi+1←xi+ϵ∇xlog⁡p",{"2":{"225":1}}],["xi​−xˉ",{"2":{"789":1,"809":1}}],["xi​=",{"2":{"390":1}}],["xi​",{"2":{"153":3,"532":1,"789":2,"809":2}}],["xixixi",{"2":{"193":1}}],["xix",{"2":{"153":1,"390":2}}],["xi",{"2":{"153":7,"532":1,"789":2,"809":2}}],["xi∈xx",{"2":{"153":1}}],["xiang",{"2":{"209":2}}],["xia",{"2":{"90":1,"123":1,"209":1}}],["xiongchun11",{"2":{"48":1}}],["xorg是x11的实现",{"2":{"74":1}}],["xorg",{"2":{"74":2}}],["xc​",{"2":{"660":1}}],["xc",{"2":{"660":1}}],["xcx",{"2":{"660":3}}],["xconfig",{"2":{"66":2}}],["xcb",{"0":{"53":1},"1":{"64":1,"74":1},"2":{"64":3,"74":2}}],["x86",{"2":{"66":3}}],["xxi​∈x",{"2":{"153":1}}],["xx",{"2":{"41":1}}],["xxx给定第",{"2":{"681":1}}],["xxx属于第",{"2":{"681":1}}],["xxx足够接近任何一个高斯",{"2":{"681":1}}],["xxx接近高斯",{"2":{"681":1}}],["xxx被占用的概率",{"2":{"681":1}}],["xxx处的整体占用概率",{"2":{"681":1}}],["xxx处的整体占用预测",{"2":{"656":1}}],["xxx处对应的语义高斯分布",{"2":{"656":1}}],["xxx和压缩信号",{"2":{"137":1}}],["xxx",{"2":{"8":3,"31":1,"32":10,"38":4,"137":11,"153":2,"741":1,"749":1}}],["xenial",{"2":{"36":2}}],["x3c",{"2":{"27":1,"40":2,"52":2,"57":7,"63":4,"67":10,"93":6,"104":4,"115":4,"130":9,"146":14,"161":4,"196":41,"239":1,"254":75,"261":6,"284":1,"309":1,"327":5,"335":1,"361":1,"389":1,"418":1,"534":3,"571":2,"654":12,"685":2,"708":1,"774":2,"795":4,"888":8,"929":12}}],["xμx​",{"2":{"8":1}}],["xyxyxy坐标",{"2":{"832":1}}],["xyz",{"2":{"738":2}}],["xyz×p",{"2":{"738":2}}],["xyhm=px​y",{"2":{"666":1}}],["xy",{"2":{"8":2}}],["x^sem",{"2":{"870":2}}],["x^occ​",{"2":{"870":1}}],["x^occ",{"2":{"870":1}}],["x^pts​与预训练网络",{"2":{"870":1}}],["x^pts​",{"2":{"870":1}}],["x^pts",{"2":{"870":2}}],["x^depth​",{"2":{"870":2}}],["x^depth",{"2":{"870":2}}],["x^i",{"2":{"390":2}}],["x^∣x",{"2":{"235":4}}],["x^2σx2​",{"2":{"8":1}}],["x^",{"2":{"8":2,"235":2,"950":1}}],["x",{"2":{"8":25,"13":2,"31":9,"38":4,"99":1,"111":8,"124":6,"129":3,"132":1,"137":48,"140":49,"153":28,"161":1,"171":12,"174":13,"175":3,"188":4,"193":7,"208":92,"213":12,"225":13,"235":115,"236":8,"251":2,"254":6,"256":3,"257":6,"268":2,"273":21,"280":49,"304":3,"316":13,"318":6,"321":1,"333":2,"334":3,"338":1,"342":10,"344":3,"351":23,"355":2,"357":3,"360":3,"372":3,"378":7,"390":5,"406":2,"412":1,"422":1,"429":3,"435":1,"452":1,"464":1,"513":9,"532":25,"563":1,"579":1,"590":1,"609":1,"619":1,"621":4,"632":1,"654":2,"656":24,"660":1,"672":1,"681":49,"682":9,"693":7,"694":21,"696":1,"699":2,"712":1,"724":1,"728":1,"741":2,"746":6,"780":5,"787":1,"789":4,"793":2,"809":10,"844":2,"863":2,"870":6,"900":2,"904":5,"910":5,"916":10,"947":2,"950":9,"957":15}}],["=∣ν∣1​i∈ν∑​da",{"2":{"957":1}}],["=ψs​",{"2":{"950":1}}],["=ψs",{"2":{"950":1,"957":1}}],["=φt​",{"2":{"950":1}}],["=φt",{"2":{"950":1}}],["=φf​",{"2":{"942":1}}],["=φf",{"2":{"942":1}}],["=43π",{"2":{"916":1}}],["=vcoverage​∑i=1p​vi",{"2":{"916":1}}],["=vi+δviv^",{"2":{"372":1}}],["=ntotal​ncorrect​​×100",{"2":{"916":1}}],["=ncorrectntotal×100",{"2":{"916":1}}],["=n1​n=1∑n​i=1∑r​da",{"2":{"716":1}}],["=c",{"2":{"863":2}}],["=conditional",{"2":{"513":1}}],["=concat",{"2":{"372":2}}],["=g=1∑g​k=1∑k​wg​mgk​xg​",{"2":{"863":1}}],["=gcn",{"2":{"372":2}}],["=k=1∑k​wk​mk​x",{"2":{"844":1}}],["=k=1∑ℓ2​c∈ck​∑​pk​",{"2":{"814":1}}],["=oθ​∈",{"2":{"712":1}}],["=oθ∈",{"2":{"712":1}}],["=bce",{"2":{"704":2}}],["=w",{"2":{"670":4,"694":3}}],["=a⋅exp",{"2":{"656":1}}],["=a⋅exp⁡",{"2":{"656":1}}],["=∑g=1g∑k=1kwgmgkxg",{"2":{"863":1}}],["=∑k=1kwkmkx",{"2":{"844":1}}],["=∑k=1ℓ2∑c∈ckpk",{"2":{"814":1}}],["=∑p∈bin",{"2":{"741":1}}],["=∑pn∈rp⋅x",{"2":{"672":1,"696":1}}],["=∑i∈n",{"2":{"738":1}}],["=∑i=1nheadwi∑j=1nkeyaijwijf2d",{"2":{"950":1}}],["=∑i=1nggi",{"2":{"532":1}}],["=∑i=1pvi",{"2":{"916":1}}],["=∑i=1pexp⁡",{"2":{"693":1}}],["=∑i=1pp",{"2":{"681":1}}],["=∑i=1pgi",{"2":{"656":1,"693":1}}],["=∑x∈x∑y∈yp",{"2":{"137":1}}],["=σ⋅exp",{"2":{"532":1}}],["=σ⋅exp⁡",{"2":{"532":1}}],["=σxy+c3σxσy+c3",{"2":{"8":1}}],["=γ∇log⁡p",{"2":{"513":1}}],["=log∑i​",{"2":{"794":1}}],["=log∑i​ipi​=c​∑i​p^​i",{"2":{"794":1}}],["=log∑i​p^​i",{"2":{"794":1}}],["=log⁡∑i",{"2":{"794":1}}],["=log⁡∑ip^i",{"2":{"794":2}}],["=log⁡pϕ",{"2":{"422":1}}],["=logpϕ​",{"2":{"422":1}}],["=mlp",{"2":{"344":3,"716":2}}],["=max",{"2":{"31":1}}],["=max⁡",{"2":{"31":1}}],["=β",{"2":{"273":2}}],["=βˉ​i​",{"2":{"273":1}}],["=βˉi",{"2":{"273":1}}],["=−c1​c=1∑c​",{"2":{"794":1}}],["=−1c∑c=1c",{"2":{"794":1}}],["=−1−αˉt​xt​−αt​ˉ​​x0​​",{"2":{"316":1}}],["=−12β",{"2":{"273":1}}],["=−xt−αtˉx01−αˉt",{"2":{"316":1}}],["=−21​β",{"2":{"273":1}}],["=−∇x​fθ​",{"2":{"235":1}}],["=−∇xfθ",{"2":{"235":1}}],["=dim",{"2":{"351":1}}],["=dtd",{"2":{"273":1}}],["=d",{"2":{"273":1}}],["=1∣ν∣∑i∈νda",{"2":{"957":1}}],["=1p∑i=1p",{"2":{"916":1}}],["=1p∑i=1pmin⁡v∈v∥mi−v∥1",{"2":{"916":1}}],["=1n∑n=1n∑i=1rda",{"2":{"716":1}}],["=1wf​=wb​=wc​=1",{"2":{"694":1}}],["=1wce​=wls​=wgeo​=wsem​=1",{"2":{"670":1}}],["=1",{"2":{"268":1,"681":1,"916":1}}],["=1−i=1∏p​",{"2":{"681":1}}],["=1−∏i=1p",{"2":{"681":1}}],["=1−∥δi∥∥δt∥",{"2":{"268":1}}],["=1−",{"2":{"268":1}}],["=∇logp",{"2":{"513":1}}],["=∇log⁡p",{"2":{"513":2}}],["=∇θ​edata​",{"2":{"235":1}}],["=∇θ​epdata​",{"2":{"235":1}}],["=∇θedata",{"2":{"235":1}}],["=∇θepdata",{"2":{"235":1}}],["=∇x​log",{"2":{"235":1}}],["=∇xlog",{"2":{"235":1}}],["=0",{"2":{"235":1,"273":3}}],["=zθ​e−fθ​",{"2":{"213":1}}],["=e−fθ",{"2":{"213":1}}],["=exp",{"2":{"13":1,"208":2,"681":1,"693":1}}],["=exp⁡",{"2":{"13":1,"208":2,"681":1,"693":1}}],["=f2d​",{"2":{"950":1}}],["=f2d",{"2":{"950":1}}],["=f",{"2":{"208":1,"950":1}}],["=p1​i=1∑p​​j=i∑​bci",{"2":{"916":1}}],["=p1​i=1∑p​v∈vmin​∥mi​−v∥1​",{"2":{"916":1}}],["=p∈bin",{"2":{"741":1}}],["=pn​∈r∑​p⋅x",{"2":{"672":1,"696":1}}],["=p",{"2":{"208":6}}],["=unet",{"2":{"175":1}}],["=i∈n",{"2":{"738":1}}],["=i=1∑nhead​​wi​j=1∑nkey​​aij​wij​f2d​",{"2":{"950":1}}],["=i=1∑ng​​gi​",{"2":{"532":1}}],["=i=1∑p​exp",{"2":{"693":1}}],["=i=1∑p​p",{"2":{"681":1}}],["=i=1∑p​gi​",{"2":{"656":1,"693":1}}],["=i",{"2":{"146":1,"153":4}}],["=αˉt​​xt​​",{"2":{"140":1,"280":1}}],["=αˉt​​x0​+1−αˉt​​z∼n",{"2":{"140":1,"280":1}}],["=xt​+f",{"2":{"208":1}}],["=xtαˉt",{"2":{"140":1,"280":1}}],["=x",{"2":{"208":1,"251":1,"273":3}}],["=x∈x∑​y∈y∑​p",{"2":{"137":1}}],["=q",{"2":{"140":3,"280":3}}],["=h",{"2":{"137":4}}],["=s",{"2":{"115":1,"130":2,"372":2}}],["=>",{"2":{"57":1}}],["==对于特征增强",{"2":{"665":1}}],["==并将现有方法系统地分为三类",{"2":{"665":1}}],["==扩展到实时操作并不平凡",{"2":{"141":1}}],["==在对象及其",{"2":{"116":1}}],["==高级理解的第三个要素是描述场景中的静态和动态实体并推理它们之间的关系的能力",{"2":{"116":1}}],["==几何信息对机器人安全导航和操纵对象至关重要",{"2":{"116":1}}],["==第一个要素",{"2":{"116":1}}],["==",{"2":{"52":2,"196":1,"351":1}}],["=2σxσy+c2σx2+σy2+c2s",{"2":{"8":1}}],["=2μxμy+c1μx2+μy2+c1c",{"2":{"8":1}}],["=",{"2":{"5":1,"8":7,"13":1,"15":1,"31":1,"34":7,"41":1,"52":4,"57":17,"63":2,"93":1,"111":5,"124":11,"132":3,"136":1,"137":3,"140":19,"153":3,"171":5,"174":10,"175":2,"184":9,"196":5,"208":10,"213":1,"235":7,"236":5,"251":2,"257":11,"271":1,"273":12,"278":1,"280":19,"316":1,"333":21,"351":12,"355":1,"357":2,"372":3,"373":7,"379":11,"390":11,"417":1,"422":1,"425":2,"431":5,"435":2,"437":2,"464":5,"504":6,"513":3,"522":1,"524":1,"532":9,"534":2,"563":6,"571":2,"582":1,"590":1,"595":8,"609":1,"621":4,"623":8,"632":2,"634":1,"638":1,"649":1,"651":3,"654":13,"656":7,"660":3,"666":4,"672":1,"676":8,"681":10,"682":5,"690":1,"693":16,"694":2,"696":1,"699":5,"703":1,"704":4,"705":7,"707":1,"712":2,"716":12,"724":1,"728":6,"730":1,"738":5,"741":1,"746":1,"749":2,"750":1,"752":3,"766":4,"780":2,"789":2,"794":11,"802":2,"807":2,"809":2,"814":2,"834":1,"844":1,"848":2,"853":1,"863":2,"867":1,"884":2,"888":1,"910":1,"915":1,"916":13,"929":3,"942":1,"944":1,"947":3,"950":4,"957":6,"976":1,"985":2,"988":1,"998":3}}],["2或3个房间",{"2":{"930":1}}],["2b",{"2":{"917":1}}],["2b−12^b",{"2":{"8":1}}],["2和4",{"2":{"779":1}}],["2×10−4",{"2":{"771":1}}],["2×10−42",{"2":{"771":1}}],["2×6",{"2":{"749":2,"781":1}}],["2×51",{"2":{"749":2,"781":1}}],["2exp⁡",{"2":{"681":1,"916":1}}],["2∣σ∣1",{"2":{"681":2,"916":4}}],["2π",{"2":{"681":2,"916":2}}],["2点ransac以及使用2点ransac和imu感知特征跟踪",{"2":{"662":1}}],["2x",{"2":{"519":1}}],["2加权地点的投票",{"2":{"480":1}}],["2n",{"2":{"464":1}}],["2n−1−12^",{"2":{"57":1}}],["2n−1",{"2":{"57":2}}],["2的nds",{"2":{"893":1}}],["2的miou",{"2":{"779":1}}],["2的rayiou",{"2":{"421":1,"779":1}}],["2的位置转换参数",{"2":{"355":1}}],["2的位置转换参数r",{"2":{"355":1}}],["2基于点的网络",{"0":{"391":1},"1":{"420":1,"450":1,"481":1,"511":1,"542":1,"574":1,"607":1,"636":1,"664":1,"688":1}}],["2miou的显著提升",{"2":{"779":1}}],["2m+12m+12m+1",{"2":{"524":1}}],["2m以上的距离",{"2":{"480":1}}],["2m",{"2":{"345":1,"652":2,"739":5,"800":1,"828":2}}],["2mse=",{"2":{"5":1}}],["2tr",{"2":{"235":1}}],["2s",{"2":{"235":1}}],["2δt​",{"2":{"208":1}}],["2δt2g2",{"2":{"208":1}}],["2g2",{"2":{"208":1}}],["2g^2",{"2":{"208":8}}],["2f",{"2":{"208":3,"840":1}}],["2−",{"2":{"208":2}}],["2w2​",{"2":{"181":2}}],["2z2​",{"2":{"181":1}}],["2°",{"2":{"173":1}}],["2a",{"2":{"140":3,"280":3,"917":1}}],["2+",{"2":{"140":2,"280":2,"500":1}}],["2​−1−αˉt​",{"2":{"140":1,"280":1}}],["2​+1−αˉt−1​",{"2":{"140":1,"280":1}}],["2​",{"2":{"140":2,"280":2,"464":1}}],["2σ2",{"2":{"140":1,"280":1}}],["2节展示了我们的flashocc与其他最先进方法在占据预测上的公平比较的主要结果",{"2":{"748":1}}],["2节所述",{"2":{"636":1}}],["2节中的流程进行交互和优化",{"2":{"728":1}}],["2节中的多帧网格更准确",{"2":{"362":1}}],["2节中详细阐述",{"2":{"576":1}}],["2节讨论预训练和规模化工作",{"2":{"551":1}}],["2节显示kimera",{"2":{"541":1}}],["2节",{"0":{"336":1},"2":{"131":1,"285":1,"669":2,"954":1}}],["2hz",{"2":{"126":1,"277":1,"652":1,"739":1,"749":1}}],["26m",{"2":{"198":1}}],["26",{"2":{"121":1,"125":3,"135":1,"172":1,"277":2,"420":1,"512":1,"534":2,"535":1,"547":1,"566":1,"603":1,"612":1,"640":1,"693":2,"735":1,"749":1,"757":1,"759":1,"766":1,"771":1,"808":1,"841":2,"842":1,"893":1,"901":1,"917":1,"942":2,"950":2,"957":1,"975":1,"985":4,"997":2,"1000":1}}],["269",{"2":{"40":1}}],["2828资助",{"2":{"467":1}}],["289",{"2":{"277":1,"534":1}}],["28",{"2":{"114":1,"121":1,"172":1,"277":1,"302":1,"420":1,"421":1,"425":1,"502":1,"534":1,"535":1,"566":2,"603":1,"641":1,"700":1,"735":3,"759":1,"803":1,"808":1,"811":1,"910":3,"917":1,"922":1,"923":1,"982":1,"985":1}}],["273",{"2":{"277":1,"534":1,"828":1}}],["27",{"2":{"114":1,"121":1,"172":1,"206":1,"277":1,"301":1,"420":1,"534":1,"535":1,"547":1,"603":1,"609":2,"612":1,"643":1,"652":1,"677":1,"686":1,"709":2,"735":1,"757":1,"759":1,"823":1,"828":2,"927":1,"942":1,"996":2}}],["231",{"2":{"947":1}}],["2312",{"2":{"776":1}}],["233",{"2":{"828":1}}],["2339",{"2":{"57":1}}],["2376个训练",{"2":{"793":1}}],["2303",{"2":{"671":1}}],["239",{"2":{"277":1,"534":1}}],["23α=0",{"2":{"271":1}}],["23α",{"2":{"271":1}}],["23",{"2":{"82":1,"121":1,"126":1,"145":1,"159":1,"172":1,"271":1,"277":3,"302":1,"363":1,"421":1,"431":1,"482":1,"534":3,"535":1,"547":2,"552":1,"566":1,"603":1,"612":1,"636":1,"665":1,"677":1,"686":2,"693":2,"703":1,"709":2,"714":1,"744":1,"770":1,"791":1,"808":1,"893":1,"971":2}}],["214",{"2":{"996":1}}],["2144",{"2":{"43":1}}],["21389",{"2":{"947":1}}],["21​exp",{"2":{"681":1,"916":1}}],["2110",{"2":{"414":1}}],["2112",{"2":{"205":1}}],["216",{"2":{"277":1,"534":1}}],["218",{"2":{"277":1,"534":1}}],["21867",{"2":{"136":1}}],["219",{"2":{"277":1,"534":1}}],["21−αˉt",{"2":{"140":1,"280":1}}],["21−αˉt−1−",{"2":{"140":1,"280":1}}],["21−αt+",{"2":{"140":1,"280":1}}],["2108",{"2":{"264":1,"266":1}}],["2101",{"2":{"106":1}}],["2109",{"2":{"96":1}}],["21",{"2":{"67":1,"121":1,"173":1,"176":1,"190":1,"277":1,"337":1,"421":1,"425":1,"482":1,"534":1,"535":1,"596":1,"603":1,"609":1,"612":1,"665":1,"686":5,"709":1,"714":1,"744":1,"749":1,"792":1,"839":1,"853":1,"900":1,"908":1,"1000":1}}],["22miou的性能提升",{"2":{"800":1}}],["2211",{"2":{"584":1}}],["220条路线",{"2":{"360":1}}],["220",{"2":{"360":1}}],["226",{"2":{"277":1}}],["22",{"2":{"60":3,"78":1,"82":1,"125":1,"172":1,"175":1,"277":1,"363":1,"469":1,"534":1,"535":2,"566":2,"660":1,"665":1,"686":3,"690":1,"703":1,"714":1,"744":1,"779":1,"781":1,"791":1,"803":1,"808":3,"811":2,"823":1,"841":1,"886":1,"893":1,"957":1,"989":1}}],["2^l",{"2":{"766":2,"884":2}}],["2^2+",{"2":{"235":1}}],["2^2",{"2":{"235":5,"342":1}}],["2^",{"2":{"57":1}}],["297",{"2":{"277":1,"534":1}}],["29",{"2":{"128":1,"172":1,"603":1,"627":1,"686":1,"735":2,"757":1,"759":1,"760":1,"771":1,"781":1,"822":1,"823":1,"922":1,"924":1,"932":1,"1000":1}}],["2964",{"2":{"51":3}}],["2936",{"2":{"43":3}}],["25m",{"2":{"944":3}}],["251",{"2":{"916":7}}],["25和λ=0",{"2":{"758":1}}],["256×704",{"2":{"803":3}}],["256×256×32",{"2":{"853":1,"900":1}}],["256×256×32256",{"2":{"749":1}}],["256×256",{"2":{"321":1}}],["256",{"2":{"749":1}}],["2566个关键帧",{"2":{"781":1}}],["2566",{"2":{"749":1}}],["256的图像上",{"2":{"345":1}}],["2505",{"2":{"514":1,"578":1}}],["250",{"2":{"173":1}}],["2506",{"2":{"62":1}}],["2540",{"2":{"57":1}}],["25",{"2":{"43":4,"51":2,"125":1,"128":1,"172":1,"363":1,"419":1,"435":1,"482":1,"502":1,"532":2,"547":1,"563":1,"603":3,"612":1,"627":1,"655":1,"665":1,"677":1,"686":2,"700":3,"745":1,"759":1,"766":1,"808":2,"841":3,"853":1,"906":1,"914":2}}],["255",{"2":{"43":2}}],["244",{"2":{"947":1}}],["241",{"2":{"947":1}}],["24gb",{"2":{"867":1}}],["247",{"2":{"277":1,"349":1,"534":1}}],["242",{"2":{"136":2}}],["240×144×240",{"2":{"853":1}}],["2403",{"2":{"445":1,"545":1}}],["240",{"2":{"277":1,"534":1}}],["24044v1",{"2":{"62":1}}],["2405",{"2":{"23":1,"577":1}}],["24",{"2":{"30":1,"121":1,"128":1,"277":3,"363":1,"366":1,"421":1,"437":1,"519":1,"534":3,"535":1,"566":1,"603":1,"612":1,"665":1,"677":1,"686":4,"690":1,"709":3,"759":1,"766":1,"779":2,"782":3,"803":1,"808":2,"823":1,"1000":1,"1004":1}}],["2d激光雷达",{"2":{"967":1}}],["2d场景图已用于图像检索",{"2":{"961":1}}],["2d到3d的转换可以表示为",{"2":{"950":1}}],["2d到3d的转换",{"0":{"950":1}}],["2d到3d的转换将在下一节详细讨论",{"2":{"942":1}}],["2d深度图由lidar点云生成的稀疏深度图进行监督",{"2":{"941":1}}],["2d与3d分支的融合",{"0":{"923":1}}],["2d示意图展示了高斯到体素的溅射方法",{"2":{"738":1}}],["2d目标固定框问题",{"2":{"630":1}}],["2d或者2",{"2":{"630":1}}],["2d图像编码器",{"2":{"598":1}}],["2d模块整合环视摄像头",{"2":{"503":1}}],["2d语义分割和立体深度重建",{"2":{"408":1}}],["2defaultctrlistrate",{"2":{"106":2}}],["2d",{"0":{"404":1,"829":1},"1":{"433":1,"464":1},"2":{"23":1,"277":1,"333":1,"366":1,"369":1,"378":2,"423":1,"425":1,"435":3,"465":1,"471":2,"474":1,"480":1,"495":4,"539":3,"545":1,"567":1,"570":5,"619":2,"632":8,"642":1,"660":21,"678":2,"684":1,"704":1,"707":2,"744":1,"746":3,"765":4,"768":1,"789":1,"794":1,"808":2,"826":2,"829":5,"865":1,"866":2,"867":1,"910":4,"913":1,"914":1,"917":1,"928":11,"937":1,"942":2,"945":1,"950":5,"955":4,"957":3,"968":2,"971":5,"977":1,"978":1}}],["20m",{"2":{"652":1,"828":1,"944":3}}],["20ms",{"2":{"285":1}}],["2048",{"2":{"333":1}}],["20米处右转",{"2":{"283":1}}],["203",{"2":{"277":1}}],["2080",{"2":{"816":1}}],["2080ti",{"2":{"761":1}}],["208",{"2":{"277":1,"534":1}}],["20880415",{"2":{"220":1}}],["20hz",{"2":{"173":1,"211":1}}],["200×200×16",{"2":{"787":1}}],["200",{"2":{"739":2,"757":1,"816":1,"968":1}}],["2009",{"2":{"588":1,"698":1,"967":3}}],["2009年",{"2":{"310":1}}],["2003",{"2":{"209":1,"961":1}}],["2007年",{"2":{"390":4,"634":1}}],["2007",{"2":{"155":1,"209":1,"588":1,"648":1,"967":4}}],["2008b",{"2":{"648":1}}],["2008",{"2":{"189":1,"648":2,"961":2,"967":3}}],["2008a",{"2":{"123":1,"826":1,"864":1}}],["2008年",{"2":{"116":1,"362":1,"732":1}}],["2005",{"2":{"123":1,"525":1,"648":1,"826":1,"961":3}}],["2005年",{"2":{"116":1}}],["2006",{"2":{"123":1,"525":2,"961":1}}],["2006年",{"2":{"116":1,"905":1}}],["2002",{"2":{"123":1}}],["2001",{"2":{"123":1,"648":2,"698":1}}],["2000",{"2":{"124":1,"155":1,"257":1,"525":1,"961":1}}],["2000年",{"2":{"116":1,"310":1}}],["2000t≈2000",{"2":{"111":1,"236":1}}],["2004年",{"2":{"131":2,"197":2,"310":2,"390":1}}],["2004",{"2":{"90":1,"171":1,"189":1,"525":1,"961":2}}],["2010",{"2":{"648":1,"961":1,"967":2}}],["2012",{"2":{"189":1,"209":4,"525":1,"648":1,"806":1,"967":7}}],["2012年",{"2":{"116":1,"310":2,"390":1,"419":1}}],["2014年",{"2":{"310":1,"634":1}}],["2014",{"2":{"189":1,"209":2,"525":2,"556":1,"648":2,"967":8}}],["2011a",{"2":{"189":1,"525":1}}],["2011b",{"2":{"189":1,"806":1}}],["2011",{"2":{"155":1,"189":1,"209":3,"525":2,"648":2,"806":1,"967":1}}],["2011年",{"2":{"116":2,"419":1,"449":2,"905":1,"939":1}}],["2018a",{"2":{"806":1,"967":1}}],["2018a年",{"2":{"510":1}}],["2018b",{"2":{"139":2,"961":1,"967":2}}],["2018",{"2":{"123":1,"139":1,"209":5,"237":1,"252":1,"259":1,"360":1,"410":1,"435":1,"476":1,"495":3,"525":4,"698":2,"743":1,"806":1,"961":1,"967":22}}],["2018年a",{"2":{"162":1,"197":1}}],["2018年b",{"2":{"116":1,"419":1}}],["2018年",{"2":{"116":3,"162":1,"285":1,"362":1,"390":4,"419":1,"480":1,"605":1,"634":3,"686":2,"816":1,"930":1}}],["2013b",{"2":{"967":1}}],["2013a",{"2":{"961":1}}],["2013",{"2":{"123":2,"189":1,"209":4,"525":3,"556":1,"648":2,"698":2,"826":1,"961":1,"967":6}}],["2013年a",{"2":{"116":1}}],["2013年",{"2":{"116":2,"419":2,"605":2,"634":1}}],["2015年",{"2":{"116":2,"131":1,"362":1,"390":1,"419":2,"634":2,"732":1}}],["2015",{"2":{"90":1,"189":2,"209":6,"274":1,"350":1,"588":1,"648":1,"961":1,"967":7}}],["2019b年",{"2":{"775":1}}],["2019b",{"2":{"139":2,"209":1,"274":1,"285":1,"419":3,"775":1,"816":1,"967":3}}],["2019a",{"2":{"139":1,"274":1,"967":1}}],["2019年b",{"2":{"905":1}}],["2019年a",{"2":{"362":1}}],["2019年相比",{"2":{"131":1}}],["2019年",{"2":{"116":12,"162":1,"178":1,"285":1,"336":3,"362":1,"390":1,"419":1,"605":2,"634":1,"686":1,"905":6,"930":2}}],["2019",{"0":{"75":1},"2":{"75":1,"123":1,"126":3,"139":3,"209":4,"274":2,"275":1,"302":1,"525":2,"588":2,"619":1,"648":1,"698":3,"806":2,"826":2,"961":4,"967":24}}],["2016年",{"2":{"116":2,"131":1,"178":1,"362":1,"572":1,"605":1,"930":1}}],["2016",{"0":{"54":1},"2":{"189":2,"252":1,"274":1,"648":1,"763":1,"961":6,"967":8}}],["2017a",{"2":{"274":1,"350":1,"588":1}}],["2017b",{"2":{"189":1,"588":1}}],["2017年",{"2":{"116":10,"131":1,"285":2,"310":3,"362":9,"390":2,"419":1,"480":1,"510":1,"605":2,"732":1,"816":1,"905":2}}],["2017",{"2":{"31":1,"90":1,"139":2,"171":1,"189":2,"209":10,"252":2,"274":1,"495":3,"525":1,"588":2,"616":1,"743":1,"806":1,"961":6,"967":13}}],["202",{"2":{"739":1}}],["2021a",{"2":{"525":1}}],["2021年",{"2":{"390":1,"634":1}}],["2021年发布的latent",{"2":{"205":1}}],["2021",{"2":{"90":1,"123":1,"135":1,"139":2,"189":3,"209":8,"244":1,"252":1,"274":3,"317":1,"394":1,"435":1,"495":4,"525":6,"588":3,"619":6,"698":2,"743":1,"765":1,"826":1,"960":1}}],["2022自动驾驶研讨会上宣布了其全新的仅基于摄像头的占用网络",{"2":{"759":1}}],["2022a",{"2":{"123":1,"698":1,"826":2}}],["2022b",{"2":{"90":1,"826":1,"864":1}}],["2022",{"2":{"90":3,"139":1,"148":1,"185":1,"189":1,"209":2,"252":1,"268":1,"274":3,"287":1,"312":1,"350":1,"369":1,"410":1,"428":1,"452":1,"550":1,"619":5,"648":1,"692":1,"698":1,"806":1,"826":1,"864":1}}],["2020c",{"2":{"209":1}}],["2020d",{"2":{"209":1}}],["2020年8月",{"2":{"534":1}}],["2020年",{"2":{"131":1,"285":1,"449":1,"816":1}}],["2020a",{"2":{"123":1,"131":1,"139":1,"209":1,"274":2,"495":1,"525":1,"648":1,"698":2,"967":2}}],["2020a年",{"2":{"116":1,"131":4,"285":1,"390":2,"634":1,"732":1}}],["2020b年",{"2":{"131":3,"605":1}}],["2020b",{"2":{"123":1,"139":2,"209":1,"525":5,"698":1,"743":1,"806":1}}],["2020",{"0":{"65":1,"84":1},"2":{"90":2,"123":2,"126":1,"139":1,"209":1,"243":1,"252":3,"274":2,"350":1,"360":1,"495":3,"525":1,"743":1,"806":4,"826":1,"967":9}}],["20250422",{"2":{"573":1}}],["2025年代表性vla4ad模型",{"2":{"238":1}}],["2025",{"2":{"62":1,"90":1,"209":1,"334":11,"360":3,"387":1,"453":1,"525":2,"588":1,"619":1,"648":1,"698":3,"765":2,"806":1,"826":3,"837":2}}],["2023c",{"2":{"588":1}}],["2023a",{"2":{"495":1,"588":1,"765":3}}],["2023b",{"2":{"123":1,"350":1,"648":1,"765":2}}],["2023",{"2":{"23":1,"90":3,"159":1,"189":2,"209":4,"274":13,"306":1,"323":1,"334":3,"350":2,"439":1,"490":1,"495":2,"498":1,"515":1,"525":5,"528":1,"550":1,"556":2,"588":3,"619":4,"648":2,"663":1,"668":1,"671":1,"687":1,"698":2,"710":1,"715":1,"721":1,"733":1,"765":8,"826":1,"845":1,"864":2,"914":1,"1000":1}}],["2024自动驾驶大挑战赛",{"2":{"1000":1}}],["2024c",{"2":{"123":1}}],["2024a",{"2":{"90":1,"588":1}}],["2024b",{"2":{"90":1,"123":1,"588":1}}],["2024",{"2":{"23":1,"30":1,"90":2,"123":3,"155":1,"209":3,"274":1,"334":3,"350":1,"360":3,"525":7,"556":2,"577":1,"588":1,"619":1,"648":3,"698":2,"755":1,"765":4,"776":1,"797":1,"817":2,"826":2,"890":1,"1005":1}}],["20",{"2":{"15":1,"43":2,"114":2,"121":1,"126":1,"157":1,"173":2,"176":1,"190":1,"211":1,"277":1,"337":1,"360":1,"495":1,"512":1,"534":1,"547":1,"564":1,"603":3,"641":1,"652":1,"659":1,"665":1,"677":1,"686":2,"714":1,"744":1,"749":1,"761":1,"770":1,"771":1,"803":1,"805":1,"853":1,"928":1}}],["2ld",{"2":{"694":2}}],["2lg=l1g​+l2g​",{"2":{"582":1}}],["2l",{"2":{"8":1}}],["2=0",{"2":{"8":1}}],["2=",{"2":{"8":1}}],["2c3​=c2​",{"2":{"8":1}}],["2c",{"2":{"8":2}}],["2",{"0":{"59":1,"92":1,"100":1,"103":1,"110":1,"114":2,"121":1,"123":1,"124":1,"128":1,"139":2,"145":1,"147":1,"155":2,"162":1,"171":2,"178":2,"189":3,"195":1,"197":1,"209":2,"218":1,"231":1,"240":1,"252":1,"257":1,"262":1,"263":1,"274":2,"283":1,"299":1,"363":1,"378":1,"404":1,"420":1,"433":1,"447":1,"450":2,"451":1,"464":1,"474":1,"500":1,"525":1,"534":1,"542":1,"551":1,"555":1,"563":1,"565":1,"566":1,"580":1,"599":1,"603":1,"605":1,"609":1,"612":1,"619":1,"626":1,"629":1,"634":1,"636":1,"641":2,"654":1,"655":1,"662":1,"664":1,"673":1,"677":1,"679":2,"681":1,"684":1,"689":1,"697":2,"705":1,"712":1,"716":1,"721":1,"725":2,"735":2,"737":1,"743":1,"747":2,"757":1,"758":1,"759":1,"765":2,"769":3,"771":1,"778":1,"780":2,"791":1,"799":1,"801":1,"802":1,"813":1,"814":1,"821":1,"826":1,"841":2,"850":1,"857":1,"858":1,"860":1,"887":1,"889":1,"903":1,"907":1,"913":1,"914":1,"917":3,"923":1,"933":1,"939":1,"942":1,"950":2,"957":1,"962":1,"967":1,"976":1,"982":1,"983":1,"987":1,"988":1,"990":2,"992":1,"998":1,"999":1,"1000":1,"1001":2,"1004":1},"1":{"103":1,"110":1,"114":1,"123":2,"128":1,"139":2,"145":1,"155":1,"162":1,"171":3,"189":3,"197":2,"209":3,"218":2,"231":1,"240":2,"252":2,"262":2,"274":2,"299":2,"433":1,"464":1,"481":2,"482":1,"511":2,"512":1,"530":1,"561":1,"574":1,"585":1,"597":1,"607":1,"612":1,"617":1,"626":1,"641":1,"646":1,"654":2,"662":1,"673":1,"679":2,"697":1,"702":4,"707":1,"712":1,"725":1,"730":1,"735":1,"743":1,"747":3,"752":1,"757":1,"759":1,"765":1,"769":3,"778":1,"780":1,"790":6,"799":1,"801":1,"821":2,"841":2,"860":2,"874":1,"891":1,"903":1,"917":1,"942":1,"950":1,"957":1,"987":1,"990":1,"1000":1,"1001":1},"2":{"5":3,"8":13,"13":1,"15":1,"17":1,"20":4,"57":5,"66":2,"82":1,"90":1,"93":2,"104":4,"107":2,"109":1,"111":3,"115":2,"124":1,"130":3,"140":7,"146":2,"155":1,"161":6,"171":1,"184":1,"196":2,"208":6,"225":1,"231":4,"235":4,"236":3,"257":1,"261":1,"265":3,"273":3,"274":5,"277":8,"280":7,"301":1,"305":1,"315":1,"316":2,"321":2,"324":1,"325":1,"333":6,"334":9,"349":1,"351":7,"355":2,"360":3,"380":1,"384":2,"394":1,"417":1,"418":1,"433":1,"435":2,"436":1,"455":1,"458":9,"464":13,"466":1,"467":3,"470":1,"486":2,"502":2,"509":1,"518":1,"520":1,"530":1,"532":4,"534":8,"536":1,"539":1,"540":1,"556":1,"564":2,"566":1,"567":2,"570":3,"571":1,"585":2,"590":1,"621":6,"622":1,"623":2,"628":1,"632":7,"636":1,"642":1,"649":1,"656":2,"660":6,"665":2,"667":1,"681":6,"682":1,"686":5,"690":1,"693":2,"694":1,"700":2,"705":3,"709":2,"712":10,"714":1,"724":2,"728":3,"729":1,"732":1,"738":2,"744":1,"746":8,"749":5,"758":1,"759":1,"765":1,"771":1,"773":1,"780":1,"782":1,"790":1,"792":3,"799":1,"800":1,"803":1,"812":1,"823":1,"824":1,"832":1,"835":1,"840":1,"851":1,"853":5,"854":1,"864":1,"866":1,"867":1,"870":2,"885":1,"886":1,"888":2,"893":5,"900":1,"901":1,"903":2,"908":1,"916":9,"917":5,"927":1,"928":10,"936":2,"947":6,"950":1,"957":1,"959":1,"976":1,"982":7,"988":2,"989":1,"992":2,"998":1,"1000":1,"1003":1}}],["krause等人",{"2":{"961":1}}],["krishna等人",{"2":{"961":1}}],["krishna",{"2":{"131":1,"147":1}}],["krishnan",{"2":{"126":1}}],["krizhevsky等人",{"2":{"116":1}}],["kt−k",{"2":{"957":1}}],["ktmk​−gk​",{"2":{"390":1}}],["ktmk​=gk​",{"2":{"390":1}}],["kδpk​",{"2":{"844":2}}],["k$",{"2":{"844":1}}],["kck​上计算",{"2":{"814":1}}],["kck​",{"2":{"814":1}}],["kcnet",{"2":{"574":1}}],["kpk​",{"2":{"844":1,"863":1}}],["kpk​作为kkk中体素的真实类别分布",{"2":{"814":1}}],["kp^k​和p^k",{"2":{"814":1}}],["kpconv",{"2":{"481":1,"588":1}}],["k0≤i",{"2":{"741":1}}],["k0",{"2":{"741":1}}],["kk×k",{"2":{"741":2}}],["kkk",{"2":{"5":1,"153":3,"716":1,"738":1,"741":1,"780":1,"833":2,"844":4,"950":1,"976":1}}],["k×kk",{"2":{"741":2}}],["k是储存的object的数量",{"2":{"718":1}}],["ksk​",{"2":{"666":1}}],["ks^k​",{"2":{"666":1}}],["ksem​",{"2":{"441":1}}],["ksemk",{"2":{"441":1}}],["k|",{"2":{"666":1}}],["kd",{"2":{"636":2}}],["kwk​",{"2":{"863":1}}],["kwargs",{"2":{"623":2}}],["kwon",{"2":{"525":2,"698":1,"721":1}}],["kmk​",{"2":{"844":1,"863":1}}],["kmono​∈r3×3",{"2":{"705":1}}],["kmono∈r3×3k",{"2":{"705":1}}],["km",{"2":{"623":5}}],["k⁻¹",{"2":{"435":1}}],["knn",{"2":{"396":1,"955":1,"976":1}}],["k=256",{"2":{"718":1}}],["k=1",{"2":{"666":1,"814":2,"844":1,"863":1}}],["k=",{"2":{"524":1,"693":2}}],["k=−m",{"2":{"524":2}}],["k=0",{"2":{"390":1}}],["k=5",{"2":{"351":1}}],["kgk​",{"2":{"390":1}}],["kullback",{"2":{"814":1,"823":1}}],["kumawat等人",{"2":{"511":1}}],["kundu",{"2":{"209":1}}],["kuipers",{"2":{"116":1,"961":1}}],["karaman和frazzoli",{"2":{"905":1}}],["kargobot",{"2":{"395":1}}],["kassab",{"2":{"826":1}}],["kanazawa等人",{"2":{"967":1}}],["kanade跟踪器提供初始猜测",{"2":{"310":1}}],["kanade跟踪器",{"2":{"310":1}}],["kangjie",{"2":{"477":1}}],["kautz",{"2":{"458":1}}],["kalapos",{"2":{"252":1}}],["kalashnikov",{"2":{"123":1,"806":1}}],["kaess等人",{"2":{"310":1}}],["kaess",{"2":{"189":2}}],["khanna",{"2":{"698":1}}],["khan",{"2":{"189":1}}],["khronos和clio",{"2":{"462":1}}],["khronos",{"2":{"27":1,"431":2}}],["k−l+1k−l+1k−l+1",{"2":{"153":1}}],["k−1",{"2":{"153":1}}],["kx~k​",{"2":{"153":1}}],["kocabas等人",{"2":{"967":1}}],["ko",{"2":{"648":1}}],["konolige",{"2":{"648":1}}],["kollar等人",{"2":{"905":1}}],["kolotouros等人",{"2":{"285":1,"419":2,"775":1,"816":1,"967":6}}],["kolve",{"2":{"139":1}}],["kostavelis",{"2":{"90":1,"209":1}}],["kebijuelun",{"2":{"508":1}}],["kerr",{"2":{"619":2}}],["kerr等人",{"2":{"121":1}}],["kernel",{"2":{"351":1}}],["kernels",{"2":{"306":1,"384":2}}],["kexue",{"2":{"292":2}}],["key=none",{"2":{"623":1}}],["key=",{"2":{"530":1}}],["keys",{"2":{"384":1}}],["keyserver",{"2":{"76":2}}],["key",{"2":{"76":2,"177":1,"196":9,"254":3,"534":1,"550":1,"950":1}}],["keyframeandpose",{"2":{"67":2}}],["keyframe",{"2":{"67":6}}],["ki​∈r3×3∣i=1",{"2":{"693":1}}],["ki∈r3×3∣i=1",{"2":{"693":1}}],["kintinuous",{"2":{"967":1}}],["kinect传感器收集的",{"2":{"889":1,"947":1}}],["kinect相机收集的",{"2":{"855":1}}],["kinect的rgb和深度相机捕获",{"2":{"757":1}}],["kinect提供的深度估计质量高于realsense",{"2":{"686":1}}],["kinect",{"2":{"605":2,"686":1,"853":1,"889":1}}],["kins​",{"2":{"441":1}}],["kins​+ksem​",{"2":{"441":1}}],["kinsk",{"2":{"441":1}}],["kins+ksemk",{"2":{"441":1}}],["kirillov",{"2":{"350":1,"765":1}}],["kirillov等人",{"2":{"162":1}}],["kitti包含来自22个场景的约15k标注帧和约15k",{"2":{"997":1}}],["kitti",{"0":{"901":1},"2":{"126":2,"302":2,"536":1,"567":1,"749":2,"771":4,"781":2,"792":1,"842":1,"851":1,"901":1,"917":1,"931":2,"995":1,"997":1,"999":1,"1000":7}}],["kim",{"2":{"209":1,"525":2}}],["kim等人",{"2":{"116":4,"121":1,"125":1,"905":2,"961":1}}],["kimera重建的3d网格",{"2":{"947":1}}],["kimera都能够重建一个全局一致的3d网格和一个连贯的dsg",{"2":{"947":1}}],["kimera都能够重建一个全局一致的3d网格以及一个连贯的dsg",{"2":{"889":1}}],["kimera可能会在dsg中将一个房间过度分割为多个房间",{"2":{"930":1}}],["kimera就可以在真实数据上实现准确的重建",{"2":{"889":1}}],["kimera正确重建了地点层",{"2":{"872":1}}],["kimera多帧和全局网格的完整性评估",{"2":{"686":1}}],["kimera在euroc数据集上的绝对平移误差",{"2":{"686":1}}],["kimera在视觉",{"2":{"105":1}}],["kimera对噪声是鲁棒的",{"2":{"686":1}}],["kimera包括一个持续集成服务器",{"2":{"510":1}}],["kimera包括准确的算法",{"2":{"105":1}}],["kimera还提供了一个开源的评估工具套件",{"2":{"510":1}}],["kimera只分割了10个地面真实房间中的2个",{"2":{"437":1}}],["kimera采用立体帧和高频率惯性测量作为输入",{"2":{"285":1}}],["kimera是第一个从视觉",{"2":{"162":1}}],["kimera的3d网格估计",{"2":{"686":1}}],["kimera的语义网格已经包含墙壁",{"2":{"480":1}}],["kimera的输入是立体或rgb",{"2":{"285":1}}],["kimera的模块",{"2":{"131":1}}],["kimera的核心模块已在https",{"2":{"131":1}}],["kimera上发布",{"2":{"131":1}}],["kimera有两组模块",{"2":{"131":1}}],["kimera",{"0":{"94":1,"285":1,"310":1,"336":1,"362":1,"390":1,"419":1,"449":1,"480":1},"1":{"105":1,"116":1,"131":1,"147":1,"162":1,"178":1,"197":1,"218":1,"240":1,"262":1,"285":1,"310":2,"336":2,"362":2,"390":2,"419":2,"449":2,"480":2,"510":2,"541":1,"572":1,"605":1,"634":1,"662":1,"686":1,"709":1,"732":1,"754":1,"775":1,"796":1,"816":1,"836":1,"855":1,"872":1,"889":1,"905":1,"919":1,"930":1,"939":1,"947":1,"954":1,"961":1,"967":1,"973":1},"2":{"94":1,"95":1,"105":1,"125":1,"131":17,"253":1,"276":1,"285":33,"310":2,"336":1,"362":1,"390":11,"419":3,"437":1,"449":8,"480":2,"510":1,"572":2,"634":4,"686":6,"709":1,"732":1,"754":2,"816":9,"836":3,"872":5}}],["killed",{"2":{"11":1}}],["kl散度具有方向",{"2":{"328":1}}],["kl散度",{"2":{"13":1,"328":1,"985":1}}],["kl",{"2":{"13":3,"328":1,"390":1,"814":4,"823":1,"985":1}}],["k2​=0",{"2":{"8":1}}],["k2​l",{"2":{"8":1}}],["k2=0",{"2":{"8":1}}],["k2l",{"2":{"8":1}}],["k1=0",{"2":{"8":1}}],["k1​l",{"2":{"8":1}}],["k1l",{"2":{"8":1}}],["k",{"0":{"971":1},"2":{"5":1,"8":3,"153":24,"225":3,"278":2,"321":2,"351":1,"360":7,"390":12,"405":1,"435":1,"441":2,"481":1,"495":4,"524":1,"595":3,"623":4,"666":1,"693":2,"716":6,"741":1,"780":2,"814":8,"844":8,"863":3,"886":2,"950":6,"957":5}}],["n是场景中的建筑物数量",{"2":{"947":1}}],["n是储存的帧数",{"2":{"718":1}}],["ntotal​分别表示均值位于占用空间中的高斯数量和高斯的总数",{"2":{"916":1}}],["ntotaln",{"2":{"916":1}}],["nts",{"2":{"525":3}}],["nserc",{"2":{"958":1}}],["nsize",{"2":{"904":1}}],["nsurf​",{"2":{"372":1}}],["nsurf​​",{"2":{"372":1}}],["nsurf​​​=concat",{"2":{"372":1}}],["nsurfn",{"2":{"372":1}}],["nsurf",{"2":{"372":1}}],["nsurf=gcn",{"2":{"372":1}}],["n=2n=2n=2",{"2":{"928":1}}],["n=4n=4n=4",{"2":{"853":1,"928":1}}],["n=1",{"2":{"716":1}}],["ndtw",{"2":{"806":1}}],["nds",{"2":{"653":1,"671":1,"893":2}}],["nlmap",{"2":{"765":2}}],["nlp",{"2":{"340":1,"631":2}}],["nyuv2",{"0":{"992":1},"2":{"757":1,"853":4,"886":1,"903":4,"917":2,"928":7,"978":1,"982":1}}],["n∣gi​=",{"2":{"728":1}}],["n∣gi=",{"2":{"728":1}}],["n∣q^​i​=qi​+qdepth​",{"2":{"705":1}}],["n∣q^i=qi+qdepth",{"2":{"705":1}}],["n+",{"2":{"696":1}}],["n+1n+1n+1",{"2":{"355":1}}],["nbv",{"2":{"668":1}}],["nbr",{"2":{"254":2}}],["nüchter和hertzberg",{"2":{"967":1}}],["nüchter",{"2":{"588":1}}],["n0",{"2":{"582":1}}],["n008",{"2":{"476":1}}],["n00014",{"2":{"467":1}}],["nfn",{"2":{"563":1}}],["nfni​",{"2":{"357":1}}],["ng​",{"2":{"532":1,"563":1}}],["ng",{"2":{"532":1,"563":2}}],["ngn",{"2":{"532":1,"563":1}}],["nju",{"2":{"517":1,"776":1}}],["nxk",{"2":{"718":1}}],["nx上测量了uhumans2办公室场景的计时统计",{"2":{"437":1}}],["nx",{"2":{"437":1}}],["n×n×n",{"2":{"429":2}}],["nm",{"2":{"390":3}}],["n^t",{"2":{"357":1}}],["nc​",{"2":{"985":1,"998":1}}],["nc​​evic",{"2":{"985":1}}],["ncorrect​和",{"2":{"916":1}}],["ncorrectn",{"2":{"916":1}}],["ncn",{"2":{"532":1,"985":1,"998":1}}],["ncevic",{"2":{"985":1}}],["nce",{"2":{"424":1}}],["ncap",{"2":{"334":1}}],["ncsn",{"2":{"251":1,"273":1}}],["nhead=nheads",{"2":{"333":1}}],["nheads=8",{"2":{"333":1}}],["nheads",{"2":{"333":1}}],["n组32通道图",{"2":{"305":1}}],["n张3通道的图像",{"2":{"305":1}}],["n张图像和n个文本分别被各自模态的encoder编码成高维向量",{"2":{"184":1}}],["nϕn​",{"2":{"264":1,"266":1}}],["nvn",{"2":{"563":2,"985":1}}],["nv​",{"2":{"563":2,"985":1}}],["nvlabs",{"2":{"490":1,"635":1}}],["nv",{"2":{"247":1,"563":1}}],["nvidiaxxxx你下载的驱动具体名字",{"2":{"66":1}}],["nvidia",{"0":{"55":1},"1":{"66":1},"2":{"66":7,"437":1,"458":1,"589":1,"677":1}}],["nießner",{"2":{"968":1}}],["nie等人",{"2":{"967":1}}],["nips",{"2":{"763":1}}],["nipsw",{"2":{"175":1}}],["nijn",{"2":{"741":1}}],["nij​",{"2":{"741":2}}],["nij",{"2":{"741":1}}],["nine",{"2":{"571":1}}],["ninety",{"2":{"571":1}}],["nistér",{"2":{"310":1,"390":1}}],["nicholson等人",{"2":{"967":1}}],["nicholson",{"2":{"209":1}}],["nnn分别表示预定义的类别集合",{"2":{"656":1}}],["nnn",{"2":{"357":1,"666":1,"693":1,"705":1,"712":2,"728":1,"780":1,"910":1,"928":1}}],["nn",{"2":{"174":4,"333":10,"351":3,"850":1}}],["n118b05518w",{"2":{"173":1}}],["nagatani",{"2":{"698":1}}],["narita等人",{"2":{"967":2}}],["narasimhan",{"2":{"350":1,"495":1}}],["narrow",{"2":{"136":1}}],["nav",{"2":{"525":1}}],["navsim",{"2":{"334":1}}],["navigation",{"2":{"139":8,"173":1,"806":1}}],["nabla",{"2":{"208":10,"225":2,"235":22,"316":2,"338":1,"342":1,"513":9}}],["natural",{"0":{"452":1},"2":{"135":1,"201":1,"399":1,"452":1}}],["names",{"2":{"504":1}}],["namespace",{"2":{"63":1,"93":1,"104":1,"115":1,"130":1,"146":1,"161":1,"196":1}}],["name后跟你喜欢的容器名",{"2":{"60":1}}],["namely",{"2":{"38":1}}],["name",{"2":{"11":1,"60":1,"68":1,"136":1,"196":1,"254":3,"504":2}}],["nuv↔ν中mmm关系的复杂计数",{"2":{"730":1}}],["nuν",{"2":{"730":1,"957":1}}],["nu",{"2":{"730":11,"957":2}}],["nuinteract",{"2":{"360":3,"447":2}}],["nuimages",{"2":{"302":1}}],["nuscene数据集上",{"2":{"1006":1}}],["nuscene",{"2":{"653":1}}],["nuscenes仅计算可见3d体素的miou",{"2":{"1000":1}}],["nuscenes仅4万样本",{"2":{"617":1}}],["nuscenes使用环视图像作为输入",{"2":{"1000":1}}],["nuscenes的任务设置更简单",{"2":{"1000":1}}],["nuscenes的验证集上进行消融研究",{"2":{"800":1}}],["nuscenes收集了来自1",{"2":{"997":1}}],["nuscenes验证数据集上的3d占据预测性能",{"2":{"791":1}}],["nuscenes验证集上3d语义占用预测的比较",{"2":{"1000":1}}],["nuscenes验证集上daocc的可视化结果",{"2":{"909":1}}],["nuscenes验证集上的定性可视化",{"2":{"909":1}}],["nuscenes验证集上的3d语义占用预测结果",{"2":{"842":1}}],["nuscenes验证集上的三维占据预测性能",{"2":{"736":2}}],["nuscenes验证集上使用相机掩码进行训练的性能miou",{"2":{"779":1,"840":1}}],["nuscenes验证集上",{"2":{"421":1}}],["nuscenes上的所有类别的iou分数也最高",{"2":{"1000":1}}],["nuscenes上达到了27",{"2":{"1000":1}}],["nuscenes上不使用相机掩码进行比较",{"2":{"779":1}}],["nuscenes上使用相机掩码进行比较",{"2":{"779":1}}],["nuscenes和sscbench",{"2":{"999":1}}],["nuscenes和surroundocc数据集上进行的广泛实验表明",{"2":{"820":1}}],["nuscenes和surroundocc基准测试中取得了新的最高水平性能",{"2":{"392":1}}],["nuscenes和waymo数据集开发",{"2":{"997":1}}],["nuscenes和nuscenes",{"2":{"757":1}}],["nuscenes和occ3d",{"2":{"757":1}}],["nuscenes是一个用于室外环境的大规模自动驾驶数据集",{"2":{"757":1}}],["nuscenes提供的相机可见掩码训练模型时",{"2":{"736":1}}],["nuscenes数据集上3d占用感知的推理速度分析",{"2":{"1001":1}}],["nuscenes数据集上的占用准确性",{"2":{"1001":1}}],["nuscenes数据集上的性能比较",{"2":{"875":1,"922":1,"949":1}}],["nuscenes数据集上的基于图像和多模态方法进行了比较",{"2":{"779":1}}],["nuscenes数据集上的评估结果",{"2":{"757":1}}],["nuscenes数据集包含700个训练场景和150个验证场景",{"2":{"770":1}}],["nuscenes数据集附带23个类的注释",{"2":{"702":1}}],["nuscenes数据集和surroundocc数据集上建立了新的最高水平性能",{"2":{"421":1}}],["nuscenes未提供2d图像语义分割标签",{"2":{"617":1}}],["nuscenes基准测试中的多种占据预测基线",{"2":{"505":1}}],["nuscenes挑战轨迹l2误差与碰撞率",{"2":{"447":1}}],["nuscenes2019",{"2":{"126":1}}],["nuscenes",{"0":{"113":1,"327":1,"504":1,"534":1,"702":1,"790":1,"810":1},"1":{"126":1,"142":1,"157":1,"173":1,"191":1,"211":1,"233":1,"254":1,"277":1,"302":1,"830":1,"850":1},"2":{"82":1,"108":1,"113":1,"126":17,"157":2,"233":1,"254":1,"277":8,"302":14,"327":2,"334":4,"360":4,"421":1,"425":3,"444":2,"455":1,"476":1,"534":10,"536":1,"567":1,"652":2,"670":1,"677":3,"702":2,"736":1,"739":8,"749":1,"757":1,"770":1,"771":4,"781":1,"782":1,"787":1,"790":1,"803":6,"850":2,"851":1,"885":1,"893":3,"900":2,"914":1,"927":1,"936":1,"944":1,"977":1,"995":2,"997":2,"1000":1}}],["nusc",{"2":{"360":1,"504":2,"534":2,"654":3}}],["num",{"2":{"254":2,"333":10,"623":5,"654":2}}],["number",{"2":{"57":1,"700":1}}],["nutonomy",{"2":{"126":1}}],["nuːsiːnz",{"2":{"126":1}}],["np分别表示通道数和环绕图像的数量",{"2":{"609":1}}],["np×cp×hp",{"2":{"609":1}}],["npn",{"2":{"532":1}}],["npz",{"2":{"327":4,"476":1}}],["np",{"2":{"184":5,"379":12,"504":4,"534":1,"654":6}}],["npos",{"2":{"52":2}}],["npy",{"2":{"32":6}}],["ne",{"2":{"730":2,"806":1}}],["new",{"2":{"496":1,"705":1,"716":1,"729":2}}],["newcombe等人",{"2":{"967":2}}],["newcombe",{"2":{"189":2}}],["neq",{"2":{"390":1,"848":4,"916":1}}],["next",{"2":{"254":3,"654":1,"729":1}}],["neighbors",{"2":{"886":2}}],["neighborhood",{"2":{"351":1}}],["neighbor",{"2":{"158":1,"850":1}}],["near",{"2":{"204":1}}],["nearest",{"2":{"158":1,"850":1,"886":2}}],["neat",{"2":{"57":1}}],["needed",{"2":{"107":1}}],["negative",{"2":{"84":1,"347":1}}],["negative点击用distance",{"2":{"54":1}}],["nerf",{"0":{"755":1},"2":{"30":1,"474":1,"619":1,"860":1,"932":1}}],["neurons",{"2":{"863":1}}],["neuro",{"2":{"334":1}}],["neural",{"2":{"30":1,"525":1,"589":2,"619":2,"698":2,"912":1}}],["neurips",{"2":{"23":2,"244":1,"469":1,"692":1}}],["netrgb^",{"2":{"978":1,"989":2}}],["net的关键组件",{"2":{"875":1}}],["net的结构与pointnet类似",{"2":{"420":1}}],["net进行基于视觉的3d占用预测",{"2":{"875":1}}],["net结构可以提取不同尺度的特征",{"2":{"875":1}}],["net架构采用编码器",{"2":{"875":1}}],["net网络",{"2":{"636":1}}],["net根据节点的分割类型在每个级别共享参数",{"2":{"636":1}}],["net风格的编码器",{"2":{"526":1}}],["net从输入点云p中提取逐点特征",{"2":{"377":1}}],["netwrok",{"2":{"221":1}}],["network由8个全连接层组成",{"2":{"149":1}}],["network中最开始的输入变成了常数张量",{"2":{"133":1}}],["network的每一层",{"2":{"133":1}}],["networks",{"0":{"616":1},"1":{"645":1,"672":1,"696":1,"719":1,"741":1,"763":1,"784":1},"2":{"123":1,"251":1,"589":1,"616":1,"763":1,"912":1}}],["network",{"0":{"149":1,"321":1,"498":1},"1":{"347":1,"375":1},"2":{"23":1,"133":2,"149":1,"181":2,"366":1,"420":1,"498":1,"589":1,"776":1}}],["net可以在低维表示上添加和删除噪声",{"2":{"205":1}}],["netstat",{"2":{"78":1}}],["net",{"0":{"412":1},"2":{"13":1,"20":1,"41":1,"48":1,"69":1,"106":1,"183":1,"205":1,"220":1,"351":1,"369":1,"382":1,"384":1,"412":1,"424":1,"508":1,"579":1,"589":1,"607":1,"636":1,"875":1,"978":3,"996":1}}],["non",{"0":{"472":1},"2":{"235":1,"380":1}}],["none",{"2":{"106":2,"174":1,"842":1}}],["norm层",{"2":{"659":1}}],["norm函数的作用是将坐标值缩放到",{"2":{"638":1}}],["norm",{"2":{"638":3,"762":1}}],["normals",{"2":{"379":6}}],["normalizing",{"2":{"203":1,"863":1}}],["normalized",{"2":{"235":1}}],["normalize",{"2":{"184":2}}],["normalization和max",{"2":{"420":1}}],["normalization",{"2":{"149":2}}],["norm3",{"2":{"174":2}}],["norm2",{"2":{"174":2}}],["norm1",{"2":{"174":2}}],["northsummer",{"2":{"906":1}}],["north",{"2":{"157":2}}],["nord",{"2":{"57":1}}],["nodes",{"2":{"271":1}}],["node",{"2":{"97":1}}],["nouveau",{"2":{"66":9}}],["notebook",{"2":{"510":1}}],["note",{"2":{"327":3,"496":1}}],["notag",{"2":{"111":3,"137":2,"140":18,"153":1,"208":22,"236":3,"273":11,"280":18,"513":2}}],["not",{"0":{"53":1},"1":{"64":1,"74":1},"2":{"40":1,"49":1,"64":2,"67":1,"74":2,"327":2,"496":1}}],["no",{"2":{"17":2,"48":1,"64":1,"66":4,"109":1,"358":1,"519":1}}],["noetic",{"2":{"15":1,"76":2,"87":1,"107":3}}],["noise",{"2":{"5":1,"111":1,"175":1,"236":1,"251":1,"440":1,"790":1}}],["n",{"2":{"5":1,"57":2,"93":2,"104":1,"111":3,"124":3,"140":8,"146":1,"161":1,"174":1,"184":7,"188":1,"208":2,"236":3,"254":2,"256":1,"257":3,"280":8,"316":1,"328":1,"351":2,"357":4,"372":2,"383":2,"390":2,"411":1,"412":1,"464":2,"495":4,"532":5,"534":1,"563":6,"590":1,"595":2,"621":5,"649":1,"654":1,"666":3,"672":2,"693":9,"696":2,"705":1,"712":4,"716":3,"724":2,"728":1,"738":4,"741":1,"746":4,"747":1,"780":4,"888":7,"904":2,"910":1,"916":4,"947":1,"950":2,"957":5,"985":6,"998":2}}],["^g",{"2":{"863":1}}],["^k",{"2":{"844":1,"863":1}}],["^i",{"2":{"738":2}}],["^cc∈rc",{"2":{"705":1}}],["^cf3d=fd⊗fc",{"2":{"595":1}}],["^cfc",{"2":{"595":1}}],["^4r∈r4",{"2":{"705":1}}],["^4ri​∈r4",{"2":{"532":1}}],["^4",{"2":{"693":1}}],["^pg=",{"2":{"656":1,"681":1}}],["^fk",{"2":{"579":1}}],["^fr",{"2":{"579":1}}],["^dfd",{"2":{"595":1}}],["^d",{"2":{"563":1,"595":1,"693":1,"716":1}}],["^3s∈r3",{"2":{"705":1}}],["^3si​∈r3",{"2":{"532":1}}],["^3m∈r3",{"2":{"705":1}}],["^3mi​∈r3",{"2":{"532":1}}],["^3",{"2":{"693":2}}],["^31",{"2":{"677":1}}],["^ni=",{"2":{"656":1}}],["^n",{"2":{"390":1,"464":1}}],["^mq∈rm",{"2":{"705":1}}],["^m",{"2":{"390":1,"563":1,"716":1}}],["^l",{"2":{"342":1}}],["^t",{"2":{"235":2,"273":3,"532":3,"656":1,"681":2,"693":2,"738":1,"916":3}}],["^~~~~",{"2":{"67":1}}],["^|",{"2":{"57":1}}],["^rl=",{"2":{"704":2}}],["^r",{"2":{"57":2}}],["^251",{"2":{"749":1}}],["^2+~",{"2":{"140":1,"280":1}}],["^2c1​=",{"2":{"8":1}}],["^2",{"2":{"5":1,"8":1,"140":5,"208":2,"280":5,"390":1}}],["^",{"2":{"5":3,"8":3,"20":1,"57":3,"111":1,"153":1,"235":2,"236":1,"316":1,"458":9,"464":5,"532":7,"563":3,"585":2,"590":1,"595":3,"609":2,"621":10,"647":2,"649":1,"656":2,"666":4,"670":4,"676":4,"681":5,"682":5,"693":7,"694":12,"699":5,"705":1,"712":5,"716":2,"724":1,"738":3,"739":1,"742":1,"746":23,"750":14,"766":1,"778":1,"780":3,"794":1,"807":1,"814":2,"844":1,"863":3,"884":1,"910":3,"915":1,"916":6,"950":4,"957":2,"985":4,"998":1}}],["s​",{"2":{"957":1}}],["s2tpvformer",{"2":{"858":1}}],["s2d",{"2":{"660":1}}],["s2d​中采样对应的特征",{"2":{"660":1}}],["s2d​",{"2":{"660":2}}],["s2df^",{"2":{"660":2}}],["s3cnet的iou最高",{"2":{"1000":1}}],["s3cnet",{"2":{"870":1,"923":1,"1000":1}}],["s3的矩阵",{"2":{"752":1}}],["s3的超体素",{"2":{"730":1}}],["s3hwd",{"2":{"752":1}}],["s3n^2",{"2":{"730":1}}],["s3s^3s3",{"2":{"730":1}}],["s3dis",{"2":{"349":1,"979":1}}],["sb​",{"2":{"694":1}}],["sbs",{"2":{"694":1}}],["sf​",{"2":{"694":1}}],["sfs",{"2":{"694":1}}],["sfcnn能够抵抗旋转和扰动",{"2":{"511":1}}],["s∈r3s",{"2":{"705":1}}],["s∈r3",{"2":{"693":2}}],["s1",{"2":{"660":2}}],["s^3hwd×hwd",{"2":{"752":1}}],["s^3",{"2":{"730":3}}],["s^3n2",{"2":{"730":1}}],["s^k",{"2":{"666":1}}],["s^t",{"2":{"656":1,"693":1}}],["s^",{"2":{"647":1,"716":8}}],["s=",{"2":{"647":1,"660":3}}],["s=diag",{"2":{"532":2,"656":2,"693":2}}],["sjtu",{"2":{"517":1}}],["s界限对数据关联的可行性进行阈值处理",{"2":{"419":1}}],["swintransformer",{"2":{"803":1}}],["swintransformer在保持多样化基准测试中竞争力的同时实现了高效率和高可扩展性",{"2":{"627":1}}],["swin",{"0":{"602":1},"1":{"631":1,"659":1,"683":1,"706":1,"729":1,"751":1},"2":{"620":1,"627":1,"631":4,"659":2,"699":9,"729":1,"782":1,"803":5}}],["sweeps",{"2":{"327":1}}],["swapfil",{"2":{"33":1}}],["swapfile",{"2":{"26":7,"33":2}}],["swapoff",{"2":{"33":1}}],["swapon",{"2":{"26":1}}],["swap栏都是",{"2":{"26":1}}],["swap",{"0":{"26":1,"33":1},"2":{"18":1,"26":2,"33":2,"161":2,"854":3,"904":1}}],["smith",{"2":{"973":1}}],["smask​",{"2":{"405":1}}],["smask",{"2":{"377":1}}],["smooth",{"2":{"375":1}}],["smoother",{"2":{"310":1}}],["smpl网格",{"2":{"419":1}}],["smpl",{"2":{"131":1,"967":1}}],["slice",{"2":{"906":1}}],["sliceocc",{"0":{"906":1},"2":{"906":2}}],["slidarseg",{"2":{"254":1,"534":1}}],["slp",{"2":{"481":1}}],["slam和移动对象跟踪",{"2":{"967":1}}],["slam和度量",{"2":{"510":1}}],["slam3",{"2":{"390":1,"634":1,"686":1}}],["slam2",{"2":{"58":3,"152":1}}],["slam",{"0":{"56":1,"155":1,"171":1,"189":1,"209":1},"1":{"171":1,"189":1,"209":1},"2":{"30":12,"94":1,"116":1,"123":1,"155":4,"171":4,"189":11,"209":12,"285":1,"435":4,"525":3,"588":9,"619":1,"698":2,"826":2,"846":1,"967":4}}],["sks",{"2":{"666":1}}],["skočaj",{"2":{"252":1}}],["skiplist",{"2":{"27":1}}],["sθ​",{"2":{"225":1,"235":5}}],["sθ",{"2":{"225":1,"235":5}}],["sr",{"2":{"806":2}}],["sreal​或spreds",{"2":{"429":1}}],["sreal​∈rn×n×n",{"2":{"429":1}}],["sreal∈rn×n×ns",{"2":{"429":1}}],["srinet",{"2":{"420":1}}],["srn",{"2":{"420":1}}],["sr3",{"0":{"175":1,"304":1},"1":{"193":1,"213":1,"235":1,"256":1,"279":1,"304":1,"329":2,"354":2,"382":1},"2":{"175":1,"382":4}}],["src",{"2":{"27":5,"120":2}}],["svm",{"2":{"169":1}}],["s的容量为10",{"2":{"146":1}}],["s的容量为5",{"2":{"146":1}}],["szot",{"2":{"139":1}}],["symphonies",{"2":{"875":1}}],["symmetric",{"2":{"379":2}}],["synthetic",{"2":{"498":1}}],["synthesizing",{"2":{"439":1}}],["synthesis基于clip模型的多模态图像引导生成more",{"2":{"201":1}}],["synthesis",{"0":{"244":1,"365":1,"422":1},"2":{"133":2,"181":1,"201":1,"205":1,"247":1,"287":1,"317":1,"422":1}}],["synsin0",{"2":{"367":1,"453":1}}],["system",{"2":{"102":1}}],["square",{"2":{"124":1,"136":1,"257":1}}],["squeezesegv2",{"2":{"955":1}}],["squeeze",{"2":{"124":1,"257":1}}],["sqrt",{"2":{"111":12,"124":4,"140":35,"175":2,"188":1,"208":3,"225":1,"236":12,"251":1,"257":4,"273":23,"280":35,"316":4,"916":1}}],["s容器内元素为1",{"2":{"161":1}}],["s容器内元素为3",{"2":{"161":1}}],["s容器内元素为4",{"2":{"115":2}}],["s容器为空",{"2":{"115":2}}],["s+3",{"2":{"93":1}}],["sst",{"2":{"715":1}}],["sss来实现",{"2":{"928":1}}],["sss和旋转",{"2":{"681":1}}],["sss分别表示协方差矩阵",{"2":{"656":1}}],["sss",{"2":{"621":1,"660":2,"693":1,"705":1,"738":1,"928":1}}],["sss​",{"2":{"434":1}}],["ssc研究主要处理静态室内场景",{"2":{"841":1}}],["sscbench",{"2":{"749":1,"792":1,"997":1}}],["sscnet",{"2":{"603":1,"841":1}}],["ssc",{"2":{"539":2,"566":1,"570":5,"603":8,"632":5,"684":2,"794":1,"841":1,"853":3,"870":1,"903":1,"917":1,"937":1,"989":1}}],["ss算法",{"2":{"169":1}}],["sshd",{"2":{"78":2}}],["ssh",{"0":{"78":1},"2":{"60":1,"74":2,"78":7}}],["ssim",{"0":{"8":1},"2":{"8":4,"220":1,"382":3,"988":2}}],["sarmiento等人",{"2":{"961":1}}],["sachini",{"2":{"958":1}}],["sayre",{"2":{"605":1}}],["safeauto",{"2":{"283":1,"334":1,"417":2,"447":1,"478":1}}],["saputra",{"2":{"209":1}}],["savinov",{"2":{"525":2}}],["savarese",{"2":{"209":1}}],["savva",{"2":{"139":1,"958":1}}],["salas",{"2":{"116":1,"123":1,"209":2,"698":1,"967":2}}],["samba",{"2":{"960":1}}],["sample全程加入参考图片",{"2":{"266":1}}],["samples",{"2":{"254":1,"327":1,"476":1}}],["sample",{"2":{"180":1,"254":13,"328":1,"476":3,"534":2,"654":4}}],["sampling",{"0":{"140":1,"280":1},"2":{"30":1,"396":1,"420":1,"589":1,"616":2,"863":1}}],["same",{"2":{"67":2,"120":1,"315":1}}],["sam",{"2":{"45":1,"617":1,"765":2,"988":1}}],["sa版权协议",{"2":{"41":1,"48":1,"220":1,"351":1}}],["stückler",{"2":{"556":1}}],["stückler和behnke",{"2":{"190":1}}],["stft",{"2":{"511":1}}],["sturgess",{"2":{"209":1}}],["study",{"2":{"45":1}}],["styles",{"2":{"181":2}}],["style组合的结果也不同",{"2":{"181":1}}],["style",{"0":{"181":1},"2":{"133":2,"181":3}}],["stylegan的做法是在每一次卷积操作后都加入噪声",{"2":{"199":1}}],["stylegan中的",{"2":{"133":1}}],["stylegan2",{"2":{"133":1,"143":1}}],["stylegan",{"0":{"133":1},"1":{"149":1,"165":1,"181":1,"199":1,"221":1},"2":{"133":2}}],["star",{"2":{"635":1,"687":1,"710":1,"733":1}}],["start",{"2":{"64":1,"66":1,"78":1}}],["standard",{"2":{"616":1}}],["stacking",{"0":{"896":1}}],["stack",{"0":{"685":1},"1":{"708":1,"731":1,"753":1,"774":1,"795":1},"2":{"351":3,"685":1,"708":1,"835":1}}],["stachniss",{"2":{"123":1,"826":1}}],["stablediffusion",{"0":{"185":1},"1":{"205":1,"227":1,"248":1,"270":1,"294":1,"319":1,"345":1,"373":1,"401":1,"430":1,"461":1,"491":1,"521":1,"552":1},"2":{"428":1}}],["stable",{"0":{"428":1},"1":{"459":1},"2":{"159":1,"185":1,"205":1,"373":2,"428":1}}],["stage",{"2":{"138":2,"315":1,"562":1}}],["states",{"2":{"373":1,"623":1}}],["statistical",{"2":{"235":1}}],["static",{"2":{"67":2,"702":1,"790":4}}],["status",{"2":{"78":1}}],["stl中",{"2":{"685":1}}],["stl",{"2":{"67":1,"217":1,"685":2}}],["stores",{"2":{"496":1}}],["storing",{"2":{"496":1}}],["stochastic",{"0":{"148":1,"199":1},"1":{"164":1,"180":1,"198":1,"220":1},"2":{"148":2,"170":1,"199":1,"287":1}}],["stop",{"2":{"66":1}}],["stod",{"2":{"63":3}}],["stof",{"2":{"63":2}}],["stoull",{"2":{"63":2}}],["stoul",{"2":{"63":2}}],["stold",{"2":{"63":2}}],["stoll可以兼容stoi",{"2":{"63":1}}],["stoll",{"2":{"63":2}}],["stol",{"2":{"63":3}}],["stoi",{"2":{"63":2}}],["stroller",{"2":{"702":1,"790":1}}],["streampetr",{"2":{"671":2}}],["structnav",{"2":{"648":1}}],["structures",{"2":{"43":1}}],["structure",{"2":{"8":1,"38":1,"209":1}}],["structural",{"2":{"8":1}}],["str>",{"2":{"254":56,"534":3,"654":7}}],["strategy",{"0":{"488":1,"518":1},"1":{"518":1,"549":1},"2":{"106":2,"315":2,"384":1,"518":2}}],["stride",{"2":{"715":1}}],["stripes",{"2":{"57":1}}],["string函数详解",{"2":{"63":1}}],["string型变量转换为double型变量",{"2":{"63":1}}],["string型变量转换为float型变量",{"2":{"63":1}}],["string型变量转换为long",{"2":{"63":2}}],["string型变量转换为long型变量",{"2":{"63":1}}],["string型变量转换为unsigned",{"2":{"63":2}}],["string型变量转换为int型变量",{"2":{"63":1}}],["string>",{"2":{"52":2,"63":1,"196":3}}],["string",{"0":{"52":1},"1":{"63":1},"2":{"52":1,"57":1,"63":1,"196":2}}],["std",{"2":{"40":2,"63":1,"67":5,"93":1,"104":1,"115":1,"130":1,"146":1,"161":1,"196":1,"685":2,"835":6,"888":1}}],["stem机器学习与计算机视觉实验室进行",{"2":{"1008":1}}],["steam",{"0":{"671":1},"1":{"695":1,"718":1,"740":1,"762":1,"783":1}}],["stein",{"2":{"235":1}}],["stefano",{"2":{"209":1}}],["stereo",{"2":{"136":1}}],["stevenlovegrove",{"2":{"40":1}}],["step的流水线流程使得它们的性能受到二维图像检测器的限制",{"2":{"818":1}}],["step",{"2":{"562":1,"818":1}}],["steps",{"2":{"111":1,"124":3,"236":1,"257":3,"345":1}}],["step3",{"2":{"32":1,"38":1}}],["step2",{"2":{"32":1,"38":1}}],["step1",{"2":{"32":1,"38":1}}],["sdk",{"2":{"1001":1}}],["sd相当于vqgan里的transformer被替换成了diffusion",{"2":{"459":1,"552":1}}],["sd和ddpm一样采用预测noise的方法来训练unet",{"2":{"401":1}}],["sd采用clip",{"2":{"373":1}}],["sd采用基于kl",{"2":{"345":1}}],["sdedit",{"0":{"287":1},"2":{"287":1}}],["sde",{"0":{"170":1,"188":1,"208":1,"251":1,"273":1},"1":{"188":1,"208":1,"230":1,"251":1,"273":1},"2":{"188":1,"273":1}}],["sdfs",{"2":{"619":1}}],["sdf",{"0":{"344":1},"2":{"31":5,"247":2,"269":1,"372":1}}],["sdb",{"2":{"24":2}}],["sn=linear",{"2":{"957":1}}],["sn​​=linear",{"2":{"957":1}}],["sn​",{"2":{"957":1}}],["sns",{"2":{"957":1}}],["sni",{"2":{"30":2}}],["snt",{"2":{"30":1}}],["sed",{"2":{"765":1}}],["serm",{"2":{"585":1}}],["serve",{"2":{"384":1,"659":1}}],["server",{"2":{"78":2}}],["service",{"2":{"66":2,"74":1,"78":3}}],["seven",{"2":{"571":1}}],["se",{"2":{"390":2}}],["seamlessly",{"2":{"384":1}}],["search提取2000个候选框",{"2":{"250":1}}],["search",{"2":{"158":1,"207":4,"272":1}}],["sequential",{"2":{"333":1}}],["sequencer",{"0":{"340":1},"1":{"368":1,"396":1,"426":1,"456":1},"2":{"315":1}}],["sequence",{"2":{"32":2,"38":2,"315":1,"333":1}}],["sec",{"2":{"384":3}}],["second",{"2":{"177":2,"670":2}}],["security",{"2":{"36":4}}],["selective",{"2":{"207":4}}],["selection",{"0":{"54":1,"471":1},"2":{"54":1}}],["selfocc的miou为7",{"2":{"1000":1}}],["selfocc",{"2":{"949":1,"1000":1}}],["selfattention",{"2":{"659":1}}],["self",{"2":{"174":21,"333":18,"351":6,"394":1,"623":3,"651":1,"659":1,"668":2,"715":2,"729":3}}],["senet2d",{"2":{"971":2}}],["senet3d",{"2":{"971":3}}],["senet",{"2":{"829":2,"971":2}}],["sensitive",{"0":{"763":1}}],["sensor",{"0":{"445":1},"2":{"254":6,"327":1,"476":2,"545":1,"597":2,"654":3}}],["sengupta",{"2":{"209":1}}],["send",{"2":{"57":1}}],["sen",{"2":{"52":16}}],["set底层实现为hash",{"2":{"571":1}}],["setp",{"2":{"312":1}}],["sethian",{"2":{"274":1}}],["set6",{"2":{"261":1,"418":1}}],["set5",{"2":{"261":1}}],["set4",{"2":{"261":1,"361":1,"389":1}}],["set3",{"2":{"261":1,"335":1}}],["set2",{"2":{"261":2,"309":1,"571":2}}],["set1",{"2":{"261":4,"284":1,"309":1,"335":2,"479":1,"509":1,"540":1,"571":5,"604":1,"633":6,"661":1}}],["set>",{"2":{"239":1}}],["settings",{"2":{"45":1}}],["set",{"0":{"217":1,"448":1},"1":{"239":1,"261":1,"284":1,"309":1,"335":1,"361":1,"389":1,"418":1,"448":1,"479":2,"509":2,"540":2,"571":2,"604":2,"633":2,"661":2},"2":{"41":2,"48":2,"107":1,"217":9,"261":6,"284":1,"309":1,"335":1,"361":1,"384":1,"389":1,"418":1,"571":1,"700":1}}],["setup",{"2":{"34":1,"57":1,"87":1,"120":3,"152":1}}],["seg",{"2":{"550":1,"644":1}}],["segs",{"2":{"32":2,"38":2}}],["segmentation",{"0":{"65":1,"75":1,"84":1,"117":1,"132":1},"2":{"75":1,"84":3,"96":1,"106":3,"159":1,"162":1,"323":2,"384":1,"405":1,"410":2,"439":1,"498":1,"528":1,"550":1,"756":1,"790":2}}],["segment",{"2":{"30":1,"45":1,"120":1,"159":1,"469":2,"765":1}}],["semexp",{"2":{"698":1}}],["sem=s",{"2":{"621":1}}],["sem​=s",{"2":{"621":1}}],["sem​",{"2":{"621":2}}],["sem​∈rx×y×z×c2​",{"2":{"621":1}}],["semp",{"2":{"621":1}}],["sem∈rx×y×z×c2p",{"2":{"621":1}}],["sem",{"2":{"32":1,"441":3,"621":5,"632":1,"670":4,"750":2,"794":1,"834":1,"870":1,"917":1,"928":2}}],["semseg",{"2":{"32":2,"38":2}}],["semgauss",{"2":{"30":2}}],["semantic3d",{"2":{"979":1,"996":1}}],["semantickitti扩展了kitti",{"2":{"997":1}}],["semantickitti",{"0":{"989":1},"2":{"302":1,"757":1,"853":5,"900":2,"903":5,"917":2,"927":1,"928":4,"945":1,"977":1,"978":1,"979":1,"982":3,"989":1,"997":1,"1000":1}}],["semantically",{"2":{"162":1}}],["semantics管道",{"2":{"732":1}}],["semantics来评估捆绑射线投射导致的初始性能损失",{"2":{"732":1}}],["semantics基于vio姿态估计构建3d网格",{"2":{"732":1}}],["semantics通过tsdf产生的慢速网格之间的定量比较",{"2":{"686":1}}],["semantics对v1",{"2":{"686":1}}],["semantics和kimera",{"2":{"572":1}}],["semantics中使用的体素大小的两倍",{"2":{"449":1}}],["semantics生成的网格是基于kimera",{"2":{"390":1}}],["semantics的更新平均需要65",{"2":{"836":1}}],["semantics的计时",{"2":{"836":1}}],["semantics的混淆矩阵",{"2":{"732":2}}],["semantics的3d网格rmse",{"2":{"709":1}}],["semantics的3d度量",{"2":{"285":1,"541":1}}],["semantics的rmse网格误差",{"2":{"709":1}}],["semantics的全局网格非常准确",{"2":{"686":1}}],["semantics的全局度量",{"2":{"131":1}}],["semantics产生的度量",{"2":{"285":1}}],["semantics使用voxblox",{"2":{"480":1}}],["semantics使用在每个关键帧产生的2d语义标记图像",{"2":{"362":1}}],["semantics使用2d语义分割的相机图像对3d网格进行标记",{"2":{"285":1}}],["semantics使用kimera",{"2":{"131":1}}],["semantics",{"0":{"362":1},"2":{"131":1,"285":3,"419":1,"709":1,"754":1,"816":1,"836":1,"842":1}}],["semanticmap综述",{"0":{"71":1},"1":{"80":1,"90":1,"100":1,"110":1,"123":1,"139":1,"155":1,"171":1,"189":1,"209":1,"231":1,"252":1,"274":1,"299":1,"324":1,"350":1,"378":1,"406":1,"435":1,"465":1,"495":1,"525":1,"556":1,"588":1,"619":1,"648":1,"675":1,"698":1,"721":1,"743":1,"765":1,"786":1,"806":1,"826":1,"846":1,"864":1,"881":1,"897":1,"913":1,"926":1,"935":1,"943":1,"951":1,"958":1}}],["semantic",{"0":{"89":1,"422":1,"445":1},"2":{"23":1,"27":3,"30":5,"32":3,"38":4,"155":1,"201":1,"209":1,"384":4,"410":3,"422":1,"439":1,"441":1,"495":3,"498":1,"504":2,"508":1,"514":1,"528":1,"545":1,"578":1,"623":1,"698":1,"906":1,"941":1}}],["shrink",{"2":{"904":1}}],["shridhar",{"2":{"806":1}}],["shelf和floor",{"2":{"732":1}}],["shell",{"2":{"48":1}}],["shu²³",{"2":{"477":1}}],["shuffle",{"2":{"420":1}}],["shuhongll",{"2":{"30":1}}],["shilong",{"2":{"914":1}}],["shiyi",{"2":{"458":1}}],["shifted",{"2":{"729":2}}],["shifting",{"2":{"631":1}}],["shift",{"2":{"328":1}}],["shi和tomasi",{"2":{"310":1}}],["shiki",{"2":{"57":1}}],["shown",{"2":{"659":2}}],["shoot",{"2":{"564":1,"585":2,"595":1}}],["shot方法可以分为两类",{"2":{"857":1}}],["shot得到的结果与resnet在128w",{"2":{"167":1}}],["shot",{"0":{"857":1},"1":{"874":1,"891":1},"2":{"151":1,"159":1,"469":2,"655":1}}],["should",{"2":{"38":1}}],["sharing",{"2":{"863":1}}],["share",{"2":{"107":1}}],["shared",{"0":{"434":1},"2":{"11":2,"17":2,"60":1}}],["shafiullah",{"2":{"619":1}}],["shah",{"2":{"209":1,"525":2,"765":1}}],["shannon散度",{"2":{"985":1}}],["shan等人",{"2":{"967":1}}],["shan",{"2":{"209":2}}],["shapes",{"2":{"616":1}}],["shapenetpart和partnet",{"2":{"356":1}}],["shapenet",{"0":{"313":1}}],["shape",{"2":{"124":1,"247":1,"257":1,"333":4,"351":3,"534":1,"623":1}}],["shakey",{"2":{"123":1}}],["sh脚本里的$1是什么意思",{"2":{"48":1}}],["sh",{"2":{"41":2,"58":2,"76":1}}],["sgn采用密集",{"2":{"875":1}}],["sgn",{"2":{"875":1}}],["sgi",{"2":{"685":1}}],["sgd容易震荡",{"2":{"129":1}}],["sgd",{"2":{"129":3}}],["sgs",{"2":{"30":2,"588":1}}],["sg",{"2":{"23":1,"437":1}}],["sc",{"2":{"736":1,"794":1,"853":1}}],["sc​",{"2":{"694":1,"794":1}}],["scsf",{"2":{"1003":1}}],["scs",{"2":{"694":1}}],["scancomplete",{"2":{"962":1}}],["scannet和occ",{"2":{"793":1}}],["scannet和embodiedocc",{"2":{"793":2}}],["scannet数据集上评估了我们的局部空间占用预测模块",{"2":{"833":1}}],["scannet数据集上使用8个nvidia",{"2":{"813":2}}],["scannet数据集中采样",{"2":{"793":1}}],["scannet数据集中采样了一个小集合作为embodiedocc",{"2":{"793":1}}],["scannet数据集中的每个场景由30个带姿态的帧及其对应的空间占用组成",{"2":{"793":1}}],["scannet数据集外",{"2":{"793":1}}],["scannet数据集",{"2":{"793":3}}],["scannet数据集提出了一个embodiedocc",{"2":{"793":1}}],["scannet数据集重新组织了一个embodiedocc",{"2":{"600":1}}],["scannet基准测试",{"0":{"793":1},"2":{"600":1,"793":1}}],["scannet上的实验结果表明",{"2":{"544":1}}],["scannetv2",{"2":{"349":2,"356":1}}],["scannet200",{"2":{"43":2,"51":1,"306":1}}],["scannet",{"0":{"886":1},"2":{"32":4,"38":4,"544":1,"793":4,"813":2,"886":9,"902":1,"979":1,"996":1}}],["scalability",{"2":{"864":1}}],["scalable",{"0":{"890":1},"2":{"515":2}}],["scalars",{"2":{"863":1}}],["scal+lfp",{"2":{"834":1}}],["scal+lgeo",{"2":{"834":1}}],["scal=lscal",{"2":{"794":2}}],["scalsem",{"2":{"766":2}}],["scalgeo",{"2":{"766":2}}],["scal​稍微降低了",{"2":{"928":1}}],["scal​则提高了几何",{"2":{"928":1}}],["scal​有助于语义",{"2":{"928":1}}],["scal​和lrell",{"2":{"834":1}}],["scal​+lfp​",{"2":{"834":1}}],["scal​+lgeo",{"2":{"834":1}}],["scal​=lscal​",{"2":{"794":2}}],["scal​",{"2":{"632":2}}],["scall",{"2":{"632":2,"834":1,"928":3}}],["scal",{"2":{"585":2,"632":3,"670":4,"750":4,"794":6,"834":3,"928":4}}],["scaling",{"0":{"912":1},"2":{"306":1,"912":1}}],["scales",{"2":{"616":1}}],["scale",{"2":{"277":1,"379":1,"584":1,"692":2,"922":1}}],["science",{"2":{"149":1}}],["scipt",{"2":{"66":1}}],["sce2drivex",{"2":{"128":1}}],["scenes",{"0":{"890":1},"2":{"949":1}}],["scene",{"0":{"515":1},"1":{"546":1,"579":1,"611":1,"640":1},"2":{"23":3,"94":1,"102":1,"125":1,"254":3,"323":2,"476":1,"508":1,"515":1,"537":1,"648":1,"884":1,"916":1,"989":1}}],["schwing等人",{"2":{"967":1}}],["schleich等人",{"2":{"930":1}}],["schops",{"2":{"588":1}}],["schimpl等人",{"2":{"419":1}}],["schedule",{"2":{"519":1}}],["scherer",{"2":{"189":1,"209":1}}],["scheme",{"0":{"75":1},"2":{"75":2,"729":1}}],["schöps等人",{"2":{"116":1}}],["scope",{"2":{"67":1}}],["scoreγ∇logp",{"2":{"513":1}}],["score+",{"2":{"513":1}}],["scores",{"2":{"321":1}}],["score是基于imagenet得到的",{"2":{"13":1}}],["score得分过于依赖分类器",{"2":{"13":1}}],["score不能反映过拟合",{"2":{"13":1}}],["score的估计往往是不准确的",{"0":{"267":1}}],["score的多样性检验有局限性",{"2":{"13":1}}],["score的问题",{"2":{"13":1}}],["score低的图片不一定差",{"2":{"13":1}}],["score高的图片不一定真实",{"2":{"13":1}}],["score敏感性问题",{"2":{"13":1}}],["score使用图片类别分类器来评估生成图片的质量",{"2":{"13":1}}],["score",{"0":{"13":1,"183":1,"235":1,"316":1},"1":{"203":1,"225":1,"245":1,"267":1,"291":1,"316":1,"342":1,"370":1,"398":1},"2":{"170":2,"183":1,"225":4,"235":3,"251":1,"316":2,"365":1,"513":2}}],["scribbles等应用任务",{"2":{"289":1}}],["scripts",{"2":{"120":1}}],["script>",{"2":{"57":1}}],["script",{"2":{"57":1}}],["screen的安装与使用方法",{"2":{"99":1}}],["screen",{"0":{"49":1,"59":1,"68":1,"77":1,"88":1,"99":1},"2":{"49":3,"59":1,"68":4,"88":2,"99":7}}],["screen安装与使用",{"0":{"42":1},"1":{"49":1,"59":1,"68":1,"77":1,"88":1,"99":1}}],["sup",{"2":{"1000":2}}],["superglue",{"2":{"698":1}}],["supervises",{"2":{"941":1}}],["supervised",{"2":{"366":1,"394":1,"410":2,"528":1,"715":2}}],["supervision",{"0":{"143":1},"2":{"135":1,"410":1,"668":2}}],["superpoints",{"2":{"384":1,"405":1}}],["superpoint",{"2":{"323":2,"349":5,"384":4,"405":4,"434":1}}],["super",{"2":{"32":1,"38":2,"174":1,"220":1,"333":1,"351":1,"382":1}}],["su等人",{"2":{"962":1}}],["success",{"2":{"806":2}}],["sucar",{"2":{"619":1}}],["such",{"2":{"17":2,"48":1}}],["sur",{"2":{"782":1}}],["surroundocc验证集上的三维占据预测性能",{"2":{"736":1}}],["surroundocc并没有引入人工注释",{"2":{"482":1}}],["surroundocc",{"0":{"710":1},"2":{"444":1,"482":1,"545":1,"652":2,"700":3,"710":1,"736":1,"749":1,"787":1,"850":1,"893":1,"899":1,"900":3,"922":1,"965":1,"997":1}}],["surfels",{"2":{"967":1}}],["surfel",{"2":{"556":1,"640":1}}],["surface",{"0":{"372":1,"400":1},"2":{"500":1,"790":2}}],["surf",{"2":{"189":1,"372":14}}],["submanifold",{"2":{"500":2}}],["subset",{"2":{"420":1}}],["substr",{"2":{"52":4}}],["substring",{"2":{"52":1}}],["subvidision的",{"2":{"400":1}}],["subfolder=",{"2":{"373":2}}],["subdivision",{"0":{"372":1,"400":1}}],["suggests",{"2":{"366":2}}],["sunny",{"2":{"258":1}}],["sualeh",{"2":{"209":1}}],["sudo",{"2":{"17":2,"24":6,"26":4,"33":2,"36":11,"40":1,"47":1,"66":2,"74":1,"76":4,"107":1,"120":5}}],["sumner等人",{"2":{"390":4}}],["summarized",{"2":{"365":1}}],["sum^k",{"2":{"153":1}}],["sum",{"2":{"5":2,"57":1,"137":2,"325":1,"342":1,"379":1,"390":5,"464":1,"532":1,"563":2,"595":2,"623":2,"647":2,"656":1,"660":1,"666":2,"672":1,"681":3,"693":2,"694":7,"696":1,"716":2,"738":2,"739":1,"741":1,"742":1,"749":1,"752":3,"766":1,"778":1,"794":7,"802":1,"807":1,"814":3,"844":1,"848":1,"863":2,"884":1,"915":1,"916":4,"950":2,"957":1,"985":4,"998":1}}],["sogdet开发了两个并发任务",{"2":{"1003":1}}],["som具有更高的层次性",{"2":{"636":1}}],["som中每个节点的特征是使用通道最大池从与该节点相关联的点特征中提取",{"2":{"636":1}}],["som",{"2":{"636":1}}],["softmax",{"2":{"632":1,"670":3,"681":2,"738":1,"766":1,"782":1,"863":1,"884":1}}],["softmax损失来监督网络训练",{"2":{"988":1}}],["softmax损失和尺度不变对数损失",{"2":{"988":1}}],["softmax损失",{"2":{"532":1,"585":1,"690":1,"750":1,"985":1}}],["soft",{"2":{"470":1}}],["solve",{"2":{"384":1}}],["solving",{"2":{"163":1}}],["sortvox",{"2":{"738":3}}],["sort",{"2":{"379":3,"929":2}}],["sorting",{"2":{"340":1}}],["sorted",{"2":{"315":1}}],["sota",{"2":{"334":2,"438":1,"503":1,"807":1,"827":5,"847":1,"865":4,"915":1,"952":1,"965":1}}],["sota模型运算量很",{"2":{"220":1}}],["sooner高的博客",{"2":{"183":1}}],["sousa",{"2":{"209":1}}],["souce",{"2":{"181":1}}],["sourabh",{"2":{"126":1}}],["sourced",{"2":{"120":1}}],["source=distribute",{"2":{"106":1}}],["sources",{"2":{"76":1}}],["sourcestring",{"2":{"52":1}}],["source",{"2":{"34":1,"87":2,"120":3,"152":1,"181":8}}],["soatto和chiuso",{"2":{"121":1}}],["song等人",{"2":{"967":1}}],["song",{"2":{"90":1,"183":2,"382":2}}],["sohu",{"2":{"31":1}}],["so",{"0":{"58":1},"1":{"67":1},"2":{"17":2,"107":3,"636":1}}],["specific",{"2":{"550":1}}],["sptm",{"2":{"525":1}}],["spconv8x",{"2":{"670":1}}],["spconv稀疏卷积",{"2":{"500":1}}],["spconv",{"0":{"500":1},"1":{"530":1,"561":1},"2":{"500":1}}],["sphnet",{"2":{"481":1}}],["spheral",{"2":{"481":1}}],["spiderconv",{"2":{"481":1}}],["spidercnn",{"2":{"481":1}}],["spred​与位置",{"2":{"429":1}}],["spred​",{"2":{"429":1}}],["spred​是网格",{"2":{"429":1}}],["spred​∈rn×n×n",{"2":{"429":1}}],["spreds",{"2":{"429":2}}],["spred∈rn×n×ns",{"2":{"429":1}}],["spformer的整体架构",{"2":{"377":1}}],["spformer",{"0":{"298":1,"323":1},"1":{"323":1,"349":2,"377":2,"405":2,"434":2},"2":{"215":1,"349":4,"384":1}}],["spm=1001",{"2":{"106":1}}],["spaces",{"2":{"292":2}}],["space上进行插值",{"2":{"221":1}}],["space",{"0":{"165":1,"227":1},"2":{"149":3,"165":1,"500":3}}],["sparsefusion",{"2":{"625":1}}],["sparseocc从历史帧中采样",{"2":{"957":1}}],["sparseocc结合了稀疏特征",{"2":{"922":1}}],["sparseocc",{"0":{"776":1},"2":{"482":1,"517":2,"776":1,"850":1,"922":1,"957":1,"998":1}}],["sparse",{"0":{"385":1,"412":1,"413":1},"2":{"306":1,"384":1,"423":1,"500":2,"589":2,"593":1,"715":1,"746":1,"776":1}}],["sparsead",{"2":{"114":1}}],["spark",{"2":{"12":1,"27":1,"98":1,"109":1,"131":1,"141":1}}],["spatial",{"0":{"472":1},"2":{"80":1,"94":1,"102":1,"173":1,"333":1,"378":1,"465":1,"500":1,"603":1}}],["sp",{"2":{"32":1}}],["spl",{"2":{"806":1}}],["splatnet",{"2":{"962":1}}],["splattering",{"2":{"698":1}}],["splatting",{"2":{"30":2,"516":1,"588":1}}],["splats",{"2":{"588":1}}],["splatad",{"2":{"474":1}}],["splat",{"2":{"423":1,"564":1,"585":2,"595":1,"655":1}}],["splitstring",{"2":{"52":1}}],["split",{"2":{"8":2,"52":1,"235":2,"623":1}}],["s",{"2":{"8":3,"11":1,"30":3,"63":2,"68":1,"93":2,"99":1,"104":3,"115":13,"130":4,"146":11,"161":5,"225":1,"235":7,"342":1,"344":2,"360":2,"372":12,"405":2,"419":1,"524":2,"532":9,"585":1,"618":1,"621":1,"647":2,"656":6,"660":8,"666":3,"693":10,"694":3,"705":9,"708":1,"716":8,"728":1,"731":1,"738":1,"753":1,"774":1,"780":3,"794":3,"795":1,"947":1,"950":2,"957":11}}],["sil",{"2":{"877":1}}],["sidewalk",{"2":{"790":2}}],["sidpac",{"2":{"437":1}}],["sidpac数据集是在研究生宿舍楼中使用视觉",{"2":{"437":1}}],["sis",{"2":{"656":1,"728":1}}],["siegwart",{"2":{"648":1}}],["six",{"2":{"571":1}}],["sinusoidal",{"2":{"549":1}}],["singapore",{"2":{"254":1}}],["singh",{"2":{"90":1}}],["single",{"0":{"857":1},"1":{"874":1,"891":1},"2":{"45":1,"384":1,"659":1,"715":1,"857":1}}],["si​",{"2":{"532":1,"656":1,"693":1,"728":1,"738":1}}],["si",{"2":{"532":1,"656":1,"693":1,"728":1,"738":1,"877":1}}],["si∈r3",{"2":{"532":1}}],["sizhe",{"2":{"387":1}}],["size为n的输入为例",{"2":{"184":1}}],["size=",{"2":{"124":1,"257":1,"351":1}}],["size",{"2":{"52":1,"73":2,"124":3,"136":1,"146":4,"184":1,"254":1,"257":3,"333":1,"519":1,"654":1,"659":2,"700":1,"741":1,"854":2,"904":2,"929":1}}],["siting",{"2":{"204":1}}],["site",{"2":{"64":1}}],["sift等特征子",{"2":{"305":1}}],["sift",{"2":{"189":1}}],["simonovsky等人",{"2":{"574":1}}],["simpleoccupancy",{"2":{"941":1,"985":1}}],["simplebev",{"2":{"678":1}}],["simpleclick",{"2":{"45":1}}],["simply",{"2":{"384":1}}],["simplified",{"2":{"351":1}}],["sim2^",{"2":{"111":1,"236":1}}],["simultaneous",{"0":{"155":1},"1":{"171":1,"189":1,"209":1},"2":{"90":1}}],["simlingo动作想象基准",{"2":{"447":1}}],["simlingo",{"2":{"82":1,"308":1,"334":1}}],["sim3>",{"2":{"67":2}}],["sim3",{"2":{"67":2}}],["similar",{"2":{"45":1,"707":1}}],["similarity",{"0":{"234":1,"255":1},"2":{"8":1}}],["sim",{"2":{"13":2,"111":2,"140":5,"188":1,"208":2,"236":2,"256":1,"280":5,"316":1}}],["sight",{"2":{"660":1,"875":1}}],["sigmoid",{"2":{"333":1,"434":1,"844":1}}],["sigma|",{"2":{"916":1}}],["sigma|^",{"2":{"681":1,"916":2}}],["sigmaς",{"2":{"656":1,"693":1}}],["sigma^",{"2":{"656":1,"681":2,"693":1,"738":1,"916":2}}],["sigma^2=",{"2":{"140":1,"280":1}}],["sigma^2",{"2":{"140":3,"251":2,"273":6,"280":3}}],["sigma",{"2":{"8":10,"20":6,"235":3,"251":3,"342":2,"532":6,"563":1,"623":3,"656":1,"693":2,"916":9,"957":4}}],["siggraph",{"2":{"275":1}}],["signed",{"2":{"31":3}}],["signal",{"2":{"5":1,"11":1,"366":1}}],["1×11",{"2":{"928":1}}],["1×10−4",{"2":{"677":1,"764":1}}],["1×10−41×10^",{"2":{"764":1}}],["1×10−41",{"2":{"677":1}}],["1∥mi​−v∥1​分别表示第",{"2":{"916":1}}],["1a",{"2":{"903":1}}],["1米",{"2":{"836":1}}],["1米到5",{"2":{"770":1}}],["1b",{"2":{"824":1,"903":1,"989":1}}],["1k训练即可取得84",{"2":{"824":1}}],["1毫秒",{"2":{"811":1}}],["1个序列",{"2":{"781":1}}],["1个空闲类别和1个未知类别",{"2":{"781":1}}],["1λ1​",{"2":{"750":1}}],["1γ=1",{"2":{"728":2}}],["1到1的范围内",{"2":{"638":1}}],["1到帧t的3d坐标对齐",{"2":{"550":1}}],["1∣preproj​−p1​∣",{"2":{"592":1}}],["1|",{"2":{"592":2}}],["1|p",{"2":{"592":1}}],["1st",{"2":{"571":1}}],["1的3d坐标首先通过姿态变换将变换为当前帧t的坐标系",{"2":{"583":1}}],["1的3d坐标首先通过姿态变换",{"2":{"550":1}}],["1的骨架的beta参数",{"2":{"419":1}}],["1m",{"2":{"449":1,"652":1,"736":1,"742":1}}],["1楼和3楼",{"2":{"437":1}}],["1⎤ᵀ",{"2":{"435":3}}],["1d1​",{"2":{"411":2}}],["1秒来更新每个关键帧的全局度量",{"2":{"816":1}}],["1秒",{"2":{"362":1}}],["1^t",{"2":{"357":1}}],["1有一个多帧网格",{"2":{"336":1}}],["1基于投影的网络",{"0":{"311":1},"1":{"337":1,"363":1}}],["1w1​",{"2":{"181":2}}],["1z1​",{"2":{"181":1,"221":1}}],["1°",{"2":{"173":1}}],["1~0",{"2":{"153":1}}],["1−mave",{"2":{"998":2}}],["1−ssim",{"2":{"988":2}}],["1−vi​",{"2":{"985":1}}],["1−vi",{"2":{"985":1}}],["1−v^i​",{"2":{"985":1}}],["1−v^i",{"2":{"985":1}}],["1−ipi​=c​",{"2":{"794":2}}],["1−ipi=c",{"2":{"794":2}}],["1−p^​i",{"2":{"794":1}}],["1−p^i",{"2":{"794":1}}],["1−pij​",{"2":{"666":2}}],["1−pij",{"2":{"666":2}}],["1−a^m",{"2":{"752":2}}],["1−am",{"2":{"752":4}}],["1−cos",{"2":{"694":1}}],["1−cos⁡",{"2":{"694":1}}],["1−yij​",{"2":{"666":1}}],["1−yij",{"2":{"666":1}}],["1−γ",{"2":{"513":2}}],["1−21​β",{"2":{"273":2}}],["1−12β",{"2":{"273":2}}],["1−α",{"2":{"681":6,"988":2}}],["1−αˉtxt+αˉt−1βt1−αˉt1αˉt",{"2":{"140":1,"280":1}}],["1−αˉtxt+αˉt−1βt1−αˉtx0",{"2":{"140":1,"280":1}}],["1−αˉt+αˉt−1x0βt1−αˉt=αt",{"2":{"140":1,"280":1}}],["1−αˉt−11−αˉtβt=αtxt",{"2":{"140":1,"280":1}}],["1−αˉt−1​",{"2":{"140":5,"280":5}}],["1−αˉt−1",{"2":{"140":5,"280":5}}],["1−αˉt​αt​−αˉt​+βt​​",{"2":{"140":1,"280":1}}],["1−αˉt​1−αˉt−1​​βt​=1−αˉt​αt​​xt​",{"2":{"140":1,"280":1}}],["1−αˉt​",{"2":{"140":2,"188":1,"280":2,"316":1}}],["1−αˉt",{"2":{"140":2,"188":1,"280":2,"316":1}}],["1−αtˉ",{"2":{"316":1}}],["1−αtαˉt−1=1−αˉt−11−αˉtβt",{"2":{"140":1,"280":1}}],["1−αt​ˉ​",{"2":{"316":1}}],["1−αt​",{"2":{"140":3,"280":3}}],["1−αt",{"2":{"140":2,"280":2}}],["1−βt=αt1",{"2":{"111":1,"236":1}}],["1节所述",{"2":{"855":1,"947":1}}],["1节详细介绍基准测试和指标",{"2":{"748":1}}],["1节中讨论的物理属性",{"2":{"716":1}}],["1节中量化",{"2":{"709":1}}],["1节中概述的设置",{"2":{"680":1}}],["1节中的目标参数",{"2":{"563":1}}],["1节中介绍用于评估的数据集",{"2":{"541":1}}],["1节阐述模型设计",{"2":{"551":1}}],["1节",{"0":{"310":1},"2":{"131":1,"285":1,"669":1,"796":1,"954":1}}],["169",{"2":{"1003":1}}],["16和32的下采样率的多尺度图像特征",{"2":{"822":1}}],["16m的间隔初始化高斯分布来表示一个新场景",{"2":{"813":1}}],["16个训练",{"2":{"793":1}}],["16个语义类别",{"2":{"781":1}}],["16​",{"2":{"609":1}}],["16×h",{"2":{"609":2}}],["16×16",{"2":{"278":2,"382":1}}],["16k",{"2":{"360":1}}],["168",{"2":{"195":1,"260":1,"277":1,"334":2,"534":1,"1003":1}}],["161​",{"2":{"768":1}}],["161",{"2":{"195":1,"277":1,"534":1,"1003":1}}],["16x16",{"2":{"181":1}}],["163",{"2":{"114":1,"277":1,"534":1,"1003":1}}],["164",{"2":{"114":1,"128":1,"1003":1}}],["162",{"2":{"114":1,"1003":1}}],["16",{"2":{"109":1,"114":1,"121":2,"172":1,"277":2,"278":1,"360":1,"476":1,"482":1,"534":2,"535":1,"547":1,"562":1,"564":1,"603":1,"609":3,"649":2,"652":1,"665":1,"670":1,"686":8,"693":3,"697":1,"709":2,"714":1,"738":1,"739":2,"749":1,"761":1,"768":1,"790":1,"842":2,"903":1,"947":1,"971":1}}],["166",{"2":{"82":1,"145":1,"277":1,"534":1,"948":1,"962":1,"1003":1}}],["1600900×1600",{"2":{"771":1}}],["1600×900",{"2":{"173":1,"545":1,"739":1,"965":1}}],["1600×1200",{"2":{"173":1}}],["160",{"2":{"82":1,"360":3,"417":1,"447":1,"1003":1}}],["167",{"2":{"82":1,"260":1,"417":1,"447":2,"478":1,"507":1,"996":1,"1003":1}}],["165",{"2":{"82":1,"176":1,"216":1,"283":1,"334":1,"1003":1}}],["189",{"2":{"948":1,"962":1,"1006":1}}],["188",{"2":{"948":1,"962":1,"1006":1}}],["186",{"2":{"948":1,"962":1,"1006":1}}],["185",{"2":{"948":1,"955":1,"1006":1}}],["18525734",{"2":{"276":1}}],["184",{"2":{"948":1,"955":1,"1006":1}}],["183",{"2":{"948":1,"955":1,"1006":1}}],["182",{"2":{"948":1,"955":1,"996":1,"1005":1}}],["181",{"2":{"948":1,"955":1,"1005":2}}],["1812",{"2":{"749":1,"781":1}}],["18b参数量取得了65",{"2":{"824":1}}],["18个语义类别和1个空闲类别",{"2":{"781":1}}],["18m",{"2":{"545":1,"965":1}}],["180°",{"2":{"917":1}}],["180",{"2":{"545":1,"965":1,"1005":2}}],["1805",{"2":{"84":1}}],["18k图",{"2":{"360":1}}],["187",{"2":{"277":1,"534":1,"948":1,"962":1,"1006":1}}],["18",{"2":{"82":2,"96":1,"121":1,"164":1,"172":1,"277":3,"334":2,"337":1,"360":4,"425":1,"467":1,"534":3,"603":1,"612":1,"627":2,"652":1,"665":1,"666":1,"676":1,"686":3,"709":1,"714":1,"739":2,"749":2,"764":1,"768":1,"803":3,"808":1,"949":1}}],["179",{"2":{"1005":2}}],["175",{"2":{"1004":1}}],["17582154",{"2":{"276":1}}],["174",{"2":{"1003":1}}],["1743",{"2":{"51":1}}],["173",{"2":{"1003":1}}],["17341",{"2":{"136":1}}],["172",{"2":{"1003":1}}],["171",{"2":{"996":1,"1003":1}}],["17118",{"2":{"776":1}}],["170",{"2":{"996":2,"1003":1}}],["1703",{"2":{"616":1}}],["177",{"2":{"996":1,"1005":1}}],["176",{"2":{"996":1,"1005":1}}],["178",{"2":{"277":2,"534":2,"947":1,"1005":1}}],["17",{"2":{"82":2,"109":1,"145":1,"172":1,"277":2,"283":1,"334":1,"337":1,"360":1,"366":1,"417":1,"421":1,"467":1,"492":1,"522":1,"534":1,"547":1,"566":1,"649":1,"665":1,"709":1,"714":1,"724":1,"739":3,"742":1,"782":1,"803":2,"917":1,"941":1,"971":2}}],["11×1",{"2":{"928":1}}],["11×1卷积",{"2":{"660":1}}],["113",{"2":{"195":1,"942":3,"950":2,"957":1}}],["116",{"2":{"145":1,"176":1,"768":1,"942":1,"957":1}}],["110",{"2":{"128":1,"308":1,"910":1}}],["11027",{"2":{"126":1}}],["118159",{"2":{"136":1}}],["118",{"2":{"128":1,"942":2,"950":2,"957":2,"998":1,"1001":3,"1004":1}}],["11926",{"2":{"671":1}}],["119",{"2":{"128":2,"176":1,"195":1}}],["114",{"2":{"114":1,"545":1,"942":1,"957":1,"965":1,"971":2,"985":2}}],["114885638",{"2":{"106":2}}],["117225213",{"2":{"220":1}}],["117",{"2":{"114":1,"942":1}}],["112",{"2":{"114":1,"942":1}}],["111",{"2":{"114":2,"780":1,"942":1}}],["115285213",{"2":{"106":3}}],["115",{"2":{"82":1,"360":3,"447":1,"942":1}}],["11",{"2":{"63":2,"82":1,"109":2,"121":1,"153":1,"190":1,"260":1,"277":4,"360":1,"380":1,"417":1,"421":1,"482":1,"486":1,"527":1,"532":1,"534":4,"535":1,"547":1,"563":1,"564":1,"603":1,"609":1,"617":1,"665":1,"670":2,"676":1,"686":4,"691":2,"693":1,"738":1,"739":1,"759":1,"787":1,"790":1,"803":1,"827":1,"828":1,"853":1,"899":1,"903":1,"910":1,"917":1,"928":1,"970":2,"976":1,"979":1,"989":1,"997":1,"1000":1}}],["15个和24个epoch",{"2":{"876":1}}],["15m",{"2":{"449":1}}],["155",{"2":{"216":1}}],["15215824",{"2":{"1008":1}}],["152",{"2":{"195":1,"277":1,"534":1,"988":1}}],["1533151603537558",{"2":{"476":1}}],["153",{"2":{"145":1,"283":1,"334":1,"360":1,"417":3,"447":1,"478":1,"507":1,"1000":1}}],["158",{"2":{"128":1,"1000":1}}],["159",{"2":{"128":1,"277":1,"534":1,"1001":2}}],["154",{"2":{"128":1,"1004":1}}],["150k",{"2":{"803":1}}],["150个序列",{"2":{"781":1}}],["150个场景中的6008个点云",{"2":{"534":1}}],["150个场景",{"2":{"534":1}}],["1500",{"2":{"489":1}}],["150",{"2":{"126":1,"128":1,"260":1,"277":1,"534":1,"652":1,"739":2,"749":2,"781":1,"988":1}}],["151",{"2":{"114":1,"988":1}}],["156",{"2":{"114":1,"277":2,"534":2,"1000":1}}],["157",{"2":{"82":1,"277":1,"1000":1}}],["15",{"2":{"51":2,"109":1,"121":2,"128":1,"157":1,"277":1,"421":1,"437":1,"476":1,"503":1,"534":1,"547":1,"566":1,"570":1,"617":1,"665":1,"670":1,"677":1,"686":4,"691":1,"703":1,"704":1,"739":1,"770":1,"771":1,"790":1,"792":1,"811":1,"812":1,"832":1,"901":1,"970":2,"973":1,"976":1,"979":1}}],["137个训练",{"2":{"793":1}}],["137",{"2":{"195":1,"886":1,"985":1}}],["1373",{"2":{"43":3}}],["130",{"2":{"195":1,"976":1}}],["135",{"2":{"195":1,"985":1}}],["1356",{"2":{"51":3}}],["13hz",{"2":{"173":1}}],["1399",{"2":{"652":1,"828":1}}],["13950hx",{"2":{"522":1}}],["139",{"2":{"173":1,"176":1,"277":1,"534":1,"985":1}}],["133",{"2":{"145":1,"176":1,"985":1}}],["131",{"2":{"128":1,"798":1,"976":1}}],["134",{"2":{"128":1,"176":1,"985":1}}],["132",{"2":{"114":1,"768":1,"985":1}}],["13",{"2":{"114":1,"121":2,"137":1,"190":1,"277":3,"421":1,"527":1,"534":2,"547":1,"564":1,"603":1,"609":1,"617":1,"655":1,"665":1,"670":1,"686":6,"691":1,"700":1,"709":2,"742":1,"790":1,"808":1,"853":1,"959":1,"995":1}}],["138",{"2":{"114":1,"985":1}}],["13条消息",{"2":{"96":1}}],["136",{"2":{"43":1,"128":1,"985":1}}],["196",{"2":{"962":1}}],["195",{"2":{"962":1}}],["194",{"2":{"955":1}}],["193",{"2":{"955":1}}],["192",{"2":{"955":1,"1006":2}}],["1920×1080",{"2":{"739":1}}],["1920×1280",{"2":{"739":1}}],["191",{"2":{"948":1,"968":1,"1006":1}}],["1911",{"2":{"84":1}}],["190",{"2":{"948":1,"968":1,"1006":1}}],["1903",{"2":{"126":1}}],["1978",{"2":{"961":1}}],["1978年",{"2":{"116":1}}],["197",{"2":{"277":1,"534":1,"962":1}}],["199",{"2":{"962":1}}],["1998b",{"2":{"648":2}}],["1998a",{"2":{"155":1}}],["1994年",{"2":{"310":1}}],["1996",{"2":{"274":1}}],["1992年",{"2":{"131":1,"147":1,"686":1}}],["1997",{"2":{"123":1,"274":1}}],["198",{"2":{"962":1}}],["1989",{"2":{"698":1}}],["1987年",{"2":{"310":1,"362":2,"390":1}}],["1985",{"2":{"123":1,"961":1}}],["1985年",{"2":{"116":1}}],["1981",{"2":{"123":1}}],["1984",{"2":{"123":1}}],["19th",{"2":{"57":1}}],["19",{"2":{"43":1,"114":1,"121":1,"277":1,"337":1,"352":1,"467":1,"471":1,"490":1,"512":1,"534":1,"564":1,"566":1,"570":1,"603":1,"612":1,"665":1,"686":1,"699":1,"709":3,"714":1,"739":1,"749":1,"785":1,"825":1,"839":1,"853":1,"893":1,"908":1,"947":1,"971":3}}],["14的结果包括在附录h中",{"2":{"431":1}}],["147",{"2":{"360":2,"997":1}}],["143",{"2":{"216":1,"283":1,"334":1,"360":1,"417":3,"507":1,"997":2}}],["142",{"2":{"176":1,"997":2}}],["146",{"2":{"176":1,"996":1,"997":1}}],["148",{"2":{"145":1,"176":1,"195":1,"283":1,"334":1,"478":1,"507":1,"988":1}}],["148536",{"2":{"136":1}}],["141818806",{"2":{"369":1}}],["141",{"2":{"145":1,"260":1,"277":1,"334":1,"534":1,"985":1}}],["1408376×1408",{"2":{"771":1}}],["140",{"2":{"126":3,"128":1,"985":1}}],["1449",{"2":{"853":1}}],["144000",{"2":{"792":1}}],["144",{"2":{"114":1,"997":1}}],["149帧和16个类别",{"2":{"757":1}}],["149",{"2":{"114":1,"277":1,"988":1}}],["145",{"2":{"114":1,"996":1,"997":1}}],["14",{"2":{"43":3,"109":2,"114":1,"121":1,"126":1,"153":3,"172":1,"277":2,"302":1,"421":1,"431":1,"482":1,"512":1,"527":1,"534":2,"535":1,"545":1,"566":2,"603":1,"609":1,"612":1,"617":1,"649":1,"665":1,"670":1,"686":3,"691":1,"693":1,"700":1,"746":1,"790":1,"867":1,"965":1,"970":2,"976":1}}],["121",{"2":{"195":1,"950":1}}],["12900k",{"2":{"431":1}}],["129",{"2":{"176":1,"970":1}}],["12hz",{"2":{"173":1,"211":2}}],["1241×376",{"2":{"900":1}}],["1249",{"2":{"652":1,"828":1}}],["124",{"2":{"145":1,"957":1}}],["126",{"2":{"128":1,"277":1,"534":1,"798":1,"957":1}}],["125",{"2":{"128":1,"957":1}}],["1200×1920",{"2":{"677":1,"828":1}}],["1200",{"2":{"333":1}}],["120",{"2":{"128":1,"942":2,"947":1,"957":1}}],["127405153",{"2":{"508":1}}],["127",{"2":{"114":1,"957":1,"985":2}}],["12709",{"2":{"84":1}}],["12",{"2":{"82":1,"109":1,"172":1,"211":1,"277":2,"421":2,"497":1,"534":2,"535":1,"564":1,"566":1,"603":2,"609":2,"617":1,"653":1,"665":1,"670":2,"686":7,"691":2,"709":2,"758":1,"779":1,"782":1,"790":1,"822":2,"841":1,"870":1,"910":1,"917":1,"923":1,"928":1,"970":2,"976":1,"979":1,"992":1}}],["1220×370",{"2":{"853":1}}],["1226×370",{"2":{"853":1}}],["122",{"2":{"67":2,"128":1,"277":1,"534":1,"950":1}}],["122294045",{"2":{"41":1}}],["123",{"2":{"57":1,"82":1,"950":1}}],["12n−1−1",{"2":{"57":1}}],["12800",{"2":{"771":1,"792":1}}],["128×128×16",{"2":{"853":1}}],["128×128",{"2":{"321":1,"382":1}}],["128",{"2":{"43":2,"51":1,"145":1,"700":1,"957":1,"985":2}}],["12b−1",{"2":{"8":1}}],["1l",{"2":{"8":1}}],["1=",{"2":{"8":1}}],["10−4",{"2":{"853":2}}],["10−410^",{"2":{"853":2}}],["10−4∼2−2",{"2":{"111":2,"236":2}}],["10hz",{"2":{"739":1,"828":1}}],["10节所示",{"2":{"686":1}}],["10节定性地展示了kimera在我们收集的真实数据集上的性能",{"2":{"541":1}}],["10^",{"2":{"677":2,"686":3,"771":1,"867":1}}],["10m",{"2":{"480":1,"652":4,"828":4}}],["104",{"2":{"277":1,"308":1,"534":1,"910":1}}],["103",{"2":{"195":1,"970":2,"976":1,"985":1,"1000":1}}],["10305v1",{"2":{"23":1}}],["101和swintransformer",{"2":{"791":1}}],["101",{"2":{"195":1,"686":1,"947":1}}],["1080",{"2":{"173":1}}],["108",{"2":{"145":1,"910":2,"985":1,"1003":1}}],["10685",{"2":{"514":1}}],["106",{"2":{"114":1,"277":2,"534":2,"910":1}}],["10752",{"2":{"205":1}}],["107",{"2":{"103":1,"910":3}}],["105205326",{"2":{"351":1}}],["105",{"2":{"82":2,"176":1,"308":1,"334":1,"417":2,"447":1,"507":2,"910":1}}],["10242",{"2":{"552":1}}],["1024的长度只能生成32",{"2":{"343":1}}],["1024尺寸的噪声",{"2":{"205":1}}],["1024",{"2":{"205":3}}],["1024x1024",{"2":{"181":1}}],["102",{"2":{"82":1,"128":1,"195":1,"260":1,"996":1}}],["100191",{"2":{"608":1}}],["1000个场景",{"2":{"997":1}}],["1000下完成",{"2":{"467":1}}],["1000段20秒真实世界片段",{"2":{"360":1}}],["1000",{"2":{"126":3,"157":1,"467":1,"652":1,"739":1,"749":1}}],["100",{"2":{"82":1,"128":1,"129":1,"173":1,"254":1,"277":3,"333":8,"425":1,"437":1,"534":3,"681":1,"686":1,"782":1,"803":1,"916":1,"970":2,"976":1}}],["1006435",{"2":{"11":1}}],["109",{"2":{"82":1,"910":1,"947":1}}],["10",{"0":{"855":1,"872":1,"889":1},"1":{"872":1,"889":1},"2":{"5":2,"57":1,"109":1,"121":1,"172":1,"176":1,"223":1,"261":2,"277":1,"302":1,"360":1,"418":2,"421":1,"495":1,"527":1,"534":1,"535":2,"548":1,"564":1,"566":1,"603":2,"609":1,"617":1,"641":1,"643":1,"665":1,"667":1,"670":1,"677":1,"686":5,"693":1,"700":1,"744":1,"759":1,"771":2,"790":1,"791":1,"800":1,"803":1,"808":1,"828":1,"853":1,"867":1,"888":2,"899":2,"931":1,"942":1,"957":1,"971":1,"979":1,"982":2,"985":1,"989":2,"997":1,"998":1,"1003":2}}],["1",{"0":{"49":1,"82":1,"90":1,"103":1,"109":1,"110":1,"111":1,"116":1,"123":2,"139":1,"162":1,"171":1,"176":1,"236":1,"241":1,"252":1,"260":1,"337":2,"350":1,"357":1,"363":1,"376":1,"417":1,"420":1,"421":1,"433":1,"444":1,"464":1,"476":1,"495":1,"504":2,"520":1,"524":1,"532":1,"534":1,"535":1,"547":1,"567":1,"570":1,"572":1,"576":1,"588":1,"600":1,"605":1,"612":1,"626":1,"627":1,"639":1,"652":1,"654":2,"656":1,"660":1,"662":1,"665":1,"673":1,"679":1,"682":1,"693":1,"698":1,"709":1,"712":1,"734":1,"736":1,"743":1,"747":1,"749":1,"756":2,"759":1,"770":1,"781":1,"793":1,"794":1,"806":1,"821":1,"830":1,"839":1,"857":1,"870":1,"872":1,"894":1,"897":1,"899":1,"903":1,"908":1,"910":2,"923":1,"930":1,"942":1,"948":1,"955":2,"961":1,"962":1,"968":1,"970":1,"974":1,"978":1,"985":1,"987":1,"989":1,"994":1,"997":2,"998":1,"1000":1,"1003":1},"1":{"123":1,"131":1,"139":1,"385":1,"413":1,"442":1,"472":1,"504":1,"534":1,"605":1,"654":1,"667":1,"679":1,"691":1,"702":2,"714":1,"756":1,"777":3,"798":3,"818":3,"838":3,"857":1,"874":2,"891":2,"910":1,"923":1,"955":1,"962":1,"968":1,"974":1,"979":1,"997":1,"998":1},"2":{"5":3,"8":3,"11":1,"13":1,"15":1,"17":1,"20":3,"31":9,"52":2,"57":10,"66":2,"74":1,"93":1,"104":4,"106":1,"109":1,"111":15,"115":4,"120":2,"121":1,"124":3,"126":1,"128":1,"129":1,"130":3,"132":3,"136":6,"137":3,"140":94,"146":2,"153":6,"155":1,"161":3,"171":1,"173":8,"175":2,"188":3,"196":1,"208":10,"221":4,"225":3,"231":1,"236":15,"257":3,"261":1,"265":3,"273":15,"277":10,"280":94,"301":1,"305":1,"306":1,"312":1,"316":3,"321":4,"324":1,"325":2,"333":19,"334":7,"349":1,"351":8,"355":2,"357":4,"360":2,"366":1,"378":1,"379":2,"382":1,"390":10,"394":1,"405":1,"417":1,"418":1,"419":2,"436":1,"437":3,"444":2,"455":2,"458":21,"464":4,"465":1,"466":1,"467":2,"470":3,"503":2,"504":4,"512":1,"513":1,"520":1,"530":1,"532":7,"534":12,"552":1,"556":1,"561":7,"562":3,"563":8,"570":4,"571":1,"572":2,"582":1,"590":4,"592":2,"595":2,"603":1,"605":1,"609":4,"621":2,"623":8,"628":1,"632":5,"633":2,"641":1,"647":1,"649":1,"652":6,"656":2,"659":1,"660":9,"665":2,"666":6,"667":1,"670":3,"681":11,"682":4,"686":9,"693":8,"694":2,"698":1,"700":4,"703":1,"705":1,"709":1,"712":19,"714":1,"716":4,"724":2,"728":1,"729":1,"730":3,"738":3,"739":2,"742":1,"744":1,"746":6,"749":10,"750":1,"752":3,"759":1,"761":2,"766":2,"768":3,"770":1,"773":1,"778":1,"779":1,"780":9,"781":1,"782":1,"790":1,"791":3,"792":1,"794":4,"799":1,"802":1,"803":1,"807":1,"808":1,"811":6,"823":3,"824":2,"835":1,"840":1,"844":1,"848":1,"853":13,"854":1,"863":1,"866":3,"867":1,"884":3,"888":4,"893":4,"900":1,"903":6,"904":2,"908":1,"910":1,"915":1,"916":13,"917":2,"928":12,"936":1,"945":1,"947":6,"950":3,"957":2,"976":1,"982":3,"985":4,"988":4,"989":3,"992":5,"996":1,"998":6,"1000":1,"1003":1}}],["j|",{"2":{"916":1}}],["j​​",{"2":{"916":1}}],["j​=∣σij​∣∣σi​∣∣σj​∣​​exp",{"2":{"916":1}}],["j​=",{"2":{"153":1}}],["jeffwang987",{"2":{"687":1}}],["jetson",{"2":{"605":1,"836":1}}],["jenkins",{"2":{"510":1}}],["jensfelt",{"2":{"209":2,"648":1}}],["j∑​dfa",{"2":{"595":1}}],["jdfa",{"2":{"595":1}}],["just",{"2":{"496":1}}],["jun",{"2":{"62":1}}],["jpg",{"2":{"476":1}}],["jpeg",{"2":{"120":1,"173":1}}],["johnson等人",{"2":{"961":2}}],["joho等人",{"2":{"939":1}}],["joint",{"2":{"826":1}}],["join",{"2":{"504":2,"534":1}}],["jose",{"2":{"458":1}}],["journal=",{"2":{"126":1}}],["jiajun",{"2":{"477":1}}],["jiangyong",{"2":{"477":1}}],["jiangkun",{"2":{"395":1}}],["jiang等人",{"2":{"116":1,"961":1}}],["jiwoon",{"2":{"410":1}}],["jimenez",{"2":{"390":1}}],["j=∣σi∣∣σj∣∣σij∣exp⁡",{"2":{"916":1}}],["j=1",{"2":{"153":3,"390":1,"464":6,"681":1,"950":1}}],["j=",{"2":{"153":2}}],["j=0ϕ",{"2":{"153":1}}],["j=0",{"2":{"5":1,"153":2}}],["js3c",{"2":{"978":4,"989":2}}],["js3cnetrgb^",{"2":{"870":2}}],["js3cnet",{"2":{"870":1}}],["js",{"2":{"153":2}}],["json",{"2":{"32":4,"38":4,"327":6,"476":13,"534":1}}],["jx~j​",{"2":{"153":1}}],["jaritz等人",{"2":{"968":1}}],["jatavallabhula",{"2":{"556":1,"588":1}}],["jatavallabhula等人",{"2":{"121":1}}],["janzen",{"2":{"525":1}}],["jan",{"2":{"458":1}}],["james",{"2":{"387":1}}],["java",{"2":{"196":3}}],["java教程",{"2":{"196":6}}],["javascript",{"2":{"57":1}}],["j4",{"2":{"36":1,"120":1}}],["j",{"0":{"965":1},"2":{"5":6,"153":4,"171":4,"390":3,"435":1,"464":4,"563":6,"579":1,"595":1,"666":3,"681":2,"741":12,"916":8}}],["ik",{"2":{"976":2}}],["i|",{"2":{"916":1}}],["i|x",{"2":{"681":2}}],["i是伊万斯括号",{"2":{"794":1}}],["iw",{"2":{"752":1}}],["i∑​",{"2":{"752":1}}],["i2​",{"2":{"712":1}}],["i2",{"2":{"712":1}}],["i1​",{"2":{"712":1}}],["i1",{"2":{"712":1,"976":2}}],["i​∑i​",{"2":{"752":1}}],["i​loga^m",{"2":{"752":1}}],["i​",{"2":{"676":4,"752":4,"957":3}}],["iai​和语义",{"2":{"656":1}}],["i∈",{"2":{"563":2}}],["i0i",{"2":{"464":1}}],["i9",{"2":{"431":1,"522":1}}],["iαi​",{"2":{"400":2}}],["iαˉt​=∏i=1t​αi​",{"2":{"111":1,"236":1}}],["i3",{"2":{"390":2}}],["igi​使用其均值",{"2":{"656":1}}],["igi​",{"2":{"532":1,"681":1}}],["ig~​il​=gl​−gi​",{"2":{"390":1}}],["ignore",{"2":{"27":1,"702":9,"790":12}}],["idris",{"2":{"960":1}}],["idx",{"2":{"651":5}}],["identity",{"2":{"384":1}}],["ids送入text",{"2":{"373":1}}],["ids",{"2":{"373":4}}],["idi​",{"2":{"355":1,"411":1}}],["iδi",{"2":{"268":1}}],["ilharco",{"2":{"806":1}}],["ilog⁡a^m",{"2":{"752":1}}],["il仍为vla4ad主力",{"2":{"417":1}}],["il",{"2":{"390":4,"417":1}}],["ilvr",{"0":{"266":1},"1":{"289":1},"2":{"264":1,"266":1,"289":1}}],["illustrated",{"2":{"518":1}}],["illustration",{"2":{"315":1,"616":1,"729":1}}],["ill",{"2":{"220":1}}],["ieee",{"2":{"256":1}}],["ieeexplore",{"2":{"256":1}}],["ic^",{"2":{"985":1}}],["ic",{"2":{"985":2}}],["icra",{"2":{"906":1,"1005":1}}],["ici​",{"2":{"728":1}}],["ici​来描述一个局部区域",{"2":{"656":1}}],["ica",{"2":{"716":4}}],["ic~i​分别表示点",{"2":{"681":1}}],["iccv",{"2":{"394":1,"439":1,"616":1,"671":1,"914":1}}],["iccv2019",{"2":{"243":1}}],["iccv2021",{"0":{"96":1},"2":{"96":1}}],["iclr",{"2":{"287":1}}],["icp",{"2":{"189":1}}],["ioi​",{"2":{"728":1}}],["iou和miou分数更高",{"2":{"1000":1}}],["iou分数",{"2":{"1000":1}}],["iou评估了几何占用感知的性能",{"2":{"1000":1}}],["iou↑",{"2":{"971":2}}],["iou=tp=c0​​+fp=c0​​+fn=c0​​tp=c0​​​",{"2":{"848":1}}],["iou=tp≠c0tp≠c0+fp≠c0+fn≠c0",{"2":{"848":1}}],["iou=tp+fp+fntp​",{"2":{"807":1,"998":1}}],["iou=tptp+fp+fn",{"2":{"807":1,"998":1}}],["iou=tpo​+fpo​+fno​tpo​​",{"2":{"778":1}}],["iou=tpotpo+fpo+fnoiou=",{"2":{"778":1}}],["iou=tpc0​​+fpc0​​+fnc0​​tpc0​​​",{"2":{"749":1,"802":1}}],["iou=tpc0tpc0+fpc0+fnc0",{"2":{"749":1,"802":1}}],["iou被定义为忽略它们的语义类别的占据体素的交并比",{"2":{"736":1}}],["iou",{"2":{"434":2,"447":1,"677":1,"700":4,"749":2,"778":5,"802":2,"803":1,"807":3,"826":4,"827":2,"848":3,"853":3,"903":2,"915":3,"917":3,"928":6,"931":1,"985":1,"998":2}}],["iou至少为",{"2":{"206":1}}],["io",{"2":{"175":1,"247":1,"275":1,"382":1,"387":1,"514":1}}],["iostream>",{"2":{"63":1,"93":1,"104":1,"115":1,"130":1,"146":1,"161":1,"196":1}}],["izatt和tedrake",{"2":{"172":1}}],["ixi​只是节点",{"2":{"390":1}}],["ixi​和",{"2":{"390":1}}],["ixi​",{"2":{"153":1}}],["ix~i​",{"2":{"153":1}}],["ijyi​j",{"2":{"666":1}}],["ijpi​j",{"2":{"666":1}}],["ij",{"2":{"153":2,"171":6,"390":2,"595":7,"666":7,"741":2,"916":3,"950":7}}],["i+fn",{"2":{"848":1}}],["i+fp",{"2":{"848":1}}],["i++",{"2":{"146":1,"929":1}}],["i+1",{"2":{"57":1,"225":1}}],["ivi",{"2":{"372":1,"400":1}}],["ivi​",{"2":{"355":1}}],["ivlr里实际用了低通滤波和下上采样来抽取出低频信息来影响后向去噪过程",{"2":{"287":1}}],["ivlr",{"0":{"264":1}}],["iv",{"0":{"326":1,"717":1,"722":1,"849":1},"1":{"352":1,"380":1,"739":1,"744":1,"761":1,"766":1,"782":1,"787":1,"803":1,"807":1,"823":1,"827":1,"843":1,"847":1,"865":1,"867":1,"882":1,"884":1,"900":1,"915":1,"927":1,"936":1,"944":1,"952":1,"959":1,"965":1,"971":1},"2":{"125":1,"131":1,"147":1,"162":1,"285":1,"320":1,"503":1,"552":1,"803":1,"865":1,"936":1}}],["ib将计算任务相关聚类",{"2":{"137":1}}],["ib",{"2":{"98":1,"109":1,"121":3,"137":1,"153":3,"271":1}}],["ipi​是体素iii的真实类别",{"2":{"794":1}}],["ipv4",{"2":{"78":1}}],["ipc=host",{"2":{"11":2}}],["ii∈r3×h×w∣i=1",{"2":{"693":1}}],["ii​∈r3×h×w∣i=1",{"2":{"693":1}}],["ii​",{"2":{"464":1,"532":1,"656":1}}],["iida",{"2":{"90":1}}],["ii",{"0":{"156":1,"468":1,"487":1,"533":1},"1":{"172":1,"190":1,"497":1,"517":1,"527":1,"548":1,"564":1,"596":1,"625":1,"653":1,"678":1},"2":{"72":1,"82":1,"125":2,"131":2,"141":2,"147":1,"162":1,"178":2,"195":1,"197":1,"218":1,"240":1,"285":2,"320":1,"336":1,"362":1,"380":2,"388":1,"390":1,"408":1,"419":1,"437":1,"447":1,"464":1,"480":1,"503":1,"532":1,"552":1,"656":1,"686":1,"803":1,"827":1,"836":1,"905":1,"927":2,"961":1,"998":1,"1000":2}}],["iii遍历关系矩阵的所有元素",{"2":{"752":1}}],["iii个高斯的均值",{"2":{"916":1}}],["iii个高斯分布的条件概率以及经过",{"2":{"681":1}}],["iii个高斯分布的后验概率",{"2":{"681":1}}],["iii个语义高斯对",{"2":{"656":1}}],["iii",{"0":{"210":1,"558":1,"581":1,"701":1},"1":{"232":1,"253":1,"276":1,"301":1,"590":1,"613":1,"621":1,"642":1,"649":1,"670":1,"676":1,"694":1,"699":1,"724":1,"746":1,"768":1,"789":1,"809":1,"829":1},"2":{"5":1,"72":1,"82":1,"125":2,"131":2,"141":1,"147":1,"162":1,"178":2,"195":1,"197":1,"218":1,"240":1,"285":2,"320":1,"372":1,"380":1,"419":1,"437":1,"447":1,"464":2,"503":1,"552":1,"642":2,"676":1,"686":1,"738":2,"803":1,"827":1,"915":1,"927":1,"942":1,"961":1,"976":1,"988":1,"998":1}}],["i=",{"2":{"532":2,"656":1,"693":2,"712":2}}],["i=t",{"2":{"273":1}}],["i=1r​作为监督来优化我们的初始化模块",{"2":{"704":1}}],["i=1r​",{"2":{"704":1}}],["i=1rl",{"2":{"704":2}}],["i=1m​",{"2":{"676":3}}],["i=1m",{"2":{"676":3}}],["i=1p​解释为其周围空间被占用的概率",{"2":{"681":1}}],["i=1p​",{"2":{"656":1}}],["i=1pg",{"2":{"656":1,"681":1}}],["i=1ni",{"2":{"656":1}}],["i=1nf​​",{"2":{"563":1}}],["i=1nf",{"2":{"563":1}}],["i=1ng​​",{"2":{"532":1,"563":2}}],["i=1ng",{"2":{"532":1,"563":2}}],["i=1np​​",{"2":{"532":1}}],["i=1np",{"2":{"532":1}}],["i=1nc​​",{"2":{"532":1}}],["i=1nc",{"2":{"532":1}}],["i=1n​预测体素级语义分割结果",{"2":{"656":1}}],["i=1n​",{"2":{"464":1}}],["i=1n",{"2":{"464":1}}],["i=1∑l​λ",{"2":{"342":1}}],["i=1t​→β",{"2":{"273":1}}],["i=1t​=1−tβˉ​t+1​​​xt​+tβˉ​t+1​​​ε",{"2":{"273":1}}],["i=1t​",{"2":{"273":1}}],["i=1t→β",{"2":{"273":1}}],["i=1txt+1=1−βˉt+1txt+βˉt+1tεt→∞",{"2":{"273":1}}],["i=1t",{"2":{"273":1}}],["i=1",{"2":{"57":1,"111":1,"236":1,"273":3,"342":1,"372":6,"464":2,"532":4,"563":3,"656":3,"676":3,"681":4,"693":2,"704":2,"705":2,"716":1,"728":2,"738":1,"807":1,"915":1,"916":3,"950":1,"998":1}}],["i=0",{"2":{"5":1,"146":1,"225":2,"390":1,"647":1,"985":2}}],["ifni​",{"2":{"915":1}}],["ifpi​",{"2":{"915":1}}],["if~|x",{"2":{"132":1}}],["if",{"2":{"52":2,"115":1,"132":2,"153":9,"174":1,"666":2,"795":1,"957":4}}],["if=",{"2":{"26":1}}],["iri​",{"2":{"656":1,"728":1}}],["ir",{"2":{"57":1}}],["ir⋯",{"2":{"57":2}}],["iros",{"2":{"31":1}}],["irmvlab",{"2":{"30":1}}],["imonoi",{"2":{"705":1}}],["imono∈rh×w×3i",{"2":{"682":1}}],["imono​∈rh×w×3",{"2":{"682":1}}],["imono​",{"2":{"682":1,"705":1}}],["imono",{"2":{"682":1}}],["imov3d",{"2":{"23":2}}],["img",{"2":{"621":5}}],["imgn​",{"2":{"621":1}}],["imgn",{"2":{"621":1}}],["img3​",{"2":{"621":1}}],["img3",{"2":{"621":1}}],["img2​",{"2":{"621":1}}],["img2",{"2":{"621":1}}],["img1​",{"2":{"621":1}}],["img1",{"2":{"621":1}}],["img=",{"2":{"621":2}}],["imi​",{"2":{"390":2,"656":1,"728":1,"916":1}}],["imu前端需要大约40",{"2":{"816":1}}],["imu预积分误差",{"2":{"510":1}}],["imu以跟踪运动",{"2":{"176":1}}],["imu",{"2":{"126":1,"171":1,"173":2,"189":1,"285":4,"605":1,"652":2,"749":1}}],["image2image",{"0":{"491":1}}],["image的条件下能够生成高质量的图片样本",{"2":{"289":1}}],["imagenet",{"2":{"743":2,"771":1}}],["imagenet数据训练效果一致",{"2":{"167":1}}],["imagenav",{"2":{"139":1,"588":1}}],["image一起concat成6",{"2":{"106":1}}],["image",{"0":{"65":1,"75":1,"117":1,"244":1,"365":1,"370":1,"422":1,"521":1},"2":{"34":3,"45":1,"120":3,"136":4,"139":1,"175":4,"184":3,"185":1,"201":2,"204":1,"205":1,"268":1,"287":1,"289":1,"317":1,"382":2,"399":1,"405":1,"410":1,"422":1,"428":1,"440":1,"452":2,"469":1,"659":4}}],["images基于隐式分类器的文生图大模型classifier",{"2":{"201":1}}],["images",{"0":{"452":1},"2":{"23":1,"135":1,"184":1,"439":1,"452":2,"496":1,"498":1}}],["impromptu",{"2":{"82":1,"334":3,"360":2,"478":1}}],["implicit",{"0":{"721":1},"1":{"743":1,"765":1},"2":{"30":1,"80":1,"203":1,"721":1}}],["imports",{"2":{"17":1}}],["import",{"2":{"17":2,"27":1,"57":3,"333":3,"373":1}}],["importerror",{"2":{"17":2}}],["innmann等人",{"2":{"967":1}}],["inner",{"2":{"379":1}}],["in​",{"2":{"712":1}}],["indiv",{"2":{"916":5}}],["indices",{"2":{"651":2}}],["indoor",{"0":{"890":1},"2":{"906":1}}],["index=6",{"2":{"106":1}}],["index",{"2":{"47":1,"52":1,"254":1,"790":1}}],["in中对应了v=0",{"2":{"530":1}}],["in表示着activate输入的标志",{"2":{"530":1}}],["in这张输入哈希表",{"2":{"530":1}}],["inversematrixvt3d",{"2":{"545":1,"867":3,"875":1,"965":1}}],["inverse",{"2":{"496":1,"654":2,"806":1}}],["invariance",{"2":{"379":1}}],["invariant",{"0":{"325":1},"1":{"351":1},"2":{"379":1}}],["invalid",{"2":{"99":2}}],["inpainting",{"0":{"312":1,"370":1,"521":1},"2":{"201":1,"312":1}}],["inputs",{"2":{"333":5,"351":2,"384":1}}],["input",{"0":{"318":1},"2":{"315":1,"333":1,"373":3,"405":1,"452":3,"500":1,"659":2,"741":1}}],["input输入模型",{"2":{"106":1}}],["input送进分割模型",{"2":{"54":1}}],["inertial",{"2":{"189":1}}],["inmeta",{"2":{"135":1}}],["inactive",{"2":{"57":1}}],["intelrealsense",{"2":{"605":1}}],["integration",{"2":{"390":1}}],["intern",{"2":{"764":1}}],["internimage",{"0":{"584":1},"1":{"616":1,"645":1,"672":1,"696":1,"719":1,"741":1,"763":1,"784":1,"804":1,"824":1,"844":1,"863":1,"880":1,"896":1,"912":1,"925":1},"2":{"584":2,"620":1,"824":5}}],["internvit",{"2":{"417":1}}],["internvl2",{"2":{"334":1}}],["inter",{"0":{"255":1},"2":{"623":2}}],["interpolation",{"2":{"221":1,"594":1}}],["interpolations",{"0":{"165":1},"2":{"165":1}}],["interpreter",{"0":{"41":1},"2":{"41":1}}],["interaction",{"2":{"75":1,"594":1}}],["interactive",{"0":{"54":1,"65":1,"75":1,"84":1,"117":1,"132":1},"2":{"54":1,"75":1,"84":3,"96":1,"106":3,"117":1}}],["interface",{"2":{"57":1}}],["into",{"2":{"315":1,"366":1,"741":1}}],["intrinsic",{"0":{"826":1},"2":{"254":1,"597":1}}],["intra",{"0":{"234":1}}],["introducing",{"2":{"863":1}}],["intro",{"0":{"205":1,"421":1,"444":1},"1":{"227":1,"248":1}}],["int>",{"2":{"93":4,"104":2,"115":2,"130":3,"146":1,"161":2,"254":10,"261":6,"284":1,"309":1,"335":1,"361":1,"389":1,"418":1,"571":1,"654":2,"685":1,"708":1,"888":7,"929":1}}],["int",{"2":{"52":2,"63":1,"93":4,"104":2,"115":1,"130":2,"146":4,"161":2,"196":1,"235":2,"685":1,"835":2,"888":1,"904":2,"929":3}}],["in",{"0":{"65":1,"132":1},"2":{"45":1,"64":1,"67":1,"111":1,"137":2,"149":1,"153":3,"158":1,"208":2,"221":1,"236":1,"273":1,"278":1,"306":1,"315":2,"327":2,"351":5,"366":2,"379":1,"384":2,"390":4,"405":1,"412":1,"496":3,"500":3,"518":2,"532":6,"563":6,"590":1,"609":3,"616":2,"621":10,"647":1,"649":1,"651":1,"656":1,"659":4,"660":1,"672":1,"676":1,"682":5,"693":9,"696":1,"705":7,"712":7,"716":2,"724":1,"729":6,"738":1,"741":1,"746":9,"749":1,"752":3,"780":2,"802":1,"814":1,"848":1,"910":3,"914":1,"916":3,"957":2,"989":1}}],["infin",{"2":{"273":1}}],["infty",{"2":{"235":2}}],["infer",{"0":{"204":1}}],["inference",{"2":{"27":4,"519":1,"593":2,"700":1}}],["infonce",{"2":{"223":2}}],["information",{"2":{"98":1,"137":1,"153":3,"271":1,"384":1,"496":2,"518":1,"826":1}}],["info",{"2":{"43":3,"51":2,"120":1,"850":1}}],["infos",{"2":{"32":1,"38":1}}],["instructnav",{"2":{"765":1}}],["institute",{"2":{"387":1}}],["instance",{"2":{"32":3,"38":1,"149":2,"254":3,"323":2,"384":5,"476":1,"654":1}}],["instances",{"2":{"32":2,"38":2}}],["install",{"2":{"17":2,"27":5,"36":7,"40":1,"47":1,"59":1,"66":1,"69":3,"74":1,"76":1,"78":1,"87":1,"107":1,"120":2}}],["insight",{"2":{"158":1}}],["inserting",{"2":{"571":1}}],["insert",{"0":{"571":1},"2":{"104":6,"571":11,"904":3}}],["ins",{"2":{"32":1,"441":3}}],["increase",{"2":{"496":1}}],["incremental",{"2":{"31":1}}],["include",{"2":{"63":2,"67":3,"73":1,"93":2,"104":2,"115":2,"130":2,"146":2,"161":2,"196":3,"239":1,"888":1,"929":2}}],["inception",{"0":{"13":1,"20":1},"2":{"13":9,"20":1,"574":1}}],["initializer",{"2":{"571":1}}],["initialized",{"2":{"64":1}}],["initial",{"0":{"344":1},"2":{"198":1}}],["init的工作",{"2":{"87":1}}],["init和",{"2":{"87":1}}],["initramfs",{"2":{"66":1}}],["init",{"2":{"17":1,"27":1,"174":2,"333":2,"351":2,"704":1,"910":4}}],["it++",{"2":{"929":1}}],["itpi​",{"2":{"915":1}}],["itn​",{"2":{"780":2}}],["itn",{"2":{"780":2}}],["it1​",{"2":{"780":2}}],["it1",{"2":{"780":2}}],["it​∈rh×w×3",{"2":{"682":1}}],["it​",{"2":{"682":1,"728":1}}],["it∈rh×w×3",{"2":{"682":1}}],["iter2++",{"2":{"130":1}}],["iter2",{"2":{"130":2}}],["iter2=s",{"2":{"130":1}}],["iter1++",{"2":{"130":1}}],["iter1",{"2":{"130":2}}],["iter1=s",{"2":{"130":1}}],["iter++",{"2":{"115":1}}],["iter==5",{"2":{"115":1}}],["iter=s",{"2":{"115":1}}],["iter",{"2":{"104":3,"115":4,"196":7,"571":1}}],["iterations",{"2":{"328":1}}],["iterative",{"0":{"328":1},"2":{"106":4,"168":1,"175":1,"382":3}}],["iteratively",{"2":{"84":2}}],["iterator",{"2":{"104":10,"115":8,"130":7,"161":2,"196":1,"571":3,"685":1,"904":8,"929":1}}],["its",{"2":{"23":1,"67":1}}],["it",{"2":{"11":1,"60":1,"64":1,"135":2,"273":1,"327":2,"434":1,"496":1,"500":2,"659":1,"682":1,"728":1,"904":4,"929":4}}],["isi​",{"2":{"656":1,"728":1}}],["iso的核心设计围绕从二维到三维空间的特征转换展开",{"2":{"544":1}}],["iso利用预训练深度模型的优势",{"2":{"544":1}}],["iso",{"0":{"544":1},"2":{"890":1}}],["is值越大越好",{"2":{"13":1}}],["is是对生成图片清晰度和多样性的衡量",{"2":{"13":1}}],["is",{"2":{"11":2,"13":3,"40":1,"57":6,"67":1,"135":1,"158":1,"174":3,"254":1,"315":3,"327":1,"351":1,"366":1,"382":1,"384":1,"405":1,"496":6,"500":1,"518":2,"571":1,"589":1,"616":1,"671":1,"700":1,"729":3,"741":1}}],["i^​1​",{"2":{"988":1}}],["i^∥1",{"2":{"988":1}}],["i^3",{"2":{"464":1}}],["i^2",{"2":{"464":1}}],["i^1",{"2":{"464":1}}],["i^",{"2":{"5":1,"623":12,"693":1,"780":4,"988":4}}],["i",{"0":{"125":1,"438":1,"455":1,"503":1,"959":1},"1":{"141":1},"2":{"5":10,"11":1,"72":1,"73":1,"82":1,"111":9,"125":2,"131":2,"137":15,"140":15,"141":2,"146":2,"147":1,"153":27,"162":1,"171":5,"178":2,"184":13,"188":3,"195":1,"197":1,"208":3,"218":1,"225":2,"236":9,"240":1,"256":1,"268":2,"273":5,"280":15,"285":2,"308":1,"316":3,"320":1,"334":1,"336":1,"342":8,"357":1,"362":1,"372":15,"380":2,"388":1,"390":24,"408":1,"411":1,"419":1,"437":1,"447":1,"464":4,"480":1,"532":21,"552":1,"563":6,"579":1,"595":8,"623":2,"647":13,"656":10,"666":3,"676":17,"681":9,"682":3,"686":1,"693":18,"694":8,"699":6,"704":5,"705":4,"712":13,"716":6,"728":9,"738":6,"739":1,"741":10,"749":5,"752":14,"782":1,"789":14,"794":23,"802":5,"807":4,"809":19,"827":1,"836":1,"848":3,"905":1,"915":4,"916":11,"927":2,"929":3,"931":1,"942":3,"950":2,"957":9,"961":1,"976":4,"985":4,"988":6,"998":8,"1000":2}}],["möller",{"2":{"905":1}}],["mgk∈rm",{"2":{"863":2}}],["mgk​",{"2":{"863":1}}],["mgkm",{"2":{"863":1}}],["myqueue",{"2":{"835":1}}],["m251",{"2":{"749":1}}],["m2ae",{"0":{"692":1},"2":{"692":1}}],["m^",{"2":{"716":6}}],["m^k",{"2":{"390":6}}],["m+m^",{"2":{"716":2}}],["m+δmi​∣i=1",{"2":{"716":1}}],["m+δmi∣i=1",{"2":{"716":1}}],["m+1",{"2":{"153":1}}],["mδm",{"2":{"716":1}}],["m∈mm",{"2":{"752":1}}],["m∈",{"2":{"712":2}}],["m∈r3m",{"2":{"705":1}}],["m∈r3",{"2":{"693":2}}],["m=",{"2":{"707":2,"746":2}}],["mt​∈r3×4",{"2":{"682":1}}],["mt​",{"2":{"682":1,"728":1}}],["mt∈r3×4x",{"2":{"682":1}}],["mt",{"2":{"682":1,"728":1}}],["mtl",{"2":{"32":2,"38":2}}],["m∑​fikmℓ​σikmℓ​",{"2":{"623":1}}],["mfikmℓσikmℓ",{"2":{"623":1}}],["mσikmℓ+ϵ∑k",{"2":{"623":1}}],["m~ij​",{"2":{"595":1}}],["m~ij​=m~i​+δm~ij​",{"2":{"595":1}}],["m~ij",{"2":{"595":1}}],["m~ij=m~i+δm~ij",{"2":{"595":1}}],["m~i​=",{"2":{"595":1}}],["m~i=",{"2":{"595":1}}],["mhsa",{"2":{"824":3,"844":1}}],["mh",{"2":{"572":2,"662":1,"686":5}}],["mhbn通过协调双线性池来集成局部卷积特征",{"2":{"337":1}}],["msa",{"0":{"729":1,"751":1}}],["msa结构再使用一个sw",{"2":{"659":1}}],["msa结构",{"2":{"659":3}}],["msckf",{"2":{"634":2,"686":1}}],["ms",{"2":{"545":1,"609":1,"965":1}}],["msemaxi2​​",{"2":{"5":1}}],["mse=mn1​i=0∑m−1​j=0∑n−1​",{"2":{"5":1}}],["mse=1mn∑i=0m−1∑j=0n−1",{"2":{"5":1}}],["mse",{"2":{"5":2,"382":1,"640":1,"694":1,"823":2}}],["m²",{"2":{"495":1}}],["mₜ",{"2":{"435":12,"495":2}}],["mln",{"0":{"762":1}}],["mln​∈rcl​×hl​×wl​",{"2":{"746":1}}],["mln​∣n∈",{"2":{"746":1}}],["mln∈rcl×hl×wlm",{"2":{"746":1}}],["mln∣n∈",{"2":{"746":1}}],["mln实现了隐式的运动补偿",{"2":{"740":1}}],["mlvl",{"2":{"623":1}}],["mlp​",{"2":{"910":1}}],["mlp被用作每个边缘的特征学习函数",{"2":{"574":1}}],["mlp",{"2":{"405":1,"420":1,"427":1,"434":1,"481":6,"489":1,"525":1,"549":1,"619":1,"621":3,"676":3,"705":1,"716":2,"877":1,"910":2,"957":2,"974":1}}],["mllm",{"2":{"72":1,"334":1}}],["mj",{"2":{"390":2}}],["m1",{"2":{"390":3}}],["m中均匀间隔的10个距离",{"2":{"301":1}}],["mc",{"2":{"877":1}}],["mcg",{"2":{"776":1}}],["mccord等人",{"2":{"605":1}}],["mccormac",{"2":{"209":2}}],["mccormac等人",{"2":{"116":1,"362":1,"967":4}}],["mccnn",{"2":{"481":1}}],["mcmc",{"2":{"256":1}}],["mp3d",{"2":{"495":2}}],["mpc",{"2":{"216":1}}],["mpdrive",{"2":{"128":1}}],["mᵢ",{"2":{"171":3}}],["m​σikmℓ​+ϵ1​k",{"2":{"623":1}}],["m​",{"2":{"153":1}}],["mmf",{"2":{"931":1}}],["mm∈m",{"2":{"752":2}}],["mm∈se",{"2":{"390":4}}],["mmcv",{"2":{"623":1}}],["mm指定的不确定区域和背景区域对原始图像进行随机裁剪得到局部图像",{"2":{"591":1}}],["mm​∈se",{"2":{"390":1}}],["mm",{"2":{"254":1}}],["mmm直接将图像特征解码为沿对应射线的占用分布",{"2":{"704":1}}],["mmm组成",{"2":{"704":1}}],["mmm的距离呈指数衰减",{"2":{"681":1}}],["mmm表示语义类别数量",{"2":{"632":1}}],["mmm",{"2":{"153":1,"429":2,"563":1,"590":1,"676":2,"681":1,"693":1,"705":1,"716":3,"738":1,"882":2}}],["mmengine",{"2":{"43":3,"51":2}}],["mmdet",{"2":{"623":1}}],["mmdetection3d",{"2":{"17":1,"43":1,"761":1}}],["mmdet3d",{"2":{"17":2,"43":1}}],["mvbts",{"2":{"988":1}}],["mvpnet",{"2":{"968":1}}],["mvcnn是一项开创性的工作",{"2":{"337":1}}],["mvsnet",{"0":{"259":1},"1":{"281":1,"305":1,"330":1,"355":1,"383":1,"411":1,"440":1,"470":1,"499":1,"529":1,"560":1,"592":1,"622":1,"650":1},"2":{"215":1}}],["mv重命名为3rscan",{"2":{"38":1}}],["mv",{"0":{"38":2,"43":1,"51":1},"2":{"38":14}}],["mdepth",{"2":{"705":2}}],["md",{"2":{"32":2,"38":2}}],["mis",{"2":{"967":1}}],["mi−mj",{"2":{"916":2}}],["mib",{"2":{"811":1}}],["mib降至124",{"2":{"811":1}}],["milioto",{"2":{"955":1}}],["milo",{"2":{"875":1}}],["mildenhall",{"2":{"619":2}}],["miller",{"2":{"209":1}}],["microsoft的azure",{"2":{"889":1}}],["microsoft",{"2":{"616":1}}],["mi=m+δmi",{"2":{"595":1}}],["mi=1∣pv∣∑j∈pv",{"2":{"563":1}}],["mi​−mj​",{"2":{"916":2}}],["mi​=m+δmi​",{"2":{"595":1}}],["mi​=∣pv​∣1​j∈pv​∑​",{"2":{"563":1}}],["mi​",{"2":{"532":1,"656":1,"693":1,"728":1,"738":1}}],["mi",{"2":{"532":1,"656":1,"693":1,"728":1,"738":1}}],["mi∈r3",{"2":{"532":1}}],["mim",{"2":{"390":2,"656":1,"728":1,"916":1}}],["miou排除了",{"2":{"1000":1}}],["miou指标分别计算每个语义类别的iou",{"2":{"998":1}}],["miou↑",{"2":{"971":2}}],["miou线性增加",{"2":{"842":1}}],["miou和0",{"2":{"811":1}}],["miou和1",{"2":{"811":1}}],["miou提升",{"2":{"811":2}}],["miou的显著提升",{"2":{"811":1}}],["miou的性能下降",{"2":{"811":1}}],["miou的提升进一步凸显了通道到高度变换在bev特征中保留体素级信息的能力",{"2":{"791":1}}],["miou的提升",{"2":{"791":1,"811":7}}],["miou=nc​1​i=1∑nc​​tpi​+fpi​+fni​tpi​​",{"2":{"998":1}}],["miou=cls1​i=1∑cls​tpi​+fpi​+fni​tpi​​",{"2":{"807":1,"915":1}}],["miou=c1​c=1∑c​tpc​+fpc​+fnc​tpc​​",{"2":{"739":1,"742":1,"778":1}}],["miou=28",{"2":{"782":1}}],["miou=∣c",{"2":{"749":1,"802":1,"848":1}}],["miou=1nc∑i=1nctpitpi+fpi+fni",{"2":{"998":1}}],["miou=1cls∑i=1clstpitpi+fpi+fnimiou",{"2":{"915":1}}],["miou=1cls∑i=1clstpitpi+fpi+fni",{"2":{"807":1}}],["miou=1c∑c=1ctpctpc+fpc+fnc",{"2":{"742":1}}],["miou=1c∑c=1ctpctpc+fpc+fncmiou=",{"2":{"739":1,"778":1}}],["miou=1∣c",{"2":{"749":1,"802":1,"848":1}}],["miou=",{"2":{"742":1}}],["miou",{"2":{"263":1,"306":1,"425":3,"492":1,"670":1,"677":1,"700":5,"732":1,"736":1,"739":1,"749":2,"770":1,"778":5,"782":2,"791":1,"792":2,"802":2,"803":11,"807":2,"823":2,"827":2,"840":1,"848":3,"853":3,"876":1,"893":1,"903":2,"915":1,"917":3,"927":1,"928":5,"971":3,"979":1,"998":3,"1000":1,"1001":1}}],["middle",{"2":{"181":1,"616":1}}],["mixing",{"0":{"181":1},"2":{"181":2}}],["mirrors",{"2":{"76":1}}],["ming等人",{"2":{"962":1}}],["mingsheng",{"2":{"458":1}}],["min​zij∑​∣∣xi−1​xj​−zij∣∣2ωij​+k=0∑m​l∈nm",{"2":{"390":1}}],["min​m1​",{"2":{"390":1}}],["min​i",{"2":{"137":1}}],["minkowskinet",{"2":{"962":1}}],["minkowskiengine",{"2":{"589":1}}],["minkowskiengine也是把点云组织成batch进行训练",{"2":{"357":1}}],["minkowski",{"2":{"589":2}}],["minkengine",{"0":{"357":1},"1":{"385":1,"413":1,"442":1,"472":1}}],["minₓ",{"2":{"171":2}}],["minus",{"2":{"124":2,"257":2}}],["mini2数据集上训练20个周期",{"2":{"813":1}}],["mini2数据集上进行了局部空间占用预测任务",{"2":{"793":1}}],["mini2数据集",{"2":{"793":1}}],["mini数据集上使用4个nvidia",{"2":{"813":1}}],["mini数据集上进行了具身空间占用预测任务",{"2":{"793":1}}],["mini数据集",{"2":{"793":1}}],["mini",{"2":{"327":3,"476":3,"534":1}}],["minibatch",{"2":{"184":2}}],["minimalegl",{"2":{"64":1}}],["minimal",{"2":{"64":1}}],["miniforge",{"2":{"27":1}}],["min",{"2":{"31":2,"137":1,"390":4,"588":1,"712":1,"916":1}}],["min⁡θl",{"2":{"712":1}}],["min⁡m1",{"2":{"390":1}}],["min⁡p",{"2":{"137":1}}],["min⁡",{"2":{"31":1}}],["mit",{"2":{"12":1,"27":1,"98":1,"109":1,"131":1,"141":1}}],["mkm",{"2":{"844":1,"863":1}}],["mk​∈r",{"2":{"844":1}}],["mk​=",{"2":{"390":1}}],["mk∈rm",{"2":{"844":1}}],["mkdir",{"2":{"27":1,"36":1,"40":1,"47":1,"107":1,"120":2}}],["mkswap",{"2":{"26":1}}],["mkfs",{"2":{"24":1}}],["motorcycle",{"2":{"702":2,"790":2}}],["motivation",{"0":{"265":1}}],["motional",{"2":{"126":4,"173":1,"302":1}}],["motion",{"0":{"143":1},"2":{"23":1,"208":1,"209":1}}],["mobility",{"2":{"702":1,"790":1}}],["mobaxterm",{"0":{"50":1},"1":{"60":1,"69":1,"78":1},"2":{"78":2}}],["mourikis和roumeliotis",{"2":{"634":1}}],["movable",{"2":{"702":4,"790":4}}],["moving",{"2":{"528":2}}],["move",{"2":{"261":1}}],["move等命令来操作",{"2":{"24":1}}],["move等操作硬盘",{"2":{"24":1}}],["mooney",{"2":{"525":1,"806":1}}],["mo",{"2":{"420":1}}],["monszpart等人",{"2":{"905":1}}],["mono使用单目相机",{"2":{"634":1}}],["monocular",{"0":{"890":1},"2":{"508":1}}],["monoscene的整体架构如图10所示",{"2":{"875":1}}],["monoscene还提出了3d上下文关系先验",{"2":{"875":1}}],["monoscene首次从单张图像中推导出三维空间占用预测",{"2":{"629":1}}],["monoscene",{"0":{"508":1,"873":1,"982":1},"1":{"539":1,"570":1,"603":1,"632":1,"660":1,"684":1,"707":1,"730":1,"752":1,"773":1,"794":1,"814":1,"834":1,"853":1,"870":1,"887":1,"903":1,"917":1,"928":1,"937":1,"945":1,"953":1,"960":1,"966":1,"972":1,"978":1,"982":1,"986":1,"989":1,"992":1,"995":1},"2":{"539":2,"570":4,"585":1,"632":2,"677":1,"759":1,"834":1,"841":1,"848":1,"853":1,"875":1,"903":5,"917":3,"928":1,"937":1,"945":1,"982":2,"989":3,"992":2,"995":2,"997":1}}],["mono",{"2":{"390":1,"682":6,"705":3,"750":5,"1000":1}}],["monte",{"2":{"256":1}}],["montemerlo",{"2":{"123":1,"525":1}}],["mostly",{"2":{"366":1}}],["moe",{"2":{"334":1}}],["more",{"0":{"422":1,"804":1},"2":{"422":1,"804":1}}],["moreno",{"2":{"123":1,"209":2,"698":1}}],["moreno等人",{"2":{"116":1,"967":2}}],["morton",{"2":{"315":1,"340":3,"426":1}}],["mopa",{"2":{"274":1,"495":2,"698":1}}],["mozos",{"2":{"209":1,"648":1}}],["moholea",{"2":{"123":1}}],["mod",{"2":{"1000":1}}],["modulation",{"2":{"863":1}}],["module",{"2":{"36":2,"174":1,"315":1,"333":1,"351":1}}],["modules",{"2":{"17":1,"174":1}}],["modal",{"0":{"512":1},"1":{"576":1,"609":1,"638":1,"666":1,"690":1,"736":1,"758":1,"779":1,"800":1},"2":{"514":1,"578":1}}],["modality",{"2":{"254":1,"700":1}}],["modeset=0",{"2":{"66":1}}],["modelnet10",{"2":{"688":2}}],["model得到77x768的特征",{"2":{"373":1}}],["model=hidden",{"2":{"333":1}}],["modeling",{"2":{"170":1,"183":1,"382":1}}],["model",{"0":{"183":1,"293":1,"562":1},"1":{"203":1,"225":1,"245":1,"267":1,"291":1,"316":1,"318":1,"342":1,"344":1,"370":1,"372":1,"398":1,"400":1,"429":1},"2":{"45":1,"111":1,"124":2,"131":1,"136":1,"185":1,"225":1,"235":1,"236":1,"248":1,"257":2,"373":2,"428":1,"459":1,"552":1,"617":1,"912":1,"949":1,"967":1}}],["models基于显式分类器的图像引导生成diffusion",{"2":{"201":1}}],["modelssdeditrepaint",{"2":{"201":1}}],["models",{"0":{"79":1,"101":1,"214":1,"235":1,"244":1,"264":1,"266":1,"312":1,"314":1,"365":1},"1":{"111":1,"124":1,"140":1,"236":1,"257":1,"280":1,"289":1},"2":{"17":1,"62":1,"135":1,"175":2,"183":1,"201":1,"203":3,"205":1,"235":1,"264":1,"266":1,"268":1,"312":1,"314":1,"333":1,"351":1,"379":1,"382":1,"439":1,"584":1}}],["modprobe",{"2":{"66":1}}],["modversion",{"2":{"36":1,"47":1}}],["mechanical",{"2":{"826":1}}],["mechanism",{"2":{"384":1,"863":1}}],["mehan",{"2":{"525":1}}],["megvii",{"2":{"369":1}}],["merging层进行下采样",{"2":{"659":1}}],["merging",{"0":{"328":1,"706":1},"2":{"659":2}}],["merged",{"2":{"746":4}}],["merge",{"2":{"153":1,"496":1}}],["mei",{"2":{"252":1}}],["methodologies",{"0":{"786":1},"1":{"806":1,"826":1,"846":1}}],["method",{"0":{"180":1,"264":1,"266":1,"319":1,"377":1,"659":1},"1":{"289":1,"345":1,"373":1,"401":1,"405":1,"434":1,"683":1,"706":1,"729":1,"751":1},"2":{"201":1,"264":1,"266":1,"274":1,"671":2,"700":1}}],["methods",{"0":{"990":1},"2":{"45":1,"519":1,"700":1,"756":1}}],["metric",{"2":{"153":1,"345":1,"705":2}}],["medium",{"2":{"135":1}}],["medium=distribute",{"2":{"106":1}}],["medical",{"2":{"45":1}}],["medeiros",{"2":{"30":1}}],["mean",{"2":{"40":1,"124":1,"257":1,"328":1,"435":1}}],["member",{"2":{"40":1}}],["memory=h",{"2":{"333":1}}],["memory",{"0":{"718":1},"2":{"11":2}}],["mescheder等人",{"2":{"665":1}}],["mescheder",{"2":{"619":1}}],["message",{"2":{"57":4}}],["meshconv",{"2":{"351":1,"526":1}}],["meshcov",{"2":{"351":1}}],["meshcnn和pointnet都采用了类似unet的结构",{"2":{"589":1}}],["meshcnn的感知域在模型表面空间",{"2":{"589":1}}],["meshcnn的上采样与下采样的结构一致性更强",{"2":{"589":1}}],["meshcnn的下采样与task的相关性更高",{"2":{"589":1}}],["meshcnn与pointnet++的一些差别",{"2":{"589":1}}],["meshcnn",{"0":{"275":1},"1":{"300":1,"325":1,"351":1,"379":1,"407":1,"436":1,"466":1,"496":1,"526":1,"557":1,"589":1},"2":{"215":1,"275":1,"351":1,"379":1,"557":1}}],["meshes",{"2":{"325":1}}],["mesher能够在不到7毫秒内生成每帧3d网格",{"2":{"816":1}}],["mesher产生了一个更嘈杂的网格",{"2":{"686":1}}],["mesher产生的快速多帧网格与kimera",{"2":{"686":1}}],["mesher获得完整的网格",{"2":{"686":1}}],["mesher和kimera",{"2":{"541":1}}],["mesher可以快速生成两种类型的3d网格",{"2":{"336":1}}],["mesher",{"0":{"336":1},"2":{"131":1,"285":3,"572":1}}],["mesh",{"0":{"351":1,"466":1,"496":1},"2":{"32":8,"38":8,"162":1,"336":1,"351":2,"379":10,"496":4}}],["mesa",{"2":{"17":1}}],["murali讨论unity",{"2":{"973":1}}],["mura等人",{"2":{"967":3}}],["mur",{"2":{"189":2,"967":1}}],["muμ",{"2":{"140":1,"280":1}}],["mutual",{"2":{"137":1,"153":1}}],["must",{"2":{"67":1}}],["multiheadattention",{"2":{"623":1}}],["multiply",{"2":{"434":1}}],["multiple",{"2":{"315":1}}],["multion",{"2":{"139":1,"252":1,"743":1}}],["multimodal",{"2":{"126":1}}],["multi",{"0":{"445":1,"512":1},"1":{"576":1,"609":1,"638":1,"666":1,"690":1,"736":1,"758":1,"779":1,"800":1},"2":{"30":3,"131":1,"139":1,"334":1,"414":1,"514":1,"545":1,"562":1,"578":1,"671":1,"692":2,"756":1,"863":1,"922":1,"967":1}}],["mu",{"2":{"8":6,"20":4,"140":5,"280":5}}],["majumdar和zac",{"2":{"973":1}}],["ma",{"2":{"877":1}}],["mam​",{"2":{"834":1}}],["mam​中的关系可以是自发现的",{"2":{"752":1}}],["mam​进行监督",{"2":{"752":1}}],["mamba",{"2":{"474":1}}],["ma^m​编码一个关系m∈mm",{"2":{"752":1}}],["ma^m​",{"2":{"752":1}}],["master",{"2":{"605":1,"663":1,"906":1}}],["masks",{"2":{"434":1,"518":1}}],["mask的",{"2":{"434":1}}],["masked",{"0":{"515":1,"751":1},"1":{"546":1,"579":1,"611":1,"640":1},"2":{"405":1,"515":1,"692":2,"715":2}}],["masking",{"0":{"488":1,"518":1},"1":{"518":1,"549":1},"2":{"315":2,"518":2}}],["mask",{"0":{"523":1},"1":{"554":1},"2":{"32":2,"38":4,"106":4,"117":1,"274":1,"315":1,"377":2,"384":1,"405":2,"434":1,"452":2,"518":1,"554":1,"698":1,"747":1,"800":1,"877":1,"967":1}}],["mao等人",{"2":{"511":1}}],["mae",{"2":{"456":1,"715":1}}],["mail",{"2":{"395":2}}],["main",{"2":{"36":2,"57":1,"63":1,"76":1,"93":1,"104":1,"115":1,"130":1,"146":1,"161":1,"196":1,"635":1,"776":1}}],["making",{"2":{"379":1}}],["makes",{"2":{"496":1}}],["make",{"2":{"36":2,"40":2,"47":2,"107":2,"120":3}}],["mazzaglia",{"2":{"274":1}}],["macarons",{"0":{"668":1},"2":{"668":1}}],["macmahon",{"2":{"525":1}}],["macc",{"2":{"263":3,"492":1,"688":1}}],["machine",{"2":{"149":1}}],["marching",{"2":{"247":2,"274":1}}],["markov",{"2":{"256":1}}],["marker",{"2":{"120":1}}],["markdown",{"0":{"6":1},"1":{"9":1,"14":1,"21":1,"28":1,"35":1,"39":1,"46":1,"57":1}}],["maggio",{"2":{"209":1}}],["manolis",{"2":{"958":1}}],["manmade",{"2":{"790":2}}],["mangelson等人",{"2":{"390":3}}],["manner",{"2":{"384":1}}],["many",{"2":{"366":1}}],["manifold",{"2":{"325":4}}],["manipulation",{"2":{"139":1,"268":1}}],["manager",{"2":{"120":1}}],["may",{"2":{"64":1,"107":1,"588":1,"698":1}}],["map指标",{"2":{"824":1}}],["mapnav",{"2":{"698":1}}],["mapnet",{"2":{"495":4,"698":1,"743":1}}],["map中",{"2":{"594":1}}],["map中去预测bounding",{"2":{"594":1}}],["map中不存在相同元素",{"2":{"177":1}}],["map50",{"2":{"306":2}}],["map上面选取每个",{"2":{"296":1}}],["mapper",{"2":{"274":2}}],["mapping网络将z变换成w",{"2":{"133":1}}],["mapping",{"0":{"149":1,"155":1},"1":{"171":1,"189":1,"209":1},"2":{"32":2,"38":2,"90":1,"133":1,"149":2,"181":1,"327":2,"668":2,"826":1}}],["map讲解",{"2":{"196":1}}],["map>",{"2":{"196":1}}],["map和map的区别",{"2":{"177":1}}],["mapillary",{"2":{"126":1}}],["maps送入rpn",{"2":{"296":1}}],["maps",{"2":{"80":2,"327":1,"328":1,"476":1,"659":2,"721":1,"941":2,"949":1}}],["map",{"0":{"89":1,"177":1,"196":1,"278":1,"556":1,"648":1,"675":1},"1":{"588":1,"619":1,"698":1,"721":1,"743":1,"765":1},"2":{"67":4,"75":1,"106":1,"177":3,"196":12,"234":1,"254":2,"255":1,"263":1,"328":1,"349":1,"378":4,"465":4,"476":1,"495":2,"504":1,"528":2,"550":1,"560":1,"616":3,"671":1,"678":1,"721":1,"741":2,"765":1,"826":1,"893":2}}],["map进行表示",{"2":{"54":1}}],["mave测量了8个语义类别中真正例射线的平均速度误差",{"2":{"998":1}}],["mave",{"2":{"998":2}}],["mav",{"2":{"31":1}}],["matuszek",{"2":{"525":1}}],["maturana",{"2":{"209":1}}],["matterport3d",{"2":{"495":2}}],["mathrm",{"2":{"647":2,"672":6,"696":7,"844":3,"863":4}}],["mathbf",{"2":{"342":5,"464":3,"524":3,"532":42,"563":3,"595":23,"647":3,"712":3}}],["mathbb",{"2":{"13":2,"235":1,"342":1,"345":2,"532":4,"563":2,"590":1,"609":3,"621":10,"649":1,"656":1,"676":1,"682":5,"693":9,"705":7,"716":2,"724":1,"746":7,"780":1,"794":6,"844":2,"863":1,"910":3,"957":2}}],["mathcal",{"2":{"256":1,"268":1,"532":7,"563":10,"595":4,"670":10,"672":1,"696":1,"712":7,"848":2,"884":4,"985":2,"988":1}}],["match",{"2":{"225":1,"651":1}}],["matching的方法去估计扰动后的数据分布的score",{"2":{"235":1}}],["matching",{"2":{"23":1,"235":2,"384":1}}],["matrix",{"2":{"132":2,"136":3,"357":4,"651":2,"654":2,"666":2}}],["maxfeaturesperframe",{"2":{"836":1}}],["maxpoolz",{"2":{"676":2}}],["maxpool",{"2":{"676":6}}],["maxtj​​ϕ",{"2":{"153":1}}],["max⁡tjϕ",{"2":{"153":1}}],["maxi2​为图片可能的最大像素值",{"2":{"5":1}}],["maxi2mse",{"2":{"5":1}}],["max",{"2":{"5":1,"31":1,"153":1,"373":3,"435":1,"437":6,"496":1,"698":1,"904":1,"998":1}}],["m",{"2":{"5":1,"26":2,"106":2,"136":1,"153":2,"171":2,"390":6,"419":1,"434":1,"452":2,"458":1,"495":4,"518":1,"524":4,"532":4,"563":1,"590":1,"595":10,"623":5,"632":1,"656":3,"676":3,"681":4,"682":2,"686":3,"693":9,"700":1,"704":3,"705":7,"707":1,"709":2,"712":6,"716":11,"728":2,"738":3,"746":2,"749":1,"752":10,"844":1,"863":1,"916":11,"931":1,"947":1,"1005":1}}],["mn",{"2":{"5":1}}],["m×nm×nm×n",{"2":{"5":1}}],["峰值信噪比",{"2":{"5":1}}],["r表示雷达",{"2":{"997":1}}],["r4",{"2":{"872":1}}],["r2",{"2":{"796":2,"872":3}}],["r5",{"2":{"796":3,"872":3}}],["r50",{"2":{"782":1,"803":2,"823":1}}],["r6",{"2":{"796":1}}],["r3",{"2":{"796":3,"872":3,"947":1}}],["r18a",{"2":{"803":1}}],["r18^c",{"2":{"782":1}}],["r18^b",{"2":{"782":2}}],["r18^a",{"2":{"782":2}}],["r1",{"2":{"796":2,"872":1}}],["rc​",{"2":{"794":1}}],["rc",{"2":{"794":1}}],["rcnet",{"2":{"664":2}}],["rcnn检测此场景中不存在的某些对象类别",{"2":{"872":1}}],["rcnn来轻松移除",{"2":{"872":1}}],["rcnn慢十几倍",{"2":{"386":1}}],["rcnn",{"2":{"362":1,"605":1}}],["rnr",{"2":{"721":1}}],["r=",{"2":{"716":2,"944":2}}],["r=q2r",{"2":{"532":2,"656":2,"693":2}}],["rfloor",{"2":{"712":1}}],["rfθ​",{"2":{"193":1}}],["r∈r4r",{"2":{"705":1}}],["r∈r4",{"2":{"693":2}}],["rd​",{"2":{"676":3,"699":1}}],["rd",{"2":{"676":7,"699":4}}],["rdp",{"2":{"549":1}}],["rbf特征提取层在减少参数个数数量级的同时",{"2":{"664":1}}],["rbf特征提取层计算每个点的所有核响应",{"2":{"664":1}}],["rbf",{"2":{"664":1,"962":1}}],["rbfnet",{"2":{"664":1}}],["rbegin",{"2":{"130":2,"918":1}}],["rho",{"2":{"660":3,"950":4}}],["rrr个参考点",{"2":{"704":1}}],["rrr参数化的高斯概率分布作为条件概率",{"2":{"681":1}}],["rrr",{"2":{"676":1,"693":1,"944":3}}],["rrr构造的旋转矩阵",{"2":{"656":1}}],["rrr和",{"2":{"656":1}}],["rri",{"2":{"574":1}}],["rˉg​=",{"2":{"595":1}}],["rˉg=",{"2":{"595":1}}],["rünz和agapito",{"2":{"967":2}}],["rünz等人",{"2":{"967":3}}],["rünz",{"2":{"588":1}}],["rt3dso",{"2":{"976":1}}],["rtrtrt",{"2":{"950":1}}],["rtr​",{"2":{"20":1}}],["rt",{"2":{"950":6}}],["rtx4090",{"2":{"758":1}}],["rtx",{"2":{"522":1,"783":1,"813":3,"816":1,"840":2,"859":1}}],["rsn​×sn​",{"2":{"957":1}}],["rsn×sn",{"2":{"957":1}}],["rss",{"2":{"532":1}}],["rsconv",{"2":{"481":1}}],["rs",{"2":{"481":1,"605":1}}],["rgcnn",{"2":{"607":1}}],["rg​=",{"2":{"595":1}}],["rg=",{"2":{"595":1}}],["rg是地面真实房间的集合",{"2":{"437":1}}],["rg|",{"2":{"437":1}}],["rg∈rg",{"2":{"437":6}}],["rgb的差距分别为",{"2":{"989":1}}],["rgb的输入",{"2":{"870":4}}],["rgb和",{"2":{"989":2}}],["rgb还需要一个语义点云",{"2":{"870":1}}],["rgb图像的2d特征图",{"2":{"942":1}}],["rgb图像捕捉了丰富的环境纹理",{"2":{"942":1}}],["rgb图像",{"2":{"641":1}}],["rgb颜色",{"2":{"162":1}}],["rgb",{"2":{"31":1,"125":1,"152":1,"189":2,"285":1,"360":8,"525":1,"539":1,"570":4,"588":1,"603":2,"632":5,"652":1,"668":3,"686":1,"743":3,"853":2,"870":11,"885":1,"900":1,"903":1,"917":3,"928":1,"937":1,"955":2,"967":2,"968":1,"978":9,"989":6}}],["rgbd",{"2":{"30":1,"31":1,"152":2,"853":1}}],["rgbds",{"2":{"30":2}}],["ryzen9",{"2":{"437":1}}],["r⁻¹",{"2":{"435":1}}],["rxi​0​txi​1​",{"2":{"390":1}}],["rxitxi01",{"2":{"390":1}}],["rpe",{"2":{"826":1}}],["rpn依靠一个在共享特征图上滑动的窗口",{"2":{"321":1}}],["rpn",{"2":{"296":1}}],["rpn生成待检测框",{"2":{"296":1}}],["rpgo在我们的euroc实验中最多需要50毫秒",{"2":{"816":1}}],["rpgo在euroc数据集上的姿态估计性能",{"2":{"541":1}}],["rpgo不优化网格",{"2":{"754":1}}],["rpgo不优化3d网格",{"2":{"390":1}}],["rpgo对α的选择相当不敏感",{"2":{"634":1}}],["rpgo确保了鲁棒性能",{"2":{"634":1}}],["rpgo和pcm异常值拒绝",{"2":{"419":1}}],["rpgo和kimera",{"2":{"390":2,"510":1,"572":1,"634":1}}],["rpgo仅优化了728个姿态节点",{"2":{"390":1}}],["rpgo的定位误差不同",{"2":{"754":1}}],["rpgo的准确性",{"2":{"634":1}}],["rpgo的性能",{"2":{"634":1}}],["rpgo的三倍",{"2":{"390":1}}],["rpgo的严格概括",{"2":{"390":2}}],["rpgo是我们在",{"2":{"390":1}}],["rpgo优化机器人轨迹的姿态图",{"2":{"390":1}}],["rpgo检测视觉回路闭合",{"2":{"390":1}}],["rpgo代替kimera",{"2":{"285":1}}],["rpgo一样",{"2":{"131":1}}],["rpgo",{"2":{"131":1,"285":3,"686":2}}],["rl通常叠加于il热启动之上",{"2":{"417":1}}],["rl×l以跟踪成对一致的回路",{"2":{"390":1}}],["rl",{"2":{"252":2,"417":1}}],["r^3形成鲜明对比",{"2":{"947":1}}],["r^3v∈r3计算一个特征向量fvol",{"2":{"318":1}}],["r^t",{"2":{"656":1,"693":1}}],["r^",{"2":{"153":1,"412":1,"429":2,"609":1,"716":8,"863":1}}],["rviz",{"2":{"120":1}}],["r−i+1",{"2":{"57":2}}],["ruiz",{"2":{"961":1}}],["rusu和cousins",{"2":{"449":2}}],["rublee",{"2":{"189":1}}],["rules",{"0":{"896":1,"912":1},"2":{"120":2}}],["rule是",{"2":{"57":1}}],["runwayml",{"2":{"373":2}}],["runtimeerror",{"2":{"11":1}}],["run",{"2":{"11":1,"38":1,"60":1,"66":6}}],["r后",{"2":{"48":1}}],["r会什么都不显示",{"2":{"48":1}}],["r这个字符的原因",{"2":{"48":1}}],["rigid",{"2":{"702":1,"790":1}}],["right|",{"2":{"957":1}}],["rightarrow0αˉt​​→0",{"2":{"273":1}}],["rightarrow0xt​→xt+δt​",{"2":{"208":1}}],["rightarrow0",{"2":{"111":1,"236":1}}],["rightarrow",{"2":{"111":2,"140":2,"208":4,"236":2,"273":3,"280":2}}],["right",{"2":{"31":2,"57":4,"132":1,"137":1,"193":1,"208":4,"268":3,"357":2,"464":2,"532":1,"647":2,"656":1,"666":1,"681":3,"693":2,"694":2,"729":1,"738":4,"752":1,"780":3,"910":2,"916":3,"942":4,"950":13,"957":11,"976":3,"985":5,"988":3}}],["rir",{"2":{"656":1,"728":1}}],["ri∈r4",{"2":{"532":1}}],["ri作为变形图中姿态顶点i的初始里程计旋转",{"2":{"390":1}}],["riding",{"2":{"373":1}}],["ri​",{"2":{"57":1,"532":1,"656":1,"693":1,"728":1,"738":1}}],["ri",{"2":{"57":1,"532":1,"656":1,"693":1,"728":1,"738":1}}],["riωi",{"2":{"57":1}}],["ritm",{"0":{"106":1},"2":{"45":1,"117":1}}],["rmgk​∈r",{"2":{"863":2}}],["rmse",{"2":{"634":1,"686":4,"826":1,"917":1}}],["rmk=i3r",{"2":{"390":1}}],["rmk​0​tmk​1​",{"2":{"390":1}}],["rmktmk01",{"2":{"390":1}}],["rm",{"2":{"33":1,"390":1}}],["robo3d",{"2":{"1005":1}}],["robodrive挑战赛",{"2":{"1005":1}}],["robustness",{"2":{"826":1}}],["robust",{"2":{"268":1}}],["rogers和christensen",{"2":{"967":1}}],["roc",{"2":{"806":1}}],["roldao等人",{"2":{"714":1}}],["rolandxxx的博客",{"2":{"325":1}}],["room",{"2":{"682":6,"728":1}}],["root",{"2":{"32":1,"34":4,"38":2,"43":1,"64":1,"504":1}}],["rovio和vins",{"2":{"634":1}}],["rovio",{"2":{"634":1,"686":1}}],["rondom",{"2":{"424":1}}],["row",{"2":{"333":2}}],["rows",{"2":{"136":4}}],["roi边框修正也是对于非背景的roi进行修正",{"2":{"463":1}}],["roi边框修正和rpn中的anchor边框修正原理一样",{"2":{"463":1}}],["roi",{"0":{"432":1,"719":1,"741":1,"763":1},"1":{"741":1,"763":1},"2":{"296":2,"432":1,"463":1,"554":6,"741":5,"765":1}}],["rotation",{"2":{"254":3,"379":1,"654":6}}],["rosu等人",{"2":{"962":1,"967":1}}],["rosparam",{"2":{"120":1}}],["rosservice",{"2":{"120":1}}],["rostopic",{"2":{"120":1}}],["roscd",{"2":{"120":1}}],["roscore",{"2":{"97":1}}],["rosinol",{"2":{"123":2,"209":1,"525":1,"619":1,"648":1,"686":2}}],["rosinol等人",{"2":{"116":1,"125":1,"131":8,"172":1,"190":1,"285":2,"336":3,"390":2,"605":1,"634":1,"732":1,"967":2}}],["rosinstall",{"2":{"27":1}}],["rosrun",{"2":{"97":1,"136":1,"152":1}}],["rosbag",{"2":{"34":1}}],["roslaunch",{"2":{"34":2,"120":1,"152":1}}],["rosdepc安装完毕并且更新好了依赖项",{"2":{"87":1}}],["rosdepc",{"2":{"87":1}}],["rosdep是ros的依赖项管理工具",{"2":{"87":1}}],["rosdep",{"0":{"87":1},"2":{"27":2,"87":1}}],["ros",{"0":{"15":1,"19":1,"27":1,"34":1,"76":1,"107":1},"1":{"22":1,"29":1,"36":1,"40":1,"47":1,"58":1,"67":1,"76":1,"87":2,"97":2,"107":2,"120":1,"136":1,"152":1},"2":{"15":2,"34":2,"76":3,"87":1,"107":3,"120":10,"136":1}}],["ros部署orbslam2算法使用astra",{"0":{"10":1}}],["rehder等人",{"2":{"605":1}}],["red",{"2":{"659":1}}],["reduce",{"2":{"496":1}}],["redmon和farhadi",{"2":{"116":1}}],["re|",{"2":{"437":1}}],["re∈re",{"2":{"437":6}}],["reproj",{"2":{"592":4}}],["representing",{"2":{"384":1}}],["representations",{"2":{"518":1}}],["representation",{"0":{"269":1},"2":{"247":1,"366":1,"515":2,"578":1,"906":1}}],["repeat",{"2":{"333":3}}],["repaint",{"0":{"312":1},"2":{"312":1}}],["repository",{"2":{"36":2}}],["reinstates",{"2":{"496":1}}],["reinstalling",{"2":{"64":1}}],["reijgwart等人",{"2":{"190":1,"967":1}}],["regular",{"0":{"672":1},"2":{"729":1}}],["registration",{"2":{"495":1}}],["regime",{"2":{"366":1}}],["region",{"0":{"321":1},"1":{"347":1,"375":1},"2":{"34":2,"384":1,"763":1}}],["reg的autoencoder",{"2":{"345":1}}],["reg",{"0":{"375":1},"2":{"345":2,"623":2}}],["regressively",{"2":{"290":1,"315":1}}],["regression进行目标包围框的修正",{"2":{"187":1}}],["regression调整目标包围框的大小",{"2":{"169":1}}],["remolina和kuipers",{"2":{"131":1,"197":1,"961":1}}],["remove",{"2":{"66":1,"405":1}}],["ren",{"2":{"274":2,"350":1,"914":1}}],["rendered",{"2":{"941":1,"949":1}}],["renderocc",{"0":{"755":1},"2":{"566":1,"791":1,"811":1,"941":1}}],["rend",{"2":{"130":2,"918":1}}],["ren等人",{"2":{"116":1,"362":1}}],["reversible",{"2":{"496":1}}],["reverse",{"2":{"130":3,"929":1}}],["reviving",{"2":{"106":4}}],["retain",{"2":{"496":1}}],["retrieve",{"2":{"469":2}}],["retinanet启发",{"2":{"138":1}}],["rethinking",{"0":{"84":1},"2":{"912":1}}],["returns",{"2":{"571":2}}],["return",{"2":{"52":2,"63":1,"93":1,"104":1,"115":1,"124":1,"130":1,"146":1,"161":1,"174":2,"196":1,"257":1,"333":1,"351":1,"373":1,"379":3,"929":1}}],["reference",{"2":{"623":1}}],["references",{"2":{"623":1}}],["refer",{"2":{"500":1}}],["ref的特征图则是直接在每个深度下复制",{"2":{"383":1}}],["refine",{"2":{"180":1}}],["refinement",{"0":{"75":1,"84":1,"148":1,"372":1},"1":{"164":1,"180":1,"198":1,"220":1},"2":{"75":2,"148":2,"175":1,"289":1,"372":1,"382":2,"562":1}}],["refined",{"2":{"32":8,"38":8,"499":1,"699":1}}],["ref",{"2":{"57":2,"268":2}}],["respres",{"2":{"638":2}}],["resores",{"2":{"638":4}}],["resolving",{"2":{"379":1}}],["resolution太大了",{"2":{"631":1}}],["resolution",{"2":{"205":1,"220":1,"247":1,"317":1,"382":1,"496":3,"631":1,"659":1}}],["reshape",{"2":{"504":2,"534":1}}],["research",{"2":{"369":1,"616":1}}],["reserve",{"2":{"146":1}}],["results",{"0":{"804":1},"2":{"700":1,"804":1}}],["resulting",{"2":{"518":1,"729":1}}],["result",{"0":{"220":1,"557":1,"925":1},"2":{"384":1}}],["resnet101",{"2":{"677":1,"746":1,"768":1,"771":1,"865":1,"867":1}}],["resnet3d骨干替换为second骨干",{"2":{"670":1}}],["resnet的多残差块设计使其能够优雅地获取具有丰富和多粒度语义信息的特征表示",{"2":{"627":1}}],["resnet50",{"2":{"333":3,"744":1,"771":1,"803":1,"865":1}}],["resnet",{"2":{"184":1,"274":1,"333":1,"425":1,"495":1,"562":1,"743":5,"803":3,"823":1}}],["resize",{"2":{"146":2,"904":1}}],["restart重启一下ssh",{"2":{"78":1}}],["restart",{"2":{"74":1}}],["res",{"2":{"57":2}}],["required",{"2":{"67":1,"107":1}}],["req",{"2":{"57":1}}],["rel",{"2":{"752":3,"834":2,"853":1,"928":2}}],["rellis",{"2":{"652":2,"677":3,"828":2}}],["rellis3d",{"2":{"444":1}}],["relu",{"2":{"549":1}}],["relpv",{"2":{"511":1}}],["relation",{"2":{"875":1}}],["relations",{"2":{"559":1}}],["relational",{"2":{"30":1,"420":1}}],["relative",{"2":{"379":1,"549":1,"826":1}}],["related",{"0":{"164":1}}],["reload",{"2":{"120":1}}],["relevant",{"2":{"106":5}}],["release",{"2":{"36":1,"40":1,"76":1}}],["releases",{"2":{"36":1}}],["recall",{"2":{"806":1,"826":1}}],["recision",{"2":{"794":1}}],["receptive",{"2":{"616":2}}],["receive",{"2":{"518":1}}],["reconstruction",{"2":{"850":1}}],["recognition",{"2":{"659":1}}],["recover",{"2":{"496":1}}],["recovery",{"2":{"106":2}}],["records",{"2":{"496":1}}],["reco",{"0":{"469":1},"2":{"469":5}}],["recv",{"2":{"76":1}}],["rectification",{"2":{"136":1}}],["rect",{"2":{"34":1}}],["recursive",{"2":{"27":1}}],["reason2drive",{"2":{"360":3,"447":2}}],["reasonplan",{"2":{"128":1}}],["readonly",{"2":{"57":1}}],["readme",{"2":{"32":2,"38":2}}],["readme~",{"0":{"0":1}}],["realsense",{"2":{"34":2,"437":1,"605":4,"686":1,"872":1,"947":2}}],["real",{"2":{"30":1,"102":1,"429":2}}],["reboot",{"2":{"24":1,"66":1}}],["rσr​",{"2":{"20":1}}],["rμr​",{"2":{"20":1}}],["r+∑i=1r​ωi",{"2":{"57":1}}],["r+∑i=1r",{"2":{"57":1}}],["r+",{"2":{"20":1}}],["r",{"0":{"154":1,"229":1,"296":1,"523":1},"1":{"169":1,"187":1,"207":1,"250":1,"272":1,"321":1,"347":1,"375":1,"403":1,"432":1,"463":1,"493":1,"554":1},"2":{"20":3,"24":1,"27":1,"48":1,"57":1,"88":1,"122":4,"138":1,"272":1,"274":2,"296":2,"390":3,"412":1,"435":1,"495":2,"525":2,"532":14,"554":2,"563":2,"590":1,"595":2,"609":4,"621":12,"638":1,"649":1,"656":6,"672":1,"676":16,"682":5,"693":18,"696":1,"698":1,"705":13,"712":6,"716":20,"724":1,"728":1,"738":1,"741":5,"746":7,"763":1,"780":1,"794":3,"844":2,"863":1,"877":1,"910":3,"944":1,"947":3,"957":2,"997":1,"1001":1}}],["ravichandran开源化tesse模拟器",{"2":{"973":1}}],["rayiou",{"2":{"736":1}}],["raycasting",{"2":{"362":1}}],["raychaudhuri",{"2":{"274":4,"495":2,"525":1,"698":2,"806":1,"826":1}}],["rack",{"2":{"702":1,"790":1}}],["racinskis",{"2":{"209":1}}],["ramakrishnan",{"2":{"495":1,"826":1}}],["rad",{"2":{"724":6,"746":4,"809":2}}],["radn​",{"2":{"724":1}}],["radn",{"2":{"724":1}}],["rad2​",{"2":{"724":1}}],["rad2",{"2":{"724":1}}],["rad1​",{"2":{"724":1}}],["rad1",{"2":{"724":1}}],["rad=",{"2":{"724":3}}],["radocc提出了一种渲染辅助的蒸馏范式",{"2":{"941":1}}],["radocc",{"2":{"548":1,"803":5,"840":1,"941":1}}],["radford",{"2":{"274":1,"619":1,"765":1}}],["radarocc在恶劣天气条件下展示了比以激光雷达为中心和以视觉为中心的方法更准确的3d占用预测",{"2":{"1005":1}}],["radar",{"2":{"254":2,"360":1,"654":1}}],["rag",{"2":{"195":1,"283":1,"334":1,"507":1}}],["ransac",{"2":{"310":3}}],["ranahanocka",{"2":{"275":1,"351":1,"379":1}}],["rangle",{"2":{"268":1}}],["rangenet++",{"2":{"955":1}}],["range=point",{"2":{"623":1}}],["range",{"2":{"196":1,"392":1,"623":1,"904":1}}],["ranganathan和dellaert",{"2":{"131":1,"197":1,"961":1}}],["randla",{"2":{"996":1}}],["rand",{"2":{"333":3}}],["random",{"2":{"137":1,"315":1,"424":2}}],["randn",{"2":{"124":1,"257":1,"333":1}}],["randint",{"2":{"124":1,"257":1}}],["raider",{"2":{"467":1}}],["raibert",{"2":{"123":1}}],["raise",{"2":{"11":1}}],["raulmur",{"2":{"58":1}}],["raw​",{"2":{"621":3}}],["rawp",{"2":{"621":1}}],["raw",{"2":{"34":2,"136":1,"440":1,"621":5}}],["ratios",{"2":{"379":11}}],["ratio",{"2":{"5":1}}],["p+",{"2":{"950":1}}],["p+△pijp+",{"2":{"950":1}}],["p+△pij​",{"2":{"950":2}}],["p+△pij",{"2":{"950":1}}],["p∈rn×3",{"2":{"910":1}}],["p∈rn×3p",{"2":{"910":1}}],["p∈rn×6",{"2":{"412":1}}],["p^k",{"2":{"814":2}}],["p^​",{"2":{"794":7}}],["p^​i",{"2":{"794":1}}],["p^",{"2":{"794":7}}],["p^i",{"2":{"794":1}}],["p−mi​",{"2":{"693":2}}],["p−mi",{"2":{"693":2}}],["p−m",{"2":{"693":4,"738":4}}],["p0+pk+δpgk",{"2":{"863":1}}],["p0+pk+δpk",{"2":{"844":1}}],["p0+p",{"2":{"741":1}}],["p0+pn+δpn",{"2":{"696":1}}],["p0+pn",{"2":{"672":1}}],["p0​+pk​+δpgk​",{"2":{"863":1}}],["p0​+pk​+δpk​",{"2":{"844":1}}],["p0​+p",{"2":{"741":1}}],["p0​+pn​+δpn​",{"2":{"696":1}}],["p0​+pn​",{"2":{"672":1}}],["p0​",{"2":{"672":1,"696":1,"741":1,"844":1,"863":1}}],["p0",{"2":{"672":1,"696":1,"741":1,"844":1,"863":1}}],["p1",{"2":{"592":2}}],["p1位置对应到卷积核中的位置就是",{"2":{"561":1}}],["p和负样本之间的差异",{"2":{"591":1}}],["p和正样本之间的差异",{"2":{"591":1}}],["pgo",{"2":{"686":1}}],["pgt",{"2":{"582":1}}],["pgtp",{"2":{"582":1}}],["pgmo能够利用循环闭合同时变形网格和优化传感器的轨迹",{"2":{"872":1}}],["pgmo与dvio相比的重建误差的rmse",{"2":{"754":1}}],["pgmo中优化后为13厘米",{"2":{"754":1}}],["pgmo变形之后",{"2":{"754":1}}],["pgmo效果的定性可视化",{"2":{"754":1}}],["pgmo相反",{"2":{"754":1}}],["pgmo相比",{"2":{"390":1}}],["pgmo可能只在定位上提供边际收益",{"2":{"754":1}}],["pgmo在我们的euroc实验中最多需要140毫秒",{"2":{"816":1}}],["pgmo在大规模场景",{"2":{"754":1}}],["pgmo在定位误差方面的性能",{"2":{"754":1}}],["pgmo在euroc数据集上的性能",{"2":{"510":1}}],["pgmo的网格变形实现了最佳的几何和语义性能",{"2":{"754":1}}],["pgmo的3d网格比未优化的kimera",{"2":{"754":1}}],["pgmo的几何误差",{"2":{"754":1}}],["pgmo的几何重建",{"2":{"572":1}}],["pgmo的定位误差与表1中kimera",{"2":{"754":1}}],["pgmo的定位性能",{"2":{"572":1}}],["pgmo的定位和重建性能",{"2":{"541":1}}],["pgmo的时间几乎是kimera",{"2":{"390":1}}],["pgmo直接产生描述机器人在离散时间步的姿态的时间戳姿态图",{"2":{"419":1}}],["pgmo为euroc",{"2":{"390":1}}],["pgmo还额外优化网格",{"2":{"390":1}}],["pgmo都执行回路闭合检测和异常值拒绝",{"2":{"390":1}}],["pgmo是kimera",{"2":{"390":2}}],["pgmo同时优化网格和轨迹",{"2":{"390":1}}],["pgmo优化的度量",{"2":{"449":2}}],["pgmo优化",{"2":{"285":1}}],["pgmo包括一个拒绝异常回路闭合的机制",{"2":{"131":1}}],["pgmo",{"0":{"390":1},"2":{"131":3,"285":4,"390":3,"634":1,"686":1}}],["pgm",{"2":{"23":1}}],["pj",{"2":{"579":1}}],["pvrnet",{"2":{"664":1}}],["pv",{"2":{"563":1,"877":1,"976":1}}],["pˉ=",{"2":{"563":2}}],["pnp​",{"2":{"532":1}}],["png",{"2":{"32":2,"38":2,"476":1}}],["p=",{"2":{"532":2,"693":2}}],["p~​k​=p+kst",{"2":{"524":1}}],["p~k=p+kst",{"2":{"524":1}}],["pxp​",{"2":{"464":1}}],["ppd",{"2":{"582":1}}],["ppd​",{"2":{"582":1}}],["ppdp",{"2":{"582":1}}],["ppp个高斯基元",{"2":{"656":1}}],["ppp",{"2":{"440":1,"693":2,"716":1,"738":1,"950":1}}],["ppo",{"2":{"274":1}}],["pᵥ",{"2":{"435":2}}],["pᵢⱼ",{"2":{"435":1}}],["psi",{"2":{"910":2,"950":8,"957":2}}],["psparse​",{"2":{"746":1}}],["psparsep",{"2":{"746":1}}],["psa",{"2":{"410":1}}],["psnr和ssim等自动图像质量分数通常会惩罚合成的高频细节",{"2":{"382":1}}],["psnr越大",{"2":{"345":1}}],["psnr=10⋅log10​",{"2":{"5":1}}],["psnr=10⋅log10",{"2":{"5":1}}],["psnr",{"0":{"5":1},"2":{"5":5,"382":3}}],["pmatrix",{"2":{"390":4}}],["pq",{"2":{"306":1}}],["pθ​",{"2":{"193":1,"213":1,"235":2}}],["pθ",{"2":{"193":1,"213":1,"235":1}}],["pdense​",{"2":{"746":1}}],["pdensep",{"2":{"746":1}}],["pdce",{"2":{"334":1}}],["pdata​",{"2":{"235":1}}],["pdata",{"2":{"235":2}}],["pd",{"2":{"164":1,"453":1,"582":1}}],["pdf",{"2":{"23":1,"219":1,"244":1,"264":1,"266":1,"414":1,"445":1,"514":1,"545":1,"578":1,"671":1,"776":1}}],["pcf",{"2":{"1003":1}}],["pc​",{"2":{"794":2}}],["pcam",{"2":{"621":4,"676":6}}],["pcam​∈rx×y×z×c",{"2":{"621":1}}],["pcam∈rx×y×z×cp",{"2":{"621":1}}],["pc0",{"2":{"504":2}}],["pcnn",{"2":{"481":1}}],["pcpk​",{"2":{"464":1}}],["pcm异常值拒绝特别适合于移除需要人类以任意速度移动",{"2":{"419":1}}],["pcm",{"2":{"390":2,"686":1}}],["pc",{"2":{"106":4,"504":4,"623":1,"794":2}}],["p容器值为4",{"2":{"104":1}}],["p容器内元素为2",{"2":{"104":2,"161":1}}],["p容器内元素为1",{"2":{"104":1,"161":1}}],["p容器元素为3",{"2":{"93":1}}],["pfeifer",{"2":{"90":1}}],["pecificity",{"2":{"794":1}}],["pe在3d感知中的有效性",{"2":{"583":1}}],["pe",{"2":{"427":1,"615":1}}],["peng等人",{"2":{"665":1}}],["peng",{"2":{"350":1,"556":1,"588":2,"826":1}}],["petr在时域条件下工作良好",{"2":{"583":1}}],["petr已经证明了3d",{"2":{"583":1}}],["petrv2是将petr扩展到时序模型以及bev语义分割上",{"2":{"550":1}}],["petrv2",{"0":{"550":1},"1":{"583":1,"615":1,"644":1}}],["petr",{"0":{"341":1,"369":1,"671":1},"1":{"369":1,"397":2,"427":2,"457":2,"489":2,"519":2,"550":1,"583":1,"615":1,"644":1,"671":1,"695":2,"718":2,"740":2,"762":2,"783":2},"2":{"359":1,"369":2,"550":1}}],["pedestrian",{"2":{"254":1,"702":11,"790":11}}],["perc",{"2":{"812":1,"916":4}}],["perceptual",{"0":{"221":1},"2":{"221":1,"345":2}}],["perception",{"2":{"94":1,"102":1,"107":1,"164":1,"577":1,"610":1}}],["performance",{"2":{"366":1,"671":1}}],["performed",{"2":{"158":1}}],["permute",{"2":{"333":1,"623":2}}],["permitrootlogin",{"2":{"78":1}}],["personal",{"2":{"702":1,"790":1}}],["person",{"2":{"131":1,"967":1}}],["peak",{"2":{"5":1}}],["pho",{"2":{"988":1}}],["photometric",{"2":{"949":1}}],["photograph",{"2":{"373":1}}],["photo",{"2":{"204":4}}],["phi",{"2":{"153":3,"264":1,"266":1,"422":2,"660":3,"780":2,"910":2,"942":2,"950":2}}],["phase",{"2":{"75":2}}],["php",{"2":{"47":1}}],["p后跟端口映射",{"2":{"60":1}}],["pulse",{"2":{"382":1}}],["pullable",{"2":{"702":1,"790":1}}],["pull",{"2":{"60":1}}],["puri等人",{"2":{"967":1}}],["purpose",{"2":{"659":1}}],["purposes",{"2":{"315":1}}],["purge",{"2":{"66":1}}],["pu",{"2":{"189":1,"209":1}}],["publisher",{"2":{"120":1}}],["push与emplace区别详见",{"2":{"835":1}}],["pushable",{"2":{"702":1,"790":1}}],["push",{"2":{"52":4,"104":2,"115":4,"130":3,"146":1,"731":1,"835":2,"904":2,"938":1}}],["p>",{"2":{"57":2}}],["pt​",{"2":{"780":1}}],["pt​作为输入ωt=",{"2":{"780":1}}],["ptp",{"2":{"780":1}}],["ptc解决了vit存在的过度平滑问题",{"2":{"591":1}}],["ptc",{"0":{"559":1}}],["pt",{"2":{"373":1,"780":1}}],["pts​",{"2":{"870":1}}],["pts",{"2":{"254":2,"654":2,"870":4}}],["pth",{"2":{"43":2,"51":1}}],["ptr",{"2":{"40":1}}],["pkp",{"2":{"844":1,"863":1}}],["pk​",{"2":{"814":1}}],["pk​∥p^k​",{"2":{"814":1}}],["pk∥p^k",{"2":{"814":1}}],["pk",{"2":{"814":1}}],["pkg",{"2":{"36":1,"47":1}}],["pkgconfig=on",{"2":{"36":1}}],["pkl",{"2":{"32":1,"38":1}}],["pkl文件",{"2":{"32":1,"38":1}}],["plidi=",{"2":{"789":2}}],["plidi​​=",{"2":{"789":2}}],["plidi​​",{"2":{"789":1}}],["plidip",{"2":{"789":1}}],["plidar=mlp",{"2":{"621":1}}],["plidar∈rx×y×z×cp",{"2":{"621":1}}],["plidar",{"2":{"621":26,"676":6}}],["plidar​=mlp",{"2":{"621":1}}],["plidar​∈rx×y×z×c",{"2":{"621":1}}],["plidar​",{"2":{"621":2}}],["plidarp",{"2":{"621":2}}],["plumb",{"2":{"136":1}}],["plugins",{"2":{"64":2}}],["plugin",{"2":{"64":3}}],["plane",{"2":{"423":1}}],["planner",{"2":{"274":1}}],["planning",{"2":{"31":1}}],["platform",{"2":{"64":3}}],["play",{"2":{"34":1}}],["placed",{"2":{"826":1}}],["places",{"2":{"137":1}}],["place",{"2":{"34":2,"125":1}}],["ply",{"2":{"32":2,"38":2}}],["please",{"2":{"11":1}}],["pirk等人",{"2":{"905":1}}],["pijp",{"2":{"666":1}}],["pij​",{"2":{"666":1}}],["pij",{"2":{"666":1}}],["pin",{"2":{"561":3}}],["pi=",{"2":{"532":1}}],["pi​=",{"2":{"532":1}}],["pi​",{"2":{"532":1,"563":1,"957":3}}],["pixel",{"2":{"410":1,"439":1,"469":1}}],["pi",{"2":{"379":1,"532":1,"563":1,"579":1,"592":3,"595":2,"681":1,"716":2,"916":2,"957":2}}],["pillai",{"2":{"209":2}}],["pip",{"2":{"27":2,"957":1}}],["pid控制器等",{"2":{"260":1}}],["pid或mpc控制器执行最终指令",{"2":{"103":1}}],["pid",{"2":{"11":1}}],["pradi​​=",{"2":{"809":2}}],["pradi=",{"2":{"809":2}}],["practical",{"0":{"117":1},"2":{"96":1}}],["pr",{"2":{"571":2}}],["priority",{"0":{"946":1},"2":{"946":1}}],["prior",{"2":{"496":3,"875":1}}],["prior用于可驾驶的表面和人行道",{"2":{"254":1}}],["prime",{"2":{"863":3,"957":1,"985":2}}],["prim也在实时运行",{"2":{"462":1}}],["prim",{"2":{"431":1}}],["primitives",{"2":{"153":1,"271":1}}],["print",{"2":{"333":1}}],["privileged=true",{"2":{"60":2}}],["precision",{"2":{"806":2,"826":1}}],["preceding",{"2":{"518":2,"616":2}}],["preception",{"2":{"164":1}}],["presp​",{"2":{"638":2}}],["preserving",{"2":{"273":1}}],["pred",{"2":{"429":4,"651":3}}],["predictor",{"2":{"180":1,"198":1}}],["predict",{"2":{"180":1}}],["prediction上组织了一个定期更新的相关论文",{"2":{"637":1}}],["predictions中就会有k个能够匹配到这k个ground",{"2":{"358":1}}],["predictions和ground",{"2":{"358":1}}],["predictions",{"2":{"333":1}}],["prediction",{"0":{"344":1,"434":1,"445":1,"482":1,"890":1},"2":{"23":1,"315":1,"434":1,"469":1,"514":1,"537":1,"545":1,"549":1,"578":1,"715":2,"839":1,"906":1}}],["pretraining",{"2":{"394":1}}],["pretrained",{"2":{"373":4,"949":1}}],["previous",{"2":{"659":1,"729":1}}],["prev",{"2":{"254":3,"654":1}}],["preprint",{"2":{"126":1}}],["premature",{"2":{"120":1}}],["pre",{"0":{"260":1},"2":{"66":1,"243":1,"290":1,"315":1,"336":1,"366":1,"518":1,"692":2,"715":2}}],["prefix=",{"2":{"36":1}}],["prokhorov",{"2":{"826":1}}],["prokudin等人",{"2":{"664":1}}],["progress",{"2":{"806":1}}],["provide",{"2":{"949":1}}],["provided",{"2":{"66":1}}],["providing",{"2":{"729":1}}],["proceedings",{"2":{"244":1}}],["process",{"0":{"208":1},"2":{"452":1}}],["pronobis和jensfelt",{"2":{"967":1}}],["pronobis",{"2":{"209":2,"648":2}}],["projectpage",{"2":{"486":1}}],["project",{"2":{"333":1}}],["projection",{"2":{"136":1,"660":1,"839":1,"875":1}}],["proj",{"2":{"184":2}}],["produce",{"2":{"659":1}}],["prod",{"2":{"111":1,"236":1,"681":1}}],["probability",{"2":{"440":1}}],["probabilistic",{"0":{"101":1,"214":1,"264":1,"266":1,"312":1,"314":1},"1":{"111":1,"124":1,"140":1,"236":1,"257":1,"280":1,"289":1},"2":{"201":2,"264":1,"266":1,"312":1,"314":1,"382":2}}],["problem",{"2":{"64":1}}],["propagation",{"0":{"740":1},"1":{"762":1}}],["propagate",{"2":{"31":1}}],["proportion",{"2":{"518":1}}],["proposed",{"2":{"518":1,"659":1,"729":1}}],["proposal",{"0":{"321":1,"990":1},"1":{"347":1,"375":1}}],["propto",{"2":{"140":5,"208":1,"280":5,"316":1}}],["property",{"2":{"57":2}}],["protocol",{"2":{"54":1}}],["prompts",{"2":{"549":1}}],["prompting",{"2":{"469":1}}],["prompt",{"2":{"45":1,"373":2,"452":1}}],["pro相机输入",{"0":{"10":1}}],["pavlakos等人",{"2":{"967":1}}],["pages",{"2":{"914":1}}],["page下载",{"2":{"47":1}}],["pa",{"2":{"877":1}}],["paul",{"2":{"525":1}}],["paches指随机丢弃视图中的一部分",{"2":{"424":1}}],["package前面",{"2":{"107":1}}],["package",{"2":{"107":1}}],["packages",{"2":{"64":1}}],["padding=",{"2":{"373":1}}],["paszke等人",{"2":{"362":1}}],["pass",{"2":{"351":1,"384":1}}],["passwd",{"2":{"78":1}}],["paligemma",{"2":{"334":1}}],["palette",{"2":{"175":2}}],["patki",{"2":{"525":2,"698":1}}],["pats",{"2":{"420":1}}],["pattabiraman等人",{"2":{"390":1}}],["pattern",{"2":{"136":1}}],["patch14",{"2":{"373":3}}],["patches",{"2":{"315":2,"424":1,"659":1}}],["patch",{"0":{"559":1,"683":1,"706":1},"2":{"158":1,"340":1,"559":1,"631":1,"659":1}}],["pathak",{"2":{"274":1}}],["path",{"0":{"221":1},"2":{"32":1,"38":1,"221":1,"504":2,"534":1,"806":1}}],["paths",{"2":{"27":1}}],["paired",{"2":{"496":1}}],["pair",{"2":{"67":2,"177":1,"196":1,"424":1,"571":3}}],["partition和linear",{"2":{"659":1}}],["partition后图像shape由",{"2":{"659":1}}],["partition模块中进行分块",{"2":{"659":1}}],["partitioning",{"2":{"340":1,"729":2}}],["partial^r",{"2":{"57":1}}],["partial",{"2":{"23":1,"57":1,"208":10,"496":1}}],["part分割等",{"2":{"290":1}}],["params",{"2":{"688":1}}],["parameter",{"2":{"184":1,"333":3,"741":1}}],["parameters和class",{"2":{"562":1}}],["parameters",{"2":{"174":1,"496":1}}],["para",{"2":{"114":1}}],["parseint",{"2":{"57":1}}],["papers",{"2":{"45":1,"148":1,"243":1,"268":1,"287":1,"290":1,"306":1,"312":1,"323":1,"394":1,"399":1,"422":1,"452":1,"498":1,"513":2,"515":1,"593":2,"668":1,"692":1,"715":2}}],["paperswithcode",{"2":{"30":2,"414":1}}],["paper",{"2":{"30":2,"244":2,"414":1}}],["pangercic等人",{"2":{"967":1}}],["pangolin",{"0":{"40":1},"2":{"15":1,"40":3}}],["pan等人",{"2":{"607":1}}],["panoocc",{"2":{"482":1,"517":1,"922":1,"957":1,"1000":1}}],["panopticfusion",{"2":{"967":1}}],["panoptic",{"2":{"23":1,"162":1,"327":4,"384":1,"476":2}}],["pandaset",{"2":{"302":1}}],["pan",{"2":{"123":1,"126":1}}],["po",{"2":{"877":1}}],["poisson",{"2":{"850":1}}],["pointocc",{"2":{"858":1,"910":1}}],["point2sequences",{"2":{"664":1}}],["pointflow中可以对其上采样",{"2":{"618":1}}],["pointcnn",{"2":{"511":1}}],["pointconv",{"2":{"481":1}}],["pointcontrast",{"0":{"243":1},"1":{"265":1,"288":1,"313":1,"339":1,"366":1},"2":{"243":1,"485":1}}],["pointweb建立在pointnet++基础之上",{"2":{"420":1}}],["pointnet++使用knn挑选空间距离上的领域点",{"2":{"589":1}}],["pointnet++中的上采样和下采样的感知域是不一样的",{"2":{"589":1}}],["pointnet++在下卷积时通过fps",{"2":{"589":1}}],["pointnet++",{"2":{"588":1,"692":1}}],["pointnet++可以从局部几何结构中学习特征",{"2":{"420":1}}],["pointnet",{"2":{"420":1,"456":6,"588":1,"974":1}}],["pointnav",{"2":{"139":1,"252":1,"274":1}}],["pointmvs",{"0":{"297":1},"1":{"322":1,"348":1,"376":1,"404":1,"433":1,"464":1,"494":1,"524":1,"555":1,"587":1,"618":1,"647":1,"674":1},"2":{"215":1}}],["pointgpt",{"0":{"290":1,"315":1},"1":{"315":1,"340":1,"368":1,"396":1,"426":1,"456":1,"488":1,"518":1,"549":1,"582":1,"614":1,"643":1},"2":{"215":1,"290":2,"315":1,"368":1,"456":1,"688":1}}],["points=reference",{"2":{"623":1}}],["points=1",{"2":{"623":1}}],["points",{"2":{"32":2,"38":4,"43":2,"327":2,"379":9,"384":1,"504":4,"534":1,"623":1,"863":1}}],["point",{"0":{"132":1,"158":1,"314":1,"340":1,"692":1},"1":{"368":1,"396":1,"426":1,"456":1},"2":{"23":1,"43":2,"45":1,"139":1,"143":2,"158":1,"237":1,"243":1,"290":1,"313":1,"314":1,"315":4,"327":2,"340":1,"384":1,"394":1,"396":1,"424":1,"456":1,"485":1,"518":1,"588":1,"589":1,"593":1,"692":3,"715":2,"863":1,"877":1}}],["po是占据注释坐标系xy平面上预定义的一组点",{"2":{"638":1}}],["polyu",{"2":{"1008":1}}],["police",{"2":{"702":2,"790":2}}],["policy",{"2":{"525":2}}],["polar平面共享相同的编码器和解码器",{"2":{"699":1}}],["polar平面输入到任务头中以进行3d语义占据预测",{"2":{"621":1}}],["polar平面输出到预测头",{"2":{"578":1}}],["polar平面",{"2":{"578":2,"621":2,"676":2,"699":3,"898":1}}],["polar",{"0":{"676":1},"2":{"438":1,"578":1,"621":2,"676":1,"865":1,"882":2,"898":1}}],["polarpoint",{"2":{"114":1}}],["pooled学习特征映射",{"2":{"664":1}}],["pooled",{"2":{"496":1}}],["pooling示意图如下所示",{"2":{"741":1}}],["pooling具有更相似的内在含义",{"2":{"589":1}}],["pooling聚合",{"2":{"574":1}}],["pooling算法对邻域信息进行聚合",{"2":{"574":1}}],["pooling做了改进并提出了roi",{"2":{"554":1}}],["pooling这样做",{"2":{"554":1}}],["pooling的取整操作",{"2":{"554":1}}],["pooling的操作",{"2":{"554":1}}],["pooling的原因",{"2":{"272":1}}],["pooling过后的得到的输出可能和原图像上的roi对不上",{"2":{"554":1}}],["pooling是直接通过四舍五入取整得到的结果",{"2":{"554":1}}],["pooling主要做了两件事",{"2":{"432":1,"741":1}}],["pooling操作来独立地学习点特征",{"2":{"420":1}}],["pooling层提取全局形状特征",{"2":{"420":1}}],["pooling灵活的池化",{"2":{"384":1}}],["pooling",{"0":{"432":1,"436":1,"442":1,"466":1,"719":1,"741":1,"763":1},"1":{"466":1,"496":1,"741":1,"763":1},"2":{"250":1,"296":1,"384":1,"463":1,"496":9,"554":1,"603":1,"741":2}}],["potential",{"2":{"405":1}}],["potentially",{"2":{"366":1}}],["pop",{"2":{"115":2,"685":1,"753":2,"774":1,"835":2,"904":2,"938":1,"975":1,"988":3,"1006":1}}],["port",{"2":{"78":1}}],["pos=query",{"2":{"623":1}}],["positive",{"2":{"347":1}}],["positional",{"2":{"333":4,"549":2,"623":1}}],["position",{"0":{"427":1,"763":1},"2":{"104":1,"405":1,"550":1,"623":1}}],["post",{"2":{"315":1}}],["postive",{"2":{"84":1}}],["pose是我们论文中描述的基于激光雷达地图的定位算法的输出",{"2":{"254":1}}],["posed问题的求解过程",{"2":{"220":1}}],["posediffusion",{"0":{"163":1},"2":{"163":1}}],["pose",{"2":{"163":1,"254":3,"550":1,"654":2,"806":1,"826":1}}],["pos",{"2":{"52":1,"130":1,"333":6,"623":6}}],["possible",{"2":{"11":1}}],["pyramid",{"2":{"603":1}}],["py生成的矩形",{"2":{"321":1}}],["pycharm中qt",{"2":{"74":1}}],["python的序列数据只有list和tuple",{"2":{"351":1}}],["python教程",{"2":{"196":2}}],["python3",{"2":{"27":3,"64":1}}],["python",{"2":{"27":1,"32":2,"38":3,"43":1,"51":1,"196":2}}],["pythonpath=",{"2":{"38":1}}],["pythonpath",{"2":{"17":1}}],["py",{"2":{"17":1,"32":8,"38":9,"43":3,"51":2,"136":1,"174":1,"351":1,"379":1,"850":2}}],["p||q",{"2":{"13":1}}],["p∣∣q",{"2":{"13":2}}],["p",{"2":{"13":14,"27":1,"60":1,"93":2,"104":8,"120":1,"132":7,"137":25,"153":25,"161":3,"193":1,"208":37,"213":1,"225":2,"235":15,"271":3,"276":2,"316":5,"338":1,"342":2,"422":1,"450":1,"464":3,"495":1,"513":9,"524":2,"532":4,"561":3,"563":7,"579":3,"592":1,"621":7,"638":1,"647":8,"656":1,"663":1,"666":4,"672":5,"676":4,"681":16,"693":19,"696":6,"716":6,"738":16,"741":3,"780":1,"789":2,"794":41,"809":2,"814":7,"839":1,"840":1,"844":6,"863":6,"877":1,"910":3,"916":5,"947":3,"950":3,"957":2}}],["笔记大全",{"2":{"63":1}}],["笔记",{"0":{"2":1}}]],"serializationVersion":2}';export{t as default};
