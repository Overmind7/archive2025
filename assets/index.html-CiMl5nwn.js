import{_ as i,c as t,b as a,o as r}from"./app-IQA0dJD3.js";const n={};function l(o,e){return r(),t("div",null,e[0]||(e[0]=[a('<blockquote><p>(cvpr 2022&#39;)Deblurring via Stochastic Refinement</p><p><a href="https://paperswithcode.com/paper/deblurring-via-stochastic-refinement" target="_blank" rel="noopener noreferrer">Deblurring via Stochastic Refinement | Papers With Code</a></p><p>未开源</p></blockquote><h2 id="related-work" tabindex="-1"><a class="header-anchor" href="#related-work"><span>related work</span></a></h2><ul><li>cvpr 18‘ the preception-distortion tradeoff</li><li>pd 曲线</li></ul><img src="https://raw.githubusercontent.com/Overmind7/images/main/image-20230321162647617.png" alt="" style="zoom:50%;"><blockquote><p><a href="https://blog.csdn.net/gwplovekimi/article/details/84707451" target="_blank" rel="noopener noreferrer">论文阅读笔记之——《The Perception-Distortion Tradeoff》_gwpscut的博客-CSDN博客</a></p></blockquote><h2 id="method" tabindex="-1"><a class="header-anchor" href="#method"><span>method</span></a></h2><ul><li>predict ＆ refine，扩散模型的 x0 不再是原图，而是原图和 predictor 的残差</li></ul><p><img src="https://raw.githubusercontent.com/Overmind7/images/main/image-20230311141615606.png" alt="image-20230311141615606"></p><ul><li>sample averaging：由于每一次采样的随机性，可以多重建几次，取平均</li><li>采样步数越多，主观质量越好，反之客观质量越好 <ul><li><img src="https://raw.githubusercontent.com/Overmind7/images/main/image-20230311142218597.png" alt="image-20230311142218597" style="zoom:50%;"></li></ul></li><li>训练的时候用小patch，测试的时候用整张图————low level task</li></ul><h2 id="网络架构" tabindex="-1"><a class="header-anchor" href="#网络架构"><span>网络架构</span></a></h2><p><img src="https://raw.githubusercontent.com/Overmind7/images/main/image-20230311142928780.png" alt="image-20230311142928780"></p><ul><li>未开源</li><li>initial predictor 和 denoiser 是一样的，base channel 前者64，后者32</li><li>参数量前者 26m，后者7m</li></ul><h2 id="result" tabindex="-1"><a class="header-anchor" href="#result"><span>result</span></a></h2><img src="https://raw.githubusercontent.com/Overmind7/images/main/image-20230311143618168.png" alt="image-20230311143618168" style="zoom:67%;"><img src="https://raw.githubusercontent.com/Overmind7/images/main/image-20230311143702099.png" alt="image-20230311143702099" style="zoom:67%;"><p><img src="https://raw.githubusercontent.com/Overmind7/images/main/image-20230311141651053.png" alt="image-20230311141651053"></p><blockquote><p>Low-level任务：常见的包括 Super-Resolution，denoise， deblur， dehze， low-light enhancement， deartifacts等。简单来说，是把特定降质下的图片还原成好看的图像，现在基本上用end-to-end的模型来学习这类 ill-posed问题的求解过程，客观指标主要是PSNR，SSIM，大家指标都刷的很高。目前面临以下几点问题：</p><ul><li>泛化性差，换个数据集，同种任务变现就很差</li><li>客观指标与主观感受存在，GAP，指标刷很高，人眼观感不佳，用GAN可缓解 落地的问题，SOTA模型运算量很(上百G Flops)，但实际不可能这么用</li><li>主要是为人眼服务，缺乏与High-level之间的联系</li></ul><hr><p>High-level任务：分类，检测，分割等。一般公开训练数据都是高品质的图像，当送入降质图像时，性能会有下降，即使网络已经经过大量的数据增强（形状，亮度，色度等变换）</p><p>真实应用场景是不可能像训练集那样完美的，采集图像的过程中会面临各种降质问题，需要两者来结合。简单来说，结合的方式分为以下几种</p><ul><li>直接在降质图像上fine-tuning</li><li>先经过low-level的增强网络，再送入High-level的模型，两者分开训练</li><li>将增强网络和高层模型（如分类）联合训练 ———————————————— 版权声明：本文为CSDN博主「WTHunt」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。 原文链接：https://blog.csdn.net/qq_20880415/article/details/117225213</li></ul></blockquote>',17)]))}const m=i(n,[["render",l]]),c=JSON.parse('{"path":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/1po6vfar/","title":"Deblurring-via-Stochastic-Refinement","lang":"zh-CN","frontmatter":{"title":"Deblurring-via-Stochastic-Refinement","createTime":"2024/08/11 11:31:15","permalink":"/生成模型/1po6vfar/"},"readingTime":{"minutes":2.19,"words":658},"git":{"updatedTime":1750820984000,"contributors":[{"name":"weiwen","username":"","email":"a1036359215@163.com","commits":1,"avatar":"https://gravatar.com/avatar/cd8e1d2cae5eb43df4bdc241dd3c0611439067bff22550061317525e3b170bab?d=retro"}]},"filePathRelative":"notes/生成模型/diffusion/Deblurring-via-Stochastic-Refinement.md","headers":[],"categoryList":[{"id":"4358b5","sort":10000,"name":"notes"},{"id":"bdd74e","sort":10006,"name":"生成模型"},{"id":"9bc14f","sort":10010,"name":"diffusion"}]}');export{m as comp,c as data};
