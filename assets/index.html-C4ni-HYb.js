import{_ as a,c as t,b as n,o as e}from"./app-IQA0dJD3.js";const m={};function p(i,s){return e(),t("div",null,s[0]||(s[0]=[n('<h2 id="spformer" tabindex="-1"><a class="header-anchor" href="#spformer"><span>SPFormer</span></a></h2><blockquote><p><a href="https://paperswithcode.com/paper/superpoint-transformer-for-3d-scene-instance" target="_blank" rel="noopener noreferrer">Superpoint Transformer for 3D Scene Instance Segmentation | Papers With Code</a></p><p>Superpoint Transformer for 3D Scene Instance Segmentation</p><p>AAAI 2023</p></blockquote><h3 id="摘要" tabindex="-1"><a class="header-anchor" href="#摘要"><span>摘要</span></a></h3><p>大多数现有方法通过扩展用于 3D 对象检测或 3D 语义分割的模型来实现 3D 实例分割。然而，这些非直接方法有两个缺点：</p><p>1）不精确的边界框或不令人满意的语义预测限制了整个 3D 实例分割框架的性能。</p><p>2）现有方法需要耗时的聚合中间步骤。</p><p>为了解决这些问题，本文提出了一种基于 Superpoint Transformer的新颖的端到端3D实例分割方法，命名为SPFormer。它将点云中的潜在特征分组为 Superpoint，并通过查询向量直接预测实例，而不依赖于对象检测或语义分割的结果。该框架的关键步骤是一种带有 Transformer 的新型查询解码器，它可以通过 superpoint 交叉注意机制捕获实例信息并生成实例的 Superpoint 掩码。通过基于 superpoint 掩码的二分匹配，SPFormer 可以实现无需中间聚合步骤的网络训练，从而加速网络。 ScanNetv2 和 S3DIS 基准的大量实验验证了我们的方法简洁而高效。值得注意的是，SPFormer 在 ScanNetv2 隐藏测试集上的 mAP 超过了最先进的方法 4.3%，同时保持了快速的推理速度（每帧 247 毫秒）</p><blockquote><p>提出一个混合框架，避免缺点并同时从两种类型的方法中受益。两阶段端到端的 3D 实例分割方法：SPFormer。 SPFormer 将点云中自下而上的潜在特征分组为超级点，并通过查询向量作为自上而下的管道提出实例。</p></blockquote><h3 id="method" tabindex="-1"><a class="header-anchor" href="#method"><span>Method</span></a></h3><p><img src="https://raw.githubusercontent.com/Overmind7/images/main/img/image-20240104142224787.png" alt="image-20240104142224787"></p><blockquote><p>SPFormer的整体架构，包含两个阶段。在自下而上的分组阶段，稀疏3D U-net从输入点云P中提取逐点特征，然后超点池化层将同质相邻点分组为超点特征S。在自上而下的提议阶段，查询解码器为分为两个分支。实例分支通过 Transformer Decoder 获取查询向量特征 Z’。 mask 分支提取 mask-aware 特征 Smask。最后，预测头生成实例预测，并在训练/推理期间将它们输入到二分匹配或排名中。</p></blockquote><h4 id="query-decoder" tabindex="-1"><a class="header-anchor" href="#query-decoder"><span>Query Decoder</span></a></h4><p>查询解码器由实例分支和掩码分支组成。</p><p>在掩模分支中，一个简单的多层感知器（MLP）旨在提取掩模感知特征<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mrow><mi>m</mi><mi>a</mi><mi>s</mi><mi>k</mi></mrow></msub></mrow><annotation encoding="application/x-tex">S_{mask}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">ma</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。</p><p>实例分支由一系列 Transformer 解码器层组成。通过超点交叉注意力来解码可学习的查询向量。假设有 K 个可学习的查询向量。我们将每个 Transformer 解码器层的查询向量的特征预定义为 D 是嵌入维数</p><p><strong>考虑到 Superpoint 的无序性和数量的不确定性</strong>，引入 Transformer 结构来处理变长输入。Superpoint 的潜在特征和可学习的查询向量被用作变压器解码器的输入。我们修改后的 Transformer 解码器层的详细架构如下图所示：</p><img src="https://raw.githubusercontent.com/Overmind7/images/main/img/image-20240104142507489.png" alt="image-20240104142507489" style="zoom:50%;"><div class="hint-container warning"><p class="hint-container-title">注意</p><p>In addition, because the input is the potential features of superpoints, we empirically remove position embedding.</p><p><em>《Masked-attention mask transformer for universal image segmentation》CVPR2022</em></p></div><p>查询向量在训练前随机初始化，每个点云的实例信息只能通过超点交叉注意力获得，因此，与标准解码器层相比，我们的 Transformer 解码器层交换了自注意力层和交叉注意力层的顺序</p><p>经过线性投影后的 Superpoint 特征<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>S</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><annotation encoding="application/x-tex">S&#39;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span> ，来自上一层的查询向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mrow><mi>l</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">Z_{l-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8917em;vertical-align:-0.2083em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span></span></span></span> 通过 Superpoint 交叉注意机制捕获上下文信息，可以表示为：</p><img src="https://raw.githubusercontent.com/Overmind7/images/main/img/image-20240104143304087.png" alt="image-20240104143304087" style="zoom:50%;"><h5 id="shared-prediction-head" tabindex="-1"><a class="header-anchor" href="#shared-prediction-head"><span>Shared Prediction Head</span></a></h5><img src="https://raw.githubusercontent.com/Overmind7/images/main/img/image-20240104150958286.png" alt="image-20240104150958286" style="zoom:50%;"><p>使用来自实例分支的查询向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>Z</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><annotation encoding="application/x-tex">Z&#39;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span>，我们使用两个独立的 MLP 来预测每个查询向量的分类 ，并使用 IoU 感知分数分别。</p><p>此外，提案的排名深刻地影响实例分割结果，</p><ul><li>而在实践中，由于一对一的匹配方式，大多数提案会被视为背景，这导致提案质量排名的错位。</li><li>因此，我们设计了一个分数分支来估计预测的超点mask和gt-mask的 IoU，以补偿未对准misalignment.。</li><li>mask-aware features <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span>​, directly multiply it by query vectors Z‘ followed a sigmoid function to generate superpoint masks prediction M‘</li></ul>',26)]))}const o=a(m,[["render",p]]),l=JSON.parse('{"path":"/%E6%84%9F%E7%9F%A5/hy41uhht/","title":"SPFormer","lang":"zh-CN","frontmatter":{"title":"SPFormer","createTime":"2025/04/28 15:07:12","permalink":"/感知/hy41uhht/"},"readingTime":{"minutes":3.81,"words":1144},"git":{"updatedTime":1750820984000,"contributors":[{"name":"weiwen","username":"","email":"a1036359215@163.com","commits":1,"avatar":"https://gravatar.com/avatar/cd8e1d2cae5eb43df4bdc241dd3c0611439067bff22550061317525e3b170bab?d=retro"}]},"filePathRelative":"notes/感知/3D/SPFormer.md","headers":[],"categoryList":[{"id":"4358b5","sort":10000,"name":"notes"},{"id":"fcfb7c","sort":10007,"name":"感知"},{"id":"facae4","sort":10011,"name":"3D"}]}');export{o as comp,l as data};
