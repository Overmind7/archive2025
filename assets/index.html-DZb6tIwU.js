import{_ as a,c as t,b as n,o as i}from"./app-IQA0dJD3.js";const r={};function o(s,e){return i(),t("div",null,e[0]||(e[0]=[n('<p><img src="https://raw.githubusercontent.com/Overmind7/images/main/img/image-20230610121650716.png" alt="image-20230610121650716"></p><img src="https://raw.githubusercontent.com/Overmind7/images/main/img/image-20230610121706201.png" alt="image-20230610121706201" style="zoom:50%;"><h2 id="motion-supervision" tabindex="-1"><a class="header-anchor" href="#motion-supervision"><span>Motion Supervision</span></a></h2><p>GAN 生成的中间 feature 具有很强的语义性</p><p>Handle Point</p><p>Target Point</p><blockquote><p>如何监督 GAN 生成图像的点运动之前还没有太多探索。在这项工作中，我们提出了一种不依赖于任何额外神经网络的运动监督损失。关键思想是生成器的中间特征非常有辨别力，因此简单的损失就足以监督运动。具体来说，我们考虑了 StyleGAN2 第 6 个块之后的特征图 F，由于分辨率和判别力之间的良好权衡，它在所有特征中表现最好。我们通过双线性插值调整 F 的大小，使其具有与最终图像相同的分辨率。</p></blockquote><h2 id="point-tracking" tabindex="-1"><a class="header-anchor" href="#point-tracking"><span>Point Tracking</span></a></h2><blockquote><p>The insight is that the discriminative features of GANs well capture dense correspondence and thus tracking can be effectively performed via nearest neighbor search in a feature patch.</p></blockquote><p>更新 handle point</p>',10)]))}const m=a(r,[["render",o]]),p=JSON.parse('{"path":"/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/q4lwpm2b/","title":"DragGan","lang":"zh-CN","frontmatter":{"title":"DragGan","createTime":"2024/08/11 11:31:15","permalink":"/生成模型/q4lwpm2b/"},"readingTime":{"minutes":0.84,"words":253},"git":{"updatedTime":1750820984000,"contributors":[{"name":"weiwen","username":"","email":"a1036359215@163.com","commits":1,"avatar":"https://gravatar.com/avatar/cd8e1d2cae5eb43df4bdc241dd3c0611439067bff22550061317525e3b170bab?d=retro"}]},"filePathRelative":"notes/生成模型/gan/DragGan.md","headers":[],"categoryList":[{"id":"4358b5","sort":10000,"name":"notes"},{"id":"bdd74e","sort":10006,"name":"生成模型"},{"id":"a4328f","sort":10009,"name":"gan"}]}');export{m as comp,p as data};
